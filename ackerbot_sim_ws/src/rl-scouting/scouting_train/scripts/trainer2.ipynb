{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from gym.spaces import Discrete, Tuple\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "from ray.rllib.agents.impala import ImpalaTrainer\n",
    "from ray.rllib.models import ModelCatalog, ModelV2\n",
    "from ray.rllib.models.tf.misc import normc_initializer\n",
    "from ray.rllib.models.utils import get_filter_config\n",
    "from ray.rllib.utils import override\n",
    "from scouting_gym.tasks.scouting_discrete_task import ScoutingDiscreteTask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1612294227.373047, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1612294227.375833, 0.000000]: Start Init ControllersConnection\n",
      "[WARN] [1612294227.376552, 0.000000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 1.0, (84, 84, 4), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Scouting-v0')\n",
    "\n",
    "print(env.observation_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5882353186607361\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa9b40e8760>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(obs.max())\n",
    "plt.imshow(obs[:, :, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa9b403fac0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAARPElEQVR4nO3da4xc5X3H8e/PO7teY7rYBkMclsZcUhKaCENXKZSoTUMckTSCvEkUqlRpmoo3tCVppDS0UqW8qMSLKiIvUCQrIaXNlRBoIhQlkJuqSgnF4RIui7FDHLMYjCEQO7Z317P774tzdmaA3Z0ze2Zn5uzz+0jWnHnmzJznrPe//2fO5fkrIjCztW9dvztgZr3hYDdLhIPdLBEOdrNEONjNEuFgN0tEqWCXdJWkPZL2Sfp0tzplZt2nlZ5nlzQEPAnsBKaA+4FrI+Lx7nXPzLqlVuK9bwP2RcRTAJK+DlwDLBnsIyMbY3R0c4lNmtlypqdfYnb2mBZ7rUywnw083fJ8Cvjj5d4wOrqZiYnrS2zSzJaze/ctS75WJtgX++vxmu8Ekq4DrgNYv35Tic2ZWRllDtBNAee0PB8HDr56pYjYFRETETExMrKxxObMrIwywX4/8EZJ50oaAT4EfKc73TKzblvxMD4i6pL+Dvg+MATcGhGPda1nZtZVZb6zExHfBb7bpb6Y2SryFXRmiXCwmyXCwW6WCAe7WSIc7GaJcLCbJcLBbpYIB7tZIhzsZolwsJslwsFulggHu1kiHOxmiXCwmyXCwW6WCAe7WSIc7GaJaBvskm6V9LykR1vatki6V9Le/NGTwZsNuCKZ/T+Aq17V9mnghxHxRuCH+XMzG2Btgz0i/gf4zauarwFuy5dvA97f5X6ZWZet9Dv7WRHxLED+eGb3umRmq6HU7LJFuCKM2WBYaWY/JGkbQP74/FIruiKM2WBYabB/B/hIvvwR4Nvd6Y6ZrZYip96+BvwUuFDSlKSPATcBOyXtJavPftPqdtPMymr7nT0irl3ipSu73BczW0W+gs4sEQ52s0Q42M0S4WA3S4SD3SwRDnazRDjYzRLhYDdLhIPdLBGrftdbCjQXjeWhEycLvkmNxfrG4cbyutm5VzwCzG3IXo+h5ntqv5vtuJ/1U0c6fk9Zqs8DMDRd7/m2B9n8yNArHnvBmd0sEc7sXdCatWL3o8us2bRudLT55LKLGou1w0cBmNv7VPPzL/nDrK1lBFB0O60jCP7skmLv6aLa0RkA5h+e7Pm2B9nw+NkAzFxwVs+26cxulggHu1kiPIwvYeSZlwHQiZlGW9HDUFFvrrl+/wvN9qO/e826Q8+9mD2ONIfxKznc1bqdnpnOh/G93/JAiyPZ17X1+5sH6Oqvy6ZtmxtdnbB0ZjdLhDN7CXHwEABzx451/t6WzF7ff2DZdevPPtfx5zc31Dwt2G471jtzR45kCwuPwLrTsjka+5bZJZ0j6ceSJiU9JumGvN1VYcwqpMgwvg58MiLeDFwGXC/pIlwVxqxSilSEeTYiHsiXjwKTwNm4KoxZpXR0gE7SduAS4D4KVoWRdJ2k3ZJ2z852/t3WzLqjcLBLOhX4FvDxiDjSbv0FLhJhVoxm62i2ztB08183FQp2ScNkgf6ViLgzby5cFcbM+q/I0XgBXwQmI+KzLS+5KoxZhRQ5oXcF8FfAI5Ieytv+mawKzO15hZgDwAdWp4tmaZib3JstrNLNS0UqwvwvoCVedlUYs4rw5bJmifDlsmYDova6/N72UzY02uaWWHclnNnNEuHMbjYg5s/aAsDJzRvarLkyzuxmiXCwmyXCw/gS4qLzABg63pzWee6xPf3qjlXdnl8BMDK6vtE0u+P8rn28M7tZIpzZS5gfzv5Wqua/mVbe/PR0tjAzs/yKK+TfUrNEONjNEuFhfAlDD+8DYH4FE06a9Zozu1kiHOxmifAw3mxADG3dCoBOaRb99I0wZtYxZ3azARGvPwOA2X7dCCNpVNL/SXo4rwjzmbzdFWHMKqTIMH4GeGdEXAzsAK6SdBmuCGNWKUXmoAtgoY7wcP4vyCrCvCNvvw34CfBPXe+hWSr2ZYU3X3EjzFu3d+3ji84bP5TPLPs8cG9EuCKMWcUUOkAXEXPADkmbgLskvaXoBiJiF7ALYGxsPNqsXikazn58qjV/jK2lmM060bgS8/jxltbtXfv8jk69RcTLZMP1q3BFGLNKKXI0fmue0ZG0AXgX8ASuCGNWKUWG8duA2yQNkf1xuD0i7pb0UxKvCLMwi0jt2Mlm4/2P9Kk3ZssrcjT+F2Rlml/d/iKuCGNWGb5c1iwRvly2hJHD2dFTnWhOI+Rj8bZSQ6dn88ZrgyvCmFkJzuwlxP4pAOY8U411QYxntd76diOMma0NDnazRHgYX0L8wXYAhqZbKsJM7u1Tb8yW58xulghn9hLqp2W3ItZcEcYqwL+lZolwsJslwsFulggHu1kiHOxmiXCwmyXCwW6WCJ9nt9fYd/Nly75+wcd/1qOeWDcVzuz5dNIPSro7f+6KMGYV0skw/gZgsuW5K8KYVUihYbykceAvgH8D/jFvdkWYNabd8H2x9Tykr46imf1m4FPAfEubK8KYVUjbzC7pfcDzEfFzSe/odANruSLMWlA0m7d7vzP84CsyjL8CuFrSe4FRYEzSl8krwkTEs64IYzb42g7jI+LGiBiPiO3Ah4AfRcSHcUUYs0opc1HNTcBOSXuBnflzMxtQHV1UExE/ITvq7oowZhXjy2XNEuFgN0uEg90sEb4RJnGt58dXcs7d59erw5ndLBEOdrNEeBhvDQtDct/PvjY5s5slwpndXsOZe21yZjdLhIPdLBEextuqGjp9CwAnL3pD4ffUjkwDMP/wZJs1rRPO7GaJcLCbJcLD+BJqv50BYN30bKNtrl+dGXAxpOLrjmS/lgtfAZYy95uXWt7kGc/acWY3S4Qzewl6cj8Ac8c8a2431TcOZwtv3b7sesM/O95Ynp+eXsUerQ1F543fDxwlG6XWI2JC0hbgG8B2YD/wwYh4aanPMLP+6mQY/+cRsSMiJvLnrghjViFlhvHJV4TR9nEAaidmGm31p/b3pzMDav532Vec9fsONdrmtm4CoH7a+lKfrfOb5+5rx05kn7n/QKnP7CdNZT+j9S9uaLTNXHBW1z6/aGYP4B5JP5d0Xd7mijBmFVI0s18REQclnQncK+mJohtYyxVhZrduBKB2bKTZ+FSfOjOgYiYb9dSnnmm0DW3MM1fJzL7w8weobcgP6u0v9ZF9Nffib7IFtZym7HVmj4iD+ePzwF3A28grwmR9c0UYs0HXNtglbZT0ewvLwLuBR3FFGLNKKTKMPwu4S9nQogZ8NSK+J+l+4HZJHwMOAB9YvW4OppGHfgk0D0LZazVuhHnz7zfa5lX8arqi6qdmX6X09h3F+nXsZGM5Hnys6/0ZRG2DPSKeAi5epN0VYcwqxJfLmiXCl8uWECfr2WO93ueeDL6o9SavFN3O/Ibmr35t02nLrjv32yP5h6/uyaR1G7OzCxptnqXo5o1VzuxmiXBmtyTNjww1lmd3nL/suiMP7ANg7siRVe0TF2QHMWc3b2iz4so4s5slwsFulggP483aOWcbAEOzZyz++stHAZg7fLjUZnTwBQDWvzzaaJs5d2upz2zlzG6WCGd2szZab7hZTOM2qJKZvTEyaL3C0JndzDrlYDdLhIfxJcxdfAEAQ8eaU0m7ikl6Tp41BoC2vuYWEtbNNq+Bi92P9qxPi3FmN0uEg90sER7Gl7Du5DwAqs/3uSfWTws33yx2m0ysax5ZHx4bK/aBLe/xjTBm1jFn9hL0eDa7pCvC2FJab7mdvfSCPvakYGaXtEnSHZKekDQp6XJJWyTdK2lv/rh5tTtrZitXdBj/OeB7EfEmsimqJnFFGLNKaTuMlzQG/Cnw1wARMQvMSnJFmPHsBonadEtFmF8/3a/umC2rSGY/DzgMfEnSg5K+kE8p7YowZhVSJNhrwKXA5yPiEuAYHQzZI2JXRExExMTIyPI3FFTN7LYxZreNMXfmpsY/s0FVJNingKmIuC9/fgdZ8LsijFmFtA32iHgOeFrShXnTlcDjuCKMWaUUPc/+98BXJI2QlS78KNkfirQrwjyWHYyLo0cbbWuqcqWtKYWCPSIeAiYWeckVYcwqwlfQlRDHjwMwPz3d556Ytedr480S4WA3S4SD3SwRDnazRDjYzRLhYDdLhIPdLBEOdrNEONjNEuFgN0uEg90sEQ52s0T4RpgSNLo+e6zXG20xM7PU6mZ95cxulggHu1kiikwlfSHwjZam84B/Bf4zb98O7Ac+GBEvdb+Lg2v2rdsBqB072Wy8/5H+dMasjSJz0O2JiB0RsQP4I+A4cBcuEmFWKZ0O468EfhkRvwauISsOQf74/m52zMy6q9Oj8R8CvpYvv6JIhKRFi0SsZSOHsokmdaKlIky/OmPWRuHMns8sezXwzU424IowZoOhk8z+HuCBiDiUPz8kaVue1ZcsEhERu4BdAGNj42tqpuU4cBBwyWarhk6+s19LcwgPLhJhVilF67OfAuwE7mxpvgnYKWlv/tpN3e+emXVL0SIRx4HTX9X2Ii4SYVYZvoLOLBG+EaYEDWc/PtX8Y1yKhof73QXLObObJcLBbpYIjz9LmN1xfr+7MPB8ReHgcGY3S4SD3SwRDnazRDjYzRLhYLdK+MFXb+UHX721392oNAe7WSIc7GaJ8Hl2G1iLDdtb2971l3/Ty+5UnjO7WSKc2W3gFD0Q5yzfGWd2s0Q42M0SUWgYL+kTwN8CATwCfBQ4hcQrwlj3lD2HvvB+D+eX1jazSzob+AdgIiLeAgyRzR/vijBmFVJ0GF8DNkiqkWX0g7gijFmltB3GR8Qzkv4dOACcAO6JiHskJV8RxspZjctffYR+aUWG8ZvJsvi5wOuBjZI+XHQDrghjNhiKHKB7F/CriDgMIOlO4E9wRRgrqTXzdivLO5svrch39gPAZZJOkSSyueIncUUYs0op8p39Pkl3AA+QTSn2IFmmPhW4XdLHyP4gfGA1O2pm5SiidyPrsbHxmJi4vmfbs2payZDew/fM7t23cOTIlBZ7zVfQmSXCN8LYwFnI0u0yvLN5Z5zZzRLhYDdLRE8P0Ek6DBwDXujZRlffGXh/Btla2p8i+/KGiNi62As9DXYASbsjYqKnG11F3p/Btpb2p+y+eBhvlggHu1ki+hHsu/qwzdXk/Rlsa2l/Su1Lz7+zm1l/eBhvloieBrukqyTtkbRPUqWmsZJ0jqQfS5qU9JikG/L2LZLulbQ3f9zc7752QtKQpAcl3Z0/r+z+SNok6Q5JT+T/T5dXfH8+kf+uPSrpa5JGy+xPz4Jd0hBwC/Ae4CLgWkkX9Wr7XVAHPhkRbwYuA67P+1/1ufhuILtleUGV9+dzwPci4k3AxWT7Vcn9WZW5HyOiJ/+Ay4Hvtzy/EbixV9tfhf35NrAT2ANsy9u2AXv63bcO9mE8/4V5J3B33lbJ/QHGgF+RH4dqaa/q/pwNPA1sIbuH5W7g3WX2p5fD+IXOL5jK2ypH0nbgEuA+4BVz8QFVmovvZuBTwHxLW1X35zzgMPCl/GvJFyRtpKL7ExHPAAtzPz4L/DYi7qHE/vQy2Be7x7ZypwIknQp8C/h4RBzpd39WStL7gOcj4uf97kuX1IBLgc9HxCVkl2VXYsi+mLJzPy6ml8E+BZzT8nycbErqypA0TBboX4mIO/PmQ/kcfCw3F98AugK4WtJ+4OvAOyV9meruzxQwFRH35c/vIAv+qu5PY+7HiDgJvGLuR+h8f3oZ7PcDb5R0rqQRsoMN3+nh9kvJ59/7IjAZEZ9teamSc/FFxI0RMR4R28n+L34UER+muvvzHPC0pAvzpiuBx6no/rAacz/2+KDDe4EngV8C/9LvgyAd9v3tZF87fgE8lP97L3A62UGuvfnjln73dQX79g6aB+gquz/ADmB3/n/038Dmiu/PZ4AngEeB/wLWl9kfX0FnlghfQWeWCAe7WSIc7GaJcLCbJcLBbpYIB7tZIhzsZolwsJsl4v8Bv+9kAz5EjCQAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = None\n",
    "for _ in range(20):\n",
    "    obs, _, _, _ = env.step(action=1)\n",
    "plt.imshow(obs[:, :, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#print(obs[1])\n",
    "#print(np.rad2deg(obs[1][2]+obs[1][3]))\n",
    "#print(np.rad2deg(obs[1][2]), np.rad2deg(obs[1][3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5707918087715123 1.1475518445038917 0.42323996426762056\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (18,) and (64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-6567a5411d3f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mthetas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinspace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2.44\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2.44\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m18\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mthetas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinspace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m3.14\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3.14\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m18\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpolar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthetas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py\u001B[0m in \u001B[0;36mpolar\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   2204\u001B[0m                                  'that does not have a polar projection.')\n\u001B[1;32m   2205\u001B[0m     \u001B[0max\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgca\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpolar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2206\u001B[0;31m     \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2207\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2208\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_axes.py\u001B[0m in \u001B[0;36mplot\u001B[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m         \"\"\"\n\u001B[1;32m   1664\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcbook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalize_kwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmlines\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_alias_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1665\u001B[0;31m         \u001B[0mlines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_lines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1666\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1667\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_line\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m                 \u001B[0mthis\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m                 \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 225\u001B[0;31m             \u001B[0;32myield\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_plot_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    226\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_next_color\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001B[0m in \u001B[0;36m_plot_args\u001B[0;34m(self, tup, kwargs)\u001B[0m\n\u001B[1;32m    389\u001B[0m             \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindex_of\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 391\u001B[0;31m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_xy_from_xy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    392\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommand\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'plot'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001B[0m in \u001B[0;36m_xy_from_xy\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m    267\u001B[0m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001B[0m\u001B[1;32m    270\u001B[0m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001B[1;32m    271\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (18,) and (64, 3)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "plt.figure()\n",
    "thetas = np.linspace(-2.44, 2.44, 18)\n",
    "thetas = np.linspace(-3.14, 3.14, 18)\n",
    "plt.polar(thetas, obs[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.] [0. 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-e2419b8cd6f9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m \u001B[0mpix_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpix_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;31m#pix_x, pix_y = target_to_pixels(target_x=obs[1][0], target_y=obs[1][1], angle=obs[1][2])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcircle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mpix_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpix_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mradius\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m55\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m55\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthickness\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-e2419b8cd6f9>\u001B[0m in \u001B[0;36mnew\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpol2cart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m2.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeg2rad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrad2deg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrad2deg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget_to_pixels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-e2419b8cd6f9>\u001B[0m in \u001B[0;36mtarget_to_pixels\u001B[0;34m(target_x, target_y, angle)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtarget_to_pixels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mangle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mtarget_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m3.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mtarget_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m3.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;31m#print(target_x, target_y)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def pol2cart(rho, phi):\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def target_to_pixels(target_x, target_y, angle):\n",
    "\n",
    "    target_x = max(min(target_x, 3.), -3.)\n",
    "    target_y = max(min(target_y, 3.), -3.)\n",
    "    #print(target_x, target_y)\n",
    "    #target_x *= math.cos(angle)\n",
    "    #target_y *= math.sin(angle)\n",
    "    #print(target_x, target_y)\n",
    "    pix_x = int((30. / 3.) * target_x)\n",
    "    pix_y = int((30. / 3.) * target_y)\n",
    "    return pix_x + 30, pix_y + 30\n",
    "\n",
    "def new():\n",
    "    (x, y) = pol2cart(obs[1][4]/2., np.deg2rad(np.rad2deg(obs[1][2])-np.rad2deg(obs[1][3])-0.))\n",
    "    print(x, y)\n",
    "    x, y = target_to_pixels(x, y, 0)\n",
    "    print(x, y)\n",
    "    return x, y\n",
    "\n",
    "pix_x, pix_y = new()\n",
    "#pix_x, pix_y = target_to_pixels(target_x=obs[1][0], target_y=obs[1][1], angle=obs[1][2])\n",
    "image = cv2.circle(obs[0], (pix_x, pix_y), radius=2, color=(55, 55, 0), thickness=2)\n",
    "plt.imshow(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7ff00ddc2b80>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#env.reset()\n",
    "for _ in range(10):\n",
    "    obs, reward, done, _ = env.step(1)\n",
    "    #obs, reward, done, _ = env.step([0.6, ])\n",
    "print(obs[0].min())\n",
    "print(obs[0].max())\n",
    "\n",
    "plt.imshow(obs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#print(obs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "\n",
    "class CNNPlusFCConcatModel(TFModelV2):\n",
    "    \"\"\"TFModelV2 concat'ing CNN outputs to flat input(s), followed by FC(s).\n",
    "\n",
    "    Note: This model should be used for complex (Dict or Tuple) observation\n",
    "    spaces that have one or more image components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        # TODO: (sven) Support Dicts as well.\n",
    "        assert isinstance(obs_space.original_space, (Tuple)), \\\n",
    "            \"`obs_space.original_space` must be Tuple!\"\n",
    "\n",
    "        super().__init__(obs_space, action_space, num_outputs, model_config,\n",
    "                         name)\n",
    "\n",
    "        # Build the CNN(s) given obs_space's image components.\n",
    "        self.cnns = {}\n",
    "        concat_size = 0\n",
    "        for i, component in enumerate(obs_space.original_space):\n",
    "            # Image space.\n",
    "            if len(component.shape) == 3:\n",
    "                config = {\n",
    "                    \"conv_filters\": [[16, [3, 3], 2], [32, [3, 3], 2], [64, [3, 3], 2], [128, [5, 16], 1]],\n",
    "                    \"conv_activation\": model_config.get(\"conv_activation\"),\n",
    "                }\n",
    "                cnn = ModelCatalog.get_model_v2(\n",
    "                    component,\n",
    "                    action_space,\n",
    "                    num_outputs=None,\n",
    "                    model_config=config,\n",
    "                    framework=\"tf\",\n",
    "                    name=\"cnn_{}\".format(i))\n",
    "                concat_size += cnn.num_outputs\n",
    "                self.cnns[i] = cnn\n",
    "                self.register_variables(cnn.base_model.variables)\n",
    "            # Discrete inputs -> One-hot encode.\n",
    "            elif isinstance(component, Discrete):\n",
    "                concat_size += component.n\n",
    "            # TODO: (sven) Multidiscrete (see e.g. our auto-LSTM wrappers).\n",
    "            # Everything else (1D Box).\n",
    "            else:\n",
    "                assert len(component.shape) == 1, \\\n",
    "                    \"Only input Box 1D or 3D spaces allowed!\"\n",
    "                concat_size += component.shape[-1]\n",
    "\n",
    "        self.logits_and_value_model = None\n",
    "        self._value_out = None\n",
    "        if num_outputs:\n",
    "            # Action-distribution head.\n",
    "            concat_layer = tf.keras.layers.Input((concat_size, ))\n",
    "            logits_layer = tf.keras.layers.Dense(\n",
    "                num_outputs,\n",
    "                activation=tf.keras.activations.linear,\n",
    "                name=\"logits\")(concat_layer)\n",
    "\n",
    "            # Create the value branch model.\n",
    "            value_layer = tf.keras.layers.Dense(\n",
    "                1,\n",
    "                name=\"value_out\",\n",
    "                activation=None,\n",
    "                kernel_initializer=normc_initializer(0.01))(concat_layer)\n",
    "            self.logits_and_value_model = tf.keras.models.Model(\n",
    "                concat_layer, [logits_layer, value_layer])\n",
    "        else:\n",
    "            self.num_outputs = concat_size\n",
    "        self.register_variables(self.logits_and_value_model.variables)\n",
    "\n",
    "    @override(ModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Push image observations through our CNNs.\n",
    "        outs = []\n",
    "        for i, component in enumerate(input_dict[\"obs\"]):\n",
    "            if i in self.cnns:\n",
    "                cnn_out, _ = self.cnns[i]({\"obs\": component})\n",
    "                outs.append(cnn_out)\n",
    "            else:\n",
    "                outs.append(component)\n",
    "        # Concat all outputs and the non-image inputs.\n",
    "        out = tf.concat(outs, axis=1)\n",
    "        if not self.logits_and_value_model:\n",
    "            return out, []\n",
    "\n",
    "        # Value branch.\n",
    "        logits, values = self.logits_and_value_model(out)\n",
    "        self._value_out = tf.reshape(values, [-1])\n",
    "        return logits, []\n",
    "\n",
    "    @override(ModelV2)\n",
    "    def value_function(self):\n",
    "        return self._value_out\n",
    "\n",
    "ModelCatalog.register_custom_model(\"CNNPlusFCConcatModel\", CNNPlusFCConcatModel)\n",
    "\n",
    "config = {\n",
    "    \"env\": ScoutingDiscreteTask,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 1,  # parallelism\n",
    "    #\"model\": {\n",
    "        #\"vf_share_layers\": True\n",
    "        #\"custom_model\": \"CNNPlusFCConcatModel\",\n",
    "        #\"conv_filters\": [[8, [3, 3], 2], [16, [3, 3], 2], [32, [3, 3], 2], [64, [8, 8], 2], [128, [8, 8], 1]],\n",
    "        #\"fcnet_hiddens\": [256, 256, ],\n",
    "        #\"use_lstm\": True,\n",
    "        #\"lstm_cell_size\": 128,\n",
    "        #\"fcnet_hiddens\": tune.grid_search([[64, 64, ], [128, 128, ], [256, 256, ]])\n",
    "    #}\n",
    "}\n",
    "\n",
    "stop = {\n",
    "    \"episodes_total\": 6500,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-02 20:31:18,927\tINFO services.py:1171 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.178.60',\n 'raylet_ip_address': '192.168.178.60',\n 'redis_address': '192.168.178.60:6379',\n 'object_store_address': '/tmp/ray/session_2021-02-02_20-31-18_352919_1601264/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2021-02-02_20-31-18_352919_1601264/sockets/raylet',\n 'webui_url': '127.0.0.1:8265',\n 'session_dir': '/tmp/ray/session_2021-02-02_20-31-18_352919_1601264',\n 'metrics_export_port': 56601,\n 'node_id': '7317ba541cf82e17a1eb2f3f5f921cc749179925'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train(stop_criteria, config, restorepath):\n",
    "    \"\"\"\n",
    "    Train an RLlib PPO agent using tune until any of the configured stopping criteria is met.\n",
    "    :param stop_criteria: Dict with stopping criteria.\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/execution.html#tune-run\n",
    "    :return: Return the path to the saved agent (checkpoint) and tune's ExperimentAnalysis object\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/analysis.html#experimentanalysis-tune-experimentanalysis\n",
    "    \"\"\"\n",
    "    analysis = ray.tune.run(DQNTrainer, config=config,\n",
    "                            stop=stop_criteria,\n",
    "                            checkpoint_freq=1,\n",
    "                            checkpoint_at_end=True)\n",
    "    # list of lists: one list per checkpoint; each checkpoint list contains 1st the path, 2nd the metric value\n",
    "    checkpoints = analysis.get_trial_checkpoints_paths(trial=analysis.get_best_trial('episode_reward_mean', mode='max'),\n",
    "                                                       metric='episode_reward_mean',\n",
    "                                                       )\n",
    "    # retriev the checkpoint path; we only have a single checkpoint, so take the first one\n",
    "    checkpoint_path = checkpoints[0][0]\n",
    "    return checkpoint_path, analysis\n",
    "\n",
    "def load(checkpoint_path, config):\n",
    "    \"\"\"\n",
    "    Load a trained RLlib agent from the specified path. Call this before testing a trained agent.\n",
    "    :param path: Path pointing to the agent's saved checkpoint (only used for RLlib agents)\n",
    "    \"\"\"\n",
    "    agent = PPOTrainer(config=config)\n",
    "    agent.restore(checkpoint_path)\n",
    "    return agent\n",
    "\n",
    "def test(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 8.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m 2021-02-02 20:31:36,515\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m 2021-02-02 20:31:36,515\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m [ERROR] [1612294299.908487, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m [WARN] [1612294299.911475, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m [WARN] [1612294299.912197, 0.000000]: END Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m 2021-02-02 20:31:45,947\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m 2021-02-02 20:31:47,128\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=1601571)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=1601572)\u001B[0m None\n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-34-39\n",
      "  done: false\n",
      "  episode_len_mean: 31.03125\n",
      "  episode_reward_max: -88.52351807806672\n",
      "  episode_reward_mean: -97.917182579879\n",
      "  episode_reward_min: -105.56173087306331\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 32\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.00851768720895052\n",
      "        mean_q: -0.007747889496386051\n",
      "        mean_td_error: 3.1827824115753174\n",
      "        min_q: -0.01758842170238495\n",
      "        model: {}\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.17108433734941\n",
      "    ram_util_percent: 32.926104417670686\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07537290171071605\n",
      "    mean_env_wait_ms: 132.74150413947626\n",
      "    mean_inference_ms: 1.5769400201239192\n",
      "    mean_raw_obs_processing_ms: 38.225226826243826\n",
      "  time_since_restore: 173.8178436756134\n",
      "  time_this_iter_s: 173.8178436756134\n",
      "  time_total_s: 173.8178436756134\n",
      "  timers:\n",
      "    learn_throughput: 143.478\n",
      "    learn_time_ms: 223.031\n",
      "    update_time_ms: 5.748\n",
      "  timestamp: 1612294479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-37-38\n",
      "  done: false\n",
      "  episode_len_mean: 28.014084507042252\n",
      "  episode_reward_max: -88.52351807806672\n",
      "  episode_reward_mean: -97.96984152460313\n",
      "  episode_reward_min: -105.65614874534452\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 71\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 1504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 3.435734272003174\n",
      "        mean_q: -25.17465591430664\n",
      "        mean_td_error: 14.811376571655273\n",
      "        min_q: -97.14335632324219\n",
      "        model: {}\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 8032\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.97125984251969\n",
      "    ram_util_percent: 33.911417322834644\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0748442182116244\n",
      "    mean_env_wait_ms: 130.64345790812592\n",
      "    mean_inference_ms: 1.5631789085182466\n",
      "    mean_raw_obs_processing_ms: 40.431914019677606\n",
      "  time_since_restore: 352.3080863952637\n",
      "  time_this_iter_s: 178.49024271965027\n",
      "  time_total_s: 352.3080863952637\n",
      "  timers:\n",
      "    learn_throughput: 4131.149\n",
      "    learn_time_ms: 7.746\n",
      "    update_time_ms: 5.28\n",
      "  timestamp: 1612294658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 2\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-40-35\n",
      "  done: false\n",
      "  episode_len_mean: 26.77\n",
      "  episode_reward_max: -88.52351807806672\n",
      "  episode_reward_mean: -97.79814599552637\n",
      "  episode_reward_min: -105.65614874534452\n",
      "  episodes_this_iter: 38\n",
      "  episodes_total: 109\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.5014522075653076\n",
      "        mean_q: -39.40583801269531\n",
      "        mean_td_error: 9.878665924072266\n",
      "        min_q: -122.56241607666016\n",
      "        model: {}\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.27667984189723\n",
      "    ram_util_percent: 34.71185770750989\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0745963245940266\n",
      "    mean_env_wait_ms: 129.25612910389296\n",
      "    mean_inference_ms: 1.5570134892832288\n",
      "    mean_raw_obs_processing_ms: 41.688168302787375\n",
      "  time_since_restore: 529.3606643676758\n",
      "  time_this_iter_s: 177.0525779724121\n",
      "  time_total_s: 529.3606643676758\n",
      "  timers:\n",
      "    learn_throughput: 4057.073\n",
      "    learn_time_ms: 7.887\n",
      "    update_time_ms: 4.34\n",
      "  timestamp: 1612294835\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-43-19\n",
      "  done: false\n",
      "  episode_len_mean: 28.68\n",
      "  episode_reward_max: -92.35562782254712\n",
      "  episode_reward_mean: -98.2194026487186\n",
      "  episode_reward_min: -106.10328820376262\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 135\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 3520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.34747517108917236\n",
      "        mean_q: -36.82304382324219\n",
      "        mean_td_error: 3.482578754425049\n",
      "        min_q: -117.89497375488281\n",
      "        model: {}\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 24032\n",
      "    num_target_updates: 6\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.82649572649572\n",
      "    ram_util_percent: 35.56709401709402\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07430131705435901\n",
      "    mean_env_wait_ms: 127.9121374572676\n",
      "    mean_inference_ms: 1.5498015845199606\n",
      "    mean_raw_obs_processing_ms: 42.05845931175077\n",
      "  time_since_restore: 693.437798500061\n",
      "  time_this_iter_s: 164.07713413238525\n",
      "  time_total_s: 693.437798500061\n",
      "  timers:\n",
      "    learn_throughput: 4022.927\n",
      "    learn_time_ms: 7.954\n",
      "    update_time_ms: 4.879\n",
      "  timestamp: 1612294999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 4\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-46-06\n",
      "  done: false\n",
      "  episode_len_mean: 31.28\n",
      "  episode_reward_max: -87.62093956024589\n",
      "  episode_reward_mean: -98.27318389300521\n",
      "  episode_reward_min: -106.10328820376262\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 162\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 5.748808860778809\n",
      "        mean_q: -42.469642639160156\n",
      "        mean_td_error: 0.8966485261917114\n",
      "        min_q: -122.71966552734375\n",
      "        model: {}\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.1715481171548\n",
      "    ram_util_percent: 36.40125523012552\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07421279804168894\n",
      "    mean_env_wait_ms: 127.45040382201381\n",
      "    mean_inference_ms: 1.5487540605284267\n",
      "    mean_raw_obs_processing_ms: 41.04818035012724\n",
      "  time_since_restore: 860.3925964832306\n",
      "  time_this_iter_s: 166.95479798316956\n",
      "  time_total_s: 860.3925964832306\n",
      "  timers:\n",
      "    learn_throughput: 3841.784\n",
      "    learn_time_ms: 8.329\n",
      "    update_time_ms: 5.092\n",
      "  timestamp: 1612295166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-48-52\n",
      "  done: false\n",
      "  episode_len_mean: 35.61\n",
      "  episode_reward_max: -87.62093956024589\n",
      "  episode_reward_mean: -98.85664354627208\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 186\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 5536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.5758838653564453\n",
      "        mean_q: -36.37276840209961\n",
      "        mean_td_error: 11.440845489501953\n",
      "        min_q: -85.45482635498047\n",
      "        model: {}\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 40032\n",
      "    num_target_updates: 10\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.41772151898734\n",
      "    ram_util_percent: 36.95611814345991\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07415397227022807\n",
      "    mean_env_wait_ms: 127.37812451286587\n",
      "    mean_inference_ms: 1.546435499477478\n",
      "    mean_raw_obs_processing_ms: 39.61329011194742\n",
      "  time_since_restore: 1026.6804783344269\n",
      "  time_this_iter_s: 166.2878818511963\n",
      "  time_total_s: 1026.6804783344269\n",
      "  timers:\n",
      "    learn_throughput: 4129.027\n",
      "    learn_time_ms: 7.75\n",
      "    update_time_ms: 4.184\n",
      "  timestamp: 1612295332\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 6\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 42.17\n",
      "  episode_reward_max: -87.62093956024589\n",
      "  episode_reward_mean: -99.01333434325682\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 202\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 6544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.5180791020393372\n",
      "        mean_q: -28.714536666870117\n",
      "        mean_td_error: 8.281469345092773\n",
      "        min_q: -106.19036102294922\n",
      "        model: {}\n",
      "    num_steps_sampled: 7000\n",
      "    num_steps_trained: 48032\n",
      "    num_target_updates: 12\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.8337962962963\n",
      "    ram_util_percent: 37.766666666666666\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07410286959129389\n",
      "    mean_env_wait_ms: 127.36441602391194\n",
      "    mean_inference_ms: 1.5441296595802136\n",
      "    mean_raw_obs_processing_ms: 38.19151068136754\n",
      "  time_since_restore: 1178.177494764328\n",
      "  time_this_iter_s: 151.49701642990112\n",
      "  time_total_s: 1178.177494764328\n",
      "  timers:\n",
      "    learn_throughput: 4150.875\n",
      "    learn_time_ms: 7.709\n",
      "    update_time_ms: 4.281\n",
      "  timestamp: 1612295484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7000\n",
      "  training_iteration: 7\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-53-48\n",
      "  done: false\n",
      "  episode_len_mean: 49.03\n",
      "  episode_reward_max: 110.97093497444902\n",
      "  episode_reward_mean: -96.81734573006203\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 212\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 7552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.3938066363334656\n",
      "        mean_q: -42.55863952636719\n",
      "        mean_td_error: 1.6537699699401855\n",
      "        min_q: -111.93599700927734\n",
      "        model: {}\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 56032\n",
      "    num_target_updates: 14\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.2757281553398\n",
      "    ram_util_percent: 38.602427184466016\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0740702236387295\n",
      "    mean_env_wait_ms: 127.34146931913419\n",
      "    mean_inference_ms: 1.542500309176536\n",
      "    mean_raw_obs_processing_ms: 37.116224748027626\n",
      "  time_since_restore: 1322.6468243598938\n",
      "  time_this_iter_s: 144.4693295955658\n",
      "  time_total_s: 1322.6468243598938\n",
      "  timers:\n",
      "    learn_throughput: 4054.586\n",
      "    learn_time_ms: 7.892\n",
      "    update_time_ms: 4.317\n",
      "  timestamp: 1612295628\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 8\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-56-14\n",
      "  done: false\n",
      "  episode_len_mean: 53.44\n",
      "  episode_reward_max: 110.97093497444902\n",
      "  episode_reward_mean: -96.57661264673277\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 221\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 8560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1.128231167793274\n",
      "        mean_q: -44.29850769042969\n",
      "        mean_td_error: -1.0923796892166138\n",
      "        min_q: -112.2689437866211\n",
      "        model: {}\n",
      "    num_steps_sampled: 9000\n",
      "    num_steps_trained: 64032\n",
      "    num_target_updates: 16\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.9403846153846\n",
      "    ram_util_percent: 39.41586538461539\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07405011977152202\n",
      "    mean_env_wait_ms: 127.34927361866154\n",
      "    mean_inference_ms: 1.5410257494973394\n",
      "    mean_raw_obs_processing_ms: 36.13640384839384\n",
      "  time_since_restore: 1468.328711271286\n",
      "  time_this_iter_s: 145.6818869113922\n",
      "  time_total_s: 1468.328711271286\n",
      "  timers:\n",
      "    learn_throughput: 4104.267\n",
      "    learn_time_ms: 7.797\n",
      "    update_time_ms: 4.21\n",
      "  timestamp: 1612295774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 9\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_20-58-45\n",
      "  done: false\n",
      "  episode_len_mean: 59.58\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -93.9061410664984\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 235\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 9568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.425229549407959\n",
      "        mean_q: -35.02143096923828\n",
      "        mean_td_error: 2.722527503967285\n",
      "        min_q: -99.028076171875\n",
      "        model: {}\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 72032\n",
      "    num_target_updates: 18\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.26744186046511\n",
      "    ram_util_percent: 40.28558139534883\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07400823671285242\n",
      "    mean_env_wait_ms: 127.35271391017304\n",
      "    mean_inference_ms: 1.5384151215285056\n",
      "    mean_raw_obs_processing_ms: 34.437124607572656\n",
      "  time_since_restore: 1618.7884199619293\n",
      "  time_this_iter_s: 150.4597086906433\n",
      "  time_total_s: 1618.7884199619293\n",
      "  timers:\n",
      "    learn_throughput: 4063.387\n",
      "    learn_time_ms: 7.875\n",
      "    update_time_ms: 5.334\n",
      "  timestamp: 1612295925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 10\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 63.55\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -91.190501089405\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 251\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 10576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: -0.009541988372802734\n",
      "        mean_q: -25.39991569519043\n",
      "        mean_td_error: 8.248689651489258\n",
      "        min_q: -81.18510437011719\n",
      "        model: {}\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 80032\n",
      "    num_target_updates: 20\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.44657534246575\n",
      "    ram_util_percent: 41.102739726027394\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07396642751231985\n",
      "    mean_env_wait_ms: 127.3414335270175\n",
      "    mean_inference_ms: 1.5350409144039672\n",
      "    mean_raw_obs_processing_ms: 32.62238663050377\n",
      "  time_since_restore: 1771.9319767951965\n",
      "  time_this_iter_s: 153.1435568332672\n",
      "  time_total_s: 1771.9319767951965\n",
      "  timers:\n",
      "    learn_throughput: 4090.807\n",
      "    learn_time_ms: 7.822\n",
      "    update_time_ms: 4.53\n",
      "  timestamp: 1612296078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 11\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-03-50\n",
      "  done: false\n",
      "  episode_len_mean: 68.67\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -90.86335058756293\n",
      "  episode_reward_min: -108.50570075325146\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 266\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 11584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: -0.41632533073425293\n",
      "        mean_q: -30.276798248291016\n",
      "        mean_td_error: 8.519355773925781\n",
      "        min_q: -98.78536987304688\n",
      "        model: {}\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 88032\n",
      "    num_target_updates: 22\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.52499999999999\n",
      "    ram_util_percent: 41.97175925925925\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07392752530675663\n",
      "    mean_env_wait_ms: 127.30262534349963\n",
      "    mean_inference_ms: 1.532277240275554\n",
      "    mean_raw_obs_processing_ms: 30.87002514608279\n",
      "  time_since_restore: 1923.488713502884\n",
      "  time_this_iter_s: 151.55673670768738\n",
      "  time_total_s: 1923.488713502884\n",
      "  timers:\n",
      "    learn_throughput: 4230.181\n",
      "    learn_time_ms: 7.565\n",
      "    update_time_ms: 4.309\n",
      "  timestamp: 1612296230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 12\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-06-16\n",
      "  done: false\n",
      "  episode_len_mean: 74.38\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -88.58182073014069\n",
      "  episode_reward_min: -107.74156896441707\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 276\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 12592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: -1.591435194015503\n",
      "        mean_q: -37.25224685668945\n",
      "        mean_td_error: 3.0017971992492676\n",
      "        min_q: -108.58477020263672\n",
      "        model: {}\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 96032\n",
      "    num_target_updates: 24\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.28076923076924\n",
      "    ram_util_percent: 42.790384615384625\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07390348288405915\n",
      "    mean_env_wait_ms: 127.23716188643408\n",
      "    mean_inference_ms: 1.5310962886970045\n",
      "    mean_raw_obs_processing_ms: 29.709794859983795\n",
      "  time_since_restore: 2069.4328830242157\n",
      "  time_this_iter_s: 145.9441695213318\n",
      "  time_total_s: 2069.4328830242157\n",
      "  timers:\n",
      "    learn_throughput: 4196.861\n",
      "    learn_time_ms: 7.625\n",
      "    update_time_ms: 4.164\n",
      "  timestamp: 1612296376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 13\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-08-43\n",
      "  done: false\n",
      "  episode_len_mean: 79.27\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -88.22242736485215\n",
      "  episode_reward_min: -107.74156896441707\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 285\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 13600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.3675459623336792\n",
      "        mean_q: -31.92424964904785\n",
      "        mean_td_error: -0.4281609058380127\n",
      "        min_q: -96.95293426513672\n",
      "        model: {}\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 104032\n",
      "    num_target_updates: 26\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.93744075829385\n",
      "    ram_util_percent: 43.61563981042655\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07388436306717315\n",
      "    mean_env_wait_ms: 127.19473344564605\n",
      "    mean_inference_ms: 1.5302816919119175\n",
      "    mean_raw_obs_processing_ms: 28.573493397177252\n",
      "  time_since_restore: 2217.2298357486725\n",
      "  time_this_iter_s: 147.7969527244568\n",
      "  time_total_s: 2217.2298357486725\n",
      "  timers:\n",
      "    learn_throughput: 4070.065\n",
      "    learn_time_ms: 7.862\n",
      "    update_time_ms: 4.372\n",
      "  timestamp: 1612296523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 14\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 80.18\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -88.07553295720442\n",
      "  episode_reward_min: -107.74156896441707\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 301\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 14608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.67427659034729\n",
      "        mean_q: -29.91925048828125\n",
      "        mean_td_error: 15.374856948852539\n",
      "        min_q: -103.49503326416016\n",
      "        model: {}\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 112032\n",
      "    num_target_updates: 28\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.54590909090908\n",
      "    ram_util_percent: 44.43\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0738665974112532\n",
      "    mean_env_wait_ms: 127.17008151512124\n",
      "    mean_inference_ms: 1.5300876573229727\n",
      "    mean_raw_obs_processing_ms: 26.88179558830141\n",
      "  time_since_restore: 2371.212038755417\n",
      "  time_this_iter_s: 153.98220300674438\n",
      "  time_total_s: 2371.212038755417\n",
      "  timers:\n",
      "    learn_throughput: 4096.5\n",
      "    learn_time_ms: 7.812\n",
      "    update_time_ms: 4.992\n",
      "  timestamp: 1612296678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 15\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 79.78\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -89.59281750611764\n",
      "  episode_reward_min: -104.23027298358419\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 311\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 15616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 2.5156872272491455\n",
      "        mean_q: -16.794540405273438\n",
      "        mean_td_error: 15.402572631835938\n",
      "        min_q: -57.944236755371094\n",
      "        model: {}\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 120032\n",
      "    num_target_updates: 30\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.59095238095237\n",
      "    ram_util_percent: 45.290952380952376\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07387238520620852\n",
      "    mean_env_wait_ms: 127.18160539863577\n",
      "    mean_inference_ms: 1.5304139675051096\n",
      "    mean_raw_obs_processing_ms: 26.01806162100995\n",
      "  time_since_restore: 2518.1758522987366\n",
      "  time_this_iter_s: 146.9638135433197\n",
      "  time_total_s: 2518.1758522987366\n",
      "  timers:\n",
      "    learn_throughput: 4003.798\n",
      "    learn_time_ms: 7.992\n",
      "    update_time_ms: 4.985\n",
      "  timestamp: 1612296825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 16\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-16-15\n",
      "  done: false\n",
      "  episode_len_mean: 77.62\n",
      "  episode_reward_max: 116.38576072878982\n",
      "  episode_reward_mean: -87.27978609401023\n",
      "  episode_reward_min: -104.23027298358419\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 324\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 16624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 3.675370216369629\n",
      "        mean_q: -11.488741874694824\n",
      "        mean_td_error: 9.63917350769043\n",
      "        min_q: -82.36243438720703\n",
      "        model: {}\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 128032\n",
      "    num_target_updates: 32\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.8553488372093\n",
      "    ram_util_percent: 46.122790697674425\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07388922073903308\n",
      "    mean_env_wait_ms: 127.19693955405455\n",
      "    mean_inference_ms: 1.5314992403691756\n",
      "    mean_raw_obs_processing_ms: 25.187556079311342\n",
      "  time_since_restore: 2668.643547296524\n",
      "  time_this_iter_s: 150.46769499778748\n",
      "  time_total_s: 2668.643547296524\n",
      "  timers:\n",
      "    learn_throughput: 4148.874\n",
      "    learn_time_ms: 7.713\n",
      "    update_time_ms: 4.301\n",
      "  timestamp: 1612296975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 17\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 79.74\n",
      "  episode_reward_max: 115.87545107120766\n",
      "  episode_reward_mean: -89.7010747341473\n",
      "  episode_reward_min: -105.43863500471087\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 335\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 17632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1.668647050857544\n",
      "        mean_q: -33.77416229248047\n",
      "        mean_td_error: 1.8336281776428223\n",
      "        min_q: -102.09891510009766\n",
      "        model: {}\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 136032\n",
      "    num_target_updates: 34\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.65186915887851\n",
      "    ram_util_percent: 46.991588785046716\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07391011317642993\n",
      "    mean_env_wait_ms: 127.22860923758493\n",
      "    mean_inference_ms: 1.53294056607997\n",
      "    mean_raw_obs_processing_ms: 24.551529657389192\n",
      "  time_since_restore: 2818.6564469337463\n",
      "  time_this_iter_s: 150.0128996372223\n",
      "  time_total_s: 2818.6564469337463\n",
      "  timers:\n",
      "    learn_throughput: 4252.551\n",
      "    learn_time_ms: 7.525\n",
      "    update_time_ms: 4.321\n",
      "  timestamp: 1612297125\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 18\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-21-18\n",
      "  done: false\n",
      "  episode_len_mean: 80.25\n",
      "  episode_reward_max: 115.87545107120766\n",
      "  episode_reward_mean: -91.8499840989681\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 350\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 18640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 2.983940839767456\n",
      "        mean_q: -13.3472261428833\n",
      "        mean_td_error: 7.21922492980957\n",
      "        min_q: -92.21196746826172\n",
      "        model: {}\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 144032\n",
      "    num_target_updates: 36\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.01284403669725\n",
      "    ram_util_percent: 47.798623853211005\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07394567115611358\n",
      "    mean_env_wait_ms: 127.2735239788003\n",
      "    mean_inference_ms: 1.53532095800528\n",
      "    mean_raw_obs_processing_ms: 23.773790808823968\n",
      "  time_since_restore: 2971.3207700252533\n",
      "  time_this_iter_s: 152.66432309150696\n",
      "  time_total_s: 2971.3207700252533\n",
      "  timers:\n",
      "    learn_throughput: 4011.397\n",
      "    learn_time_ms: 7.977\n",
      "    update_time_ms: 4.31\n",
      "  timestamp: 1612297278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 19\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-23-51\n",
      "  done: false\n",
      "  episode_len_mean: 80.43\n",
      "  episode_reward_max: 115.87545107120766\n",
      "  episode_reward_mean: -92.00983304028254\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 363\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 19648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 2.5366013050079346\n",
      "        mean_q: -18.648033142089844\n",
      "        mean_td_error: 1.4512555599212646\n",
      "        min_q: -93.7279281616211\n",
      "        model: {}\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 152032\n",
      "    num_target_updates: 38\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.61467889908256\n",
      "    ram_util_percent: 48.67431192660551\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07398220049758134\n",
      "    mean_env_wait_ms: 127.33437699503767\n",
      "    mean_inference_ms: 1.5374963886583857\n",
      "    mean_raw_obs_processing_ms: 23.150905327671502\n",
      "  time_since_restore: 3124.005049943924\n",
      "  time_this_iter_s: 152.68427991867065\n",
      "  time_total_s: 3124.005049943924\n",
      "  timers:\n",
      "    learn_throughput: 4162.564\n",
      "    learn_time_ms: 7.688\n",
      "    update_time_ms: 4.673\n",
      "  timestamp: 1612297431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 20\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-26-25\n",
      "  done: false\n",
      "  episode_len_mean: 77.98\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -94.63937462865604\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 378\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 20656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: -0.8996767401695251\n",
      "        mean_q: -25.085176467895508\n",
      "        mean_td_error: 1.8907183408737183\n",
      "        min_q: -116.07850646972656\n",
      "        model: {}\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 160032\n",
      "    num_target_updates: 40\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.04818181818183\n",
      "    ram_util_percent: 49.48999999999999\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0740265777920913\n",
      "    mean_env_wait_ms: 127.41471107117573\n",
      "    mean_inference_ms: 1.5398739378643753\n",
      "    mean_raw_obs_processing_ms: 22.56868739339463\n",
      "  time_since_restore: 3278.319597005844\n",
      "  time_this_iter_s: 154.31454706192017\n",
      "  time_total_s: 3278.319597005844\n",
      "  timers:\n",
      "    learn_throughput: 4114.269\n",
      "    learn_time_ms: 7.778\n",
      "    update_time_ms: 4.644\n",
      "  timestamp: 1612297585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 21\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-28-53\n",
      "  done: false\n",
      "  episode_len_mean: 78.84\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -92.49584030299528\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 386\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 21664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 3.5613608360290527\n",
      "        mean_q: -29.383403778076172\n",
      "        mean_td_error: 3.30418062210083\n",
      "        min_q: -97.81600952148438\n",
      "        model: {}\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 168032\n",
      "    num_target_updates: 42\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.72999999999999\n",
      "    ram_util_percent: 50.36904761904762\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07405081384413448\n",
      "    mean_env_wait_ms: 127.45462235693921\n",
      "    mean_inference_ms: 1.5410230988326767\n",
      "    mean_raw_obs_processing_ms: 22.307569679540666\n",
      "  time_since_restore: 3425.731426000595\n",
      "  time_this_iter_s: 147.41182899475098\n",
      "  time_total_s: 3425.731426000595\n",
      "  timers:\n",
      "    learn_throughput: 3832.033\n",
      "    learn_time_ms: 8.351\n",
      "    update_time_ms: 5.008\n",
      "  timestamp: 1612297733\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 22\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-31-17\n",
      "  done: false\n",
      "  episode_len_mean: 85.32\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -92.52597085862271\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 394\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 22672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1.820525884628296\n",
      "        mean_q: -34.12432861328125\n",
      "        mean_td_error: 3.6044373512268066\n",
      "        min_q: -123.68091583251953\n",
      "        model: {}\n",
      "    num_steps_sampled: 23000\n",
      "    num_steps_trained: 176032\n",
      "    num_target_updates: 44\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.8490291262136\n",
      "    ram_util_percent: 50.277669902912635\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07406535475242099\n",
      "    mean_env_wait_ms: 127.49278809844918\n",
      "    mean_inference_ms: 1.541701644130295\n",
      "    mean_raw_obs_processing_ms: 22.030491952344438\n",
      "  time_since_restore: 3569.9569175243378\n",
      "  time_this_iter_s: 144.22549152374268\n",
      "  time_total_s: 3569.9569175243378\n",
      "  timers:\n",
      "    learn_throughput: 4111.043\n",
      "    learn_time_ms: 7.784\n",
      "    update_time_ms: 4.115\n",
      "  timestamp: 1612297877\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23000\n",
      "  training_iteration: 23\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-33-39\n",
      "  done: false\n",
      "  episode_len_mean: 88.07\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -92.35897073638935\n",
      "  episode_reward_min: -107.16191809174742\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 403\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 23680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 6.745516777038574\n",
      "        mean_q: -23.510635375976562\n",
      "        mean_td_error: 7.227596282958984\n",
      "        min_q: -76.74942016601562\n",
      "        model: {}\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 184032\n",
      "    num_target_updates: 46\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.62647058823529\n",
      "    ram_util_percent: 50.992156862745084\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07406009932023633\n",
      "    mean_env_wait_ms: 127.52415721601906\n",
      "    mean_inference_ms: 1.5420758014409932\n",
      "    mean_raw_obs_processing_ms: 21.697369162737253\n",
      "  time_since_restore: 3712.3548328876495\n",
      "  time_this_iter_s: 142.39791536331177\n",
      "  time_total_s: 3712.3548328876495\n",
      "  timers:\n",
      "    learn_throughput: 4069.473\n",
      "    learn_time_ms: 7.863\n",
      "    update_time_ms: 4.179\n",
      "  timestamp: 1612298019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 24\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-36-00\n",
      "  done: false\n",
      "  episode_len_mean: 91.51\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -90.5315413686932\n",
      "  episode_reward_min: -109.60100588029127\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 410\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 24688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 1.3786615133285522\n",
      "        mean_q: -28.956336975097656\n",
      "        mean_td_error: 4.983325481414795\n",
      "        min_q: -99.96204376220703\n",
      "        model: {}\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 192032\n",
      "    num_target_updates: 48\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.40299999999999\n",
      "    ram_util_percent: 51.746\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07403767936545025\n",
      "    mean_env_wait_ms: 127.54073252861967\n",
      "    mean_inference_ms: 1.542090738061515\n",
      "    mean_raw_obs_processing_ms: 21.446302337148644\n",
      "  time_since_restore: 3853.011396408081\n",
      "  time_this_iter_s: 140.65656352043152\n",
      "  time_total_s: 3853.011396408081\n",
      "  timers:\n",
      "    learn_throughput: 4178.192\n",
      "    learn_time_ms: 7.659\n",
      "    update_time_ms: 4.141\n",
      "  timestamp: 1612298160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 25\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-38-21\n",
      "  done: false\n",
      "  episode_len_mean: 94.87\n",
      "  episode_reward_max: 113.8208252426503\n",
      "  episode_reward_mean: -88.44355941223981\n",
      "  episode_reward_min: -109.60100588029127\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 417\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 25696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.5272555351257324\n",
      "        mean_q: -26.511009216308594\n",
      "        mean_td_error: 1.3748067617416382\n",
      "        min_q: -117.03326416015625\n",
      "        model: {}\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 200032\n",
      "    num_target_updates: 50\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.28811881188119\n",
      "    ram_util_percent: 52.52029702970297\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07400369136795064\n",
      "    mean_env_wait_ms: 127.55188782460893\n",
      "    mean_inference_ms: 1.5418263196305917\n",
      "    mean_raw_obs_processing_ms: 21.192122202491365\n",
      "  time_since_restore: 3994.4237220287323\n",
      "  time_this_iter_s: 141.41232562065125\n",
      "  time_total_s: 3994.4237220287323\n",
      "  timers:\n",
      "    learn_throughput: 4200.565\n",
      "    learn_time_ms: 7.618\n",
      "    update_time_ms: 3.997\n",
      "  timestamp: 1612298301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 26\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-40-44\n",
      "  done: false\n",
      "  episode_len_mean: 98.33\n",
      "  episode_reward_max: 112.6215865463204\n",
      "  episode_reward_mean: -88.50168669129329\n",
      "  episode_reward_min: -109.60100588029127\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 426\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 26704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 3.37096905708313\n",
      "        mean_q: -17.543209075927734\n",
      "        mean_td_error: 3.3715429306030273\n",
      "        min_q: -75.43719482421875\n",
      "        model: {}\n",
      "    num_steps_sampled: 27000\n",
      "    num_steps_trained: 208032\n",
      "    num_target_updates: 52\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.47931034482758\n",
      "    ram_util_percent: 53.26551724137932\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07394383667100543\n",
      "    mean_env_wait_ms: 127.55377708729307\n",
      "    mean_inference_ms: 1.541146446583374\n",
      "    mean_raw_obs_processing_ms: 20.853981702022466\n",
      "  time_since_restore: 4136.694530963898\n",
      "  time_this_iter_s: 142.2708089351654\n",
      "  time_total_s: 4136.694530963898\n",
      "  timers:\n",
      "    learn_throughput: 4019.674\n",
      "    learn_time_ms: 7.961\n",
      "    update_time_ms: 4.092\n",
      "  timestamp: 1612298444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 27\n",
      "  trial_id: 41ce7_00000\n",
      "  \n",
      "Result for DQN_ScoutingDiscreteTask_41ce7_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-02_21-43-05\n",
      "  done: false\n",
      "  episode_len_mean: 101.39\n",
      "  episode_reward_max: 114.29715931506954\n",
      "  episode_reward_mean: -86.50608863738816\n",
      "  episode_reward_min: -109.60100588029127\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 433\n",
      "  experiment_id: d183243bf0504b0baa4fa5f7a16a1149\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    last_target_update_ts: 27712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 4.542227745056152\n",
      "        mean_q: -28.451385498046875\n",
      "        mean_td_error: 10.344189643859863\n",
      "        min_q: -101.23320007324219\n",
      "        model: {}\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 216032\n",
      "    num_target_updates: 54\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.5905472636816\n",
      "    ram_util_percent: 54.05572139303482\n",
      "  pid: 1601571\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07388894595030081\n",
      "    mean_env_wait_ms: 127.54304266684908\n",
      "    mean_inference_ms: 1.540296656241269\n",
      "    mean_raw_obs_processing_ms: 20.594297183804645\n",
      "  time_since_restore: 4277.396080255508\n",
      "  time_this_iter_s: 140.70154929161072\n",
      "  time_total_s: 4277.396080255508\n",
      "  timers:\n",
      "    learn_throughput: 4231.115\n",
      "    learn_time_ms: 7.563\n",
      "    update_time_ms: 4.192\n",
      "  timestamp: 1612298585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 28\n",
      "  trial_id: 41ce7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         173.818</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">-97.9172</td><td style=\"text-align: right;\">            -88.5235</td><td style=\"text-align: right;\">            -105.562</td><td style=\"text-align: right;\">           31.0312</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 10.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         352.308</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">-97.9698</td><td style=\"text-align: right;\">            -88.5235</td><td style=\"text-align: right;\">            -105.656</td><td style=\"text-align: right;\">           28.0141</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         529.361</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">-97.7981</td><td style=\"text-align: right;\">            -88.5235</td><td style=\"text-align: right;\">            -105.656</td><td style=\"text-align: right;\">             26.77</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         693.438</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-98.2194</td><td style=\"text-align: right;\">            -92.3556</td><td style=\"text-align: right;\">            -106.103</td><td style=\"text-align: right;\">             28.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         860.393</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">-98.2732</td><td style=\"text-align: right;\">            -87.6209</td><td style=\"text-align: right;\">            -106.103</td><td style=\"text-align: right;\">             31.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         1026.68</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">-98.8566</td><td style=\"text-align: right;\">            -87.6209</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             35.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         1178.18</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">-99.0133</td><td style=\"text-align: right;\">            -87.6209</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             42.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         1322.65</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-96.8173</td><td style=\"text-align: right;\">             110.971</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             49.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         1468.33</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">-96.5766</td><td style=\"text-align: right;\">             110.971</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             53.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         1618.79</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\">-93.9061</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             59.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1771.93</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">-91.1905</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             63.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         1923.49</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-90.8634</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -108.506</td><td style=\"text-align: right;\">             68.67</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         2069.43</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">-88.5818</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -107.742</td><td style=\"text-align: right;\">             74.38</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         2217.23</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">-88.2224</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -107.742</td><td style=\"text-align: right;\">             79.27</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         2371.21</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">-88.0755</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">            -107.742</td><td style=\"text-align: right;\">             80.18</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         2518.18</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-89.5928</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">             -104.23</td><td style=\"text-align: right;\">             79.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         2668.64</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">-87.2798</td><td style=\"text-align: right;\">             116.386</td><td style=\"text-align: right;\">             -104.23</td><td style=\"text-align: right;\">             77.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         2818.66</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">-89.7011</td><td style=\"text-align: right;\">             115.875</td><td style=\"text-align: right;\">            -105.439</td><td style=\"text-align: right;\">             79.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 15.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         2971.32</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  -91.85</td><td style=\"text-align: right;\">             115.875</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             80.25</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 15.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         3124.01</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-92.0098</td><td style=\"text-align: right;\">             115.875</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             80.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 15.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         3278.32</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">-94.6394</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             77.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 15.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         3425.73</td><td style=\"text-align: right;\">22000</td><td style=\"text-align: right;\">-92.4958</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             78.84</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 15.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         3569.96</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\"> -92.526</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             85.32</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 16.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         3712.35</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\"> -92.359</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -107.162</td><td style=\"text-align: right;\">             88.07</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 16.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         3853.01</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">-90.5315</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -109.601</td><td style=\"text-align: right;\">             91.51</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 16.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         3994.42</td><td style=\"text-align: right;\">26000</td><td style=\"text-align: right;\">-88.4436</td><td style=\"text-align: right;\">             113.821</td><td style=\"text-align: right;\">            -109.601</td><td style=\"text-align: right;\">             94.87</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 16.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         4136.69</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">-88.5017</td><td style=\"text-align: right;\">             112.622</td><td style=\"text-align: right;\">            -109.601</td><td style=\"text-align: right;\">             98.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 17.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/14.45 GiB heap, 0.0/4.98 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/DQN_2021-02-02_20-31-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_ScoutingDiscreteTask_41ce7_00000</td><td>RUNNING </td><td>192.168.178.60:1601571</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">          4277.4</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-86.5061</td><td style=\"text-align: right;\">             114.297</td><td style=\"text-align: right;\">            -109.601</td><td style=\"text-align: right;\">            101.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path, analysis = train(stop_criteria=stop,\n",
    "                                  config=config,\n",
    "                                  restorepath='/home/dschori/ray_results/'\n",
    "                                              'PPO_2021-02-01_20-26-06/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_5450b_00000_0_2021-02-01_20-26-06/' \\\n",
    "                  'checkpoint_89/checkpoint-89')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-01-29_19-24-46/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_43f0f_00000_0_2021-01-29_19-24-46/' \\\n",
    "                  'checkpoint_272/checkpoint-272'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m non-resource variables are not supported in the long term\n",
      "2021-01-29 08:46:24,136\tWARNING worker.py:1034 -- Failed to unpickle actor class 'RolloutWorker' for actor ID 88866c7d01000000. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/function_manager.py\", line 496, in _load_actor_class_from_gcs\n",
      "    logger.exception(\"Failed to load actor class %s.\", class_name)\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/__init__.py\", line 5, in <module>\n",
      "    from ray.rllib.env.base_env import BaseEnv\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/__init__.py\", line 1, in <module>\n",
      "    from ray.rllib.env.base_env import BaseEnv\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/base_env.py\", line 3, in <module>\n",
      "    from ray.rllib.env.external_env import ExternalEnv\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/external_env.py\", line 7, in <module>\n",
      "    from ray.rllib.utils.annotations import PublicAPI\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/utils/__init__.py\", line 18, in <module>\n",
      "    from ray.tune.utils import merge_dicts, deep_update\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/__init__.py\", line 2, in <module>\n",
      "    from ray.tune.tune import run_experiments, run\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/tune.py\", line 10, in <module>\n",
      "    from ray.tune.ray_trial_executor import RayTrialExecutor\n",
      "  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 11, in <module>\n",
      "    from ray.exceptions import RayTimeoutError\n",
      "ImportError: cannot import name 'RayTimeoutError' from 'ray.exceptions' (/home/dschori/.local/lib/python3.8/site-packages/ray/exceptions.py)\n",
      "\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m 2021-01-29 08:46:24,130\tERROR function_manager.py:498 -- Failed to load actor class RolloutWorker.\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m Traceback (most recent call last):\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/function_manager.py\", line 496, in _load_actor_class_from_gcs\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     logger.exception(\"Failed to load actor class %s.\", class_name)\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/__init__.py\", line 5, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.rllib.env.base_env import BaseEnv\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/__init__.py\", line 1, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.rllib.env.base_env import BaseEnv\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/base_env.py\", line 3, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.rllib.env.external_env import ExternalEnv\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/external_env.py\", line 7, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.rllib.utils.annotations import PublicAPI\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/utils/__init__.py\", line 18, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.tune.utils import merge_dicts, deep_update\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/__init__.py\", line 2, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.tune.tune import run_experiments, run\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/tune.py\", line 10, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.tune.ray_trial_executor import RayTrialExecutor\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m   File \"/home/dschori/.local/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 11, in <module>\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m     from ray.exceptions import RayTimeoutError\n",
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m ImportError: cannot import name 'RayTimeoutError' from 'ray.exceptions' (/home/dschori/.local/lib/python3.8/site-packages/ray/exceptions.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=2023600)\u001B[0m None\n"
     ]
    },
    {
     "ename": "RayTaskError(AssertionError)",
     "evalue": "\u001B[36mray::RolloutWorker.foreach_policy()\u001B[39m (pid=2023600, ip=192.168.178.60)\n  File \"python/ray/_raylet.pyx\", line 422, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 442, in ray._raylet.execute_task\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 310, in deserialize_objects\n    except DeserializationError:\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 248, in _deserialize_object\n    # Check if the object should be returned as raw bytes.\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 226, in _deserialize_msgpack_data\n    python_objects = []\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 216, in _deserialize_pickle5_data\n    obj = pickle.loads(in_band)\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/__init__.py\", line 5, in <module>\n    from ray.rllib.env.base_env import BaseEnv\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/__init__.py\", line 11, in <module>\n    from ray.rllib.env.policy_client import PolicyClient\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/policy_client.py\", line 13, in <module>\n    from ray.rllib.evaluation.rollout_worker import RolloutWorker\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/__init__.py\", line 2, in <module>\n    from ray.rllib.evaluation.rollout_worker import RolloutWorker\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 73, in <module>\n    class RolloutWorker(ParallelIteratorWorker):\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 607, in RolloutWorker\n    @ray.method(num_return_vals=2)\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/actor.py\", line 45, in method\nAssertionError",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRayTaskError(AssertionError)\u001B[0m              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-7650ad861f1f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0magent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-13-8712695bee7b>\u001B[0m in \u001B[0;36mload\u001B[0;34m(checkpoint_path, config)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mPath\u001B[0m \u001B[0mpointing\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthe\u001B[0m \u001B[0magent\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0msaved\u001B[0m \u001B[0mcheckpoint\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0monly\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mRLlib\u001B[0m \u001B[0magents\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \"\"\"\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0magent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPPOTrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m     \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrestore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, config, env, logger_creator)\u001B[0m\n\u001B[1;32m    104\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_exec_impl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexecution_plan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mafter_init\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m                 \u001B[0mafter_init\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0moverride\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTrainer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, config, env, logger_creator)\u001B[0m\n\u001B[1;32m    463\u001B[0m             \u001B[0mtimestr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoday\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"%Y-%m-%d_%H-%M-%S\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m             logdir_prefix = \"{}_{}_{}\".format(self._name, self._env_id,\n\u001B[0;32m--> 465\u001B[0;31m                                               timestr)\n\u001B[0m\u001B[1;32m    466\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    467\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mdefault_logger_creator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/tune/trainable.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, config, logger_creator)\u001B[0m\n\u001B[1;32m     94\u001B[0m             \u001B[0mFileNotFoundError\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mdirectory\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mfound\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \"\"\"\n\u001B[0;32m---> 96\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Path does not exist\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001B[0m in \u001B[0;36msetup\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m    627\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"callbacks\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    628\u001B[0m         \u001B[0mlog_level\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"log_level\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 629\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mlog_level\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"WARN\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ERROR\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    630\u001B[0m             logger.info(\"Current log_level is {}. For more information, \"\n\u001B[1;32m    631\u001B[0m                         \u001B[0;34m\"set 'log_level': 'INFO' / 'DEBUG' or use the -v and \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001B[0m in \u001B[0;36m_init\u001B[0;34m(self, config, env_creator)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m         \u001B[0mArguments\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m             \u001B[0moverrides\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0muse\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mto\u001B[0m \u001B[0moverride\u001B[0m \u001B[0many\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0marguments\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m                 \u001B[0moriginally\u001B[0m \u001B[0mpassed\u001B[0m \u001B[0mto\u001B[0m \u001B[0mbuild_trainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mpolicy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m         \"\"\"\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001B[0m in \u001B[0;36m_make_workers\u001B[0;34m(self, env_creator, validate_env, policy_class, config, num_workers)\u001B[0m\n\u001B[1;32m    698\u001B[0m                 \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m             \u001B[0mpolicy\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mclass\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mThe\u001B[0m \u001B[0mPolicy\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mto\u001B[0m \u001B[0muse\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mcreating\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mpolicies\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 700\u001B[0;31m                 \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mworkers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    701\u001B[0m             \u001B[0mconfig\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mThe\u001B[0m \u001B[0mTrainer\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m             \u001B[0mnum_workers\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mNumber\u001B[0m \u001B[0mof\u001B[0m \u001B[0mremote\u001B[0m \u001B[0mrollout\u001B[0m \u001B[0mworkers\u001B[0m \u001B[0mto\u001B[0m \u001B[0mcreate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, logdir, _setup)\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mremote_workers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"ActorHandle\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0;34m\"\"\"Return a list of remote rollout workers.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_remote_workers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msync_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/worker.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(object_refs, timeout)\u001B[0m\n\u001B[1;32m   1377\u001B[0m             \u001B[0mworker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprinter_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1378\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mworker\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"logger_thread\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1379\u001B[0;31m             \u001B[0mworker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogger_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1380\u001B[0m         \u001B[0mworker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mthreads_stopped\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1381\u001B[0m         \u001B[0mworker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_session_index\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRayTaskError(AssertionError)\u001B[0m: \u001B[36mray::RolloutWorker.foreach_policy()\u001B[39m (pid=2023600, ip=192.168.178.60)\n  File \"python/ray/_raylet.pyx\", line 422, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 442, in ray._raylet.execute_task\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 310, in deserialize_objects\n    except DeserializationError:\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 248, in _deserialize_object\n    # Check if the object should be returned as raw bytes.\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 226, in _deserialize_msgpack_data\n    python_objects = []\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/serialization.py\", line 216, in _deserialize_pickle5_data\n    obj = pickle.loads(in_band)\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/__init__.py\", line 5, in <module>\n    from ray.rllib.env.base_env import BaseEnv\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/__init__.py\", line 11, in <module>\n    from ray.rllib.env.policy_client import PolicyClient\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/env/policy_client.py\", line 13, in <module>\n    from ray.rllib.evaluation.rollout_worker import RolloutWorker\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/__init__.py\", line 2, in <module>\n    from ray.rllib.evaluation.rollout_worker import RolloutWorker\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 73, in <module>\n    class RolloutWorker(ParallelIteratorWorker):\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 607, in RolloutWorker\n    @ray.method(num_return_vals=2)\n  File \"/home/dschori/.local/lib/python3.8/site-packages/ray/actor.py\", line 45, in method\nAssertionError"
     ]
    }
   ],
   "source": [
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Observation for a Box/MultiBinary/MultiDiscrete space should be an np.array, not a Python list.', (array([3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99,\n       3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99], dtype=float32), array([9.99      , 0.22813019]), array([-1.,  1.])))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\u001B[0m in \u001B[0;36mcheck_shape\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m                 \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_obs_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontains\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobservation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m                     raise ValueError(\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/gym/spaces/box.py\u001B[0m in \u001B[0;36mcontains\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    127\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Promote list to array for contains check\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 128\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlow\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhigh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-d77bb593b827>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mepisode_reward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0magent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mepisode_reward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-5-8712695bee7b>\u001B[0m in \u001B[0;36mtest\u001B[0;34m(agent, env)\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0mobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m         \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     40\u001B[0m         \u001B[0mobs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \u001B[0mepisode_reward\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001B[0m in \u001B[0;36mcompute_action\u001B[0;34m(self, observation, state, prev_action, prev_reward, info, policy_id, full_fetch, explore)\u001B[0m\n\u001B[1;32m    816\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    817\u001B[0m             \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 818\u001B[0;31m         preprocessed = self.workers.local_worker().preprocessors[\n\u001B[0m\u001B[1;32m    819\u001B[0m             policy_id].transform(observation)\n\u001B[1;32m    820\u001B[0m         filtered_obs = self.workers.local_worker().filters[policy_id](\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\u001B[0m in \u001B[0;36mtransform\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0moverride\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPreprocessor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobservation\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensorType\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobservation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mobservation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\u001B[0m in \u001B[0;36mcheck_shape\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m     65\u001B[0m                         observation, self._obs_space)\n\u001B[1;32m     66\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m                 raise ValueError(\n\u001B[0m\u001B[1;32m     68\u001B[0m                     \u001B[0;34m\"Observation for a Box/MultiBinary/MultiDiscrete space \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m                     \"should be an np.array, not a Python list.\", observation)\n",
      "\u001B[0;31mValueError\u001B[0m: ('Observation for a Box/MultiBinary/MultiDiscrete space should be an np.array, not a Python list.', (array([3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99,\n       3.99, 3.99, 3.99, 3.99, 3.99, 3.99, 3.99], dtype=float32), array([9.99      , 0.22813019]), array([-1.,  1.])))"
     ]
    }
   ],
   "source": [
    "episode_reward = test(agent=agent, env=env)\n",
    "episode_reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-49841455",
   "language": "python",
   "display_name": "PyCharm (MasterThesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}