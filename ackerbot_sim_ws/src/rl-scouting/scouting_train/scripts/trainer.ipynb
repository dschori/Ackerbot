{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import rospy\n",
    "import gym, ray\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune.registry import register_env\n",
    "from neuroracer_gym.tasks.neuroracer_discrete_task import NeuroRacerDiscreteTask\n",
    "\n",
    "from ray.tune import grid_search\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.tf.fcnet import FullyConnectedNetwork\n",
    "from ray.rllib.models.torch.visionnet import VisionNetwork\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "from ray.rllib.models.tf.misc import normc_initializer\n",
    "from ray.tune.logger import pretty_print\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from neuroracer_discrete import NeuroRacer\n",
    "\n",
    "# rospy.init_node('neuroracer_qlearn', anonymous=True, log_level=rospy.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1610481006.206943, 195.271000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1610481006.211594, 0.002000]: Start Init ControllersConnection\n",
      "[WARN] [1610481006.212852, 0.002000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 10.0, (300,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('NeuroRacer-v0')\n",
    "\n",
    "print(env.observation_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1470845\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    obs, reward, done, _ = env.step(2)\n",
    "print(obs.min())\n",
    "print(obs.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CustomModel(TFModelV2):\n",
    "    \"\"\"Example of a keras custom model that just delegates to an fc-net.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        super(CustomModel, self).__init__(obs_space, action_space, num_outputs,\n",
    "                                          model_config, name)\n",
    "        self.model = FullyConnectedNetwork(obs_space, action_space,\n",
    "                                           num_outputs, model_config, name)\n",
    "        self.register_variables(self.model.variables())\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        return self.model.forward(input_dict, state, seq_lens)\n",
    "\n",
    "    def value_function(self):\n",
    "        return self.model.value_function()\n",
    "\n",
    "class MyKerasModel(TFModelV2):\n",
    "    \"\"\"Custom model for policy gradient algorithms.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        super(MyKerasModel, self).__init__(obs_space, action_space,\n",
    "                                           num_outputs, model_config, name)\n",
    "        self.inputs = tf.keras.layers.Input(\n",
    "            shape=obs_space.shape, name=\"observations\")\n",
    "\n",
    "        layer_dense_1 = tf.keras.layers.Dense(\n",
    "            256,\n",
    "            name=\"Dense1\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=normc_initializer(1.0))(self.inputs)\n",
    "\n",
    "        layer_dense_2 = tf.keras.layers.Dense(\n",
    "            128,\n",
    "            name=\"Dense2\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=normc_initializer(1.0))(layer_dense_1)\n",
    "        layer_out = tf.keras.layers.Dense(\n",
    "            num_outputs,\n",
    "            name=\"my_out\",\n",
    "            activation=None,\n",
    "            kernel_initializer=normc_initializer(0.01))(layer_dense_2)\n",
    "        value_out = tf.keras.layers.Dense(\n",
    "            1,\n",
    "            name=\"value_out\",\n",
    "            activation=None,\n",
    "            kernel_initializer=normc_initializer(0.01))(layer_dense_2)\n",
    "        self.base_model = tf.keras.Model(self.inputs, [layer_out, value_out])\n",
    "        self.register_variables(self.base_model.variables)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        model_out, self._value_out = self.base_model(input_dict[\"obs\"])\n",
    "        return model_out, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return tf.reshape(self._value_out, [-1])\n",
    "\n",
    "    def metrics(self):\n",
    "        return {\"foo\": tf.constant(42.0)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-12 20:50:09,949\tINFO services.py:1171 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "\n",
    "ModelCatalog.register_custom_model(\n",
    "    \"my_model\", CustomModel)\n",
    "\n",
    "config = {\n",
    "    \"env\": NeuroRacerDiscreteTask,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "\n",
    "    \"num_gpus\": int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")),\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"my_model\",\n",
    "    },\n",
    "    \"num_workers\": 1,  # parallelism\n",
    "    \"vf_share_layers\": False,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": 500,\n",
    "    \"timesteps_total\": 1000000\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-12 20:50:11,513\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-01-12 20:50:11,514\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m [ERROR] [1610481014.180349, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m [WARN] [1610481014.184074, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m [WARN] [1610481014.185442, 0.000000]: END Init ControllersConnection\n",
      "2021-01-12 20:50:18,844\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m None\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 256)          77056       observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_1 (Dense)              (None, 256)          77056       observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 256)          65792       fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_2 (Dense)              (None, 256)          65792       fc_value_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc_out (Dense)                  (None, 3)            771         fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            257         fc_value_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 286,724\n",
      "Trainable params: 286,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(config=config)\n",
    "policy = trainer.get_policy()\n",
    "\n",
    "print(policy.model.model.base_model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m 2021-01-12 20:50:20,082\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=4029258)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_1/checkpoint-1\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_20-52-35\n",
      "done: false\n",
      "episode_len_mean: 172.08695652173913\n",
      "episode_reward_max: 30.940000000001277\n",
      "episode_reward_mean: -194.65217391304347\n",
      "episode_reward_min: -362.92999999999904\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 23\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0767686367034912\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.02213660627603531\n",
      "      model: {}\n",
      "      policy_loss: -0.05445832386612892\n",
      "      total_loss: 7458.43310546875\n",
      "      vf_explained_var: 0.004315183963626623\n",
      "      vf_loss: 7458.484375\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 4000\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 64.05846153846154\n",
      "  ram_util_percent: 27.936923076923073\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06463103996339782\n",
      "  mean_env_wait_ms: 25.44421858860236\n",
      "  mean_inference_ms: 0.9329386932556107\n",
      "  mean_raw_obs_processing_ms: 6.8568198331085854\n",
      "time_since_restore: 136.1932532787323\n",
      "time_this_iter_s: 136.1932532787323\n",
      "time_total_s: 136.1932532787323\n",
      "timers:\n",
      "  learn_throughput: 1482.801\n",
      "  learn_time_ms: 2697.598\n",
      "  load_throughput: 127223.489\n",
      "  load_time_ms: 31.441\n",
      "  sample_throughput: 30.007\n",
      "  sample_time_ms: 133300.667\n",
      "  update_time_ms: 1.667\n",
      "timestamp: 1610481155\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_6/checkpoint-6\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_11/checkpoint-11\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_16/checkpoint-16\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_21/checkpoint-21\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_21-28-58\n",
      "done: false\n",
      "episode_len_mean: 547.61\n",
      "episode_reward_max: 1073.7900000000036\n",
      "episode_reward_mean: 141.2779000000011\n",
      "episode_reward_min: -310.22000000000014\n",
      "episodes_this_iter: 6\n",
      "episodes_total: 178\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.44999998807907104\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8927061557769775\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.018081059679389\n",
      "      model: {}\n",
      "      policy_loss: -0.05702345818281174\n",
      "      total_loss: 2940.989013671875\n",
      "      vf_explained_var: 0.5658672451972961\n",
      "      vf_loss: 2941.0380859375\n",
      "  num_steps_sampled: 84000\n",
      "  num_steps_trained: 84000\n",
      "iterations_since_restore: 21\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.65816993464053\n",
      "  ram_util_percent: 28.11437908496732\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0638039089620411\n",
      "  mean_env_wait_ms: 23.44071802733082\n",
      "  mean_inference_ms: 0.9286076627598873\n",
      "  mean_raw_obs_processing_ms: 2.9197849042645796\n",
      "time_since_restore: 2319.371395587921\n",
      "time_this_iter_s: 107.14446926116943\n",
      "time_total_s: 2319.371395587921\n",
      "timers:\n",
      "  learn_throughput: 1518.766\n",
      "  learn_time_ms: 2633.717\n",
      "  load_throughput: 1189291.481\n",
      "  load_time_ms: 3.363\n",
      "  sample_throughput: 38.075\n",
      "  sample_time_ms: 105056.656\n",
      "  update_time_ms: 1.664\n",
      "timestamp: 1610483338\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 84000\n",
      "training_iteration: 21\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_26/checkpoint-26\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_31/checkpoint-31\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_36/checkpoint-36\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_41/checkpoint-41\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_22-04-36\n",
      "done: false\n",
      "episode_len_mean: 669.22\n",
      "episode_reward_max: 1012.1800000000031\n",
      "episode_reward_mean: 170.9772000000011\n",
      "episode_reward_min: -383.15999999999826\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 296\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.675000011920929\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.854230523109436\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.015040074475109577\n",
      "      model: {}\n",
      "      policy_loss: -0.05548729747533798\n",
      "      total_loss: 7526.37548828125\n",
      "      vf_explained_var: 0.22568781673908234\n",
      "      vf_loss: 7526.42041015625\n",
      "  num_steps_sampled: 164000\n",
      "  num_steps_trained: 164000\n",
      "iterations_since_restore: 41\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.28523489932886\n",
      "  ram_util_percent: 28.12617449664429\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06366002441452451\n",
      "  mean_env_wait_ms: 23.285097424885706\n",
      "  mean_inference_ms: 0.9305126262093146\n",
      "  mean_raw_obs_processing_ms: 2.3529095982963693\n",
      "time_since_restore: 4457.4309186935425\n",
      "time_this_iter_s: 104.53089618682861\n",
      "time_total_s: 4457.4309186935425\n",
      "timers:\n",
      "  learn_throughput: 1541.213\n",
      "  learn_time_ms: 2595.358\n",
      "  load_throughput: 1141726.621\n",
      "  load_time_ms: 3.503\n",
      "  sample_throughput: 38.491\n",
      "  sample_time_ms: 103920.261\n",
      "  update_time_ms: 1.664\n",
      "timestamp: 1610485476\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 164000\n",
      "training_iteration: 41\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_46/checkpoint-46\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_51/checkpoint-51\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_56/checkpoint-56\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_61/checkpoint-61\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_22-40-04\n",
      "done: false\n",
      "episode_len_mean: 822.39\n",
      "episode_reward_max: 1027.9100000000049\n",
      "episode_reward_mean: 318.9877000000019\n",
      "episode_reward_min: -240.89999999999998\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 394\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.675000011920929\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8382364511489868\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.016940882429480553\n",
      "      model: {}\n",
      "      policy_loss: -0.046888794749975204\n",
      "      total_loss: 7656.68798828125\n",
      "      vf_explained_var: 0.12908385694026947\n",
      "      vf_loss: 7656.72216796875\n",
      "  num_steps_sampled: 244000\n",
      "  num_steps_trained: 244000\n",
      "iterations_since_restore: 61\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.48648648648648\n",
      "  ram_util_percent: 28.396621621621627\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0636923326485422\n",
      "  mean_env_wait_ms: 23.301847648138132\n",
      "  mean_inference_ms: 0.9328727591436377\n",
      "  mean_raw_obs_processing_ms: 2.088571208838021\n",
      "time_since_restore: 6584.902784585953\n",
      "time_this_iter_s: 103.85869479179382\n",
      "time_total_s: 6584.902784585953\n",
      "timers:\n",
      "  learn_throughput: 1555.497\n",
      "  learn_time_ms: 2571.525\n",
      "  load_throughput: 1130319.277\n",
      "  load_time_ms: 3.539\n",
      "  sample_throughput: 38.716\n",
      "  sample_time_ms: 103316.664\n",
      "  update_time_ms: 1.724\n",
      "timestamp: 1610487604\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 244000\n",
      "training_iteration: 61\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_66/checkpoint-66\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_71/checkpoint-71\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_76/checkpoint-76\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_81/checkpoint-81\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_23-15-35\n",
      "done: false\n",
      "episode_len_mean: 702.55\n",
      "episode_reward_max: 1118.2300000000037\n",
      "episode_reward_mean: 228.5370000000015\n",
      "episode_reward_min: -245.0\n",
      "episodes_this_iter: 10\n",
      "episodes_total: 506\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 1.0125000476837158\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8011623024940491\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.011143986135721207\n",
      "      model: {}\n",
      "      policy_loss: -0.04692256450653076\n",
      "      total_loss: 5927.77880859375\n",
      "      vf_explained_var: 0.465594083070755\n",
      "      vf_loss: 5927.814453125\n",
      "  num_steps_sampled: 324000\n",
      "  num_steps_trained: 324000\n",
      "iterations_since_restore: 81\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.184375\n",
      "  ram_util_percent: 28.300000000000004\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06369364211649317\n",
      "  mean_env_wait_ms: 23.276525022310853\n",
      "  mean_inference_ms: 0.9327373549676349\n",
      "  mean_raw_obs_processing_ms: 1.9364670047452406\n",
      "time_since_restore: 8715.197565555573\n",
      "time_this_iter_s: 111.58548069000244\n",
      "time_total_s: 8715.197565555573\n",
      "timers:\n",
      "  learn_throughput: 1517.306\n",
      "  learn_time_ms: 2636.251\n",
      "  load_throughput: 1083750.476\n",
      "  load_time_ms: 3.691\n",
      "  sample_throughput: 38.268\n",
      "  sample_time_ms: 104524.683\n",
      "  update_time_ms: 1.67\n",
      "timestamp: 1610489735\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 324000\n",
      "training_iteration: 81\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_86/checkpoint-86\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_91/checkpoint-91\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_96/checkpoint-96\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_101/checkpoint-101\n",
      "custom_metrics: {}\n",
      "date: 2021-01-12_23-50-48\n",
      "done: false\n",
      "episode_len_mean: 786.35\n",
      "episode_reward_max: 1114.1900000000037\n",
      "episode_reward_mean: 290.4825000000012\n",
      "episode_reward_min: -330.6900000000006\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 607\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 1.0125000476837158\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7453294992446899\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.008961154147982597\n",
      "      model: {}\n",
      "      policy_loss: -0.03761148825287819\n",
      "      total_loss: 4082.32861328125\n",
      "      vf_explained_var: 0.18039220571517944\n",
      "      vf_loss: 4082.35693359375\n",
      "  num_steps_sampled: 404000\n",
      "  num_steps_trained: 404000\n",
      "iterations_since_restore: 101\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.432\n",
      "  ram_util_percent: 28.400000000000006\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06372958885375771\n",
      "  mean_env_wait_ms: 23.259189495110476\n",
      "  mean_inference_ms: 0.9325533887138485\n",
      "  mean_raw_obs_processing_ms: 1.8943488766124152\n",
      "time_since_restore: 10828.397490501404\n",
      "time_this_iter_s: 104.94890427589417\n",
      "time_total_s: 10828.397490501404\n",
      "timers:\n",
      "  learn_throughput: 1542.353\n",
      "  learn_time_ms: 2593.441\n",
      "  load_throughput: 1073206.08\n",
      "  load_time_ms: 3.727\n",
      "  sample_throughput: 38.914\n",
      "  sample_time_ms: 102789.921\n",
      "  update_time_ms: 1.752\n",
      "timestamp: 1610491848\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 404000\n",
      "training_iteration: 101\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_106/checkpoint-106\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_111/checkpoint-111\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_116/checkpoint-116\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_121/checkpoint-121\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_00-25-56\n",
      "done: false\n",
      "episode_len_mean: 881.89\n",
      "episode_reward_max: 1195.8700000000026\n",
      "episode_reward_mean: 409.8830000000011\n",
      "episode_reward_min: -222.29\n",
      "episodes_this_iter: 6\n",
      "episodes_total: 697\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 1.0125000476837158\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6653849482536316\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.009993338026106358\n",
      "      model: {}\n",
      "      policy_loss: -0.0405304953455925\n",
      "      total_loss: 3644.34423828125\n",
      "      vf_explained_var: 0.36199089884757996\n",
      "      vf_loss: 3644.3740234375\n",
      "  num_steps_sampled: 484000\n",
      "  num_steps_trained: 484000\n",
      "iterations_since_restore: 121\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.27828947368421\n",
      "  ram_util_percent: 28.405921052631584\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0637490669451524\n",
      "  mean_env_wait_ms: 23.24330515990734\n",
      "  mean_inference_ms: 0.9323028948961403\n",
      "  mean_raw_obs_processing_ms: 1.8190542856809113\n",
      "time_since_restore: 12935.59183716774\n",
      "time_this_iter_s: 106.78594851493835\n",
      "time_total_s: 12935.59183716774\n",
      "timers:\n",
      "  learn_throughput: 1560.627\n",
      "  learn_time_ms: 2563.073\n",
      "  load_throughput: 1135467.663\n",
      "  load_time_ms: 3.523\n",
      "  sample_throughput: 38.688\n",
      "  sample_time_ms: 103392.038\n",
      "  update_time_ms: 1.634\n",
      "timestamp: 1610493956\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 484000\n",
      "training_iteration: 121\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_126/checkpoint-126\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_131/checkpoint-131\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_136/checkpoint-136\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_141/checkpoint-141\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_01-01-08\n",
      "done: false\n",
      "episode_len_mean: 785.59\n",
      "episode_reward_max: 1279.8300000000029\n",
      "episode_reward_mean: 343.90690000000075\n",
      "episode_reward_min: -232.1\n",
      "episodes_this_iter: 4\n",
      "episodes_total: 799\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 1.0125000476837158\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5507947206497192\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.009909198619425297\n",
      "      model: {}\n",
      "      policy_loss: -0.028842663392424583\n",
      "      total_loss: 5924.9853515625\n",
      "      vf_explained_var: 0.21221759915351868\n",
      "      vf_loss: 5925.00390625\n",
      "  num_steps_sampled: 564000\n",
      "  num_steps_trained: 564000\n",
      "iterations_since_restore: 141\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.72466666666668\n",
      "  ram_util_percent: 28.484666666666673\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06376868513934834\n",
      "  mean_env_wait_ms: 23.23268360013989\n",
      "  mean_inference_ms: 0.9322720901729662\n",
      "  mean_raw_obs_processing_ms: 1.777675974010678\n",
      "time_since_restore: 15047.80873465538\n",
      "time_this_iter_s: 105.10478067398071\n",
      "time_total_s: 15047.80873465538\n",
      "timers:\n",
      "  learn_throughput: 1540.318\n",
      "  learn_time_ms: 2596.866\n",
      "  load_throughput: 1135083.555\n",
      "  load_time_ms: 3.524\n",
      "  sample_throughput: 38.947\n",
      "  sample_time_ms: 102704.673\n",
      "  update_time_ms: 1.691\n",
      "timestamp: 1610496068\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 564000\n",
      "training_iteration: 141\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_146/checkpoint-146\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_151/checkpoint-151\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_156/checkpoint-156\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_161/checkpoint-161\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_01-36-19\n",
      "done: false\n",
      "episode_len_mean: 757.08\n",
      "episode_reward_max: 1484.860000000001\n",
      "episode_reward_mean: 359.36960000000073\n",
      "episode_reward_min: -284.55\n",
      "episodes_this_iter: 5\n",
      "episodes_total: 903\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.7593749761581421\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5322831273078918\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.010922322981059551\n",
      "      model: {}\n",
      "      policy_loss: -0.04028730466961861\n",
      "      total_loss: 2379.714599609375\n",
      "      vf_explained_var: 0.5642911195755005\n",
      "      vf_loss: 2379.746826171875\n",
      "  num_steps_sampled: 644000\n",
      "  num_steps_trained: 644000\n",
      "iterations_since_restore: 161\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.68466666666667\n",
      "  ram_util_percent: 28.398000000000003\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06378316252927321\n",
      "  mean_env_wait_ms: 23.216121314730234\n",
      "  mean_inference_ms: 0.9322008731201831\n",
      "  mean_raw_obs_processing_ms: 1.7549539331905217\n",
      "time_since_restore: 17158.4621925354\n",
      "time_this_iter_s: 105.44056844711304\n",
      "time_total_s: 17158.4621925354\n",
      "timers:\n",
      "  learn_throughput: 1561.024\n",
      "  learn_time_ms: 2562.42\n",
      "  load_throughput: 1181768.721\n",
      "  load_time_ms: 3.385\n",
      "  sample_throughput: 39.12\n",
      "  sample_time_ms: 102249.573\n",
      "  update_time_ms: 1.613\n",
      "timestamp: 1610498179\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 644000\n",
      "training_iteration: 161\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_166/checkpoint-166\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_171/checkpoint-171\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_176/checkpoint-176\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_181/checkpoint-181\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_02-11-36\n",
      "done: false\n",
      "episode_len_mean: 755.24\n",
      "episode_reward_max: 1534.3500000000008\n",
      "episode_reward_mean: 364.43800000000084\n",
      "episode_reward_min: -288.78999999999996\n",
      "episodes_this_iter: 5\n",
      "episodes_total: 1007\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.569531261920929\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5859399437904358\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.016972031444311142\n",
      "      model: {}\n",
      "      policy_loss: -0.03689488768577576\n",
      "      total_loss: 4413.53759765625\n",
      "      vf_explained_var: 0.48173582553863525\n",
      "      vf_loss: 4413.5654296875\n",
      "  num_steps_sampled: 724000\n",
      "  num_steps_trained: 724000\n",
      "iterations_since_restore: 181\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.51324503311258\n",
      "  ram_util_percent: 28.5\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06379695302397353\n",
      "  mean_env_wait_ms: 23.20072436369045\n",
      "  mean_inference_ms: 0.9320192354813834\n",
      "  mean_raw_obs_processing_ms: 1.7345534481240839\n",
      "time_since_restore: 19275.40048146248\n",
      "time_this_iter_s: 105.99643564224243\n",
      "time_total_s: 19275.40048146248\n",
      "timers:\n",
      "  learn_throughput: 1540.631\n",
      "  learn_time_ms: 2596.34\n",
      "  load_throughput: 1279531.422\n",
      "  load_time_ms: 3.126\n",
      "  sample_throughput: 38.834\n",
      "  sample_time_ms: 103001.368\n",
      "  update_time_ms: 1.597\n",
      "timestamp: 1610500296\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 724000\n",
      "training_iteration: 181\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_186/checkpoint-186\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_191/checkpoint-191\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_196/checkpoint-196\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_201/checkpoint-201\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_02-47-16\n",
      "done: false\n",
      "episode_len_mean: 687.36\n",
      "episode_reward_max: 1525.2600000000016\n",
      "episode_reward_mean: 428.86560000000094\n",
      "episode_reward_min: -484.759999999999\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 1120\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.854296863079071\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5423684120178223\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.009014044888317585\n",
      "      model: {}\n",
      "      policy_loss: -0.031287405639886856\n",
      "      total_loss: 4856.05712890625\n",
      "      vf_explained_var: 0.5724389553070068\n",
      "      vf_loss: 4856.08056640625\n",
      "  num_steps_sampled: 804000\n",
      "  num_steps_trained: 804000\n",
      "iterations_since_restore: 201\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.39936305732485\n",
      "  ram_util_percent: 28.678980891719736\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06381955224761719\n",
      "  mean_env_wait_ms: 23.204455390272575\n",
      "  mean_inference_ms: 0.9320085420901357\n",
      "  mean_raw_obs_processing_ms: 1.7288952662502957\n",
      "time_since_restore: 21414.955017089844\n",
      "time_this_iter_s: 109.83882021903992\n",
      "time_total_s: 21414.955017089844\n",
      "timers:\n",
      "  learn_throughput: 1562.881\n",
      "  learn_time_ms: 2559.375\n",
      "  load_throughput: 1324806.418\n",
      "  load_time_ms: 3.019\n",
      "  sample_throughput: 38.201\n",
      "  sample_time_ms: 104709.652\n",
      "  update_time_ms: 1.772\n",
      "timestamp: 1610502436\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 804000\n",
      "training_iteration: 201\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_206/checkpoint-206\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_211/checkpoint-211\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_216/checkpoint-216\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_221/checkpoint-221\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_03-23-04\n",
      "done: false\n",
      "episode_len_mean: 654.48\n",
      "episode_reward_max: 1552.530000000001\n",
      "episode_reward_mean: 382.30800000000096\n",
      "episode_reward_min: -343.94\n",
      "episodes_this_iter: 6\n",
      "episodes_total: 1241\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.854296863079071\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5282382965087891\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.011242680251598358\n",
      "      model: {}\n",
      "      policy_loss: -0.04062243178486824\n",
      "      total_loss: 4116.8095703125\n",
      "      vf_explained_var: 0.5041580200195312\n",
      "      vf_loss: 4116.84033203125\n",
      "  num_steps_sampled: 884000\n",
      "  num_steps_trained: 884000\n",
      "iterations_since_restore: 221\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.41111111111111\n",
      "  ram_util_percent: 28.60588235294117\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06383814402798965\n",
      "  mean_env_wait_ms: 23.211310428085188\n",
      "  mean_inference_ms: 0.9322269590019987\n",
      "  mean_raw_obs_processing_ms: 1.747320131564345\n",
      "time_since_restore: 23563.04077720642\n",
      "time_this_iter_s: 107.04438543319702\n",
      "time_total_s: 23563.04077720642\n",
      "timers:\n",
      "  learn_throughput: 1555.019\n",
      "  learn_time_ms: 2572.316\n",
      "  load_throughput: 1226763.381\n",
      "  load_time_ms: 3.261\n",
      "  sample_throughput: 38.363\n",
      "  sample_time_ms: 104266.562\n",
      "  update_time_ms: 1.627\n",
      "timestamp: 1610504584\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 884000\n",
      "training_iteration: 221\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_226/checkpoint-226\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_231/checkpoint-231\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_236/checkpoint-236\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_241/checkpoint-241\n",
      "custom_metrics: {}\n",
      "date: 2021-01-13_03-58-50\n",
      "done: false\n",
      "episode_len_mean: 658.61\n",
      "episode_reward_max: 1561.6200000000008\n",
      "episode_reward_mean: 399.45830000000103\n",
      "episode_reward_min: -297.6600000000001\n",
      "episodes_this_iter: 7\n",
      "episodes_total: 1356\n",
      "experiment_id: 8ef5b927a9584569864261b159c35931\n",
      "hostname: workstation\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      cur_kl_coeff: 0.854296863079071\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5321859121322632\n",
      "      entropy_coeff: 0.0\n",
      "      kl: 0.009105795994400978\n",
      "      model: {}\n",
      "      policy_loss: -0.030059780925512314\n",
      "      total_loss: 4218.52490234375\n",
      "      vf_explained_var: 0.5719914436340332\n",
      "      vf_loss: 4218.54736328125\n",
      "  num_steps_sampled: 964000\n",
      "  num_steps_trained: 964000\n",
      "iterations_since_restore: 241\n",
      "node_ip: 192.168.178.60\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.68451612903226\n",
      "  ram_util_percent: 28.710967741935477\n",
      "pid: 4029065\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06384875612383313\n",
      "  mean_env_wait_ms: 23.219930875204554\n",
      "  mean_inference_ms: 0.9323895417053784\n",
      "  mean_raw_obs_processing_ms: 1.7491603542229524\n",
      "time_since_restore: 25708.302126169205\n",
      "time_this_iter_s: 109.09119176864624\n",
      "time_total_s: 25708.302126169205\n",
      "timers:\n",
      "  learn_throughput: 1537.954\n",
      "  learn_time_ms: 2600.859\n",
      "  load_throughput: 1153541.024\n",
      "  load_time_ms: 3.468\n",
      "  sample_throughput: 38.251\n",
      "  sample_time_ms: 104573.348\n",
      "  update_time_ms: 1.657\n",
      "timestamp: 1610506730\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 964000\n",
      "training_iteration: 241\n",
      "\n",
      "checkpoint saved at /home/dschori/ray_results/PPO_NeuroRacerDiscreteTask_2021-01-12_20-50-116mp15u2n/checkpoint_246/checkpoint-246\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(250):\n",
    "    result = trainer.train()\n",
    "    results.append(result)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"checkpoint saved at\", checkpoint)\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(pretty_print(result))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}