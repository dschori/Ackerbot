{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from scouting_gym.tasks.scouting_discrete_task import ScoutingDiscreteTask"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Register Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1613731558.968717, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1613731558.972389, 0.000000]: Start Init ControllersConnection\n",
      "[WARN] [1613731558.973123, 0.000000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box(0.0, 1.0, (84, 84, 4), float32)\n",
      "Action Space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Scouting-v0')\n",
    "\n",
    "print(\"Observation Space: {}\".format(env.observation_space))\n",
    "print(\"Action Space: {}\".format(env.action_space))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Environment State"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for _ in range(1):\n",
    "    obs, _, _, _ = env.step(action=2)\n",
    "plt.imshow(obs[:, :, 0])\n",
    "print(obs.min())\n",
    "print(obs.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ray Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env\": ScoutingDiscreteTask,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 1\n",
    "}\n",
    "\n",
    "stop = {\n",
    "    \"episodes_total\": 8000,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 11:46:02,347\tINFO services.py:1171 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.178.60',\n 'raylet_ip_address': '192.168.178.60',\n 'redis_address': '192.168.178.60:6379',\n 'object_store_address': '/tmp/ray/session_2021-02-19_11-46-01_840931_13830/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2021-02-19_11-46-01_840931_13830/sockets/raylet',\n 'webui_url': '127.0.0.1:8265',\n 'session_dir': '/tmp/ray/session_2021-02-19_11-46-01_840931_13830',\n 'metrics_export_port': 39522,\n 'node_id': '56ad4d6c500cc5acca027fdb6d5df9e3f67bef72'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(stop_criteria, config, restorepath):\n",
    "    \"\"\"\n",
    "    Train an RLlib PPO agent using tune until any of the configured stopping criteria is met.\n",
    "    :param stop_criteria: Dict with stopping criteria.\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/execution.html#tune-run\n",
    "    :return: Return the path to the saved agent (checkpoint) and tune's ExperimentAnalysis object\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/analysis.html#experimentanalysis-tune-experimentanalysis\n",
    "    \"\"\"\n",
    "    analysis = ray.tune.run(PPOTrainer, config=config,\n",
    "                            stop=stop_criteria,\n",
    "                            checkpoint_freq=1,\n",
    "                            checkpoint_at_end=True,\n",
    "                            restore=restorepath)\n",
    "    # list of lists: one list per checkpoint; each checkpoint list contains 1st the path, 2nd the metric value\n",
    "    checkpoints = analysis.get_trial_checkpoints_paths(trial=analysis.get_best_trial('episode_reward_mean', mode='max'),\n",
    "                                                       metric='episode_reward_mean',\n",
    "                                                       )\n",
    "    # retriev the checkpoint path; we only have a single checkpoint, so take the first one\n",
    "    checkpoint_path = checkpoints[0][0]\n",
    "    return checkpoint_path, analysis\n",
    "\n",
    "def load(checkpoint_path, config):\n",
    "    \"\"\"\n",
    "    Load a trained RLlib agent from the specified path. Call this before testing a trained agent.\n",
    "    :param path: Path pointing to the agent's saved checkpoint (only used for RLlib agents)\n",
    "    \"\"\"\n",
    "    agent = PPOTrainer(config=config)\n",
    "    agent.restore(checkpoint_path)\n",
    "    return agent\n",
    "\n",
    "def test(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward\n",
    "\n",
    "def test_traj(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    positions = []\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        positions.append(info['position'])\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward, positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:37:29,996\tINFO trainable.py:72 -- Checkpoint size is 24109446 bytes\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:33,050\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:33,050\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m [ERROR] [1612903056.157866, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m [WARN] [1612903056.160999, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m [WARN] [1612903056.161887, 0.000000]: END Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:44,110\tINFO trainable.py:99 -- Trainable.setup took 11.060 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:44,111\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:44,296\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-09_21-37-29/PPO_ScoutingDiscreteTask_a0e0c_00000_0_2021-02-09_21-37-29/tmpk4_5m957restore_from_object/checkpoint-201\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m 2021-02-09 21:37:44,296\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 201, '_timesteps_total': None, '_time_total': 109850.49397397041, '_episodes_total': 4999}\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m 2021-02-09 21:37:45,575\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2021-02-10 11:57:18,080\tINFO tune.py:448 -- Total run time: 51588.37 seconds (51586.99 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=3339694)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=3339696)\u001B[0m None\n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_21-46-53\n",
      "  done: false\n",
      "  episode_len_mean: 124.54838709677419\n",
      "  episode_reward_max: 118.38444732621318\n",
      "  episode_reward_mean: 76.36165389001842\n",
      "  episode_reward_min: -96.52579843274803\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5030\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36332884430885315\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.042046040296554565\n",
      "        model: {}\n",
      "        policy_loss: -0.10939115285873413\n",
      "        total_loss: 634.2264404296875\n",
      "        vf_explained_var: 0.745877742767334\n",
      "        vf_loss: 634.3275146484375\n",
      "    num_steps_sampled: 808000\n",
      "    num_steps_trained: 808000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.54005102040817\n",
      "    ram_util_percent: 37.63928571428571\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07231025152342285\n",
      "    mean_env_wait_ms: 123.03301668917945\n",
      "    mean_inference_ms: 1.6323711478212601\n",
      "    mean_raw_obs_processing_ms: 9.424384848173483\n",
      "  time_since_restore: 548.8673896789551\n",
      "  time_this_iter_s: 548.8673896789551\n",
      "  time_total_s: 110399.36136364937\n",
      "  timers:\n",
      "    learn_throughput: 362.336\n",
      "    learn_time_ms: 11039.478\n",
      "    load_throughput: 7795.731\n",
      "    load_time_ms: 513.101\n",
      "    sample_throughput: 7.447\n",
      "    sample_time_ms: 537142.284\n",
      "    update_time_ms: 3.479\n",
      "  timestamp: 1612903613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 808000\n",
      "  training_iteration: 202\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_21-55-49\n",
      "  done: false\n",
      "  episode_len_mean: 122.93846153846154\n",
      "  episode_reward_max: 118.39206301338692\n",
      "  episode_reward_mean: 68.52947878681303\n",
      "  episode_reward_min: -104.87960383482677\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 5064\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34911099076271057\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03168858587741852\n",
      "        model: {}\n",
      "        policy_loss: -0.09427706152200699\n",
      "        total_loss: 658.9390258789062\n",
      "        vf_explained_var: 0.730173647403717\n",
      "        vf_loss: 659.0238647460938\n",
      "    num_steps_sampled: 812000\n",
      "    num_steps_trained: 812000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.69817232375979\n",
      "    ram_util_percent: 39.63590078328981\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07166780838421083\n",
      "    mean_env_wait_ms: 122.04923723003078\n",
      "    mean_inference_ms: 1.6251301585110507\n",
      "    mean_raw_obs_processing_ms: 9.665621523277947\n",
      "  time_since_restore: 1085.5322859287262\n",
      "  time_this_iter_s: 536.6648962497711\n",
      "  time_total_s: 110936.02625989914\n",
      "  timers:\n",
      "    learn_throughput: 367.347\n",
      "    learn_time_ms: 10888.898\n",
      "    load_throughput: 8871.523\n",
      "    load_time_ms: 450.881\n",
      "    sample_throughput: 7.529\n",
      "    sample_time_ms: 531267.91\n",
      "    update_time_ms: 3.359\n",
      "  timestamp: 1612904149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 812000\n",
      "  training_iteration: 203\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 117.39\n",
      "  episode_reward_max: 118.39206301338692\n",
      "  episode_reward_mean: 64.10243533848113\n",
      "  episode_reward_min: -106.57407954938027\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 5100\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3777538239955902\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027607670053839684\n",
      "        model: {}\n",
      "        policy_loss: -0.10011913627386093\n",
      "        total_loss: 435.5245666503906\n",
      "        vf_explained_var: 0.8306372165679932\n",
      "        vf_loss: 435.6123046875\n",
      "    num_steps_sampled: 816000\n",
      "    num_steps_trained: 816000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75882352941177\n",
      "    ram_util_percent: 39.59933155080214\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07122704890654502\n",
      "    mean_env_wait_ms: 121.05374739026807\n",
      "    mean_inference_ms: 1.6194300748837451\n",
      "    mean_raw_obs_processing_ms: 9.87178882279333\n",
      "  time_since_restore: 1609.8577284812927\n",
      "  time_this_iter_s: 524.3254425525665\n",
      "  time_total_s: 111460.3517024517\n",
      "  timers:\n",
      "    learn_throughput: 369.102\n",
      "    learn_time_ms: 10837.126\n",
      "    load_throughput: 9280.505\n",
      "    load_time_ms: 431.011\n",
      "    sample_throughput: 7.616\n",
      "    sample_time_ms: 525203.062\n",
      "    update_time_ms: 3.482\n",
      "  timestamp: 1612904674\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 816000\n",
      "  training_iteration: 204\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-13-19\n",
      "  done: false\n",
      "  episode_len_mean: 123.43\n",
      "  episode_reward_max: 118.39973639751503\n",
      "  episode_reward_mean: 66.0876026378999\n",
      "  episode_reward_min: -106.57407954938027\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5128\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35615918040275574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023637687787413597\n",
      "        model: {}\n",
      "        policy_loss: -0.0918046087026596\n",
      "        total_loss: 420.1271057128906\n",
      "        vf_explained_var: 0.7704351544380188\n",
      "        vf_loss: 420.2029724121094\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.09586666666666\n",
      "    ram_util_percent: 39.641866666666665\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07057611455017486\n",
      "    mean_env_wait_ms: 119.93295846473444\n",
      "    mean_inference_ms: 1.6119281064498503\n",
      "    mean_raw_obs_processing_ms: 9.98447127191076\n",
      "  time_since_restore: 2135.1983437538147\n",
      "  time_this_iter_s: 525.340615272522\n",
      "  time_total_s: 111985.69231772423\n",
      "  timers:\n",
      "    learn_throughput: 369.739\n",
      "    learn_time_ms: 10818.441\n",
      "    load_throughput: 9527.338\n",
      "    load_time_ms: 419.844\n",
      "    sample_throughput: 7.657\n",
      "    sample_time_ms: 522418.482\n",
      "    update_time_ms: 3.412\n",
      "  timestamp: 1612905199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 205\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-22-08\n",
      "  done: false\n",
      "  episode_len_mean: 123.84\n",
      "  episode_reward_max: 118.39973639751503\n",
      "  episode_reward_mean: 61.681028557918864\n",
      "  episode_reward_min: -106.57407954938027\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5159\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3658977448940277\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01905224286019802\n",
      "        model: {}\n",
      "        policy_loss: -0.09183119237422943\n",
      "        total_loss: 595.0711059570312\n",
      "        vf_explained_var: 0.7773296236991882\n",
      "        vf_loss: 595.1437377929688\n",
      "    num_steps_sampled: 824000\n",
      "    num_steps_trained: 824000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.19046357615895\n",
      "    ram_util_percent: 39.65470198675497\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07015105436032552\n",
      "    mean_env_wait_ms: 119.19556238202821\n",
      "    mean_inference_ms: 1.6069065178908633\n",
      "    mean_raw_obs_processing_ms: 9.94925014152792\n",
      "  time_since_restore: 2664.37354183197\n",
      "  time_this_iter_s: 529.1751980781555\n",
      "  time_total_s: 112514.86751580238\n",
      "  timers:\n",
      "    learn_throughput: 370.288\n",
      "    learn_time_ms: 10802.416\n",
      "    load_throughput: 9619.207\n",
      "    load_time_ms: 415.835\n",
      "    sample_throughput: 7.67\n",
      "    sample_time_ms: 521515.59\n",
      "    update_time_ms: 3.384\n",
      "  timestamp: 1612905728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 824000\n",
      "  training_iteration: 206\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-30-48\n",
      "  done: false\n",
      "  episode_len_mean: 128.75\n",
      "  episode_reward_max: 118.39973639751503\n",
      "  episode_reward_mean: 60.061678788807875\n",
      "  episode_reward_min: -106.34109042456174\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5191\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37050333619117737\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020132984966039658\n",
      "        model: {}\n",
      "        policy_loss: -0.08390621095895767\n",
      "        total_loss: 873.0941162109375\n",
      "        vf_explained_var: 0.6204808354377747\n",
      "        vf_loss: 873.15771484375\n",
      "    num_steps_sampled: 828000\n",
      "    num_steps_trained: 828000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75330634278002\n",
      "    ram_util_percent: 39.67813765182187\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06988480245347484\n",
      "    mean_env_wait_ms: 118.80406370167451\n",
      "    mean_inference_ms: 1.6042129411050277\n",
      "    mean_raw_obs_processing_ms: 9.802837411972774\n",
      "  time_since_restore: 3184.0712366104126\n",
      "  time_this_iter_s: 519.6976947784424\n",
      "  time_total_s: 113034.56521058083\n",
      "  timers:\n",
      "    learn_throughput: 370.84\n",
      "    learn_time_ms: 10786.314\n",
      "    load_throughput: 9658.68\n",
      "    load_time_ms: 414.135\n",
      "    sample_throughput: 7.702\n",
      "    sample_time_ms: 519337.025\n",
      "    update_time_ms: 3.348\n",
      "  timestamp: 1612906248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 828000\n",
      "  training_iteration: 207\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-39-33\n",
      "  done: false\n",
      "  episode_len_mean: 126.04\n",
      "  episode_reward_max: 118.39847819203922\n",
      "  episode_reward_mean: 62.08296316352289\n",
      "  episode_reward_min: -106.56819705735226\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5223\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37174192070961\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010871256701648235\n",
      "        model: {}\n",
      "        policy_loss: -0.07195281237363815\n",
      "        total_loss: 354.7228698730469\n",
      "        vf_explained_var: 0.8198283314704895\n",
      "        vf_loss: 354.77838134765625\n",
      "    num_steps_sampled: 832000\n",
      "    num_steps_trained: 832000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.418400000000005\n",
      "    ram_util_percent: 39.686933333333336\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06972698767817331\n",
      "    mean_env_wait_ms: 118.5086039457089\n",
      "    mean_inference_ms: 1.602663524639035\n",
      "    mean_raw_obs_processing_ms: 9.731476917810149\n",
      "  time_since_restore: 3709.2126562595367\n",
      "  time_this_iter_s: 525.1414196491241\n",
      "  time_total_s: 113559.70663022995\n",
      "  timers:\n",
      "    learn_throughput: 371.17\n",
      "    learn_time_ms: 10776.742\n",
      "    load_throughput: 9727.782\n",
      "    load_time_ms: 411.193\n",
      "    sample_throughput: 7.714\n",
      "    sample_time_ms: 518558.902\n",
      "    update_time_ms: 3.356\n",
      "  timestamp: 1612906773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 832000\n",
      "  training_iteration: 208\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-48-19\n",
      "  done: false\n",
      "  episode_len_mean: 128.89\n",
      "  episode_reward_max: 118.39864965252964\n",
      "  episode_reward_mean: 70.50949181439799\n",
      "  episode_reward_min: -106.89465794440122\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5253\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37147316336631775\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012282636016607285\n",
      "        model: {}\n",
      "        policy_loss: -0.08164091408252716\n",
      "        total_loss: 278.131103515625\n",
      "        vf_explained_var: 0.8583352565765381\n",
      "        vf_loss: 278.1941223144531\n",
      "    num_steps_sampled: 836000\n",
      "    num_steps_trained: 836000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.235866666666666\n",
      "    ram_util_percent: 39.6872\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06964719806822074\n",
      "    mean_env_wait_ms: 118.27704351415736\n",
      "    mean_inference_ms: 1.6020470357376946\n",
      "    mean_raw_obs_processing_ms: 9.695159386226496\n",
      "  time_since_restore: 4235.027583360672\n",
      "  time_this_iter_s: 525.8149271011353\n",
      "  time_total_s: 114085.52155733109\n",
      "  timers:\n",
      "    learn_throughput: 371.534\n",
      "    learn_time_ms: 10766.169\n",
      "    load_throughput: 9803.36\n",
      "    load_time_ms: 408.023\n",
      "    sample_throughput: 7.721\n",
      "    sample_time_ms: 518061.246\n",
      "    update_time_ms: 3.35\n",
      "  timestamp: 1612907299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 836000\n",
      "  training_iteration: 209\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_22-56-56\n",
      "  done: false\n",
      "  episode_len_mean: 131.11\n",
      "  episode_reward_max: 118.39864965252964\n",
      "  episode_reward_mean: 70.39507968843606\n",
      "  episode_reward_min: -106.89465794440122\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5281\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3926101326942444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016002152115106583\n",
      "        model: {}\n",
      "        policy_loss: -0.09378788620233536\n",
      "        total_loss: 477.3751525878906\n",
      "        vf_explained_var: 0.80803382396698\n",
      "        vf_loss: 477.4446105957031\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50257452574525\n",
      "    ram_util_percent: 39.63929539295393\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06958959115974306\n",
      "    mean_env_wait_ms: 118.12069330087711\n",
      "    mean_inference_ms: 1.6015595647456005\n",
      "    mean_raw_obs_processing_ms: 9.633754942849516\n",
      "  time_since_restore: 4751.792055130005\n",
      "  time_this_iter_s: 516.7644717693329\n",
      "  time_total_s: 114602.28602910042\n",
      "  timers:\n",
      "    learn_throughput: 371.645\n",
      "    learn_time_ms: 10762.951\n",
      "    load_throughput: 9893.942\n",
      "    load_time_ms: 404.288\n",
      "    sample_throughput: 7.742\n",
      "    sample_time_ms: 516666.864\n",
      "    update_time_ms: 3.333\n",
      "  timestamp: 1612907816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 210\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-06-05\n",
      "  done: false\n",
      "  episode_len_mean: 134.22\n",
      "  episode_reward_max: 118.39864965252964\n",
      "  episode_reward_mean: 67.8485365884226\n",
      "  episode_reward_min: -106.89465794440122\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5312\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3889402747154236\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013187848962843418\n",
      "        model: {}\n",
      "        policy_loss: -0.08308876305818558\n",
      "        total_loss: 260.45416259765625\n",
      "        vf_explained_var: 0.8716606497764587\n",
      "        vf_loss: 260.5172424316406\n",
      "    num_steps_sampled: 844000\n",
      "    num_steps_trained: 844000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.81455938697319\n",
      "    ram_util_percent: 39.69578544061303\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06965433127114633\n",
      "    mean_env_wait_ms: 118.1830953553457\n",
      "    mean_inference_ms: 1.6021898390774285\n",
      "    mean_raw_obs_processing_ms: 9.56672742321996\n",
      "  time_since_restore: 5300.760164260864\n",
      "  time_this_iter_s: 548.9681091308594\n",
      "  time_total_s: 115151.25413823128\n",
      "  timers:\n",
      "    learn_throughput: 371.005\n",
      "    learn_time_ms: 10781.52\n",
      "    load_throughput: 9910.963\n",
      "    load_time_ms: 403.593\n",
      "    sample_throughput: 7.711\n",
      "    sample_time_ms: 518744.742\n",
      "    update_time_ms: 3.368\n",
      "  timestamp: 1612908365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 844000\n",
      "  training_iteration: 211\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 136.52\n",
      "  episode_reward_max: 118.39864965252964\n",
      "  episode_reward_mean: 68.3022603010643\n",
      "  episode_reward_min: -106.89465794440122\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5342\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34569627046585083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010820768773555756\n",
      "        model: {}\n",
      "        policy_loss: -0.06855788826942444\n",
      "        total_loss: 630.2237548828125\n",
      "        vf_explained_var: 0.6394379138946533\n",
      "        vf_loss: 630.2757568359375\n",
      "    num_steps_sampled: 848000\n",
      "    num_steps_trained: 848000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.18577075098814\n",
      "    ram_util_percent: 39.6604743083004\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06974055146883154\n",
      "    mean_env_wait_ms: 118.28900086409611\n",
      "    mean_inference_ms: 1.6030380541280653\n",
      "    mean_raw_obs_processing_ms: 9.509131197731149\n",
      "  time_since_restore: 5832.34010887146\n",
      "  time_this_iter_s: 531.5799446105957\n",
      "  time_total_s: 115682.83408284187\n",
      "  timers:\n",
      "    learn_throughput: 372.109\n",
      "    learn_time_ms: 10749.541\n",
      "    load_throughput: 10262.115\n",
      "    load_time_ms: 389.783\n",
      "    sample_throughput: 7.736\n",
      "    sample_time_ms: 517063.931\n",
      "    update_time_ms: 3.357\n",
      "  timestamp: 1612908897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 848000\n",
      "  training_iteration: 212\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-23-35\n",
      "  done: false\n",
      "  episode_len_mean: 128.22\n",
      "  episode_reward_max: 118.39781198685688\n",
      "  episode_reward_mean: 66.15294082150768\n",
      "  episode_reward_min: -106.49626118655056\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5374\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3703306317329407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012528005056083202\n",
      "        model: {}\n",
      "        policy_loss: -0.07957421988248825\n",
      "        total_loss: 550.6865844726562\n",
      "        vf_explained_var: 0.7406470775604248\n",
      "        vf_loss: 550.7471313476562\n",
      "    num_steps_sampled: 852000\n",
      "    num_steps_trained: 852000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72814614343709\n",
      "    ram_util_percent: 39.710825439783484\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.069828025006639\n",
      "    mean_env_wait_ms: 118.36789338601075\n",
      "    mean_inference_ms: 1.6039770966385931\n",
      "    mean_raw_obs_processing_ms: 9.489333436044129\n",
      "  time_since_restore: 6350.484675168991\n",
      "  time_this_iter_s: 518.1445662975311\n",
      "  time_total_s: 116200.9786491394\n",
      "  timers:\n",
      "    learn_throughput: 372.083\n",
      "    learn_time_ms: 10750.28\n",
      "    load_throughput: 10303.365\n",
      "    load_time_ms: 388.223\n",
      "    sample_throughput: 7.764\n",
      "    sample_time_ms: 515213.645\n",
      "    update_time_ms: 3.346\n",
      "  timestamp: 1612909415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 852000\n",
      "  training_iteration: 213\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 132.11\n",
      "  episode_reward_max: 118.39781198685688\n",
      "  episode_reward_mean: 64.26172557382843\n",
      "  episode_reward_min: -106.49626118655056\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5403\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39859068393707275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016669824719429016\n",
      "        model: {}\n",
      "        policy_loss: -0.09902878105640411\n",
      "        total_loss: 928.1426391601562\n",
      "        vf_explained_var: 0.615606427192688\n",
      "        vf_loss: 928.2164306640625\n",
      "    num_steps_sampled: 856000\n",
      "    num_steps_trained: 856000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49919246298789\n",
      "    ram_util_percent: 39.75248990578735\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0698164683762275\n",
      "    mean_env_wait_ms: 118.31469458177338\n",
      "    mean_inference_ms: 1.6040230680890095\n",
      "    mean_raw_obs_processing_ms: 9.470671888825322\n",
      "  time_since_restore: 6871.25160741806\n",
      "  time_this_iter_s: 520.7669322490692\n",
      "  time_total_s: 116721.74558138847\n",
      "  timers:\n",
      "    learn_throughput: 372.14\n",
      "    learn_time_ms: 10748.636\n",
      "    load_throughput: 10321.921\n",
      "    load_time_ms: 387.525\n",
      "    sample_throughput: 7.769\n",
      "    sample_time_ms: 514858.597\n",
      "    update_time_ms: 3.323\n",
      "  timestamp: 1612909936\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 856000\n",
      "  training_iteration: 214\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-41-37\n",
      "  done: false\n",
      "  episode_len_mean: 125.82\n",
      "  episode_reward_max: 118.39261575125073\n",
      "  episode_reward_mean: 51.7821219291898\n",
      "  episode_reward_min: -106.49626118655056\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 5436\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.40524041652679443\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015745460987091064\n",
      "        model: {}\n",
      "        policy_loss: -0.09811822324991226\n",
      "        total_loss: 1065.9322509765625\n",
      "        vf_explained_var: 0.6816093325614929\n",
      "        vf_loss: 1066.00634765625\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.31822721598002\n",
      "    ram_util_percent: 39.85081148564294\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0698742522387255\n",
      "    mean_env_wait_ms: 118.37591755059104\n",
      "    mean_inference_ms: 1.604894211865946\n",
      "    mean_raw_obs_processing_ms: 9.471197060300153\n",
      "  time_since_restore: 7432.794239044189\n",
      "  time_this_iter_s: 561.5426316261292\n",
      "  time_total_s: 117283.2882130146\n",
      "  timers:\n",
      "    learn_throughput: 372.191\n",
      "    learn_time_ms: 10747.169\n",
      "    load_throughput: 10300.25\n",
      "    load_time_ms: 388.34\n",
      "    sample_throughput: 7.715\n",
      "    sample_time_ms: 518478.231\n",
      "    update_time_ms: 3.35\n",
      "  timestamp: 1612910497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 215\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-50-23\n",
      "  done: false\n",
      "  episode_len_mean: 131.62\n",
      "  episode_reward_max: 118.39261575125073\n",
      "  episode_reward_mean: 49.6241970143333\n",
      "  episode_reward_min: -106.4034330093584\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5464\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3823293447494507\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015181094408035278\n",
      "        model: {}\n",
      "        policy_loss: -0.08965900540351868\n",
      "        total_loss: 831.5872192382812\n",
      "        vf_explained_var: 0.6600337624549866\n",
      "        vf_loss: 831.65380859375\n",
      "    num_steps_sampled: 864000\n",
      "    num_steps_trained: 864000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.07386666666667\n",
      "    ram_util_percent: 39.76026666666666\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06992486989123056\n",
      "    mean_env_wait_ms: 118.47425768232324\n",
      "    mean_inference_ms: 1.6055897994156567\n",
      "    mean_raw_obs_processing_ms: 9.451918397147683\n",
      "  time_since_restore: 7958.1811537742615\n",
      "  time_this_iter_s: 525.386914730072\n",
      "  time_total_s: 117808.67512774467\n",
      "  timers:\n",
      "    learn_throughput: 372.238\n",
      "    learn_time_ms: 10745.812\n",
      "    load_throughput: 10350.442\n",
      "    load_time_ms: 386.457\n",
      "    sample_throughput: 7.721\n",
      "    sample_time_ms: 518100.992\n",
      "    update_time_ms: 3.366\n",
      "  timestamp: 1612911023\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 864000\n",
      "  training_iteration: 216\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-09_23-59-04\n",
      "  done: false\n",
      "  episode_len_mean: 136.06\n",
      "  episode_reward_max: 118.39261575125073\n",
      "  episode_reward_mean: 58.01018434973405\n",
      "  episode_reward_min: -106.4034330093584\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5494\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3760596513748169\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01462327316403389\n",
      "        model: {}\n",
      "        policy_loss: -0.08527521044015884\n",
      "        total_loss: 749.9008178710938\n",
      "        vf_explained_var: 0.6483868360519409\n",
      "        vf_loss: 749.9640502929688\n",
      "    num_steps_sampled: 868000\n",
      "    num_steps_trained: 868000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.482795698924726\n",
      "    ram_util_percent: 39.79354838709678\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0699708609616078\n",
      "    mean_env_wait_ms: 118.58244688467141\n",
      "    mean_inference_ms: 1.6061777474905967\n",
      "    mean_raw_obs_processing_ms: 9.433881990642373\n",
      "  time_since_restore: 8479.533838272095\n",
      "  time_this_iter_s: 521.3526844978333\n",
      "  time_total_s: 118330.02781224251\n",
      "  timers:\n",
      "    learn_throughput: 372.175\n",
      "    learn_time_ms: 10747.637\n",
      "    load_throughput: 10388.371\n",
      "    load_time_ms: 385.046\n",
      "    sample_throughput: 7.718\n",
      "    sample_time_ms: 518265.303\n",
      "    update_time_ms: 3.397\n",
      "  timestamp: 1612911544\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 868000\n",
      "  training_iteration: 217\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 134.66\n",
      "  episode_reward_max: 118.38538584400176\n",
      "  episode_reward_mean: 64.49763012016085\n",
      "  episode_reward_min: -106.4034330093584\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5525\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4021989107131958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01526737306267023\n",
      "        model: {}\n",
      "        policy_loss: -0.10319027304649353\n",
      "        total_loss: 690.8093872070312\n",
      "        vf_explained_var: 0.7575576901435852\n",
      "        vf_loss: 690.8893432617188\n",
      "    num_steps_sampled: 872000\n",
      "    num_steps_trained: 872000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.37363515312916\n",
      "    ram_util_percent: 39.73635153129161\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06995180966212498\n",
      "    mean_env_wait_ms: 118.56926340409095\n",
      "    mean_inference_ms: 1.6059677677790973\n",
      "    mean_raw_obs_processing_ms: 9.41175756760745\n",
      "  time_since_restore: 9005.88105750084\n",
      "  time_this_iter_s: 526.3472192287445\n",
      "  time_total_s: 118856.37503147125\n",
      "  timers:\n",
      "    learn_throughput: 372.171\n",
      "    learn_time_ms: 10747.744\n",
      "    load_throughput: 10413.989\n",
      "    load_time_ms: 384.099\n",
      "    sample_throughput: 7.716\n",
      "    sample_time_ms: 518387.277\n",
      "    update_time_ms: 3.385\n",
      "  timestamp: 1612912071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 872000\n",
      "  training_iteration: 218\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 126.75\n",
      "  episode_reward_max: 118.3978775443949\n",
      "  episode_reward_mean: 55.807783045953876\n",
      "  episode_reward_min: -106.4034330093584\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5556\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38853704929351807\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012983590364456177\n",
      "        model: {}\n",
      "        policy_loss: -0.08526013046503067\n",
      "        total_loss: 635.9664916992188\n",
      "        vf_explained_var: 0.7270710468292236\n",
      "        vf_loss: 636.031982421875\n",
      "    num_steps_sampled: 876000\n",
      "    num_steps_trained: 876000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.3870320855615\n",
      "    ram_util_percent: 39.733556149732614\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0698981121342121\n",
      "    mean_env_wait_ms: 118.48905364589629\n",
      "    mean_inference_ms: 1.605367397565822\n",
      "    mean_raw_obs_processing_ms: 9.39806908709165\n",
      "  time_since_restore: 9530.036677122116\n",
      "  time_this_iter_s: 524.1556196212769\n",
      "  time_total_s: 119380.53065109253\n",
      "  timers:\n",
      "    learn_throughput: 372.06\n",
      "    learn_time_ms: 10750.946\n",
      "    load_throughput: 10330.984\n",
      "    load_time_ms: 387.185\n",
      "    sample_throughput: 7.719\n",
      "    sample_time_ms: 518213.687\n",
      "    update_time_ms: 3.383\n",
      "  timestamp: 1612912595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 876000\n",
      "  training_iteration: 219\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-25-14\n",
      "  done: false\n",
      "  episode_len_mean: 135.22\n",
      "  episode_reward_max: 118.3978775443949\n",
      "  episode_reward_mean: 64.57938547340594\n",
      "  episode_reward_min: -104.810264303511\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5583\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3952016830444336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016168497502803802\n",
      "        model: {}\n",
      "        policy_loss: -0.09861519932746887\n",
      "        total_loss: 544.4634399414062\n",
      "        vf_explained_var: 0.7608643770217896\n",
      "        vf_loss: 544.5375366210938\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.39622132253711\n",
      "    ram_util_percent: 39.66045883940621\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06985894344809128\n",
      "    mean_env_wait_ms: 118.42396443227328\n",
      "    mean_inference_ms: 1.604926499104505\n",
      "    mean_raw_obs_processing_ms: 9.379690685295252\n",
      "  time_since_restore: 10048.95786356926\n",
      "  time_this_iter_s: 518.9211864471436\n",
      "  time_total_s: 119899.45183753967\n",
      "  timers:\n",
      "    learn_throughput: 372.177\n",
      "    learn_time_ms: 10747.578\n",
      "    load_throughput: 10105.341\n",
      "    load_time_ms: 395.83\n",
      "    sample_throughput: 7.716\n",
      "    sample_time_ms: 518422.11\n",
      "    update_time_ms: 3.423\n",
      "  timestamp: 1612913114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 220\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 128.84\n",
      "  episode_reward_max: 118.3978775443949\n",
      "  episode_reward_mean: 58.169046801264976\n",
      "  episode_reward_min: -104.810264303511\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 5616\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4071144759654999\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013936731033027172\n",
      "        model: {}\n",
      "        policy_loss: -0.09179943799972534\n",
      "        total_loss: 549.5939331054688\n",
      "        vf_explained_var: 0.8084088563919067\n",
      "        vf_loss: 549.6646118164062\n",
      "    num_steps_sampled: 884000\n",
      "    num_steps_trained: 884000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.48146666666666\n",
      "    ram_util_percent: 39.63026666666667\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06981069159101434\n",
      "    mean_env_wait_ms: 118.34503471790482\n",
      "    mean_inference_ms: 1.6044976713921455\n",
      "    mean_raw_obs_processing_ms: 9.370286285722248\n",
      "  time_since_restore: 10574.980285644531\n",
      "  time_this_iter_s: 526.0224220752716\n",
      "  time_total_s: 120425.47425961494\n",
      "  timers:\n",
      "    learn_throughput: 372.919\n",
      "    learn_time_ms: 10726.177\n",
      "    load_throughput: 10151.73\n",
      "    load_time_ms: 394.022\n",
      "    sample_throughput: 7.75\n",
      "    sample_time_ms: 516153.522\n",
      "    update_time_ms: 3.405\n",
      "  timestamp: 1612913640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 884000\n",
      "  training_iteration: 221\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-42-43\n",
      "  done: false\n",
      "  episode_len_mean: 133.24\n",
      "  episode_reward_max: 118.39727598102661\n",
      "  episode_reward_mean: 68.49114500254817\n",
      "  episode_reward_min: -105.11014945249104\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5645\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3763899505138397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011760563589632511\n",
      "        model: {}\n",
      "        policy_loss: -0.0797865092754364\n",
      "        total_loss: 423.8522644042969\n",
      "        vf_explained_var: 0.7701522707939148\n",
      "        vf_loss: 423.9142150878906\n",
      "    num_steps_sampled: 888000\n",
      "    num_steps_trained: 888000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.3380187416332\n",
      "    ram_util_percent: 39.62744310575636\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06976875578396767\n",
      "    mean_env_wait_ms: 118.28445332356154\n",
      "    mean_inference_ms: 1.6041188911869433\n",
      "    mean_raw_obs_processing_ms: 9.354661437757281\n",
      "  time_since_restore: 11098.15774178505\n",
      "  time_this_iter_s: 523.1774561405182\n",
      "  time_total_s: 120948.65171575546\n",
      "  timers:\n",
      "    learn_throughput: 372.843\n",
      "    learn_time_ms: 10728.375\n",
      "    load_throughput: 10049.343\n",
      "    load_time_ms: 398.036\n",
      "    sample_throughput: 7.762\n",
      "    sample_time_ms: 515308.75\n",
      "    update_time_ms: 3.43\n",
      "  timestamp: 1612914163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 888000\n",
      "  training_iteration: 222\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_00-51-20\n",
      "  done: false\n",
      "  episode_len_mean: 135.03\n",
      "  episode_reward_max: 118.39727598102661\n",
      "  episode_reward_mean: 58.29012656358039\n",
      "  episode_reward_min: -105.11014945249104\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5673\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4235011637210846\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017769400030374527\n",
      "        model: {}\n",
      "        policy_loss: -0.10206446051597595\n",
      "        total_loss: 1317.242431640625\n",
      "        vf_explained_var: 0.5585214495658875\n",
      "        vf_loss: 1317.3173828125\n",
      "    num_steps_sampled: 892000\n",
      "    num_steps_trained: 892000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51655359565808\n",
      "    ram_util_percent: 39.67801899592945\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06972738914547522\n",
      "    mean_env_wait_ms: 118.21831596403736\n",
      "    mean_inference_ms: 1.6037760800646228\n",
      "    mean_raw_obs_processing_ms: 9.339964825916008\n",
      "  time_since_restore: 11614.76550936699\n",
      "  time_this_iter_s: 516.6077675819397\n",
      "  time_total_s: 121465.2594833374\n",
      "  timers:\n",
      "    learn_throughput: 372.949\n",
      "    learn_time_ms: 10725.34\n",
      "    load_throughput: 10022.723\n",
      "    load_time_ms: 399.093\n",
      "    sample_throughput: 7.765\n",
      "    sample_time_ms: 515156.135\n",
      "    update_time_ms: 3.456\n",
      "  timestamp: 1612914680\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 892000\n",
      "  training_iteration: 223\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 134.75\n",
      "  episode_reward_max: 118.39604431236562\n",
      "  episode_reward_mean: 66.80768685098683\n",
      "  episode_reward_min: -105.11014945249104\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5704\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3545065224170685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011419621296226978\n",
      "        model: {}\n",
      "        policy_loss: -0.08402487635612488\n",
      "        total_loss: 552.7821044921875\n",
      "        vf_explained_var: 0.7246250510215759\n",
      "        vf_loss: 552.8487548828125\n",
      "    num_steps_sampled: 896000\n",
      "    num_steps_trained: 896000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.5068456375839\n",
      "    ram_util_percent: 39.78859060402685\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06968143584951142\n",
      "    mean_env_wait_ms: 118.14712304427331\n",
      "    mean_inference_ms: 1.6033716757132896\n",
      "    mean_raw_obs_processing_ms: 9.325239462683353\n",
      "  time_since_restore: 12136.508862257004\n",
      "  time_this_iter_s: 521.7433528900146\n",
      "  time_total_s: 121987.00283622742\n",
      "  timers:\n",
      "    learn_throughput: 372.941\n",
      "    learn_time_ms: 10725.562\n",
      "    load_throughput: 10005.16\n",
      "    load_time_ms: 399.794\n",
      "    sample_throughput: 7.763\n",
      "    sample_time_ms: 515250.88\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1612915202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 896000\n",
      "  training_iteration: 224\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 136.45\n",
      "  episode_reward_max: 118.39604431236562\n",
      "  episode_reward_mean: 66.8536278195501\n",
      "  episode_reward_min: -101.6939903166946\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5734\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36472344398498535\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009808284230530262\n",
      "        model: {}\n",
      "        policy_loss: -0.0694395899772644\n",
      "        total_loss: 240.61196899414062\n",
      "        vf_explained_var: 0.8440701365470886\n",
      "        vf_loss: 240.66650390625\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.26403743315508\n",
      "    ram_util_percent: 39.77299465240641\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06963942636529645\n",
      "    mean_env_wait_ms: 118.08350682208297\n",
      "    mean_inference_ms: 1.602971837956861\n",
      "    mean_raw_obs_processing_ms: 9.310449959286673\n",
      "  time_since_restore: 12660.724661588669\n",
      "  time_this_iter_s: 524.215799331665\n",
      "  time_total_s: 122511.21863555908\n",
      "  timers:\n",
      "    learn_throughput: 373.084\n",
      "    learn_time_ms: 10721.444\n",
      "    load_throughput: 9982.028\n",
      "    load_time_ms: 400.72\n",
      "    sample_throughput: 7.82\n",
      "    sample_time_ms: 511522.553\n",
      "    update_time_ms: 3.58\n",
      "  timestamp: 1612915726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 225\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-17-37\n",
      "  done: false\n",
      "  episode_len_mean: 131.28\n",
      "  episode_reward_max: 118.3790287753994\n",
      "  episode_reward_mean: 66.97272390365706\n",
      "  episode_reward_min: -104.82634161724816\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5766\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.375631183385849\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011179999448359013\n",
      "        model: {}\n",
      "        policy_loss: -0.06664775311946869\n",
      "        total_loss: 483.6998291015625\n",
      "        vf_explained_var: 0.7273108959197998\n",
      "        vf_loss: 483.74945068359375\n",
      "    num_steps_sampled: 904000\n",
      "    num_steps_trained: 904000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.08258575197889\n",
      "    ram_util_percent: 39.843799472295515\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06959631449704855\n",
      "    mean_env_wait_ms: 118.04850477495748\n",
      "    mean_inference_ms: 1.602573168763929\n",
      "    mean_raw_obs_processing_ms: 9.310663928175689\n",
      "  time_since_restore: 13192.02332854271\n",
      "  time_this_iter_s: 531.2986669540405\n",
      "  time_total_s: 123042.51730251312\n",
      "  timers:\n",
      "    learn_throughput: 373.154\n",
      "    learn_time_ms: 10719.447\n",
      "    load_throughput: 9911.329\n",
      "    load_time_ms: 403.579\n",
      "    sample_throughput: 7.811\n",
      "    sample_time_ms: 512113.419\n",
      "    update_time_ms: 3.615\n",
      "  timestamp: 1612916257\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 904000\n",
      "  training_iteration: 226\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-26-15\n",
      "  done: false\n",
      "  episode_len_mean: 136.18\n",
      "  episode_reward_max: 118.3969949840616\n",
      "  episode_reward_mean: 74.90861563666573\n",
      "  episode_reward_min: -106.34154478137519\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5793\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4131618142127991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012094116769731045\n",
      "        model: {}\n",
      "        policy_loss: -0.08072967827320099\n",
      "        total_loss: 189.39382934570312\n",
      "        vf_explained_var: 0.9102923274040222\n",
      "        vf_loss: 189.45616149902344\n",
      "    num_steps_sampled: 908000\n",
      "    num_steps_trained: 908000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.437753721244924\n",
      "    ram_util_percent: 39.762110960757774\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0695676720797715\n",
      "    mean_env_wait_ms: 118.02734232001227\n",
      "    mean_inference_ms: 1.6023155951656958\n",
      "    mean_raw_obs_processing_ms: 9.301950987329011\n",
      "  time_since_restore: 13709.501183748245\n",
      "  time_this_iter_s: 517.4778552055359\n",
      "  time_total_s: 123559.99515771866\n",
      "  timers:\n",
      "    learn_throughput: 373.188\n",
      "    learn_time_ms: 10718.463\n",
      "    load_throughput: 9927.838\n",
      "    load_time_ms: 402.907\n",
      "    sample_throughput: 7.817\n",
      "    sample_time_ms: 511729.483\n",
      "    update_time_ms: 3.597\n",
      "  timestamp: 1612916775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 908000\n",
      "  training_iteration: 227\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-35-08\n",
      "  done: false\n",
      "  episode_len_mean: 129.27\n",
      "  episode_reward_max: 118.3969949840616\n",
      "  episode_reward_mean: 68.58974712664153\n",
      "  episode_reward_min: -106.34154478137519\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 5829\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37948763370513916\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011703908443450928\n",
      "        model: {}\n",
      "        policy_loss: -0.08630841225385666\n",
      "        total_loss: 596.18408203125\n",
      "        vf_explained_var: 0.7297237515449524\n",
      "        vf_loss: 596.2526245117188\n",
      "    num_steps_sampled: 912000\n",
      "    num_steps_trained: 912000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.27039473684211\n",
      "    ram_util_percent: 39.720263157894735\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06953961767146864\n",
      "    mean_env_wait_ms: 118.01028946630076\n",
      "    mean_inference_ms: 1.6019961694261133\n",
      "    mean_raw_obs_processing_ms: 9.313539998185963\n",
      "  time_since_restore: 14242.50863146782\n",
      "  time_this_iter_s: 533.007447719574\n",
      "  time_total_s: 124093.00260543823\n",
      "  timers:\n",
      "    learn_throughput: 373.278\n",
      "    learn_time_ms: 10715.887\n",
      "    load_throughput: 9917.827\n",
      "    load_time_ms: 403.314\n",
      "    sample_throughput: 7.806\n",
      "    sample_time_ms: 512397.608\n",
      "    update_time_ms: 3.597\n",
      "  timestamp: 1612917308\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 912000\n",
      "  training_iteration: 228\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-43-53\n",
      "  done: false\n",
      "  episode_len_mean: 127.5\n",
      "  episode_reward_max: 118.39842550449733\n",
      "  episode_reward_mean: 64.49581955380867\n",
      "  episode_reward_min: -106.34154478137519\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5861\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4086587131023407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014609979465603828\n",
      "        model: {}\n",
      "        policy_loss: -0.0944264754652977\n",
      "        total_loss: 1178.078125\n",
      "        vf_explained_var: 0.5142092108726501\n",
      "        vf_loss: 1178.1502685546875\n",
      "    num_steps_sampled: 916000\n",
      "    num_steps_trained: 916000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.450200267022694\n",
      "    ram_util_percent: 39.72016021361816\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06952045427144717\n",
      "    mean_env_wait_ms: 117.97885140882182\n",
      "    mean_inference_ms: 1.6018020253241037\n",
      "    mean_raw_obs_processing_ms: 9.32470450554547\n",
      "  time_since_restore: 14766.96776175499\n",
      "  time_this_iter_s: 524.4591302871704\n",
      "  time_total_s: 124617.4617357254\n",
      "  timers:\n",
      "    learn_throughput: 373.405\n",
      "    learn_time_ms: 10712.234\n",
      "    load_throughput: 10025.687\n",
      "    load_time_ms: 398.975\n",
      "    sample_throughput: 7.806\n",
      "    sample_time_ms: 512438.392\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1612917833\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 916000\n",
      "  training_iteration: 229\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_01-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 121.54\n",
      "  episode_reward_max: 118.39842550449733\n",
      "  episode_reward_mean: 60.63521446616135\n",
      "  episode_reward_min: -105.96584787415419\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5892\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.404553085565567\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015702731907367706\n",
      "        model: {}\n",
      "        policy_loss: -0.10384644567966461\n",
      "        total_loss: 860.2108154296875\n",
      "        vf_explained_var: 0.6867095232009888\n",
      "        vf_loss: 860.2908935546875\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.284441489361704\n",
      "    ram_util_percent: 39.76914893617022\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06950653453007911\n",
      "    mean_env_wait_ms: 117.96080810603274\n",
      "    mean_inference_ms: 1.6015930152701514\n",
      "    mean_raw_obs_processing_ms: 9.346786389571802\n",
      "  time_since_restore: 15294.35606098175\n",
      "  time_this_iter_s: 527.3882992267609\n",
      "  time_total_s: 125144.85003495216\n",
      "  timers:\n",
      "    learn_throughput: 373.482\n",
      "    learn_time_ms: 10710.018\n",
      "    load_throughput: 10220.335\n",
      "    load_time_ms: 391.377\n",
      "    sample_throughput: 7.793\n",
      "    sample_time_ms: 513296.68\n",
      "    update_time_ms: 3.651\n",
      "  timestamp: 1612918360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 230\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-01-29\n",
      "  done: false\n",
      "  episode_len_mean: 124.96\n",
      "  episode_reward_max: 118.39842550449733\n",
      "  episode_reward_mean: 62.67740543385038\n",
      "  episode_reward_min: -107.4490627888949\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 5926\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3975917398929596\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012994581833481789\n",
      "        model: {}\n",
      "        policy_loss: -0.08559347689151764\n",
      "        total_loss: 500.3450012207031\n",
      "        vf_explained_var: 0.7574440240859985\n",
      "        vf_loss: 500.41082763671875\n",
      "    num_steps_sampled: 924000\n",
      "    num_steps_trained: 924000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.38395225464191\n",
      "    ram_util_percent: 39.84045092838196\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06948767046337818\n",
      "    mean_env_wait_ms: 117.93805023447071\n",
      "    mean_inference_ms: 1.6013970974639238\n",
      "    mean_raw_obs_processing_ms: 9.36442021256352\n",
      "  time_since_restore: 15822.67797923088\n",
      "  time_this_iter_s: 528.3219182491302\n",
      "  time_total_s: 125673.1719532013\n",
      "  timers:\n",
      "    learn_throughput: 373.644\n",
      "    learn_time_ms: 10705.388\n",
      "    load_throughput: 10182.382\n",
      "    load_time_ms: 392.835\n",
      "    sample_throughput: 7.789\n",
      "    sample_time_ms: 513531.612\n",
      "    update_time_ms: 3.622\n",
      "  timestamp: 1612918889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 924000\n",
      "  training_iteration: 231\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-10-09\n",
      "  done: false\n",
      "  episode_len_mean: 120.3\n",
      "  episode_reward_max: 118.39951469513582\n",
      "  episode_reward_mean: 68.59211049811397\n",
      "  episode_reward_min: -107.4490627888949\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 5960\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37688902020454407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00973469577729702\n",
      "        model: {}\n",
      "        policy_loss: -0.07460609078407288\n",
      "        total_loss: 343.27105712890625\n",
      "        vf_explained_var: 0.7893316745758057\n",
      "        vf_loss: 343.3307800292969\n",
      "    num_steps_sampled: 928000\n",
      "    num_steps_trained: 928000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.73122476446837\n",
      "    ram_util_percent: 39.84589502018842\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06946979590045169\n",
      "    mean_env_wait_ms: 117.89959902375331\n",
      "    mean_inference_ms: 1.6011788328640475\n",
      "    mean_raw_obs_processing_ms: 9.387379383424062\n",
      "  time_since_restore: 16343.478653430939\n",
      "  time_this_iter_s: 520.800674200058\n",
      "  time_total_s: 126193.97262740135\n",
      "  timers:\n",
      "    learn_throughput: 373.696\n",
      "    learn_time_ms: 10703.882\n",
      "    load_throughput: 10241.202\n",
      "    load_time_ms: 390.579\n",
      "    sample_throughput: 7.793\n",
      "    sample_time_ms: 513298.275\n",
      "    update_time_ms: 3.605\n",
      "  timestamp: 1612919409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 928000\n",
      "  training_iteration: 232\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-18-56\n",
      "  done: false\n",
      "  episode_len_mean: 122.37\n",
      "  episode_reward_max: 118.39951469513582\n",
      "  episode_reward_mean: 68.30844329309222\n",
      "  episode_reward_min: -107.4490627888949\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5990\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3896908164024353\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012185083702206612\n",
      "        model: {}\n",
      "        policy_loss: -0.08600135147571564\n",
      "        total_loss: 339.9822692871094\n",
      "        vf_explained_var: 0.8376960754394531\n",
      "        vf_loss: 340.04974365234375\n",
      "    num_steps_sampled: 932000\n",
      "    num_steps_trained: 932000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.1184840425532\n",
      "    ram_util_percent: 39.861968085106376\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06945377551635952\n",
      "    mean_env_wait_ms: 117.86896684298218\n",
      "    mean_inference_ms: 1.6009884807007069\n",
      "    mean_raw_obs_processing_ms: 9.403574254154499\n",
      "  time_since_restore: 16870.12887263298\n",
      "  time_this_iter_s: 526.6502192020416\n",
      "  time_total_s: 126720.6228466034\n",
      "  timers:\n",
      "    learn_throughput: 373.767\n",
      "    learn_time_ms: 10701.84\n",
      "    load_throughput: 10270.834\n",
      "    load_time_ms: 389.452\n",
      "    sample_throughput: 7.778\n",
      "    sample_time_ms: 514300.741\n",
      "    update_time_ms: 3.579\n",
      "  timestamp: 1612919936\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 932000\n",
      "  training_iteration: 233\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-27-39\n",
      "  done: false\n",
      "  episode_len_mean: 121.68\n",
      "  episode_reward_max: 118.39951469513582\n",
      "  episode_reward_mean: 64.17587692406539\n",
      "  episode_reward_min: -105.88207516812984\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 6023\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4002188444137573\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012468689121305943\n",
      "        model: {}\n",
      "        policy_loss: -0.09416554123163223\n",
      "        total_loss: 795.3223876953125\n",
      "        vf_explained_var: 0.6846733093261719\n",
      "        vf_loss: 795.3976440429688\n",
      "    num_steps_sampled: 936000\n",
      "    num_steps_trained: 936000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.73691275167785\n",
      "    ram_util_percent: 40.00469798657718\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06944019983336709\n",
      "    mean_env_wait_ms: 117.82493538144796\n",
      "    mean_inference_ms: 1.6008359380452737\n",
      "    mean_raw_obs_processing_ms: 9.417097704119907\n",
      "  time_since_restore: 17392.488993406296\n",
      "  time_this_iter_s: 522.3601207733154\n",
      "  time_total_s: 127242.98296737671\n",
      "  timers:\n",
      "    learn_throughput: 373.795\n",
      "    learn_time_ms: 10701.062\n",
      "    load_throughput: 10317.486\n",
      "    load_time_ms: 387.691\n",
      "    sample_throughput: 7.777\n",
      "    sample_time_ms: 514366.062\n",
      "    update_time_ms: 3.429\n",
      "  timestamp: 1612920459\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 936000\n",
      "  training_iteration: 234\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 125.43\n",
      "  episode_reward_max: 118.39818352064461\n",
      "  episode_reward_mean: 66.14284657843405\n",
      "  episode_reward_min: -105.88207516812984\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 6056\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3621053993701935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010412427596747875\n",
      "        model: {}\n",
      "        policy_loss: -0.07137807458639145\n",
      "        total_loss: 70.972900390625\n",
      "        vf_explained_var: 0.9519039988517761\n",
      "        vf_loss: 71.02847290039062\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.265251989389924\n",
      "    ram_util_percent: 40.052387267904514\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06942394060733718\n",
      "    mean_env_wait_ms: 117.80384705886627\n",
      "    mean_inference_ms: 1.6006649335850744\n",
      "    mean_raw_obs_processing_ms: 9.426948829497483\n",
      "  time_since_restore: 17920.99021077156\n",
      "  time_this_iter_s: 528.5012173652649\n",
      "  time_total_s: 127771.48418474197\n",
      "  timers:\n",
      "    learn_throughput: 373.749\n",
      "    learn_time_ms: 10702.374\n",
      "    load_throughput: 10308.084\n",
      "    load_time_ms: 388.045\n",
      "    sample_throughput: 7.77\n",
      "    sample_time_ms: 514788.527\n",
      "    update_time_ms: 3.45\n",
      "  timestamp: 1612920987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 235\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 118.95\n",
      "  episode_reward_max: 118.39820557669739\n",
      "  episode_reward_mean: 68.68508777033611\n",
      "  episode_reward_min: -105.70302600927543\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 6090\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3769032657146454\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00883836206048727\n",
      "        model: {}\n",
      "        policy_loss: -0.07490509003400803\n",
      "        total_loss: 419.6905517578125\n",
      "        vf_explained_var: 0.7561943531036377\n",
      "        vf_loss: 419.7520446777344\n",
      "    num_steps_sampled: 944000\n",
      "    num_steps_trained: 944000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.316931216931216\n",
      "    ram_util_percent: 40.142328042328046\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06940779367379264\n",
      "    mean_env_wait_ms: 117.78173183842391\n",
      "    mean_inference_ms: 1.6005350548435646\n",
      "    mean_raw_obs_processing_ms: 9.44697858010564\n",
      "  time_since_restore: 18450.778151750565\n",
      "  time_this_iter_s: 529.7879409790039\n",
      "  time_total_s: 128301.27212572098\n",
      "  timers:\n",
      "    learn_throughput: 373.722\n",
      "    learn_time_ms: 10703.139\n",
      "    load_throughput: 10311.609\n",
      "    load_time_ms: 387.912\n",
      "    sample_throughput: 7.772\n",
      "    sample_time_ms: 514637.451\n",
      "    update_time_ms: 3.396\n",
      "  timestamp: 1612921517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 944000\n",
      "  training_iteration: 236\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_02-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 119.48\n",
      "  episode_reward_max: 118.3987819289197\n",
      "  episode_reward_mean: 77.28408257107888\n",
      "  episode_reward_min: -105.70302600927543\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 6123\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36623328924179077\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01233309879899025\n",
      "        model: {}\n",
      "        policy_loss: -0.08248881995677948\n",
      "        total_loss: 508.7405700683594\n",
      "        vf_explained_var: 0.6963388323783875\n",
      "        vf_loss: 508.80438232421875\n",
      "    num_steps_sampled: 948000\n",
      "    num_steps_trained: 948000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.94875164257556\n",
      "    ram_util_percent: 40.09145860709594\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06939537648395865\n",
      "    mean_env_wait_ms: 117.78755817760826\n",
      "    mean_inference_ms: 1.600443572974812\n",
      "    mean_raw_obs_processing_ms: 9.465584775121197\n",
      "  time_since_restore: 18984.127566576004\n",
      "  time_this_iter_s: 533.3494148254395\n",
      "  time_total_s: 128834.62154054642\n",
      "  timers:\n",
      "    learn_throughput: 373.825\n",
      "    learn_time_ms: 10700.191\n",
      "    load_throughput: 10344.24\n",
      "    load_time_ms: 386.689\n",
      "    sample_throughput: 7.749\n",
      "    sample_time_ms: 516228.445\n",
      "    update_time_ms: 3.383\n",
      "  timestamp: 1612922050\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 948000\n",
      "  training_iteration: 237\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 127.35\n",
      "  episode_reward_max: 118.3987819289197\n",
      "  episode_reward_mean: 79.64319933787448\n",
      "  episode_reward_min: -100.9123167237203\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 6150\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3793204128742218\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01016020867973566\n",
      "        model: {}\n",
      "        policy_loss: -0.07364923506975174\n",
      "        total_loss: 148.41079711914062\n",
      "        vf_explained_var: 0.8893992304801941\n",
      "        vf_loss: 148.46902465820312\n",
      "    num_steps_sampled: 952000\n",
      "    num_steps_trained: 952000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.30268817204302\n",
      "    ram_util_percent: 40.11626344086022\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06938768158468336\n",
      "    mean_env_wait_ms: 117.79283874167703\n",
      "    mean_inference_ms: 1.6004149870689566\n",
      "    mean_raw_obs_processing_ms: 9.46693475808879\n",
      "  time_since_restore: 19505.68580508232\n",
      "  time_this_iter_s: 521.5582385063171\n",
      "  time_total_s: 129356.17977905273\n",
      "  timers:\n",
      "    learn_throughput: 373.826\n",
      "    learn_time_ms: 10700.163\n",
      "    load_throughput: 10297.258\n",
      "    load_time_ms: 388.453\n",
      "    sample_throughput: 7.766\n",
      "    sample_time_ms: 515081.862\n",
      "    update_time_ms: 3.372\n",
      "  timestamp: 1612922572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 952000\n",
      "  training_iteration: 238\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-11-43\n",
      "  done: false\n",
      "  episode_len_mean: 134.81\n",
      "  episode_reward_max: 118.39921740094591\n",
      "  episode_reward_mean: 90.00238362991297\n",
      "  episode_reward_min: -105.06041095995295\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6179\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3751048445701599\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010476960800588131\n",
      "        model: {}\n",
      "        policy_loss: -0.06833427399396896\n",
      "        total_loss: 189.91024780273438\n",
      "        vf_explained_var: 0.8063831329345703\n",
      "        vf_loss: 189.96266174316406\n",
      "    num_steps_sampled: 956000\n",
      "    num_steps_trained: 956000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.861264822134395\n",
      "    ram_util_percent: 40.13162055335969\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06937900017141979\n",
      "    mean_env_wait_ms: 117.81148098629865\n",
      "    mean_inference_ms: 1.6003698550339704\n",
      "    mean_raw_obs_processing_ms: 9.458924686331398\n",
      "  time_since_restore: 20037.019586086273\n",
      "  time_this_iter_s: 531.333781003952\n",
      "  time_total_s: 129887.51356005669\n",
      "  timers:\n",
      "    learn_throughput: 373.698\n",
      "    learn_time_ms: 10703.84\n",
      "    load_throughput: 10277.354\n",
      "    load_time_ms: 389.205\n",
      "    sample_throughput: 7.755\n",
      "    sample_time_ms: 515765.268\n",
      "    update_time_ms: 3.368\n",
      "  timestamp: 1612923103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 956000\n",
      "  training_iteration: 239\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-20-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.97\n",
      "  episode_reward_max: 118.39921740094591\n",
      "  episode_reward_mean: 87.71435474128289\n",
      "  episode_reward_min: -105.06041095995295\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 6211\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3600043058395386\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008726473897695541\n",
      "        model: {}\n",
      "        policy_loss: -0.06986678391695023\n",
      "        total_loss: 418.94097900390625\n",
      "        vf_explained_var: 0.7331028580665588\n",
      "        vf_loss: 418.9975280761719\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.38535286284953\n",
      "    ram_util_percent: 40.13035952063915\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0693689447162325\n",
      "    mean_env_wait_ms: 117.82274746111437\n",
      "    mean_inference_ms: 1.6003345892255256\n",
      "    mean_raw_obs_processing_ms: 9.447860639676419\n",
      "  time_since_restore: 20563.72141766548\n",
      "  time_this_iter_s: 526.7018315792084\n",
      "  time_total_s: 130414.2153916359\n",
      "  timers:\n",
      "    learn_throughput: 373.603\n",
      "    learn_time_ms: 10706.543\n",
      "    load_throughput: 10312.585\n",
      "    load_time_ms: 387.876\n",
      "    sample_throughput: 7.757\n",
      "    sample_time_ms: 515695.942\n",
      "    update_time_ms: 3.293\n",
      "  timestamp: 1612923630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 240\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.52\n",
      "  episode_reward_max: 118.39921740094591\n",
      "  episode_reward_mean: 89.76269450957243\n",
      "  episode_reward_min: -105.06041095995295\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6240\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39139294624328613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011969340033829212\n",
      "        model: {}\n",
      "        policy_loss: -0.0875021368265152\n",
      "        total_loss: 193.0679473876953\n",
      "        vf_explained_var: 0.8410235047340393\n",
      "        vf_loss: 193.1372833251953\n",
      "    num_steps_sampled: 964000\n",
      "    num_steps_trained: 964000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.19347536617843\n",
      "    ram_util_percent: 40.15059920106525\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06935513337191469\n",
      "    mean_env_wait_ms: 117.83323486837696\n",
      "    mean_inference_ms: 1.6002763018824893\n",
      "    mean_raw_obs_processing_ms: 9.437443521624454\n",
      "  time_since_restore: 21089.69454741478\n",
      "  time_this_iter_s: 525.9731297492981\n",
      "  time_total_s: 130940.1885213852\n",
      "  timers:\n",
      "    learn_throughput: 373.546\n",
      "    learn_time_ms: 10708.187\n",
      "    load_throughput: 10313.293\n",
      "    load_time_ms: 387.849\n",
      "    sample_throughput: 7.76\n",
      "    sample_time_ms: 515453.509\n",
      "    update_time_ms: 3.356\n",
      "  timestamp: 1612924156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 964000\n",
      "  training_iteration: 241\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-38-06\n",
      "  done: false\n",
      "  episode_len_mean: 127.56\n",
      "  episode_reward_max: 118.39331475363147\n",
      "  episode_reward_mean: 91.86027214215795\n",
      "  episode_reward_min: -105.06041095995295\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 6273\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33947816491127014\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006888380739837885\n",
      "        model: {}\n",
      "        policy_loss: -0.06178026273846626\n",
      "        total_loss: 269.9424743652344\n",
      "        vf_explained_var: 0.7762779593467712\n",
      "        vf_loss: 269.9937744140625\n",
      "    num_steps_sampled: 968000\n",
      "    num_steps_trained: 968000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.33298013245033\n",
      "    ram_util_percent: 40.28582781456954\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0693395668979013\n",
      "    mean_env_wait_ms: 117.8360485768798\n",
      "    mean_inference_ms: 1.600286678916367\n",
      "    mean_raw_obs_processing_ms: 9.437720444905462\n",
      "  time_since_restore: 21618.974437475204\n",
      "  time_this_iter_s: 529.2798900604248\n",
      "  time_total_s: 131469.46841144562\n",
      "  timers:\n",
      "    learn_throughput: 373.557\n",
      "    learn_time_ms: 10707.862\n",
      "    load_throughput: 10360.047\n",
      "    load_time_ms: 386.099\n",
      "    sample_throughput: 7.747\n",
      "    sample_time_ms: 516300.185\n",
      "    update_time_ms: 3.323\n",
      "  timestamp: 1612924686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 968000\n",
      "  training_iteration: 242\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 129.49\n",
      "  episode_reward_max: 118.39331475363147\n",
      "  episode_reward_mean: 89.80739836635038\n",
      "  episode_reward_min: -107.41894245995229\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 6303\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36593928933143616\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010076526552438736\n",
      "        model: {}\n",
      "        policy_loss: -0.07489514350891113\n",
      "        total_loss: 318.55072021484375\n",
      "        vf_explained_var: 0.804060697555542\n",
      "        vf_loss: 318.6103210449219\n",
      "    num_steps_sampled: 972000\n",
      "    num_steps_trained: 972000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.97862796833773\n",
      "    ram_util_percent: 40.29445910290237\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06932824013408374\n",
      "    mean_env_wait_ms: 117.84688536826344\n",
      "    mean_inference_ms: 1.6002998298012432\n",
      "    mean_raw_obs_processing_ms: 9.434550362882582\n",
      "  time_since_restore: 22149.892201662064\n",
      "  time_this_iter_s: 530.9177641868591\n",
      "  time_total_s: 132000.38617563248\n",
      "  timers:\n",
      "    learn_throughput: 373.527\n",
      "    learn_time_ms: 10708.739\n",
      "    load_throughput: 10332.29\n",
      "    load_time_ms: 387.136\n",
      "    sample_throughput: 7.741\n",
      "    sample_time_ms: 516730.597\n",
      "    update_time_ms: 3.367\n",
      "  timestamp: 1612925217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 972000\n",
      "  training_iteration: 243\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_03-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 123.15\n",
      "  episode_reward_max: 118.39867869760657\n",
      "  episode_reward_mean: 80.68405437559427\n",
      "  episode_reward_min: -107.41894245995229\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 6337\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38638800382614136\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00940411165356636\n",
      "        model: {}\n",
      "        policy_loss: -0.07414217293262482\n",
      "        total_loss: 300.307373046875\n",
      "        vf_explained_var: 0.8129581212997437\n",
      "        vf_loss: 300.36724853515625\n",
      "    num_steps_sampled: 976000\n",
      "    num_steps_trained: 976000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.31178807947019\n",
      "    ram_util_percent: 40.34198675496689\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06931773176173554\n",
      "    mean_env_wait_ms: 117.85443498527263\n",
      "    mean_inference_ms: 1.6003060646616203\n",
      "    mean_raw_obs_processing_ms: 9.440941454061266\n",
      "  time_since_restore: 22678.723916769028\n",
      "  time_this_iter_s: 528.8317151069641\n",
      "  time_total_s: 132529.21789073944\n",
      "  timers:\n",
      "    learn_throughput: 373.562\n",
      "    learn_time_ms: 10707.715\n",
      "    load_throughput: 10302.416\n",
      "    load_time_ms: 388.258\n",
      "    sample_throughput: 7.731\n",
      "    sample_time_ms: 517375.004\n",
      "    update_time_ms: 3.345\n",
      "  timestamp: 1612925746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 976000\n",
      "  training_iteration: 244\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-04-31\n",
      "  done: false\n",
      "  episode_len_mean: 118.76\n",
      "  episode_reward_max: 118.39867869760657\n",
      "  episode_reward_mean: 67.90969658424348\n",
      "  episode_reward_min: -107.41894245995229\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 6374\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3974478244781494\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016713907942175865\n",
      "        model: {}\n",
      "        policy_loss: -0.10096389800310135\n",
      "        total_loss: 997.5489501953125\n",
      "        vf_explained_var: 0.6760058999061584\n",
      "        vf_loss: 997.62451171875\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.66173333333334\n",
      "    ram_util_percent: 40.41439999999999\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06931196026203398\n",
      "    mean_env_wait_ms: 117.84413043336457\n",
      "    mean_inference_ms: 1.600277429660567\n",
      "    mean_raw_obs_processing_ms: 9.458996371804181\n",
      "  time_since_restore: 23204.338356494904\n",
      "  time_this_iter_s: 525.6144397258759\n",
      "  time_total_s: 133054.83233046532\n",
      "  timers:\n",
      "    learn_throughput: 373.579\n",
      "    learn_time_ms: 10707.241\n",
      "    load_throughput: 10375.147\n",
      "    load_time_ms: 385.537\n",
      "    sample_throughput: 7.736\n",
      "    sample_time_ms: 517092.837\n",
      "    update_time_ms: 3.431\n",
      "  timestamp: 1612926271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 245\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-13-22\n",
      "  done: false\n",
      "  episode_len_mean: 120.5\n",
      "  episode_reward_max: 118.39867869760657\n",
      "  episode_reward_mean: 68.12611709596868\n",
      "  episode_reward_min: -106.01936315125033\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6403\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38961461186408997\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013192914426326752\n",
      "        model: {}\n",
      "        policy_loss: -0.08568117022514343\n",
      "        total_loss: 65.19156646728516\n",
      "        vf_explained_var: 0.9548618793487549\n",
      "        vf_loss: 65.25720977783203\n",
      "    num_steps_sampled: 984000\n",
      "    num_steps_trained: 984000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.9784676354029\n",
      "    ram_util_percent: 40.42721268163804\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0693065146607158\n",
      "    mean_env_wait_ms: 117.8356198894298\n",
      "    mean_inference_ms: 1.6002390450543982\n",
      "    mean_raw_obs_processing_ms: 9.47159222265225\n",
      "  time_since_restore: 23734.42484307289\n",
      "  time_this_iter_s: 530.0864865779877\n",
      "  time_total_s: 133584.9188170433\n",
      "  timers:\n",
      "    learn_throughput: 373.709\n",
      "    learn_time_ms: 10703.522\n",
      "    load_throughput: 10362.505\n",
      "    load_time_ms: 386.007\n",
      "    sample_throughput: 7.735\n",
      "    sample_time_ms: 517125.874\n",
      "    update_time_ms: 3.454\n",
      "  timestamp: 1612926802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 984000\n",
      "  training_iteration: 246\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-22-07\n",
      "  done: false\n",
      "  episode_len_mean: 123.29\n",
      "  episode_reward_max: 118.39775314424688\n",
      "  episode_reward_mean: 75.1126557353323\n",
      "  episode_reward_min: -105.14680184699387\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6434\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3633507490158081\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008570302277803421\n",
      "        model: {}\n",
      "        policy_loss: -0.07135342061519623\n",
      "        total_loss: 429.0644226074219\n",
      "        vf_explained_var: 0.7002447247505188\n",
      "        vf_loss: 429.1227722167969\n",
      "    num_steps_sampled: 988000\n",
      "    num_steps_trained: 988000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34699599465955\n",
      "    ram_util_percent: 40.42309746328438\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06930232645239451\n",
      "    mean_env_wait_ms: 117.82627443300765\n",
      "    mean_inference_ms: 1.6001871674282546\n",
      "    mean_raw_obs_processing_ms: 9.478449373207093\n",
      "  time_since_restore: 24259.33223247528\n",
      "  time_this_iter_s: 524.9073894023895\n",
      "  time_total_s: 134109.8262064457\n",
      "  timers:\n",
      "    learn_throughput: 373.606\n",
      "    learn_time_ms: 10706.477\n",
      "    load_throughput: 10353.171\n",
      "    load_time_ms: 386.355\n",
      "    sample_throughput: 7.748\n",
      "    sample_time_ms: 516274.479\n",
      "    update_time_ms: 3.472\n",
      "  timestamp: 1612927327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 988000\n",
      "  training_iteration: 247\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-30-53\n",
      "  done: false\n",
      "  episode_len_mean: 127.17\n",
      "  episode_reward_max: 118.39995180589602\n",
      "  episode_reward_mean: 79.45895675081228\n",
      "  episode_reward_min: -105.14680184699387\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6465\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4038982093334198\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012797950766980648\n",
      "        model: {}\n",
      "        policy_loss: -0.1006801649928093\n",
      "        total_loss: 671.1112060546875\n",
      "        vf_explained_var: 0.685676634311676\n",
      "        vf_loss: 671.1925048828125\n",
      "    num_steps_sampled: 992000\n",
      "    num_steps_trained: 992000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.267287234042556\n",
      "    ram_util_percent: 40.44281914893617\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06929929343814976\n",
      "    mean_env_wait_ms: 117.82996716113736\n",
      "    mean_inference_ms: 1.6001574052564382\n",
      "    mean_raw_obs_processing_ms: 9.474060235025725\n",
      "  time_since_restore: 24786.087637662888\n",
      "  time_this_iter_s: 526.7554051876068\n",
      "  time_total_s: 134636.5816116333\n",
      "  timers:\n",
      "    learn_throughput: 373.537\n",
      "    learn_time_ms: 10708.436\n",
      "    load_throughput: 10404.718\n",
      "    load_time_ms: 384.441\n",
      "    sample_throughput: 7.74\n",
      "    sample_time_ms: 516792.623\n",
      "    update_time_ms: 3.472\n",
      "  timestamp: 1612927853\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 992000\n",
      "  training_iteration: 248\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 132.98\n",
      "  episode_reward_max: 118.39995180589602\n",
      "  episode_reward_mean: 81.1533220396214\n",
      "  episode_reward_min: -115.51812555801372\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6494\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4085550606250763\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010802485048770905\n",
      "        model: {}\n",
      "        policy_loss: -0.08306783437728882\n",
      "        total_loss: 390.42413330078125\n",
      "        vf_explained_var: 0.7626205682754517\n",
      "        vf_loss: 390.4908142089844\n",
      "    num_steps_sampled: 996000\n",
      "    num_steps_trained: 996000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.373056300268104\n",
      "    ram_util_percent: 40.46353887399463\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692980132923425\n",
      "    mean_env_wait_ms: 117.82636280612914\n",
      "    mean_inference_ms: 1.600159299578397\n",
      "    mean_raw_obs_processing_ms: 9.467822501756554\n",
      "  time_since_restore: 25309.228896856308\n",
      "  time_this_iter_s: 523.1412591934204\n",
      "  time_total_s: 135159.72287082672\n",
      "  timers:\n",
      "    learn_throughput: 373.597\n",
      "    learn_time_ms: 10706.733\n",
      "    load_throughput: 10303.502\n",
      "    load_time_ms: 388.218\n",
      "    sample_throughput: 7.752\n",
      "    sample_time_ms: 515971.515\n",
      "    update_time_ms: 3.456\n",
      "  timestamp: 1612928377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 996000\n",
      "  training_iteration: 249\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-48-20\n",
      "  done: false\n",
      "  episode_len_mean: 134.56\n",
      "  episode_reward_max: 118.39995180589602\n",
      "  episode_reward_mean: 80.85583108969614\n",
      "  episode_reward_min: -115.51812555801372\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6523\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3705100119113922\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009354713372886181\n",
      "        model: {}\n",
      "        policy_loss: -0.07160551846027374\n",
      "        total_loss: 447.101318359375\n",
      "        vf_explained_var: 0.6971088647842407\n",
      "        vf_loss: 447.15875244140625\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.337265415549595\n",
      "    ram_util_percent: 40.4828418230563\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06929621072584825\n",
      "    mean_env_wait_ms: 117.81938511959008\n",
      "    mean_inference_ms: 1.6001894571800315\n",
      "    mean_raw_obs_processing_ms: 9.459822386462156\n",
      "  time_since_restore: 25832.122779130936\n",
      "  time_this_iter_s: 522.8938822746277\n",
      "  time_total_s: 135682.61675310135\n",
      "  timers:\n",
      "    learn_throughput: 373.5\n",
      "    learn_time_ms: 10709.496\n",
      "    load_throughput: 10294.072\n",
      "    load_time_ms: 388.573\n",
      "    sample_throughput: 7.758\n",
      "    sample_time_ms: 515586.867\n",
      "    update_time_ms: 3.452\n",
      "  timestamp: 1612928900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 250\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_04-57-07\n",
      "  done: false\n",
      "  episode_len_mean: 133.8\n",
      "  episode_reward_max: 118.39976690190446\n",
      "  episode_reward_mean: 81.05574716238327\n",
      "  episode_reward_min: -115.51812555801372\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 6555\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3448770344257355\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00883668102324009\n",
      "        model: {}\n",
      "        policy_loss: -0.07867418974637985\n",
      "        total_loss: 444.0412902832031\n",
      "        vf_explained_var: 0.7407037615776062\n",
      "        vf_loss: 444.10650634765625\n",
      "    num_steps_sampled: 1004000\n",
      "    num_steps_trained: 1004000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.25073041168659\n",
      "    ram_util_percent: 40.49535192563081\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692935270129379\n",
      "    mean_env_wait_ms: 117.81151708014092\n",
      "    mean_inference_ms: 1.6002313950560296\n",
      "    mean_raw_obs_processing_ms: 9.453415676255533\n",
      "  time_since_restore: 26359.432138442993\n",
      "  time_this_iter_s: 527.3093593120575\n",
      "  time_total_s: 136209.9261124134\n",
      "  timers:\n",
      "    learn_throughput: 373.472\n",
      "    learn_time_ms: 10710.31\n",
      "    load_throughput: 10300.951\n",
      "    load_time_ms: 388.314\n",
      "    sample_throughput: 7.756\n",
      "    sample_time_ms: 515724.919\n",
      "    update_time_ms: 3.387\n",
      "  timestamp: 1612929427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1004000\n",
      "  training_iteration: 251\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-05-55\n",
      "  done: false\n",
      "  episode_len_mean: 129.17\n",
      "  episode_reward_max: 118.39976690190446\n",
      "  episode_reward_mean: 85.83263967952371\n",
      "  episode_reward_min: -106.37789142805315\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6586\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3803326189517975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009797744452953339\n",
      "        model: {}\n",
      "        policy_loss: -0.07274545729160309\n",
      "        total_loss: 558.324951171875\n",
      "        vf_explained_var: 0.6885911226272583\n",
      "        vf_loss: 558.3828125\n",
      "    num_steps_sampled: 1008000\n",
      "    num_steps_trained: 1008000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.15875331564986\n",
      "    ram_util_percent: 40.490053050397876\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928874154820043\n",
      "    mean_env_wait_ms: 117.80745846136251\n",
      "    mean_inference_ms: 1.6001937942611622\n",
      "    mean_raw_obs_processing_ms: 9.450316410901385\n",
      "  time_since_restore: 26887.66395688057\n",
      "  time_this_iter_s: 528.2318184375763\n",
      "  time_total_s: 136738.15793085098\n",
      "  timers:\n",
      "    learn_throughput: 373.533\n",
      "    learn_time_ms: 10708.57\n",
      "    load_throughput: 10287.053\n",
      "    load_time_ms: 388.838\n",
      "    sample_throughput: 7.758\n",
      "    sample_time_ms: 515622.783\n",
      "    update_time_ms: 3.433\n",
      "  timestamp: 1612929955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1008000\n",
      "  training_iteration: 252\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-14-42\n",
      "  done: false\n",
      "  episode_len_mean: 124.71\n",
      "  episode_reward_max: 118.39976690190446\n",
      "  episode_reward_mean: 77.69832512584883\n",
      "  episode_reward_min: -106.37223072804238\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6617\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3632063567638397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008575016632676125\n",
      "        model: {}\n",
      "        policy_loss: -0.0754043310880661\n",
      "        total_loss: 201.8621826171875\n",
      "        vf_explained_var: 0.8663883805274963\n",
      "        vf_loss: 201.92457580566406\n",
      "    num_steps_sampled: 1012000\n",
      "    num_steps_trained: 1012000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.32490013315579\n",
      "    ram_util_percent: 40.581091877496675\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928220287693236\n",
      "    mean_env_wait_ms: 117.80595248762413\n",
      "    mean_inference_ms: 1.6001431022087758\n",
      "    mean_raw_obs_processing_ms: 9.45096879562043\n",
      "  time_since_restore: 27414.161765813828\n",
      "  time_this_iter_s: 526.497808933258\n",
      "  time_total_s: 137264.65573978424\n",
      "  timers:\n",
      "    learn_throughput: 373.494\n",
      "    learn_time_ms: 10709.677\n",
      "    load_throughput: 10247.298\n",
      "    load_time_ms: 390.347\n",
      "    sample_throughput: 7.764\n",
      "    sample_time_ms: 515178.276\n",
      "    update_time_ms: 3.406\n",
      "  timestamp: 1612930482\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1012000\n",
      "  training_iteration: 253\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-23-33\n",
      "  done: false\n",
      "  episode_len_mean: 132.0\n",
      "  episode_reward_max: 118.39976690190446\n",
      "  episode_reward_mean: 81.78724985242903\n",
      "  episode_reward_min: -106.37223072804238\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 6647\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3395882546901703\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009102328680455685\n",
      "        model: {}\n",
      "        policy_loss: -0.0652804970741272\n",
      "        total_loss: 602.163330078125\n",
      "        vf_explained_var: 0.6065481305122375\n",
      "        vf_loss: 602.2147216796875\n",
      "    num_steps_sampled: 1016000\n",
      "    num_steps_trained: 1016000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.97572559366755\n",
      "    ram_util_percent: 40.472559366754616\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06927586002715275\n",
      "    mean_env_wait_ms: 117.81394728556552\n",
      "    mean_inference_ms: 1.6000517334526334\n",
      "    mean_raw_obs_processing_ms: 9.449048254847897\n",
      "  time_since_restore: 27945.084828853607\n",
      "  time_this_iter_s: 530.9230630397797\n",
      "  time_total_s: 137795.57880282402\n",
      "  timers:\n",
      "    learn_throughput: 373.406\n",
      "    learn_time_ms: 10712.198\n",
      "    load_throughput: 10289.507\n",
      "    load_time_ms: 388.746\n",
      "    sample_throughput: 7.761\n",
      "    sample_time_ms: 515389.422\n",
      "    update_time_ms: 3.396\n",
      "  timestamp: 1612931013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1016000\n",
      "  training_iteration: 254\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-32-14\n",
      "  done: false\n",
      "  episode_len_mean: 135.05\n",
      "  episode_reward_max: 118.3991721218048\n",
      "  episode_reward_mean: 83.63744173862409\n",
      "  episode_reward_min: -106.37223072804238\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 6675\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3725070655345917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010309828445315361\n",
      "        model: {}\n",
      "        policy_loss: -0.07095495611429214\n",
      "        total_loss: 187.0923309326172\n",
      "        vf_explained_var: 0.8470891118049622\n",
      "        vf_loss: 187.14761352539062\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.324226110363384\n",
      "    ram_util_percent: 40.493135935397035\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06927126217898735\n",
      "    mean_env_wait_ms: 117.81721489263799\n",
      "    mean_inference_ms: 1.6000174089626649\n",
      "    mean_raw_obs_processing_ms: 9.44205960058755\n",
      "  time_since_restore: 28465.991718769073\n",
      "  time_this_iter_s: 520.9068899154663\n",
      "  time_total_s: 138316.4856927395\n",
      "  timers:\n",
      "    learn_throughput: 373.433\n",
      "    learn_time_ms: 10711.439\n",
      "    load_throughput: 10221.943\n",
      "    load_time_ms: 391.315\n",
      "    sample_throughput: 7.768\n",
      "    sample_time_ms: 514916.397\n",
      "    update_time_ms: 3.285\n",
      "  timestamp: 1612931534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 255\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-40-53\n",
      "  done: false\n",
      "  episode_len_mean: 137.62\n",
      "  episode_reward_max: 118.3991721218048\n",
      "  episode_reward_mean: 81.75838916499559\n",
      "  episode_reward_min: -102.87272157988244\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 6702\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4156583845615387\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013777113519608974\n",
      "        model: {}\n",
      "        policy_loss: -0.10282169282436371\n",
      "        total_loss: 612.8851928710938\n",
      "        vf_explained_var: 0.7260733246803284\n",
      "        vf_loss: 612.9671020507812\n",
      "    num_steps_sampled: 1024000\n",
      "    num_steps_trained: 1024000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.42702702702703\n",
      "    ram_util_percent: 40.51783783783784\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692643657295874\n",
      "    mean_env_wait_ms: 117.81588355220381\n",
      "    mean_inference_ms: 1.599989229536461\n",
      "    mean_raw_obs_processing_ms: 9.429475058281788\n",
      "  time_since_restore: 28984.57059931755\n",
      "  time_this_iter_s: 518.5788805484772\n",
      "  time_total_s: 138835.06457328796\n",
      "  timers:\n",
      "    learn_throughput: 373.304\n",
      "    learn_time_ms: 10715.137\n",
      "    load_throughput: 10355.598\n",
      "    load_time_ms: 386.265\n",
      "    sample_throughput: 7.786\n",
      "    sample_time_ms: 513766.999\n",
      "    update_time_ms: 3.259\n",
      "  timestamp: 1612932053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024000\n",
      "  training_iteration: 256\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-49-39\n",
      "  done: false\n",
      "  episode_len_mean: 133.93\n",
      "  episode_reward_max: 118.3991721218048\n",
      "  episode_reward_mean: 83.72954438039181\n",
      "  episode_reward_min: -99.05824168544535\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 6737\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38026756048202515\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011028818786144257\n",
      "        model: {}\n",
      "        policy_loss: -0.08933175355195999\n",
      "        total_loss: 561.9575805664062\n",
      "        vf_explained_var: 0.7296318411827087\n",
      "        vf_loss: 562.0301513671875\n",
      "    num_steps_sampled: 1028000\n",
      "    num_steps_trained: 1028000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.5595206391478\n",
      "    ram_util_percent: 40.54727030625832\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.069257745908199\n",
      "    mean_env_wait_ms: 117.80042400681265\n",
      "    mean_inference_ms: 1.5999936684549292\n",
      "    mean_raw_obs_processing_ms: 9.422013498121755\n",
      "  time_since_restore: 29510.404690265656\n",
      "  time_this_iter_s: 525.8340909481049\n",
      "  time_total_s: 139360.89866423607\n",
      "  timers:\n",
      "    learn_throughput: 373.345\n",
      "    learn_time_ms: 10713.943\n",
      "    load_throughput: 10319.777\n",
      "    load_time_ms: 387.605\n",
      "    sample_throughput: 7.784\n",
      "    sample_time_ms: 513862.277\n",
      "    update_time_ms: 3.235\n",
      "  timestamp: 1612932579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1028000\n",
      "  training_iteration: 257\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_05-58-22\n",
      "  done: false\n",
      "  episode_len_mean: 134.31\n",
      "  episode_reward_max: 118.39649847606634\n",
      "  episode_reward_mean: 87.83046871946243\n",
      "  episode_reward_min: -99.05824168544535\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 6765\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35737162828445435\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008245186880230904\n",
      "        model: {}\n",
      "        policy_loss: -0.05744369700551033\n",
      "        total_loss: 133.61537170410156\n",
      "        vf_explained_var: 0.8582574725151062\n",
      "        vf_loss: 133.66029357910156\n",
      "    num_steps_sampled: 1032000\n",
      "    num_steps_trained: 1032000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.18755020080321\n",
      "    ram_util_percent: 40.4619812583668\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06925293718327002\n",
      "    mean_env_wait_ms: 117.78800108131202\n",
      "    mean_inference_ms: 1.6000052755288174\n",
      "    mean_raw_obs_processing_ms: 9.415400140513942\n",
      "  time_since_restore: 30034.22373008728\n",
      "  time_this_iter_s: 523.8190398216248\n",
      "  time_total_s: 139884.7177040577\n",
      "  timers:\n",
      "    learn_throughput: 373.433\n",
      "    learn_time_ms: 10711.422\n",
      "    load_throughput: 10315.104\n",
      "    load_time_ms: 387.781\n",
      "    sample_throughput: 7.789\n",
      "    sample_time_ms: 513568.066\n",
      "    update_time_ms: 3.279\n",
      "  timestamp: 1612933102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1032000\n",
      "  training_iteration: 258\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-07-09\n",
      "  done: false\n",
      "  episode_len_mean: 128.24\n",
      "  episode_reward_max: 118.39649847606634\n",
      "  episode_reward_mean: 85.60566402728037\n",
      "  episode_reward_min: -105.108323360269\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6796\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3514731526374817\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01100051961839199\n",
      "        model: {}\n",
      "        policy_loss: -0.0751851424574852\n",
      "        total_loss: 631.9628295898438\n",
      "        vf_explained_var: 0.6407285332679749\n",
      "        vf_loss: 632.0213623046875\n",
      "    num_steps_sampled: 1036000\n",
      "    num_steps_trained: 1036000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.746737683089215\n",
      "    ram_util_percent: 40.47003994673768\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06925086672239267\n",
      "    mean_env_wait_ms: 117.77832740152488\n",
      "    mean_inference_ms: 1.6000539503523101\n",
      "    mean_raw_obs_processing_ms: 9.414609961651996\n",
      "  time_since_restore: 30560.631703853607\n",
      "  time_this_iter_s: 526.4079737663269\n",
      "  time_total_s: 140411.12567782402\n",
      "  timers:\n",
      "    learn_throughput: 373.38\n",
      "    learn_time_ms: 10712.95\n",
      "    load_throughput: 10305.009\n",
      "    load_time_ms: 388.161\n",
      "    sample_throughput: 7.784\n",
      "    sample_time_ms: 513891.568\n",
      "    update_time_ms: 3.297\n",
      "  timestamp: 1612933629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1036000\n",
      "  training_iteration: 259\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-16-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.05\n",
      "  episode_reward_max: 118.39649847606634\n",
      "  episode_reward_mean: 83.60177048380372\n",
      "  episode_reward_min: -105.108323360269\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 6828\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3544729948043823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010000239126384258\n",
      "        model: {}\n",
      "        policy_loss: -0.07471056282520294\n",
      "        total_loss: 532.3400268554688\n",
      "        vf_explained_var: 0.7062293887138367\n",
      "        vf_loss: 532.3995361328125\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.68766954377311\n",
      "    ram_util_percent: 40.505178791615286\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06926212703198636\n",
      "    mean_env_wait_ms: 117.83010382371107\n",
      "    mean_inference_ms: 1.6006805121075827\n",
      "    mean_raw_obs_processing_ms: 9.412745186086566\n",
      "  time_since_restore: 31128.8429479599\n",
      "  time_this_iter_s: 568.2112441062927\n",
      "  time_total_s: 140979.3369219303\n",
      "  timers:\n",
      "    learn_throughput: 373.454\n",
      "    learn_time_ms: 10710.837\n",
      "    load_throughput: 10227.939\n",
      "    load_time_ms: 391.086\n",
      "    sample_throughput: 7.716\n",
      "    sample_time_ms: 518422.604\n",
      "    update_time_ms: 3.318\n",
      "  timestamp: 1612934197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 260\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-25-24\n",
      "  done: false\n",
      "  episode_len_mean: 130.17\n",
      "  episode_reward_max: 118.38580713470606\n",
      "  episode_reward_mean: 79.39752787494295\n",
      "  episode_reward_min: -105.108323360269\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6857\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3593236207962036\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009192650206387043\n",
      "        model: {}\n",
      "        policy_loss: -0.06643503159284592\n",
      "        total_loss: 317.1968688964844\n",
      "        vf_explained_var: 0.7956193089485168\n",
      "        vf_loss: 317.2492980957031\n",
      "    num_steps_sampled: 1044000\n",
      "    num_steps_trained: 1044000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.11143617021277\n",
      "    ram_util_percent: 40.22047872340425\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06927224843781402\n",
      "    mean_env_wait_ms: 117.87998216892636\n",
      "    mean_inference_ms: 1.6012623686942706\n",
      "    mean_raw_obs_processing_ms: 9.410415330306622\n",
      "  time_since_restore: 31655.84609746933\n",
      "  time_this_iter_s: 527.0031495094299\n",
      "  time_total_s: 141506.34007143974\n",
      "  timers:\n",
      "    learn_throughput: 373.485\n",
      "    learn_time_ms: 10709.926\n",
      "    load_throughput: 10245.904\n",
      "    load_time_ms: 390.4\n",
      "    sample_throughput: 7.716\n",
      "    sample_time_ms: 518392.203\n",
      "    update_time_ms: 3.336\n",
      "  timestamp: 1612934724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1044000\n",
      "  training_iteration: 261\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-34-13\n",
      "  done: false\n",
      "  episode_len_mean: 129.49\n",
      "  episode_reward_max: 118.39824125693927\n",
      "  episode_reward_mean: 79.24406138191725\n",
      "  episode_reward_min: -105.108323360269\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 6888\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34594857692718506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008483709767460823\n",
      "        model: {}\n",
      "        policy_loss: -0.0662190392613411\n",
      "        total_loss: 186.4908447265625\n",
      "        vf_explained_var: 0.8455460667610168\n",
      "        vf_loss: 186.54417419433594\n",
      "    num_steps_sampled: 1048000\n",
      "    num_steps_trained: 1048000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.209549071618035\n",
      "    ram_util_percent: 40.25928381962865\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928216808832993\n",
      "    mean_env_wait_ms: 117.93462148463153\n",
      "    mean_inference_ms: 1.6018289707504474\n",
      "    mean_raw_obs_processing_ms: 9.409357172458153\n",
      "  time_since_restore: 32184.06649661064\n",
      "  time_this_iter_s: 528.2203991413116\n",
      "  time_total_s: 142034.56047058105\n",
      "  timers:\n",
      "    learn_throughput: 373.448\n",
      "    learn_time_ms: 10711.004\n",
      "    load_throughput: 10236.371\n",
      "    load_time_ms: 390.763\n",
      "    sample_throughput: 7.716\n",
      "    sample_time_ms: 518390.816\n",
      "    update_time_ms: 3.308\n",
      "  timestamp: 1612935253\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1048000\n",
      "  training_iteration: 262\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 134.7\n",
      "  episode_reward_max: 118.39824125693927\n",
      "  episode_reward_mean: 83.62067637720499\n",
      "  episode_reward_min: -104.85008915358314\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 6915\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3844476044178009\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010237504728138447\n",
      "        model: {}\n",
      "        policy_loss: -0.07038916647434235\n",
      "        total_loss: 496.0287170410156\n",
      "        vf_explained_var: 0.6634261012077332\n",
      "        vf_loss: 496.08367919921875\n",
      "    num_steps_sampled: 1052000\n",
      "    num_steps_trained: 1052000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.21954484605087\n",
      "    ram_util_percent: 40.2809906291834\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928366145585907\n",
      "    mean_env_wait_ms: 117.95154516633418\n",
      "    mean_inference_ms: 1.6019173655563566\n",
      "    mean_raw_obs_processing_ms: 9.401972036509285\n",
      "  time_since_restore: 32707.550357341766\n",
      "  time_this_iter_s: 523.4838607311249\n",
      "  time_total_s: 142558.04433131218\n",
      "  timers:\n",
      "    learn_throughput: 373.499\n",
      "    learn_time_ms: 10709.523\n",
      "    load_throughput: 10284.31\n",
      "    load_time_ms: 388.942\n",
      "    sample_throughput: 7.721\n",
      "    sample_time_ms: 518090.868\n",
      "    update_time_ms: 3.328\n",
      "  timestamp: 1612935776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1052000\n",
      "  training_iteration: 263\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_06-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 132.53\n",
      "  episode_reward_max: 118.39824125693927\n",
      "  episode_reward_mean: 85.79009329627091\n",
      "  episode_reward_min: -98.82845309206152\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 6949\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3898640275001526\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012257159687578678\n",
      "        model: {}\n",
      "        policy_loss: -0.08705633133649826\n",
      "        total_loss: 754.8258666992188\n",
      "        vf_explained_var: 0.6555668711662292\n",
      "        vf_loss: 754.8944091796875\n",
      "    num_steps_sampled: 1056000\n",
      "    num_steps_trained: 1056000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.25587846763541\n",
      "    ram_util_percent: 40.23817701453104\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928193335118149\n",
      "    mean_env_wait_ms: 117.95359603329948\n",
      "    mean_inference_ms: 1.6018059597783378\n",
      "    mean_raw_obs_processing_ms: 9.398420222244923\n",
      "  time_since_restore: 33237.608710289\n",
      "  time_this_iter_s: 530.0583529472351\n",
      "  time_total_s: 143088.10268425941\n",
      "  timers:\n",
      "    learn_throughput: 373.532\n",
      "    learn_time_ms: 10708.584\n",
      "    load_throughput: 10179.306\n",
      "    load_time_ms: 392.954\n",
      "    sample_throughput: 7.722\n",
      "    sample_time_ms: 518001.435\n",
      "    update_time_ms: 3.342\n",
      "  timestamp: 1612936306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056000\n",
      "  training_iteration: 264\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-01-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.12\n",
      "  episode_reward_max: 118.39824125693927\n",
      "  episode_reward_mean: 81.47117357207296\n",
      "  episode_reward_min: -106.38216724440176\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6978\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39508214592933655\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010031311772763729\n",
      "        model: {}\n",
      "        policy_loss: -0.07565855979919434\n",
      "        total_loss: 354.84161376953125\n",
      "        vf_explained_var: 0.7663719654083252\n",
      "        vf_loss: 354.90203857421875\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.79052890528905\n",
      "    ram_util_percent: 40.269987699877\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06929920923964472\n",
      "    mean_env_wait_ms: 118.00207648844453\n",
      "    mean_inference_ms: 1.6019380236310843\n",
      "    mean_raw_obs_processing_ms: 9.39443753144497\n",
      "  time_since_restore: 33807.324840307236\n",
      "  time_this_iter_s: 569.7161300182343\n",
      "  time_total_s: 143657.81881427765\n",
      "  timers:\n",
      "    learn_throughput: 369.443\n",
      "    learn_time_ms: 10827.108\n",
      "    load_throughput: 10149.911\n",
      "    load_time_ms: 394.092\n",
      "    sample_throughput: 7.652\n",
      "    sample_time_ms: 522759.33\n",
      "    update_time_ms: 3.368\n",
      "  timestamp: 1612936876\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 265\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 132.45\n",
      "  episode_reward_max: 118.39257948109737\n",
      "  episode_reward_mean: 85.37231120307699\n",
      "  episode_reward_min: -106.38216724440176\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 7006\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3483186662197113\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008010245859622955\n",
      "        model: {}\n",
      "        policy_loss: -0.05721196532249451\n",
      "        total_loss: 212.0830841064453\n",
      "        vf_explained_var: 0.7778230309486389\n",
      "        vf_loss: 212.1281280517578\n",
      "    num_steps_sampled: 1064000\n",
      "    num_steps_trained: 1064000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.3830808080808\n",
      "    ram_util_percent: 40.35037878787878\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06933076654768668\n",
      "    mean_env_wait_ms: 118.07893922329464\n",
      "    mean_inference_ms: 1.6022921866095237\n",
      "    mean_raw_obs_processing_ms: 9.39082092427615\n",
      "  time_since_restore: 34362.60400271416\n",
      "  time_this_iter_s: 555.2791624069214\n",
      "  time_total_s: 144213.09797668457\n",
      "  timers:\n",
      "    learn_throughput: 365.255\n",
      "    learn_time_ms: 10951.265\n",
      "    load_throughput: 10001.62\n",
      "    load_time_ms: 399.935\n",
      "    sample_throughput: 7.6\n",
      "    sample_time_ms: 526296.591\n",
      "    update_time_ms: 3.384\n",
      "  timestamp: 1612937432\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1064000\n",
      "  training_iteration: 266\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-19-17\n",
      "  done: false\n",
      "  episode_len_mean: 127.94\n",
      "  episode_reward_max: 118.3911407878765\n",
      "  episode_reward_mean: 89.54052084198247\n",
      "  episode_reward_min: -106.38216724440176\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 7040\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36846548318862915\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007897048257291317\n",
      "        model: {}\n",
      "        policy_loss: -0.07120607048273087\n",
      "        total_loss: 170.25970458984375\n",
      "        vf_explained_var: 0.8771083950996399\n",
      "        vf_loss: 170.3188934326172\n",
      "    num_steps_sampled: 1068000\n",
      "    num_steps_trained: 1068000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.868\n",
      "    ram_util_percent: 40.428266666666666\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06936872774089586\n",
      "    mean_env_wait_ms: 118.16369377636036\n",
      "    mean_inference_ms: 1.6027677305677492\n",
      "    mean_raw_obs_processing_ms: 9.390226908187486\n",
      "  time_since_restore: 34887.94112968445\n",
      "  time_this_iter_s: 525.3371269702911\n",
      "  time_total_s: 144738.43510365486\n",
      "  timers:\n",
      "    learn_throughput: 365.093\n",
      "    learn_time_ms: 10956.121\n",
      "    load_throughput: 10001.031\n",
      "    load_time_ms: 399.959\n",
      "    sample_throughput: 7.601\n",
      "    sample_time_ms: 526241.612\n",
      "    update_time_ms: 3.443\n",
      "  timestamp: 1612937957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1068000\n",
      "  training_iteration: 267\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 136.71\n",
      "  episode_reward_max: 118.3911407878765\n",
      "  episode_reward_mean: 89.60415341925747\n",
      "  episode_reward_min: -106.38216724440176\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 7065\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4166446030139923\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013184037990868092\n",
      "        model: {}\n",
      "        policy_loss: -0.09656470268964767\n",
      "        total_loss: 689.5965576171875\n",
      "        vf_explained_var: 0.6984066963195801\n",
      "        vf_loss: 689.6730346679688\n",
      "    num_steps_sampled: 1072000\n",
      "    num_steps_trained: 1072000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.59615894039735\n",
      "    ram_util_percent: 40.43271523178807\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06938695961377285\n",
      "    mean_env_wait_ms: 118.2059860558049\n",
      "    mean_inference_ms: 1.6030180166530983\n",
      "    mean_raw_obs_processing_ms: 9.383628867445791\n",
      "  time_since_restore: 35417.17981028557\n",
      "  time_this_iter_s: 529.23868060112\n",
      "  time_total_s: 145267.67378425598\n",
      "  timers:\n",
      "    learn_throughput: 362.539\n",
      "    learn_time_ms: 11033.288\n",
      "    load_throughput: 9998.123\n",
      "    load_time_ms: 400.075\n",
      "    sample_throughput: 7.594\n",
      "    sample_time_ms: 526706.616\n",
      "    update_time_ms: 3.414\n",
      "  timestamp: 1612938486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1072000\n",
      "  training_iteration: 268\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-36-58\n",
      "  done: false\n",
      "  episode_len_mean: 134.34\n",
      "  episode_reward_max: 118.3911407878765\n",
      "  episode_reward_mean: 87.92099272091004\n",
      "  episode_reward_min: -99.4603476714637\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 7096\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37500157952308655\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01283953431993723\n",
      "        model: {}\n",
      "        policy_loss: -0.09724997729063034\n",
      "        total_loss: 698.0765991210938\n",
      "        vf_explained_var: 0.6827164888381958\n",
      "        vf_loss: 698.154296875\n",
      "    num_steps_sampled: 1076000\n",
      "    num_steps_trained: 1076000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.613852242744066\n",
      "    ram_util_percent: 40.54960422163589\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06939583314122276\n",
      "    mean_env_wait_ms: 118.2229687330249\n",
      "    mean_inference_ms: 1.6031287007288164\n",
      "    mean_raw_obs_processing_ms: 9.378442631564404\n",
      "  time_since_restore: 35948.442828416824\n",
      "  time_this_iter_s: 531.2630181312561\n",
      "  time_total_s: 145798.93680238724\n",
      "  timers:\n",
      "    learn_throughput: 362.446\n",
      "    learn_time_ms: 11036.13\n",
      "    load_throughput: 10054.548\n",
      "    load_time_ms: 397.83\n",
      "    sample_throughput: 7.587\n",
      "    sample_time_ms: 527188.453\n",
      "    update_time_ms: 3.4\n",
      "  timestamp: 1612939018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1076000\n",
      "  training_iteration: 269\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 131.06\n",
      "  episode_reward_max: 118.39547731734571\n",
      "  episode_reward_mean: 77.2293580192358\n",
      "  episode_reward_min: -105.8802001808491\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 7130\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3431065082550049\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008472778834402561\n",
      "        model: {}\n",
      "        policy_loss: -0.06977755576372147\n",
      "        total_loss: 130.01055908203125\n",
      "        vf_explained_var: 0.9219914674758911\n",
      "        vf_loss: 130.06747436523438\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50039577836412\n",
      "    ram_util_percent: 40.508179419525064\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06940315622627075\n",
      "    mean_env_wait_ms: 118.23035459395508\n",
      "    mean_inference_ms: 1.6031870624719602\n",
      "    mean_raw_obs_processing_ms: 9.375691606620277\n",
      "  time_since_restore: 36479.297374010086\n",
      "  time_this_iter_s: 530.8545455932617\n",
      "  time_total_s: 146329.7913479805\n",
      "  timers:\n",
      "    learn_throughput: 362.383\n",
      "    learn_time_ms: 11038.03\n",
      "    load_throughput: 10103.067\n",
      "    load_time_ms: 395.919\n",
      "    sample_throughput: 7.642\n",
      "    sample_time_ms: 523451.677\n",
      "    update_time_ms: 3.414\n",
      "  timestamp: 1612939549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 270\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_07-54-39\n",
      "  done: false\n",
      "  episode_len_mean: 129.68\n",
      "  episode_reward_max: 118.39547731734571\n",
      "  episode_reward_mean: 81.19330089898682\n",
      "  episode_reward_min: -105.8802001808491\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 7159\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35232308506965637\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01306112576276064\n",
      "        model: {}\n",
      "        policy_loss: -0.08413372188806534\n",
      "        total_loss: 262.5661926269531\n",
      "        vf_explained_var: 0.8584184050559998\n",
      "        vf_loss: 262.6304931640625\n",
      "    num_steps_sampled: 1084000\n",
      "    num_steps_trained: 1084000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.684676354029065\n",
      "    ram_util_percent: 40.504359313077934\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06941002960283575\n",
      "    mean_env_wait_ms: 118.23792426628793\n",
      "    mean_inference_ms: 1.6032417434272777\n",
      "    mean_raw_obs_processing_ms: 9.37499722153915\n",
      "  time_since_restore: 37009.707545518875\n",
      "  time_this_iter_s: 530.4101715087891\n",
      "  time_total_s: 146860.2015194893\n",
      "  timers:\n",
      "    learn_throughput: 362.291\n",
      "    learn_time_ms: 11040.838\n",
      "    load_throughput: 10117.451\n",
      "    load_time_ms: 395.357\n",
      "    sample_throughput: 7.637\n",
      "    sample_time_ms: 523785.471\n",
      "    update_time_ms: 3.45\n",
      "  timestamp: 1612940079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1084000\n",
      "  training_iteration: 271\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-03-26\n",
      "  done: false\n",
      "  episode_len_mean: 130.01\n",
      "  episode_reward_max: 118.39547731734571\n",
      "  episode_reward_mean: 80.98324524255646\n",
      "  episode_reward_min: -105.8802001808491\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 7190\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38195422291755676\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011975212022662163\n",
      "        model: {}\n",
      "        policy_loss: -0.08833307772874832\n",
      "        total_loss: 324.47723388671875\n",
      "        vf_explained_var: 0.847353458404541\n",
      "        vf_loss: 324.5473937988281\n",
      "    num_steps_sampled: 1088000\n",
      "    num_steps_trained: 1088000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.64667553191489\n",
      "    ram_util_percent: 40.43377659574469\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06941623108221807\n",
      "    mean_env_wait_ms: 118.23888459789225\n",
      "    mean_inference_ms: 1.6033289318295698\n",
      "    mean_raw_obs_processing_ms: 9.376941493870792\n",
      "  time_since_restore: 37536.50109601021\n",
      "  time_this_iter_s: 526.793550491333\n",
      "  time_total_s: 147386.99506998062\n",
      "  timers:\n",
      "    learn_throughput: 362.198\n",
      "    learn_time_ms: 11043.693\n",
      "    load_throughput: 10119.119\n",
      "    load_time_ms: 395.291\n",
      "    sample_throughput: 7.639\n",
      "    sample_time_ms: 523639.369\n",
      "    update_time_ms: 3.446\n",
      "  timestamp: 1612940606\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1088000\n",
      "  training_iteration: 272\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-12-08\n",
      "  done: false\n",
      "  episode_len_mean: 130.98\n",
      "  episode_reward_max: 118.38507119432211\n",
      "  episode_reward_mean: 85.17821922297034\n",
      "  episode_reward_min: -105.8802001808491\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 7220\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36194854974746704\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010024256072938442\n",
      "        model: {}\n",
      "        policy_loss: -0.07011985033750534\n",
      "        total_loss: 438.0443420410156\n",
      "        vf_explained_var: 0.7122790217399597\n",
      "        vf_loss: 438.09918212890625\n",
      "    num_steps_sampled: 1092000\n",
      "    num_steps_trained: 1092000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.77812080536912\n",
      "    ram_util_percent: 40.32617449664429\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06941969300998256\n",
      "    mean_env_wait_ms: 118.23434205916698\n",
      "    mean_inference_ms: 1.6034069907240012\n",
      "    mean_raw_obs_processing_ms: 9.374755259648738\n",
      "  time_since_restore: 38058.417748212814\n",
      "  time_this_iter_s: 521.9166522026062\n",
      "  time_total_s: 147908.91172218323\n",
      "  timers:\n",
      "    learn_throughput: 362.031\n",
      "    learn_time_ms: 11048.787\n",
      "    load_throughput: 10062.914\n",
      "    load_time_ms: 397.499\n",
      "    sample_throughput: 7.641\n",
      "    sample_time_ms: 523476.219\n",
      "    update_time_ms: 3.411\n",
      "  timestamp: 1612941128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1092000\n",
      "  training_iteration: 273\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 131.71\n",
      "  episode_reward_max: 118.38507119432211\n",
      "  episode_reward_mean: 79.22942595241358\n",
      "  episode_reward_min: -105.33218453158977\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 7250\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3783925473690033\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01028820313513279\n",
      "        model: {}\n",
      "        policy_loss: -0.08333862572908401\n",
      "        total_loss: 550.1541748046875\n",
      "        vf_explained_var: 0.7420992255210876\n",
      "        vf_loss: 550.2218017578125\n",
      "    num_steps_sampled: 1096000\n",
      "    num_steps_trained: 1096000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.09199475065618\n",
      "    ram_util_percent: 40.39265091863517\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06942265016359\n",
      "    mean_env_wait_ms: 118.23378203597204\n",
      "    mean_inference_ms: 1.6034889354493906\n",
      "    mean_raw_obs_processing_ms: 9.372234335143201\n",
      "  time_since_restore: 38592.20010614395\n",
      "  time_this_iter_s: 533.7823579311371\n",
      "  time_total_s: 148442.69408011436\n",
      "  timers:\n",
      "    learn_throughput: 361.897\n",
      "    learn_time_ms: 11052.881\n",
      "    load_throughput: 10136.897\n",
      "    load_time_ms: 394.598\n",
      "    sample_throughput: 7.636\n",
      "    sample_time_ms: 523848.517\n",
      "    update_time_ms: 3.423\n",
      "  timestamp: 1612941662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1096000\n",
      "  training_iteration: 274\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 130.31\n",
      "  episode_reward_max: 118.38507119432211\n",
      "  episode_reward_mean: 79.09474967024781\n",
      "  episode_reward_min: -105.33218453158977\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 7282\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3556593656539917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008046400733292103\n",
      "        model: {}\n",
      "        policy_loss: -0.06431816518306732\n",
      "        total_loss: 292.83050537109375\n",
      "        vf_explained_var: 0.8125525712966919\n",
      "        vf_loss: 292.8826599121094\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.40815789473684\n",
      "    ram_util_percent: 40.44618421052631\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06942496642427029\n",
      "    mean_env_wait_ms: 118.23601783551679\n",
      "    mean_inference_ms: 1.6035466441877326\n",
      "    mean_raw_obs_processing_ms: 9.371829499104463\n",
      "  time_since_restore: 39124.77579474449\n",
      "  time_this_iter_s: 532.5756886005402\n",
      "  time_total_s: 148975.2697687149\n",
      "  timers:\n",
      "    learn_throughput: 365.564\n",
      "    learn_time_ms: 10942.006\n",
      "    load_throughput: 10226.877\n",
      "    load_time_ms: 391.126\n",
      "    sample_throughput: 7.689\n",
      "    sample_time_ms: 520252.098\n",
      "    update_time_ms: 3.396\n",
      "  timestamp: 1612942195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 275\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 132.46\n",
      "  episode_reward_max: 118.3886910187728\n",
      "  episode_reward_mean: 83.35827181379476\n",
      "  episode_reward_min: -105.33218453158977\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 7311\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3425547480583191\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008906719274818897\n",
      "        model: {}\n",
      "        policy_loss: -0.06300731748342514\n",
      "        total_loss: 353.84796142578125\n",
      "        vf_explained_var: 0.6911104917526245\n",
      "        vf_loss: 353.89739990234375\n",
      "    num_steps_sampled: 1104000\n",
      "    num_steps_trained: 1104000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.42052287581699\n",
      "    ram_util_percent: 40.50104575163399\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06942795409863542\n",
      "    mean_env_wait_ms: 118.25214717421484\n",
      "    mean_inference_ms: 1.6035921121970107\n",
      "    mean_raw_obs_processing_ms: 9.369955467890632\n",
      "  time_since_restore: 39661.3459918499\n",
      "  time_this_iter_s: 536.5701971054077\n",
      "  time_total_s: 149511.8399658203\n",
      "  timers:\n",
      "    learn_throughput: 367.868\n",
      "    learn_time_ms: 10873.461\n",
      "    load_throughput: 10321.285\n",
      "    load_time_ms: 387.549\n",
      "    sample_throughput: 7.715\n",
      "    sample_time_ms: 518455.955\n",
      "    update_time_ms: 3.381\n",
      "  timestamp: 1612942732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1104000\n",
      "  training_iteration: 276\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-48-08\n",
      "  done: false\n",
      "  episode_len_mean: 135.97\n",
      "  episode_reward_max: 118.39580941565114\n",
      "  episode_reward_mean: 87.53104609220624\n",
      "  episode_reward_min: -105.33218453158977\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 7338\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3476717472076416\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009480617940425873\n",
      "        model: {}\n",
      "        policy_loss: -0.06909433007240295\n",
      "        total_loss: 469.2999267578125\n",
      "        vf_explained_var: 0.6792575716972351\n",
      "        vf_loss: 469.3545837402344\n",
      "    num_steps_sampled: 1108000\n",
      "    num_steps_trained: 1108000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.87254408060453\n",
      "    ram_util_percent: 40.70025188916877\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06944218106007716\n",
      "    mean_env_wait_ms: 118.29156193076598\n",
      "    mean_inference_ms: 1.6037570564433796\n",
      "    mean_raw_obs_processing_ms: 9.36536120888139\n",
      "  time_since_restore: 40217.38514947891\n",
      "  time_this_iter_s: 556.0391576290131\n",
      "  time_total_s: 150067.87912344933\n",
      "  timers:\n",
      "    learn_throughput: 364.048\n",
      "    learn_time_ms: 10987.567\n",
      "    load_throughput: 10264.55\n",
      "    load_time_ms: 389.691\n",
      "    sample_throughput: 7.672\n",
      "    sample_time_ms: 521409.713\n",
      "    update_time_ms: 3.385\n",
      "  timestamp: 1612943288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1108000\n",
      "  training_iteration: 277\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_08-57-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.53\n",
      "  episode_reward_max: 118.39580941565114\n",
      "  episode_reward_mean: 79.14564286162533\n",
      "  episode_reward_min: -105.52323032972315\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 7369\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42577964067459106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01852702721953392\n",
      "        model: {}\n",
      "        policy_loss: -0.11602400988340378\n",
      "        total_loss: 1199.9779052734375\n",
      "        vf_explained_var: 0.6293759346008301\n",
      "        vf_loss: 1200.06591796875\n",
      "    num_steps_sampled: 1112000\n",
      "    num_steps_trained: 1112000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.832904884318765\n",
      "    ram_util_percent: 40.518637532133674\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06946259458584826\n",
      "    mean_env_wait_ms: 118.34849367585859\n",
      "    mean_inference_ms: 1.603997160937983\n",
      "    mean_raw_obs_processing_ms: 9.359939897861125\n",
      "  time_since_restore: 40762.35188269615\n",
      "  time_this_iter_s: 544.9667332172394\n",
      "  time_total_s: 150612.84585666656\n",
      "  timers:\n",
      "    learn_throughput: 366.393\n",
      "    learn_time_ms: 10917.239\n",
      "    load_throughput: 10307.985\n",
      "    load_time_ms: 388.049\n",
      "    sample_throughput: 7.647\n",
      "    sample_time_ms: 523058.185\n",
      "    update_time_ms: 3.385\n",
      "  timestamp: 1612943833\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1112000\n",
      "  training_iteration: 278\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 137.55\n",
      "  episode_reward_max: 118.3976878155662\n",
      "  episode_reward_mean: 77.25007403359892\n",
      "  episode_reward_min: -105.52323032972315\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 7398\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4034528434276581\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011728320270776749\n",
      "        model: {}\n",
      "        policy_loss: -0.07793018221855164\n",
      "        total_loss: 602.981201171875\n",
      "        vf_explained_var: 0.62846440076828\n",
      "        vf_loss: 603.0413208007812\n",
      "    num_steps_sampled: 1116000\n",
      "    num_steps_trained: 1116000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.38916776750329\n",
      "    ram_util_percent: 40.5443857331572\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06948366589806465\n",
      "    mean_env_wait_ms: 118.39865715950458\n",
      "    mean_inference_ms: 1.6042411251738866\n",
      "    mean_raw_obs_processing_ms: 9.353458141439141\n",
      "  time_since_restore: 41292.729105472565\n",
      "  time_this_iter_s: 530.377222776413\n",
      "  time_total_s: 151143.22307944298\n",
      "  timers:\n",
      "    learn_throughput: 366.288\n",
      "    learn_time_ms: 10920.374\n",
      "    load_throughput: 10381.488\n",
      "    load_time_ms: 385.301\n",
      "    sample_throughput: 7.649\n",
      "    sample_time_ms: 522971.039\n",
      "    update_time_ms: 3.421\n",
      "  timestamp: 1612944363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1116000\n",
      "  training_iteration: 279\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-14-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.02\n",
      "  episode_reward_max: 118.3976878155662\n",
      "  episode_reward_mean: 75.17532373335648\n",
      "  episode_reward_min: -105.52323032972315\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 7430\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3691219091415405\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010335390456020832\n",
      "        model: {}\n",
      "        policy_loss: -0.07603420317173004\n",
      "        total_loss: 283.4937438964844\n",
      "        vf_explained_var: 0.7773721218109131\n",
      "        vf_loss: 283.5540466308594\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.305235602094236\n",
      "    ram_util_percent: 40.51675392670157\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06949693533174083\n",
      "    mean_env_wait_ms: 118.43573541676615\n",
      "    mean_inference_ms: 1.604398965273203\n",
      "    mean_raw_obs_processing_ms: 9.35150265498284\n",
      "  time_since_restore: 41828.68137764931\n",
      "  time_this_iter_s: 535.9522721767426\n",
      "  time_total_s: 151679.17535161972\n",
      "  timers:\n",
      "    learn_throughput: 366.123\n",
      "    learn_time_ms: 10925.28\n",
      "    load_throughput: 10322.615\n",
      "    load_time_ms: 387.499\n",
      "    sample_throughput: 7.641\n",
      "    sample_time_ms: 523473.059\n",
      "    update_time_ms: 3.408\n",
      "  timestamp: 1612944899\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 280\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 136.16\n",
      "  episode_reward_max: 118.3976878155662\n",
      "  episode_reward_mean: 89.8180215661961\n",
      "  episode_reward_min: -106.1800133472685\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 7456\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37231138348579407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011143573559820652\n",
      "        model: {}\n",
      "        policy_loss: -0.07171215116977692\n",
      "        total_loss: 389.7134704589844\n",
      "        vf_explained_var: 0.6836399435997009\n",
      "        vf_loss: 389.768310546875\n",
      "    num_steps_sampled: 1124000\n",
      "    num_steps_trained: 1124000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.33488063660477\n",
      "    ram_util_percent: 40.52175066312998\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06950029131288073\n",
      "    mean_env_wait_ms: 118.44942270458586\n",
      "    mean_inference_ms: 1.6044624901248203\n",
      "    mean_raw_obs_processing_ms: 9.346769151518554\n",
      "  time_since_restore: 42356.51848053932\n",
      "  time_this_iter_s: 527.8371028900146\n",
      "  time_total_s: 152207.01245450974\n",
      "  timers:\n",
      "    learn_throughput: 365.96\n",
      "    learn_time_ms: 10930.154\n",
      "    load_throughput: 10279.254\n",
      "    load_time_ms: 389.133\n",
      "    sample_throughput: 7.645\n",
      "    sample_time_ms: 523213.818\n",
      "    update_time_ms: 3.367\n",
      "  timestamp: 1612945427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1124000\n",
      "  training_iteration: 281\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-32-42\n",
      "  done: false\n",
      "  episode_len_mean: 129.56\n",
      "  episode_reward_max: 118.38907803189579\n",
      "  episode_reward_mean: 79.15793387668813\n",
      "  episode_reward_min: -106.1800133472685\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 7491\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4181641936302185\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01874413527548313\n",
      "        model: {}\n",
      "        policy_loss: -0.11580529063940048\n",
      "        total_loss: 903.9219360351562\n",
      "        vf_explained_var: 0.741776704788208\n",
      "        vf_loss: 904.0093994140625\n",
      "    num_steps_sampled: 1128000\n",
      "    num_steps_trained: 1128000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.52149410222805\n",
      "    ram_util_percent: 40.55032765399738\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06950381122408152\n",
      "    mean_env_wait_ms: 118.46017629196584\n",
      "    mean_inference_ms: 1.6045572335347642\n",
      "    mean_raw_obs_processing_ms: 9.347407631388204\n",
      "  time_since_restore: 42891.106843948364\n",
      "  time_this_iter_s: 534.5883634090424\n",
      "  time_total_s: 152741.60081791878\n",
      "  timers:\n",
      "    learn_throughput: 365.925\n",
      "    learn_time_ms: 10931.188\n",
      "    load_throughput: 10295.921\n",
      "    load_time_ms: 388.503\n",
      "    sample_throughput: 7.634\n",
      "    sample_time_ms: 523991.819\n",
      "    update_time_ms: 3.4\n",
      "  timestamp: 1612945962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1128000\n",
      "  training_iteration: 282\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-41-35\n",
      "  done: false\n",
      "  episode_len_mean: 131.38\n",
      "  episode_reward_max: 118.37268002476236\n",
      "  episode_reward_mean: 68.3818894872424\n",
      "  episode_reward_min: -106.1800133472685\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 7522\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45041367411613464\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015993593260645866\n",
      "        model: {}\n",
      "        policy_loss: -0.1078135147690773\n",
      "        total_loss: 917.2972412109375\n",
      "        vf_explained_var: 0.6977779269218445\n",
      "        vf_loss: 917.3807373046875\n",
      "    num_steps_sampled: 1132000\n",
      "    num_steps_trained: 1132000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34323258869909\n",
      "    ram_util_percent: 40.58055190538765\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0695060439899176\n",
      "    mean_env_wait_ms: 118.46810521919463\n",
      "    mean_inference_ms: 1.6046388531288642\n",
      "    mean_raw_obs_processing_ms: 9.347778173045032\n",
      "  time_since_restore: 43424.396802425385\n",
      "  time_this_iter_s: 533.2899584770203\n",
      "  time_total_s: 153274.8907763958\n",
      "  timers:\n",
      "    learn_throughput: 365.813\n",
      "    learn_time_ms: 10934.56\n",
      "    load_throughput: 10282.908\n",
      "    load_time_ms: 388.995\n",
      "    sample_throughput: 7.617\n",
      "    sample_time_ms: 525124.248\n",
      "    update_time_ms: 3.439\n",
      "  timestamp: 1612946495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1132000\n",
      "  training_iteration: 283\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 127.44\n",
      "  episode_reward_max: 118.398246663027\n",
      "  episode_reward_mean: 61.838339995953405\n",
      "  episode_reward_min: -105.69028246594925\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 7552\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.40359172224998474\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009850187227129936\n",
      "        model: {}\n",
      "        policy_loss: -0.07553484290838242\n",
      "        total_loss: 327.4836730957031\n",
      "        vf_explained_var: 0.8231552839279175\n",
      "        vf_loss: 327.54425048828125\n",
      "    num_steps_sampled: 1136000\n",
      "    num_steps_trained: 1136000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.292772667542714\n",
      "    ram_util_percent: 40.60972404730617\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06950834913283394\n",
      "    mean_env_wait_ms: 118.47616458931476\n",
      "    mean_inference_ms: 1.604710811935626\n",
      "    mean_raw_obs_processing_ms: 9.350908301096528\n",
      "  time_since_restore: 43957.74543118477\n",
      "  time_this_iter_s: 533.3486287593842\n",
      "  time_total_s: 153808.23940515518\n",
      "  timers:\n",
      "    learn_throughput: 365.729\n",
      "    learn_time_ms: 10937.065\n",
      "    load_throughput: 10275.164\n",
      "    load_time_ms: 389.288\n",
      "    sample_throughput: 7.618\n",
      "    sample_time_ms: 525075.996\n",
      "    update_time_ms: 3.525\n",
      "  timestamp: 1612947029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1136000\n",
      "  training_iteration: 284\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_09-59-24\n",
      "  done: false\n",
      "  episode_len_mean: 130.14\n",
      "  episode_reward_max: 118.398246663027\n",
      "  episode_reward_mean: 74.5172555204358\n",
      "  episode_reward_min: -105.69028246594925\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 7582\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36293870210647583\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008887550793588161\n",
      "        model: {}\n",
      "        policy_loss: -0.06467510014772415\n",
      "        total_loss: 324.4293212890625\n",
      "        vf_explained_var: 0.7121971845626831\n",
      "        vf_loss: 324.4804992675781\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.196330275229364\n",
      "    ram_util_percent: 40.61114023591088\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06950992011721735\n",
      "    mean_env_wait_ms: 118.48866594726613\n",
      "    mean_inference_ms: 1.6047330625390026\n",
      "    mean_raw_obs_processing_ms: 9.350276528556721\n",
      "  time_since_restore: 44492.287269592285\n",
      "  time_this_iter_s: 534.5418384075165\n",
      "  time_total_s: 154342.7812435627\n",
      "  timers:\n",
      "    learn_throughput: 365.758\n",
      "    learn_time_ms: 10936.201\n",
      "    load_throughput: 10273.911\n",
      "    load_time_ms: 389.336\n",
      "    sample_throughput: 7.615\n",
      "    sample_time_ms: 525267.905\n",
      "    update_time_ms: 3.562\n",
      "  timestamp: 1612947564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 285\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 136.03\n",
      "  episode_reward_max: 118.398246663027\n",
      "  episode_reward_mean: 82.95946381570985\n",
      "  episode_reward_min: -105.69028246594925\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 7610\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39392825961112976\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014838993549346924\n",
      "        model: {}\n",
      "        policy_loss: -0.09969846904277802\n",
      "        total_loss: 1159.6898193359375\n",
      "        vf_explained_var: 0.4761207401752472\n",
      "        vf_loss: 1159.766845703125\n",
      "    num_steps_sampled: 1144000\n",
      "    num_steps_trained: 1144000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.633808290155436\n",
      "    ram_util_percent: 40.68821243523316\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06951423446589448\n",
      "    mean_env_wait_ms: 118.50896110344944\n",
      "    mean_inference_ms: 1.6048002376053325\n",
      "    mean_raw_obs_processing_ms: 9.346438786145281\n",
      "  time_since_restore: 45033.333627939224\n",
      "  time_this_iter_s: 541.0463583469391\n",
      "  time_total_s: 154883.82760190964\n",
      "  timers:\n",
      "    learn_throughput: 362.993\n",
      "    learn_time_ms: 11019.489\n",
      "    load_throughput: 10185.356\n",
      "    load_time_ms: 392.721\n",
      "    sample_throughput: 7.61\n",
      "    sample_time_ms: 525620.522\n",
      "    update_time_ms: 3.608\n",
      "  timestamp: 1612948105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1144000\n",
      "  training_iteration: 286\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 132.52\n",
      "  episode_reward_max: 118.398246663027\n",
      "  episode_reward_mean: 83.5106970852512\n",
      "  episode_reward_min: -105.63192916897212\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 7644\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38366809487342834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013387883082032204\n",
      "        model: {}\n",
      "        policy_loss: -0.09720607101917267\n",
      "        total_loss: 1059.09375\n",
      "        vf_explained_var: 0.5738667249679565\n",
      "        vf_loss: 1059.170654296875\n",
      "    num_steps_sampled: 1148000\n",
      "    num_steps_trained: 1148000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.12960102960102\n",
      "    ram_util_percent: 40.683912483912486\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06952904049834233\n",
      "    mean_env_wait_ms: 118.53967438018982\n",
      "    mean_inference_ms: 1.6049730312102413\n",
      "    mean_raw_obs_processing_ms: 9.34611090836681\n",
      "  time_since_restore: 45577.51814699173\n",
      "  time_this_iter_s: 544.1845190525055\n",
      "  time_total_s: 155428.01212096214\n",
      "  timers:\n",
      "    learn_throughput: 366.731\n",
      "    learn_time_ms: 10907.189\n",
      "    load_throughput: 10278.318\n",
      "    load_time_ms: 389.169\n",
      "    sample_throughput: 7.626\n",
      "    sample_time_ms: 524551.309\n",
      "    update_time_ms: 3.609\n",
      "  timestamp: 1612948649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1148000\n",
      "  training_iteration: 287\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-26-49\n",
      "  done: false\n",
      "  episode_len_mean: 127.72\n",
      "  episode_reward_max: 118.3986798301829\n",
      "  episode_reward_mean: 73.24829269215451\n",
      "  episode_reward_min: -105.63192916897212\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 7677\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37864673137664795\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0130960987880826\n",
      "        model: {}\n",
      "        policy_loss: -0.09524456411600113\n",
      "        total_loss: 867.382568359375\n",
      "        vf_explained_var: 0.6208809614181519\n",
      "        vf_loss: 867.4578247070312\n",
      "    num_steps_sampled: 1152000\n",
      "    num_steps_trained: 1152000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.55538847117795\n",
      "    ram_util_percent: 40.688345864661656\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06955522819814813\n",
      "    mean_env_wait_ms: 118.587350861571\n",
      "    mean_inference_ms: 1.6053089514824004\n",
      "    mean_raw_obs_processing_ms: 9.349701718468355\n",
      "  time_since_restore: 46137.00454354286\n",
      "  time_this_iter_s: 559.4863965511322\n",
      "  time_total_s: 155987.49851751328\n",
      "  timers:\n",
      "    learn_throughput: 363.074\n",
      "    learn_time_ms: 11017.033\n",
      "    load_throughput: 10173.866\n",
      "    load_time_ms: 393.164\n",
      "    sample_throughput: 7.606\n",
      "    sample_time_ms: 525885.197\n",
      "    update_time_ms: 3.614\n",
      "  timestamp: 1612949209\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1152000\n",
      "  training_iteration: 288\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 117.53\n",
      "  episode_reward_max: 118.3986798301829\n",
      "  episode_reward_mean: 66.70983500202433\n",
      "  episode_reward_min: -112.40000610430498\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 7711\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4144652187824249\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015483838506042957\n",
      "        model: {}\n",
      "        policy_loss: -0.10350482165813446\n",
      "        total_loss: 1087.221435546875\n",
      "        vf_explained_var: 0.6463456749916077\n",
      "        vf_loss: 1087.30126953125\n",
      "    num_steps_sampled: 1156000\n",
      "    num_steps_trained: 1156000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.90435865504358\n",
      "    ram_util_percent: 40.882814445828146\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0695912924044208\n",
      "    mean_env_wait_ms: 118.64957733641607\n",
      "    mean_inference_ms: 1.605743187851105\n",
      "    mean_raw_obs_processing_ms: 9.36009276179293\n",
      "  time_since_restore: 46699.54263949394\n",
      "  time_this_iter_s: 562.5380959510803\n",
      "  time_total_s: 156550.03661346436\n",
      "  timers:\n",
      "    learn_throughput: 359.327\n",
      "    learn_time_ms: 11131.926\n",
      "    load_throughput: 10142.681\n",
      "    load_time_ms: 394.373\n",
      "    sample_throughput: 7.562\n",
      "    sample_time_ms: 528983.042\n",
      "    update_time_ms: 3.635\n",
      "  timestamp: 1612949771\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1156000\n",
      "  training_iteration: 289\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-45-14\n",
      "  done: false\n",
      "  episode_len_mean: 112.28\n",
      "  episode_reward_max: 118.3986798301829\n",
      "  episode_reward_mean: 66.20960876280965\n",
      "  episode_reward_min: -112.40000610430498\n",
      "  episodes_this_iter: 38\n",
      "  episodes_total: 7749\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36864686012268066\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011038769036531448\n",
      "        model: {}\n",
      "        policy_loss: -0.08109961450099945\n",
      "        total_loss: 475.16961669921875\n",
      "        vf_explained_var: 0.7545323967933655\n",
      "        vf_loss: 475.23394775390625\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.693023255813955\n",
      "    ram_util_percent: 40.88514211886305\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06962534290547788\n",
      "    mean_env_wait_ms: 118.70580755902336\n",
      "    mean_inference_ms: 1.6061629696869288\n",
      "    mean_raw_obs_processing_ms: 9.37647262143582\n",
      "  time_since_restore: 47241.97667479515\n",
      "  time_this_iter_s: 542.4340353012085\n",
      "  time_total_s: 157092.47064876556\n",
      "  timers:\n",
      "    learn_throughput: 359.279\n",
      "    learn_time_ms: 11133.407\n",
      "    load_throughput: 10185.834\n",
      "    load_time_ms: 392.702\n",
      "    sample_throughput: 7.552\n",
      "    sample_time_ms: 529631.287\n",
      "    update_time_ms: 3.613\n",
      "  timestamp: 1612950314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 290\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_10-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 118.4\n",
      "  episode_reward_max: 118.38912921224835\n",
      "  episode_reward_mean: 68.4434065623748\n",
      "  episode_reward_min: -112.40000610430498\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 7778\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.41386669874191284\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016441263258457184\n",
      "        model: {}\n",
      "        policy_loss: -0.10021355003118515\n",
      "        total_loss: 458.8840026855469\n",
      "        vf_explained_var: 0.7829328179359436\n",
      "        vf_loss: 458.95916748046875\n",
      "    num_steps_sampled: 1164000\n",
      "    num_steps_trained: 1164000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.18185279187817\n",
      "    ram_util_percent: 40.5247461928934\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06965088194004117\n",
      "    mean_env_wait_ms: 118.7474820602639\n",
      "    mean_inference_ms: 1.6064223765817538\n",
      "    mean_raw_obs_processing_ms: 9.384911847632832\n",
      "  time_since_restore: 47793.75333285332\n",
      "  time_this_iter_s: 551.7766580581665\n",
      "  time_total_s: 157644.24730682373\n",
      "  timers:\n",
      "    learn_throughput: 355.917\n",
      "    learn_time_ms: 11238.564\n",
      "    load_throughput: 10234.035\n",
      "    load_time_ms: 390.853\n",
      "    sample_throughput: 7.52\n",
      "    sample_time_ms: 531920.752\n",
      "    update_time_ms: 3.642\n",
      "  timestamp: 1612950866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1164000\n",
      "  training_iteration: 291\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 122.47\n",
      "  episode_reward_max: 118.38912921224835\n",
      "  episode_reward_mean: 79.20508397509457\n",
      "  episode_reward_min: -105.57711113603389\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 7810\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37878283858299255\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010971354320645332\n",
      "        model: {}\n",
      "        policy_loss: -0.07303028553724289\n",
      "        total_loss: 534.2431030273438\n",
      "        vf_explained_var: 0.6533004641532898\n",
      "        vf_loss: 534.2994384765625\n",
      "    num_steps_sampled: 1168000\n",
      "    num_steps_trained: 1168000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.56911581569116\n",
      "    ram_util_percent: 40.40460772104607\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06967810942450732\n",
      "    mean_env_wait_ms: 118.79525882280669\n",
      "    mean_inference_ms: 1.6066931413198864\n",
      "    mean_raw_obs_processing_ms: 9.392232449464576\n",
      "  time_since_restore: 48356.63022184372\n",
      "  time_this_iter_s: 562.8768889904022\n",
      "  time_total_s: 158207.12419581413\n",
      "  timers:\n",
      "    learn_throughput: 352.335\n",
      "    learn_time_ms: 11352.837\n",
      "    load_throughput: 10238.002\n",
      "    load_time_ms: 390.701\n",
      "    sample_throughput: 7.482\n",
      "    sample_time_ms: 534634.345\n",
      "    update_time_ms: 3.617\n",
      "  timestamp: 1612951429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1168000\n",
      "  training_iteration: 292\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-12-47\n",
      "  done: false\n",
      "  episode_len_mean: 130.33\n",
      "  episode_reward_max: 118.38912921224835\n",
      "  episode_reward_mean: 83.72240122609568\n",
      "  episode_reward_min: -106.34294871916913\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 7840\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39510130882263184\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011426759883761406\n",
      "        model: {}\n",
      "        policy_loss: -0.08972674608230591\n",
      "        total_loss: 605.4160766601562\n",
      "        vf_explained_var: 0.6921168565750122\n",
      "        vf_loss: 605.4884033203125\n",
      "    num_steps_sampled: 1172000\n",
      "    num_steps_trained: 1172000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.416558018252935\n",
      "    ram_util_percent: 40.22372881355932\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0696979269686802\n",
      "    mean_env_wait_ms: 118.84365987939232\n",
      "    mean_inference_ms: 1.6068556267638692\n",
      "    mean_raw_obs_processing_ms: 9.391319383050096\n",
      "  time_since_restore: 48894.45215296745\n",
      "  time_this_iter_s: 537.8219311237335\n",
      "  time_total_s: 158744.94612693787\n",
      "  timers:\n",
      "    learn_throughput: 352.475\n",
      "    learn_time_ms: 11348.318\n",
      "    load_throughput: 10278.846\n",
      "    load_time_ms: 389.149\n",
      "    sample_throughput: 7.475\n",
      "    sample_time_ms: 535093.864\n",
      "    update_time_ms: 3.57\n",
      "  timestamp: 1612951967\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1172000\n",
      "  training_iteration: 293\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.19\n",
      "  episode_reward_max: 118.38742204131213\n",
      "  episode_reward_mean: 72.95463421203146\n",
      "  episode_reward_min: -106.34294871916913\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 7874\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4123467803001404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014242740347981453\n",
      "        model: {}\n",
      "        policy_loss: -0.10071048885583878\n",
      "        total_loss: 881.876953125\n",
      "        vf_explained_var: 0.6577810049057007\n",
      "        vf_loss: 881.9559936523438\n",
      "    num_steps_sampled: 1176000\n",
      "    num_steps_trained: 1176000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.21077922077922\n",
      "    ram_util_percent: 40.280259740259744\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06971189885187513\n",
      "    mean_env_wait_ms: 118.88648441666385\n",
      "    mean_inference_ms: 1.606951312045457\n",
      "    mean_raw_obs_processing_ms: 9.394950992697659\n",
      "  time_since_restore: 49433.24291348457\n",
      "  time_this_iter_s: 538.7907605171204\n",
      "  time_total_s: 159283.736887455\n",
      "  timers:\n",
      "    learn_throughput: 352.555\n",
      "    learn_time_ms: 11345.761\n",
      "    load_throughput: 10309.92\n",
      "    load_time_ms: 387.976\n",
      "    sample_throughput: 7.468\n",
      "    sample_time_ms: 535638.913\n",
      "    update_time_ms: 3.48\n",
      "  timestamp: 1612952506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1176000\n",
      "  training_iteration: 294\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-30-35\n",
      "  done: false\n",
      "  episode_len_mean: 127.57\n",
      "  episode_reward_max: 118.39520903028988\n",
      "  episode_reward_mean: 66.4532573770176\n",
      "  episode_reward_min: -106.34294871916913\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 7905\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.424517422914505\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014351379126310349\n",
      "        model: {}\n",
      "        policy_loss: -0.09777229279279709\n",
      "        total_loss: 900.3688354492188\n",
      "        vf_explained_var: 0.6302482485771179\n",
      "        vf_loss: 900.44482421875\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55748344370861\n",
      "    ram_util_percent: 40.26582781456954\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0697109367695881\n",
      "    mean_env_wait_ms: 118.89711604911783\n",
      "    mean_inference_ms: 1.6069038647414393\n",
      "    mean_raw_obs_processing_ms: 9.397588224928864\n",
      "  time_since_restore: 49962.43202877045\n",
      "  time_this_iter_s: 529.1891152858734\n",
      "  time_total_s: 159812.92600274086\n",
      "  timers:\n",
      "    learn_throughput: 352.563\n",
      "    learn_time_ms: 11345.483\n",
      "    load_throughput: 10325.965\n",
      "    load_time_ms: 387.373\n",
      "    sample_throughput: 7.475\n",
      "    sample_time_ms: 535109.398\n",
      "    update_time_ms: 3.459\n",
      "  timestamp: 1612953035\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 295\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-39-28\n",
      "  done: false\n",
      "  episode_len_mean: 124.78\n",
      "  episode_reward_max: 118.39520903028988\n",
      "  episode_reward_mean: 68.46295216787786\n",
      "  episode_reward_min: -104.55580536588249\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 7937\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36587488651275635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009581360034644604\n",
      "        model: {}\n",
      "        policy_loss: -0.07854931056499481\n",
      "        total_loss: 295.9751892089844\n",
      "        vf_explained_var: 0.814533531665802\n",
      "        vf_loss: 296.0391540527344\n",
      "    num_steps_sampled: 1184000\n",
      "    num_steps_trained: 1184000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46276315789474\n",
      "    ram_util_percent: 40.26381578947368\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0697092043388887\n",
      "    mean_env_wait_ms: 118.89911842003448\n",
      "    mean_inference_ms: 1.6068691827077999\n",
      "    mean_raw_obs_processing_ms: 9.402168927644249\n",
      "  time_since_restore: 50495.2579972744\n",
      "  time_this_iter_s: 532.825968503952\n",
      "  time_total_s: 160345.7519712448\n",
      "  timers:\n",
      "    learn_throughput: 356.729\n",
      "    learn_time_ms: 11212.998\n",
      "    load_throughput: 10465.575\n",
      "    load_time_ms: 382.205\n",
      "    sample_throughput: 7.485\n",
      "    sample_time_ms: 534432.449\n",
      "    update_time_ms: 3.397\n",
      "  timestamp: 1612953568\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1184000\n",
      "  training_iteration: 296\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 124.59\n",
      "  episode_reward_max: 118.39520903028988\n",
      "  episode_reward_mean: 74.79495022148967\n",
      "  episode_reward_min: -104.55580536588249\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 7970\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3668016195297241\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008641227148473263\n",
      "        model: {}\n",
      "        policy_loss: -0.0655696839094162\n",
      "        total_loss: 445.0228271484375\n",
      "        vf_explained_var: 0.6995291709899902\n",
      "        vf_loss: 445.0752868652344\n",
      "    num_steps_sampled: 1188000\n",
      "    num_steps_trained: 1188000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.4725721784777\n",
      "    ram_util_percent: 40.29658792650919\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06970880547446529\n",
      "    mean_env_wait_ms: 118.8969661357064\n",
      "    mean_inference_ms: 1.6068703361829966\n",
      "    mean_raw_obs_processing_ms: 9.406152399501334\n",
      "  time_since_restore: 51029.00226140022\n",
      "  time_this_iter_s: 533.744264125824\n",
      "  time_total_s: 160879.49623537064\n",
      "  timers:\n",
      "    learn_throughput: 356.737\n",
      "    learn_time_ms: 11212.754\n",
      "    load_throughput: 10460.887\n",
      "    load_time_ms: 382.377\n",
      "    sample_throughput: 7.499\n",
      "    sample_time_ms: 533387.448\n",
      "    update_time_ms: 3.349\n",
      "  timestamp: 1612954102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1188000\n",
      "  training_iteration: 297\n",
      "  trial_id: a0e0c_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_a0e0c_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-10_11-57-16\n",
      "  done: true\n",
      "  episode_len_mean: 121.96\n",
      "  episode_reward_max: 118.39642380797241\n",
      "  episode_reward_mean: 81.09270451922723\n",
      "  episode_reward_min: -106.63761590317708\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 8003\n",
      "  experiment_id: cbe2f70fbfd44ae186b60705bb56fcbb\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35548463463783264\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008137403056025505\n",
      "        model: {}\n",
      "        policy_loss: -0.06652414053678513\n",
      "        total_loss: 187.89691162109375\n",
      "        vf_explained_var: 0.8681357502937317\n",
      "        vf_loss: 187.95108032226562\n",
      "    num_steps_sampled: 1192000\n",
      "    num_steps_trained: 1192000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.448230668414155\n",
      "    ram_util_percent: 40.25386631716908\n",
      "  pid: 3339694\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06971002965983936\n",
      "    mean_env_wait_ms: 118.8969269058467\n",
      "    mean_inference_ms: 1.6068751061790691\n",
      "    mean_raw_obs_processing_ms: 9.411515514803384\n",
      "  time_since_restore: 51563.21537041664\n",
      "  time_this_iter_s: 534.2131090164185\n",
      "  time_total_s: 161413.70934438705\n",
      "  timers:\n",
      "    learn_throughput: 360.255\n",
      "    learn_time_ms: 11103.255\n",
      "    load_throughput: 10556.103\n",
      "    load_time_ms: 378.928\n",
      "    sample_throughput: 7.533\n",
      "    sample_time_ms: 530976.461\n",
      "    update_time_ms: 3.331\n",
      "  timestamp: 1612954636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1192000\n",
      "  training_iteration: 298\n",
      "  trial_id: a0e0c_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">          110399</td><td style=\"text-align: right;\">808000</td><td style=\"text-align: right;\"> 76.3617</td><td style=\"text-align: right;\">             118.384</td><td style=\"text-align: right;\">            -96.5258</td><td style=\"text-align: right;\">           124.548</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">          110936</td><td style=\"text-align: right;\">812000</td><td style=\"text-align: right;\"> 68.5295</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">             -104.88</td><td style=\"text-align: right;\">           122.938</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">          111460</td><td style=\"text-align: right;\">816000</td><td style=\"text-align: right;\"> 64.1024</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -106.574</td><td style=\"text-align: right;\">            117.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">          111986</td><td style=\"text-align: right;\">820000</td><td style=\"text-align: right;\"> 66.0876</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.574</td><td style=\"text-align: right;\">            123.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">          112515</td><td style=\"text-align: right;\">824000</td><td style=\"text-align: right;\">  61.681</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.574</td><td style=\"text-align: right;\">            123.84</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">          113035</td><td style=\"text-align: right;\">828000</td><td style=\"text-align: right;\"> 60.0617</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.341</td><td style=\"text-align: right;\">            128.75</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">          113560</td><td style=\"text-align: right;\">832000</td><td style=\"text-align: right;\">  62.083</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.568</td><td style=\"text-align: right;\">            126.04</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">          114086</td><td style=\"text-align: right;\">836000</td><td style=\"text-align: right;\"> 70.5095</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.895</td><td style=\"text-align: right;\">            128.89</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">          114602</td><td style=\"text-align: right;\">840000</td><td style=\"text-align: right;\"> 70.3951</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.895</td><td style=\"text-align: right;\">            131.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">          115151</td><td style=\"text-align: right;\">844000</td><td style=\"text-align: right;\"> 67.8485</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.895</td><td style=\"text-align: right;\">            134.22</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">          115683</td><td style=\"text-align: right;\">848000</td><td style=\"text-align: right;\"> 68.3023</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.895</td><td style=\"text-align: right;\">            136.52</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">          116201</td><td style=\"text-align: right;\">852000</td><td style=\"text-align: right;\"> 66.1529</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.496</td><td style=\"text-align: right;\">            128.22</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">          116722</td><td style=\"text-align: right;\">856000</td><td style=\"text-align: right;\"> 64.2617</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.496</td><td style=\"text-align: right;\">            132.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">          117283</td><td style=\"text-align: right;\">860000</td><td style=\"text-align: right;\"> 51.7821</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -106.496</td><td style=\"text-align: right;\">            125.82</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">          117809</td><td style=\"text-align: right;\">864000</td><td style=\"text-align: right;\"> 49.6242</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -106.403</td><td style=\"text-align: right;\">            131.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">          118330</td><td style=\"text-align: right;\">868000</td><td style=\"text-align: right;\"> 58.0102</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -106.403</td><td style=\"text-align: right;\">            136.06</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">          118856</td><td style=\"text-align: right;\">872000</td><td style=\"text-align: right;\"> 64.4976</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -106.403</td><td style=\"text-align: right;\">            134.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">          119381</td><td style=\"text-align: right;\">876000</td><td style=\"text-align: right;\"> 55.8078</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.403</td><td style=\"text-align: right;\">            126.75</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">          119899</td><td style=\"text-align: right;\">880000</td><td style=\"text-align: right;\"> 64.5794</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -104.81</td><td style=\"text-align: right;\">            135.22</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">          120425</td><td style=\"text-align: right;\">884000</td><td style=\"text-align: right;\">  58.169</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -104.81</td><td style=\"text-align: right;\">            128.84</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">          120949</td><td style=\"text-align: right;\">888000</td><td style=\"text-align: right;\"> 68.4911</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">             -105.11</td><td style=\"text-align: right;\">            133.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">          121465</td><td style=\"text-align: right;\">892000</td><td style=\"text-align: right;\"> 58.2901</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">             -105.11</td><td style=\"text-align: right;\">            135.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">          121987</td><td style=\"text-align: right;\">896000</td><td style=\"text-align: right;\"> 66.8077</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">             -105.11</td><td style=\"text-align: right;\">            134.75</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">          122511</td><td style=\"text-align: right;\">900000</td><td style=\"text-align: right;\"> 66.8536</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -101.694</td><td style=\"text-align: right;\">            136.45</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">          123043</td><td style=\"text-align: right;\">904000</td><td style=\"text-align: right;\"> 66.9727</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -104.826</td><td style=\"text-align: right;\">            131.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">          123560</td><td style=\"text-align: right;\">908000</td><td style=\"text-align: right;\"> 74.9086</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.342</td><td style=\"text-align: right;\">            136.18</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">          124093</td><td style=\"text-align: right;\">912000</td><td style=\"text-align: right;\"> 68.5897</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.342</td><td style=\"text-align: right;\">            129.27</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">          124617</td><td style=\"text-align: right;\">916000</td><td style=\"text-align: right;\"> 64.4958</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.342</td><td style=\"text-align: right;\">             127.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">          125145</td><td style=\"text-align: right;\">920000</td><td style=\"text-align: right;\"> 60.6352</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.966</td><td style=\"text-align: right;\">            121.54</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">          125673</td><td style=\"text-align: right;\">924000</td><td style=\"text-align: right;\"> 62.6774</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -107.449</td><td style=\"text-align: right;\">            124.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">          126194</td><td style=\"text-align: right;\">928000</td><td style=\"text-align: right;\"> 68.5921</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -107.449</td><td style=\"text-align: right;\">             120.3</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">          126721</td><td style=\"text-align: right;\">932000</td><td style=\"text-align: right;\"> 68.3084</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -107.449</td><td style=\"text-align: right;\">            122.37</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">          127243</td><td style=\"text-align: right;\">936000</td><td style=\"text-align: right;\"> 64.1759</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.882</td><td style=\"text-align: right;\">            121.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">          127771</td><td style=\"text-align: right;\">940000</td><td style=\"text-align: right;\"> 66.1428</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.882</td><td style=\"text-align: right;\">            125.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">          128301</td><td style=\"text-align: right;\">944000</td><td style=\"text-align: right;\"> 68.6851</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.703</td><td style=\"text-align: right;\">            118.95</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">          128835</td><td style=\"text-align: right;\">948000</td><td style=\"text-align: right;\"> 77.2841</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -105.703</td><td style=\"text-align: right;\">            119.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">          129356</td><td style=\"text-align: right;\">952000</td><td style=\"text-align: right;\"> 79.6432</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -100.912</td><td style=\"text-align: right;\">            127.35</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">          129888</td><td style=\"text-align: right;\">956000</td><td style=\"text-align: right;\"> 90.0024</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">             -105.06</td><td style=\"text-align: right;\">            134.81</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">          130414</td><td style=\"text-align: right;\">960000</td><td style=\"text-align: right;\"> 87.7144</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">             -105.06</td><td style=\"text-align: right;\">            131.97</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">          130940</td><td style=\"text-align: right;\">964000</td><td style=\"text-align: right;\"> 89.7627</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">             -105.06</td><td style=\"text-align: right;\">            133.52</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">          131469</td><td style=\"text-align: right;\">968000</td><td style=\"text-align: right;\"> 91.8603</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">             -105.06</td><td style=\"text-align: right;\">            127.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">          132000</td><td style=\"text-align: right;\">972000</td><td style=\"text-align: right;\"> 89.8074</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -107.419</td><td style=\"text-align: right;\">            129.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">          132529</td><td style=\"text-align: right;\">976000</td><td style=\"text-align: right;\"> 80.6841</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.419</td><td style=\"text-align: right;\">            123.15</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">          133055</td><td style=\"text-align: right;\">980000</td><td style=\"text-align: right;\"> 67.9097</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.419</td><td style=\"text-align: right;\">            118.76</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">          133585</td><td style=\"text-align: right;\">984000</td><td style=\"text-align: right;\"> 68.1261</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.019</td><td style=\"text-align: right;\">             120.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">          134110</td><td style=\"text-align: right;\">988000</td><td style=\"text-align: right;\"> 75.1127</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.147</td><td style=\"text-align: right;\">            123.29</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">          134637</td><td style=\"text-align: right;\">992000</td><td style=\"text-align: right;\">  79.459</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.147</td><td style=\"text-align: right;\">            127.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">          135160</td><td style=\"text-align: right;\">996000</td><td style=\"text-align: right;\"> 81.1533</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -115.518</td><td style=\"text-align: right;\">            132.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">          135683</td><td style=\"text-align: right;\">1000000</td><td style=\"text-align: right;\"> 80.8558</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -115.518</td><td style=\"text-align: right;\">            134.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">          136210</td><td style=\"text-align: right;\">1004000</td><td style=\"text-align: right;\"> 81.0557</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -115.518</td><td style=\"text-align: right;\">             133.8</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">          136738</td><td style=\"text-align: right;\">1008000</td><td style=\"text-align: right;\"> 85.8326</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.378</td><td style=\"text-align: right;\">            129.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">          137265</td><td style=\"text-align: right;\">1012000</td><td style=\"text-align: right;\"> 77.6983</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.372</td><td style=\"text-align: right;\">            124.71</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">          137796</td><td style=\"text-align: right;\">1016000</td><td style=\"text-align: right;\"> 81.7872</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.372</td><td style=\"text-align: right;\">               132</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">          138316</td><td style=\"text-align: right;\">1020000</td><td style=\"text-align: right;\"> 83.6374</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.372</td><td style=\"text-align: right;\">            135.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">          138835</td><td style=\"text-align: right;\">1024000</td><td style=\"text-align: right;\"> 81.7584</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -102.873</td><td style=\"text-align: right;\">            137.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">          139361</td><td style=\"text-align: right;\">1028000</td><td style=\"text-align: right;\"> 83.7295</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -99.0582</td><td style=\"text-align: right;\">            133.93</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">          139885</td><td style=\"text-align: right;\">1032000</td><td style=\"text-align: right;\"> 87.8305</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -99.0582</td><td style=\"text-align: right;\">            134.31</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">          140411</td><td style=\"text-align: right;\">1036000</td><td style=\"text-align: right;\"> 85.6057</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -105.108</td><td style=\"text-align: right;\">            128.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">          140979</td><td style=\"text-align: right;\">1040000</td><td style=\"text-align: right;\"> 83.6018</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -105.108</td><td style=\"text-align: right;\">            129.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">          141506</td><td style=\"text-align: right;\">1044000</td><td style=\"text-align: right;\"> 79.3975</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">            -105.108</td><td style=\"text-align: right;\">            130.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">          142035</td><td style=\"text-align: right;\">1048000</td><td style=\"text-align: right;\"> 79.2441</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.108</td><td style=\"text-align: right;\">            129.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">          142558</td><td style=\"text-align: right;\">1052000</td><td style=\"text-align: right;\"> 83.6207</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -104.85</td><td style=\"text-align: right;\">             134.7</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">          143088</td><td style=\"text-align: right;\">1056000</td><td style=\"text-align: right;\"> 85.7901</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -98.8285</td><td style=\"text-align: right;\">            132.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">          143658</td><td style=\"text-align: right;\">1060000</td><td style=\"text-align: right;\"> 81.4712</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.382</td><td style=\"text-align: right;\">            133.12</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">          144213</td><td style=\"text-align: right;\">1064000</td><td style=\"text-align: right;\"> 85.3723</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -106.382</td><td style=\"text-align: right;\">            132.45</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">          144738</td><td style=\"text-align: right;\">1068000</td><td style=\"text-align: right;\"> 89.5405</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -106.382</td><td style=\"text-align: right;\">            127.94</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">          145268</td><td style=\"text-align: right;\">1072000</td><td style=\"text-align: right;\"> 89.6042</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -106.382</td><td style=\"text-align: right;\">            136.71</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">          145799</td><td style=\"text-align: right;\">1076000</td><td style=\"text-align: right;\">  87.921</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -99.4603</td><td style=\"text-align: right;\">            134.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">          146330</td><td style=\"text-align: right;\">1080000</td><td style=\"text-align: right;\"> 77.2294</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -105.88</td><td style=\"text-align: right;\">            131.06</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">          146860</td><td style=\"text-align: right;\">1084000</td><td style=\"text-align: right;\"> 81.1933</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -105.88</td><td style=\"text-align: right;\">            129.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">          147387</td><td style=\"text-align: right;\">1088000</td><td style=\"text-align: right;\"> 80.9832</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -105.88</td><td style=\"text-align: right;\">            130.01</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">          147909</td><td style=\"text-align: right;\">1092000</td><td style=\"text-align: right;\"> 85.1782</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">             -105.88</td><td style=\"text-align: right;\">            130.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">          148443</td><td style=\"text-align: right;\">1096000</td><td style=\"text-align: right;\"> 79.2294</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -105.332</td><td style=\"text-align: right;\">            131.71</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">          148975</td><td style=\"text-align: right;\">1100000</td><td style=\"text-align: right;\"> 79.0947</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -105.332</td><td style=\"text-align: right;\">            130.31</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">          149512</td><td style=\"text-align: right;\">1104000</td><td style=\"text-align: right;\"> 83.3583</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -105.332</td><td style=\"text-align: right;\">            132.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">          150068</td><td style=\"text-align: right;\">1108000</td><td style=\"text-align: right;\">  87.531</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -105.332</td><td style=\"text-align: right;\">            135.97</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">          150613</td><td style=\"text-align: right;\">1112000</td><td style=\"text-align: right;\"> 79.1456</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -105.523</td><td style=\"text-align: right;\">            136.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">          151143</td><td style=\"text-align: right;\">1116000</td><td style=\"text-align: right;\"> 77.2501</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.523</td><td style=\"text-align: right;\">            137.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">          151679</td><td style=\"text-align: right;\">1120000</td><td style=\"text-align: right;\"> 75.1753</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.523</td><td style=\"text-align: right;\">            133.02</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">          152207</td><td style=\"text-align: right;\">1124000</td><td style=\"text-align: right;\">  89.818</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -106.18</td><td style=\"text-align: right;\">            136.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">          152742</td><td style=\"text-align: right;\">1128000</td><td style=\"text-align: right;\"> 79.1579</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -106.18</td><td style=\"text-align: right;\">            129.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">          153275</td><td style=\"text-align: right;\">1132000</td><td style=\"text-align: right;\"> 68.3819</td><td style=\"text-align: right;\">             118.373</td><td style=\"text-align: right;\">             -106.18</td><td style=\"text-align: right;\">            131.38</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">          153808</td><td style=\"text-align: right;\">1136000</td><td style=\"text-align: right;\"> 61.8383</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -105.69</td><td style=\"text-align: right;\">            127.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">          154343</td><td style=\"text-align: right;\">1140000</td><td style=\"text-align: right;\"> 74.5173</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -105.69</td><td style=\"text-align: right;\">            130.14</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">          154884</td><td style=\"text-align: right;\">1144000</td><td style=\"text-align: right;\"> 82.9595</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">             -105.69</td><td style=\"text-align: right;\">            136.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">          155428</td><td style=\"text-align: right;\">1148000</td><td style=\"text-align: right;\"> 83.5107</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.632</td><td style=\"text-align: right;\">            132.52</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">          155987</td><td style=\"text-align: right;\">1152000</td><td style=\"text-align: right;\"> 73.2483</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -105.632</td><td style=\"text-align: right;\">            127.72</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">          156550</td><td style=\"text-align: right;\">1156000</td><td style=\"text-align: right;\"> 66.7098</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">              -112.4</td><td style=\"text-align: right;\">            117.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   290</td><td style=\"text-align: right;\">          157092</td><td style=\"text-align: right;\">1160000</td><td style=\"text-align: right;\"> 66.2096</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">              -112.4</td><td style=\"text-align: right;\">            112.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   291</td><td style=\"text-align: right;\">          157644</td><td style=\"text-align: right;\">1164000</td><td style=\"text-align: right;\"> 68.4434</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">              -112.4</td><td style=\"text-align: right;\">             118.4</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">          158207</td><td style=\"text-align: right;\">1168000</td><td style=\"text-align: right;\"> 79.2051</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -105.577</td><td style=\"text-align: right;\">            122.47</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   293</td><td style=\"text-align: right;\">          158745</td><td style=\"text-align: right;\">1172000</td><td style=\"text-align: right;\"> 83.7224</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -106.343</td><td style=\"text-align: right;\">            130.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">          159284</td><td style=\"text-align: right;\">1176000</td><td style=\"text-align: right;\"> 72.9546</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -106.343</td><td style=\"text-align: right;\">            126.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   295</td><td style=\"text-align: right;\">          159813</td><td style=\"text-align: right;\">1180000</td><td style=\"text-align: right;\"> 66.4533</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -106.343</td><td style=\"text-align: right;\">            127.57</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   296</td><td style=\"text-align: right;\">          160346</td><td style=\"text-align: right;\">1184000</td><td style=\"text-align: right;\">  68.463</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -104.556</td><td style=\"text-align: right;\">            124.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   297</td><td style=\"text-align: right;\">          160879</td><td style=\"text-align: right;\">1188000</td><td style=\"text-align: right;\">  74.795</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -104.556</td><td style=\"text-align: right;\">            124.59</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>RUNNING </td><td>192.168.178.60:3339694</td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">          161414</td><td style=\"text-align: right;\">1192000</td><td style=\"text-align: right;\"> 81.0927</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -106.638</td><td style=\"text-align: right;\">            121.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/13.72 GiB heap, 0.0/4.74 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-09_21-37-29<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_a0e0c_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">          161414</td><td style=\"text-align: right;\">1192000</td><td style=\"text-align: right;\"> 81.0927</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -106.638</td><td style=\"text-align: right;\">            121.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path, analysis = train(stop_criteria=stop,\n",
    "                                  config=config,\n",
    "                                  restorepath='/home/dschori/ray_results/'\n",
    "                                              'PPO_2021-02-09_17-09-27/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_2f1df_00000_0_2021-02-09_17-09-27/' \\\n",
    "                  'checkpoint_201/checkpoint-201')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Restore Agent for Testing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m [ERROR] [1613730491.594615, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m [WARN] [1613730491.597638, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m [WARN] [1613730491.598538, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 11:28:17,413\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 11:28:17,569\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-19 11:28:17,570\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=9122)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_nr = 164\n",
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-4.163545654589269, -4.685642251000309)\n",
      "(-4.163660477185073, -4.622855484191511)\n",
      "(-4.15834685476084, -4.542582733687483)\n",
      "(-4.146941683532642, -4.457256055048216)\n",
      "(-4.126270718285108, -4.369402592302591)\n",
      "(-4.102308745545383, -4.301763219536582)\n",
      "(-4.0695191542337055, -4.233968972539555)\n",
      "(-4.01467702615248, -4.141141622159252)\n",
      "(-3.969922633094214, -4.073711466240663)\n",
      "(-3.918750584542717, -4.00031087356683)\n",
      "(-3.85966770830398, -3.919659110174714)\n",
      "(-3.8111553220260346, -3.854636078567108)\n",
      "(-3.7601454854127825, -3.7889604073739243)\n",
      "(-3.7117794355632867, -3.7347356628531263)\n",
      "(-3.6518635516356137, -3.6790648837270297)\n",
      "(-3.586026610014752, -3.629353538660203)\n",
      "(-3.51805562068295, -3.5849551160682673)\n",
      "(-3.441997069826733, -3.5395191453608588)\n",
      "(-3.359005931365135, -3.4929079894255732)\n",
      "(-3.2616174411781365, -3.4398272545298445)\n",
      "(-3.1846638700169865, -3.3993599678941746)\n",
      "(-3.0850206572909826, -3.3476143631966377)\n",
      "(-3.014374009703257, -3.3127820610128706)\n",
      "(-2.9427695514517787, -3.282133382645069)\n",
      "(-2.859651833350493, -3.2563238813765887)\n",
      "(-2.7816477480831305, -3.2407469812304535)\n",
      "(-2.705935037428818, -3.230906686601093)\n",
      "(-2.614179349381635, -3.2225452842155553)\n",
      "(-2.5373090899969015, -3.217573307290211)\n",
      "(-2.4566901577579787, -3.212381267283219)\n",
      "(-2.3815255819464127, -3.2052915209061794)\n",
      "(-2.303844111907251, -3.1988196501281867)\n",
      "(-2.2250721832172546, -3.193897418272061)\n",
      "(-2.1564975836681652, -3.1903236869587763)\n",
      "(-2.0592452642817265, -3.1861034173406977)\n",
      "(-1.972819989953166, -3.182802397773398)\n",
      "(-1.881713038168061, -3.179623394279204)\n",
      "(-1.7916710595006864, -3.1767016291183543)\n",
      "(-1.6635101967228234, -3.1722257672259926)\n",
      "(-1.581609142962264, -3.1707334129054403)\n",
      "(-1.5102740198464693, -3.1739838021933577)\n",
      "(-1.435935264346408, -3.183324410851933)\n",
      "(-1.3486697905459082, -3.1991863848051247)\n",
      "(-1.2746670828532773, -3.2141712892009595)\n",
      "(-1.1977566684906502, -3.2278551969437568)\n",
      "(-1.1160212743947877, -3.2440444403090356)\n",
      "(-0.9968835741364052, -3.2733372958898275)\n",
      "(-0.9242351709053955, -3.2962307086319114)\n",
      "(-0.8460865751883031, -3.319515481698288)\n",
      "(-0.7829090203754452, -3.3331007174393847)\n",
      "(-0.6887933081591642, -3.3458681017916527)\n",
      "(-0.6091597372293271, -3.352529101728271)\n",
      "(-0.529814526615992, -3.361275709091)\n",
      "(-0.46573281302802, -3.3730634455863475)\n",
      "(-0.36927276918914564, -3.3987035089865683)\n",
      "(-0.29217696440287466, -3.419246421189323)\n",
      "(-0.20465030951216395, -3.4361173065133697)\n",
      "(-0.13598690444821812, -3.4425085458473954)\n",
      "(-0.03276916331845914, -3.4422506547830642)\n",
      "(0.05405631257906082, -3.4411022313491157)\n",
      "(0.1473257630136589, -3.440666929437352)\n",
      "(0.2224580057577076, -3.4416015598777663)\n",
      "(0.3077411700825812, -3.447825703176198)\n",
      "(0.3753024995268258, -3.4579848250659193)\n",
      "(0.4482252902354057, -3.4731600150149426)\n",
      "(0.5293371771158442, -3.4928461577896424)\n",
      "(0.6119472011024295, -3.5148094036058137)\n",
      "(0.7037785536340107, -3.539074525264046)\n",
      "(0.7750967410680828, -3.5553015954951785)\n",
      "(0.8959171275706065, -3.5860417485394764)\n",
      "(0.9799808770811731, -3.6114949411404407)\n",
      "(1.0692897204341882, -3.6358554384660393)\n",
      "(1.1387189891127727, -3.650114167506551)\n",
      "(1.2239027755597567, -3.6664275481717565)\n",
      "(1.2977635037955344, -3.676052099366998)\n",
      "(1.3780800662127293, -3.6797832100449517)\n",
      "(1.4424032634663797, -3.676089848587467)\n",
      "(1.528116107353459, -3.6637584409405477)\n",
      "(1.6130925304949721, -3.6480069086029747)\n",
      "(1.69345406501429, -3.6274599508600347)\n",
      "(1.78325101480051, -3.596623710626411)\n",
      "(1.8584374370352936, -3.5712409515871135)\n",
      "(1.9303433033913626, -3.552759600297858)\n",
      "(2.003977466408745, -3.54103178810519)\n",
      "(2.0763880254573035, -3.537172118789222)\n",
      "(2.1507153112324966, -3.541470657343304)\n",
      "(2.2119829984260893, -3.5514736134497626)\n",
      "(2.282660381900281, -3.5690388083915576)\n",
      "(2.36387585526844, -3.590270382840324)\n",
      "(2.4373039177859956, -3.6048753811422536)\n",
      "(2.5114450042858723, -3.612241948188036)\n",
      "(2.5747050640705105, -3.612513437038447)\n",
      "(2.657882987950166, -3.603129894613321)\n",
      "(2.7193633571620794, -3.58857350389864)\n",
      "(2.7885990471000417, -3.5643260603150053)\n",
      "(2.8582448994464915, -3.5332912307168276)\n",
      "(2.9328855281422697, -3.4919271166240375)\n",
      "(2.992763844666225, -3.4533483899549884)\n",
      "(3.0605696034253578, -3.3998678382561143)\n",
      "(3.1153756442687772, -3.3475485557123457)\n",
      "(3.178781490424449, -3.2876334772666023)\n",
      "(3.232781902180531, -3.243111196451334)\n",
      "(3.3073636758410365, -3.1925603168826107)\n",
      "(3.382231034965473, -3.152587359766549)\n",
      "(3.4773482467067294, -3.1100556792572753)\n",
      "(3.572995017189055, -3.069535751312274)\n",
      "(3.6417805427050722, -3.035152190583409)\n",
      "(3.7018200680251576, -2.999744383436468)\n",
      "(3.7678062123509215, -2.956340529024253)\n",
      "(3.8303266591787994, -2.9112277042495025)\n",
      "(3.8923341676209144, -2.8597954220633417)\n",
      "(3.9528229028224495, -2.7996591061044276)\n",
      "(4.011122771373396, -2.733545218214257)\n",
      "(4.062815905985545, -2.6724340292884454)\n",
      "(4.123349570125593, -2.60652593180015)\n",
      "(4.176131033087948, -2.5572576628465256)\n",
      "(4.238485228648841, -2.508779466403037)\n",
      "(4.31016610897528, -2.45992094473106)\n",
      "(4.381495468453029, -2.4136612348882758)\n",
      "(4.443196697837806, -2.370709695977719)\n",
      "(4.508630837135287, -2.320676057103691)\n",
      "(4.5596092035393125, -2.275098156172765)\n",
      "(4.619410139610719, -2.209188010112899)\n",
      "(4.665231894113224, -2.1440437465572595)\n",
      "(4.706342051468831, -2.068423426195711)\n",
      "(4.734670187937531, -1.9974338675751193)\n",
      "(4.751339531219343, -1.932297995733227)\n",
      "(4.759346126147262, -1.8726383868269585)\n",
      "(4.759904980152538, -1.7878659938324561)\n",
      "(4.750421187964893, -1.7131655870437978)\n",
      "(4.734454624588508, -1.6488373967025018)\n",
      "(4.70655669237848, -1.5754593271913186)\n",
      "(4.673186907935968, -1.5079718245424225)\n",
      "(4.628002132414125, -1.437269891243624)\n",
      "(4.584274046154994, -1.3827197400394131)\n",
      "(4.537140146908458, -1.3296989534992232)\n",
      "(4.483497678513895, -1.2686089457269438)\n",
      "(4.427970232675377, -1.1944408085471414)\n",
      "(4.395299855889167, -1.1396610055874812)\n",
      "(4.356193357028218, -1.0584981978155161)\n",
      "(4.3152053028782476, -0.9675353394276645)\n",
      "(4.28169275681952, -0.8932680263675908)\n",
      "(4.245946486110689, -0.8167981454852291)\n",
      "(4.204677628257972, -0.7426002303026306)\n",
      "(4.159489833157165, -0.6777627306668653)\n",
      "(4.090311075735134, -0.6010318622487961)\n",
      "(4.03114820286121, -0.54904109439735)\n",
      "(3.9678857728471097, -0.49651664734130163)\n",
      "(3.8996936640211213, -0.44576878338407216)\n",
      "(3.8114646061639172, -0.38824234873268537)\n",
      "(3.741014082581354, -0.3501876687998397)\n",
      "(3.6565145999149946, -0.3100547960719743)\n",
      "(3.576875894248197, -0.27577425033002206)\n",
      "(3.4850163502070304, -0.23813940573710346)\n",
      "(3.4065536359416235, -0.20759837050291477)\n",
      "(3.3159255734952446, -0.1732021184421494)\n",
      "(3.2344797891952144, -0.14334934085837758)\n",
      "(3.1381649615538065, -0.10835836301077843)\n",
      "(3.05430510906962, -0.07860851138325507)\n",
      "(2.952330373642367, -0.04450420951514325)\n",
      "(2.84951674647159, -0.02012935947099395)\n",
      "(2.7574085066918537, -0.01065782249540186)\n",
      "(2.6799211658723707, -0.012641438322519273)\n",
      "(2.6009648914516696, -0.02105976645032119)\n",
      "(2.5098728946355675, -0.035014840367763186)\n",
      "(2.429098961678587, -0.04983306418531447)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_now = time.time()\n",
    "while True:\n",
    "    episode_reward = test_traj(agent=agent, env=env)\n",
    "    if time.time() - time_now > 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m [ERROR] [1613740302.894058, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m [WARN] [1613740302.897071, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m [WARN] [1613740302.897807, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:11:48,913\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:11:49,042\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_1/checkpoint-1\n",
      "2021-02-19 14:11:49,043\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 580.1686522960663, '_episodes_total': 92}\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m [ERROR] [1613740403.715722, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m [WARN] [1613740403.719199, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m [WARN] [1613740403.720205, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:13:29,241\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:13:29,365\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_5/checkpoint-5\n",
      "2021-02-19 14:13:29,366\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 5, '_timesteps_total': None, '_time_total': 2726.3251144886017, '_episodes_total': 357}\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m [ERROR] [1613740518.489837, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m [WARN] [1613740518.493218, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m [WARN] [1613740518.494132, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:15:23,975\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:15:24,101\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_10/checkpoint-10\n",
      "2021-02-19 14:15:24,101\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': None, '_time_total': 5285.743098020554, '_episodes_total': 563}\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m [ERROR] [1613740695.813331, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m [WARN] [1613740695.816712, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m [WARN] [1613740695.817613, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:18:21,488\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:18:21,609\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_40/checkpoint-40\n",
      "2021-02-19 14:18:21,610\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 40, '_timesteps_total': None, '_time_total': 20344.65621137619, '_episodes_total': 1464}\n",
      "2021-02-19 14:22:23,855\tWARNING worker.py:1017 -- The actor or task with ID ffffffffffffffff04d70eec01000000 cannot be scheduled right now. It requires {CPU: 1.000000} for placement, but this node only has remaining {node:192.168.178.60: 1.000000}, {accelerator_type:GTX: 1.000000}, {CPU: 6.000000}, {GPU: 1.000000}, {memory: 15.527344 GiB}, {object_store_memory: 5.322266 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m [ERROR] [1613740946.972106, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m [WARN] [1613740946.975276, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m [WARN] [1613740946.976299, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:22:32,740\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:22:32,885\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_80/checkpoint-80\n",
      "2021-02-19 14:22:32,886\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 80, '_timesteps_total': None, '_time_total': 40383.41257071495, '_episodes_total': 2641}\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m [ERROR] [1613741237.839739, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m [WARN] [1613741237.842661, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m [WARN] [1613741237.843592, 0.000000]: END Init ControllersConnection\n",
      "2021-02-19 14:27:23,577\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-19 14:27:23,684\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-19 14:27:23,685\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=90244)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=93239)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=96555)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=101997)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=109774)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=120784)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "trajectories = {}\n",
    "runs = 15\n",
    "checkpoints = [1, 5, 10, 40, 80, 164]\n",
    "for checkpoint in checkpoints:\n",
    "#for checkpoint in [1, 10]:\n",
    "    checkpoint_nr = checkpoint\n",
    "    checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                      'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                      'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "    agent = load(checkpoint_path=checkpoint_path, config=config)\n",
    "    trajectories['checkpoint_traj_{}'.format(checkpoint)] = {}\n",
    "    trajectories['checkpoint_success_{}'.format(checkpoint)] = {}\n",
    "    for i in range(runs):\n",
    "        episode_reward, positions = test_traj(agent=agent, env=env)\n",
    "        trajectories['checkpoint_traj_{}'.format(checkpoint)]['run{}'.format(i)] = positions\n",
    "        if episode_reward > 0:\n",
    "           trajectories['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = True\n",
    "        else:\n",
    "           trajectories['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 30, Success Rate:       0.00%\n",
      "Episode: 152, Success Rate:       0.00%\n",
      "Episode: 152, Success Rate:      13.33%\n",
      "Episode: 305, Success Rate:      20.00%\n",
      "Episode: 305, Success Rate:      46.67%\n",
      "Episode: 1221, Success Rate:      73.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_theme(style=\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "img = plt.imread(\"background_env3.png\")\n",
    "ax.imshow(img, extent=[-6.1, 8.6, -7.3, 3.3])\n",
    "\n",
    "ax.set_xlabel('X- Coordinates (m)', fontsize=16)\n",
    "ax.set_ylabel('Y- Coordinates (m)', fontsize=16)\n",
    "\n",
    "ax.set_xlim([-6.1, 8.6])\n",
    "ax.set_ylim([-7.3, 3.3])\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(150)\n",
    "\n",
    "thickness = 1.0\n",
    "i = 0\n",
    "for checkpoint_key, checkpoint_value in trajectories.items():\n",
    "    if 'success' in checkpoint_key:\n",
    "        results = 0.0\n",
    "        for _, success in checkpoint_value.items():\n",
    "            results += int(success)\n",
    "        print('Episode: {}, Success Rate: {:10.2f}%'.format(int(checkpoints[i//2]*30.5305), (results/15.)*100.))\n",
    "        continue\n",
    "    line = None\n",
    "    for run_key, run_value in checkpoint_value.items():\n",
    "        x_s = [e[0] for e in run_value]\n",
    "        y_s = [e[1] for e in run_value]\n",
    "        starting_point = (x_s[0], y_s[0])\n",
    "        ending_point = (x_s[-1], y_s[-1])\n",
    "        ax.plot(*starting_point, marker='o', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        ax.plot(*ending_point, marker='D', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        line, = ax.plot(x_s, y_s, linestyle='dashed', linewidth=thickness, c=cmap(i * 10))\n",
    "    line.set_label('Episodes played: {}'.format(int(checkpoints[i//2]*30.5305)))\n",
    "    thickness += 0.3\n",
    "    i+=1\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('training_traj.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x=-6.1, 8.6\n",
    "y=-7.3, 3.3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-49841455",
   "language": "python",
   "display_name": "PyCharm (MasterThesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}