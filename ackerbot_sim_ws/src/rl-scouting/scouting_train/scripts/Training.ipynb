{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from scouting_gym.tasks.scouting_discrete_task import ScoutingDiscreteTask"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Register Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1614083071.792531, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1614083071.795765, 0.000000]: Start Init ControllersConnection\n",
      "[WARN] [1614083071.796618, 0.000000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box(0.0, 1.0, (84, 84, 4), float32)\n",
      "Action Space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Scouting-v0')\n",
    "\n",
    "print(\"Observation Space: {}\".format(env.observation_space))\n",
    "print(\"Action Space: {}\".format(env.action_space))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Environment State"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for _ in range(1):\n",
    "    obs, _, _, _ = env.step(action=2)\n",
    "plt.imshow(obs[:, :, 0])\n",
    "print(obs.min())\n",
    "print(obs.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ray Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env\": ScoutingDiscreteTask,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    #\"model\": {\"dim\": 84,\n",
    "    #          \"conv_filters\":\n",
    "    #              [[16, [3, 3], 2], [32, [3, 3], 2], [64, [3, 3], 2], [128, [11, 11], 1]]}\n",
    "}\n",
    "\n",
    "stop = {\n",
    "    \"episodes_total\": 6000,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 13:24:36,177\tINFO services.py:1171 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.178.60',\n 'raylet_ip_address': '192.168.178.60',\n 'redis_address': '192.168.178.60:6379',\n 'object_store_address': '/tmp/ray/session_2021-02-23_13-24-35_630430_67907/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2021-02-23_13-24-35_630430_67907/sockets/raylet',\n 'webui_url': '127.0.0.1:8265',\n 'session_dir': '/tmp/ray/session_2021-02-23_13-24-35_630430_67907',\n 'metrics_export_port': 62252,\n 'node_id': '347965b06058f3837391520507b72ab829d27fda'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(stop_criteria, config, restorepath):\n",
    "    \"\"\"\n",
    "    Train an RLlib PPO agent using tune until any of the configured stopping criteria is met.\n",
    "    :param stop_criteria: Dict with stopping criteria.\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/execution.html#tune-run\n",
    "    :return: Return the path to the saved agent (checkpoint) and tune's ExperimentAnalysis object\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/analysis.html#experimentanalysis-tune-experimentanalysis\n",
    "    \"\"\"\n",
    "    analysis = ray.tune.run(PPOTrainer, config=config,\n",
    "                            stop=stop_criteria,\n",
    "                            checkpoint_freq=1,\n",
    "                            checkpoint_at_end=True)\n",
    "    # list of lists: one list per checkpoint; each checkpoint list contains 1st the path, 2nd the metric value\n",
    "    checkpoints = analysis.get_trial_checkpoints_paths(trial=analysis.get_best_trial('episode_reward_mean', mode='max'),\n",
    "                                                       metric='episode_reward_mean',\n",
    "                                                       )\n",
    "    # retriev the checkpoint path; we only have a single checkpoint, so take the first one\n",
    "    checkpoint_path = checkpoints[0][0]\n",
    "    return checkpoint_path, analysis\n",
    "\n",
    "def load(checkpoint_path, config):\n",
    "    \"\"\"\n",
    "    Load a trained RLlib agent from the specified path. Call this before testing a trained agent.\n",
    "    :param path: Path pointing to the agent's saved checkpoint (only used for RLlib agents)\n",
    "    \"\"\"\n",
    "    agent = PPOTrainer(config=config)\n",
    "    agent.restore(checkpoint_path)\n",
    "    return agent\n",
    "\n",
    "def test(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward\n",
    "\n",
    "def test_traj(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    positions = []\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        positions.append(info['position'])\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward, positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:08:50,275\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:08:50,275\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [ERROR] [1613826533.817069, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [WARN] [1613826533.820390, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [WARN] [1613826533.821599, 0.000000]: END Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:09:02,828\tINFO trainable.py:99 -- Trainable.setup took 12.554 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:09:02,828\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m 2021-02-20 14:09:04,010\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2021-02-21 19:20:56,027\tINFO tune.py:448 -- Total run time: 105129.44 seconds (105127.92 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m None\n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-18-47\n",
      "  done: false\n",
      "  episode_len_mean: 42.774193548387096\n",
      "  episode_reward_max: 118.3770226650548\n",
      "  episode_reward_mean: -93.49711607437895\n",
      "  episode_reward_min: -108.06729370123062\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 93\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0761983394622803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02286132611334324\n",
      "        model: {}\n",
      "        policy_loss: -0.07078494131565094\n",
      "        total_loss: 4563.99365234375\n",
      "        vf_explained_var: 0.00946330837905407\n",
      "        vf_loss: 4564.0595703125\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.48023952095808\n",
      "    ram_util_percent: 37.813532934131736\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07197494001514879\n",
      "    mean_env_wait_ms: 112.34553633139029\n",
      "    mean_inference_ms: 1.7809661082463453\n",
      "    mean_raw_obs_processing_ms: 27.807813261604643\n",
      "  time_since_restore: 584.9675097465515\n",
      "  time_this_iter_s: 584.9675097465515\n",
      "  time_total_s: 584.9675097465515\n",
      "  timers:\n",
      "    learn_throughput: 253.426\n",
      "    learn_time_ms: 15783.684\n",
      "    load_throughput: 7741.232\n",
      "    load_time_ms: 516.714\n",
      "    sample_throughput: 7.037\n",
      "    sample_time_ms: 568442.875\n",
      "    update_time_ms: 3.667\n",
      "  timestamp: 1613827127\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 45.28\n",
      "  episode_reward_max: 114.28859343326474\n",
      "  episode_reward_mean: -92.27542371741615\n",
      "  episode_reward_min: -108.3686866748935\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 180\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0438920259475708\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023191144689917564\n",
      "        model: {}\n",
      "        policy_loss: -0.07785279303789139\n",
      "        total_loss: 3480.796875\n",
      "        vf_explained_var: 0.046449340879917145\n",
      "        vf_loss: 3480.867431640625\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.84639303482587\n",
      "    ram_util_percent: 40.14216417910448\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07122021483620367\n",
      "    mean_env_wait_ms: 110.89191863652708\n",
      "    mean_inference_ms: 1.7778514251688329\n",
      "    mean_raw_obs_processing_ms: 26.994923029883047\n",
      "  time_since_restore: 1148.2525837421417\n",
      "  time_this_iter_s: 563.2850739955902\n",
      "  time_total_s: 1148.2525837421417\n",
      "  timers:\n",
      "    learn_throughput: 257.011\n",
      "    learn_time_ms: 15563.538\n",
      "    load_throughput: 8988.19\n",
      "    load_time_ms: 445.028\n",
      "    sample_throughput: 7.17\n",
      "    sample_time_ms: 557910.93\n",
      "    update_time_ms: 3.753\n",
      "  timestamp: 1613827691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 54.83\n",
      "  episode_reward_max: 118.27492096385373\n",
      "  episode_reward_mean: -83.1376979845979\n",
      "  episode_reward_min: -108.48955659836412\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 246\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0064120292663574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02330060675740242\n",
      "        model: {}\n",
      "        policy_loss: -0.10005206614732742\n",
      "        total_loss: 2177.936767578125\n",
      "        vf_explained_var: 0.1864335983991623\n",
      "        vf_loss: 2178.0263671875\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.02032520325203\n",
      "    ram_util_percent: 41.75830429732869\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07286805882756153\n",
      "    mean_env_wait_ms: 113.7639370369599\n",
      "    mean_inference_ms: 1.8338129633350764\n",
      "    mean_raw_obs_processing_ms: 25.34804746344035\n",
      "  time_since_restore: 1751.5004198551178\n",
      "  time_this_iter_s: 603.2478361129761\n",
      "  time_total_s: 1751.5004198551178\n",
      "  timers:\n",
      "    learn_throughput: 258.053\n",
      "    learn_time_ms: 15500.72\n",
      "    load_throughput: 9547.432\n",
      "    load_time_ms: 418.961\n",
      "    sample_throughput: 7.046\n",
      "    sample_time_ms: 567723.594\n",
      "    update_time_ms: 3.715\n",
      "  timestamp: 1613828294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-46-56\n",
      "  done: false\n",
      "  episode_len_mean: 68.51\n",
      "  episode_reward_max: 118.31157546697884\n",
      "  episode_reward_mean: -76.31402308357566\n",
      "  episode_reward_min: -108.48955659836412\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 298\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9740287661552429\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019892195239663124\n",
      "        model: {}\n",
      "        policy_loss: -0.10140877962112427\n",
      "        total_loss: 1925.67626953125\n",
      "        vf_explained_var: 0.3578816056251526\n",
      "        vf_loss: 1925.76416015625\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.986577181208055\n",
      "    ram_util_percent: 42.26724832214765\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07324381118410192\n",
      "    mean_env_wait_ms: 114.54295829627914\n",
      "    mean_inference_ms: 1.8481601318124876\n",
      "    mean_raw_obs_processing_ms: 23.396152967037246\n",
      "  time_since_restore: 2273.680137872696\n",
      "  time_this_iter_s: 522.1797180175781\n",
      "  time_total_s: 2273.680137872696\n",
      "  timers:\n",
      "    learn_throughput: 258.695\n",
      "    learn_time_ms: 15462.215\n",
      "    load_throughput: 9614.248\n",
      "    load_time_ms: 416.049\n",
      "    sample_throughput: 7.242\n",
      "    sample_time_ms: 552365.006\n",
      "    update_time_ms: 3.703\n",
      "  timestamp: 1613828816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-55-38\n",
      "  done: false\n",
      "  episode_len_mean: 80.5\n",
      "  episode_reward_max: 118.31157546697884\n",
      "  episode_reward_mean: -74.5112076002168\n",
      "  episode_reward_min: -107.92826443871176\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 345\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9424479007720947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02245231159031391\n",
      "        model: {}\n",
      "        policy_loss: -0.11653962731361389\n",
      "        total_loss: 1288.709228515625\n",
      "        vf_explained_var: 0.3869043290615082\n",
      "        vf_loss: 1288.8104248046875\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72577181208053\n",
      "    ram_util_percent: 42.22281879194631\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07249784922092387\n",
      "    mean_env_wait_ms: 113.50241287673661\n",
      "    mean_inference_ms: 1.828461425537306\n",
      "    mean_raw_obs_processing_ms: 21.573286487015874\n",
      "  time_since_restore: 2795.7982223033905\n",
      "  time_this_iter_s: 522.1180844306946\n",
      "  time_total_s: 2795.7982223033905\n",
      "  timers:\n",
      "    learn_throughput: 259.098\n",
      "    learn_time_ms: 15438.197\n",
      "    load_throughput: 9892.16\n",
      "    load_time_ms: 404.361\n",
      "    sample_throughput: 7.365\n",
      "    sample_time_ms: 543144.949\n",
      "    update_time_ms: 3.796\n",
      "  timestamp: 1613829338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 82.55\n",
      "  episode_reward_max: 118.2661259262627\n",
      "  episode_reward_mean: -74.3606947192576\n",
      "  episode_reward_min: -106.65765904648111\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 394\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9189553260803223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017654838040471077\n",
      "        model: {}\n",
      "        policy_loss: -0.11349598318338394\n",
      "        total_loss: 1229.2088623046875\n",
      "        vf_explained_var: 0.5053565502166748\n",
      "        vf_loss: 1229.3043212890625\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.80053547523427\n",
      "    ram_util_percent: 42.14631860776439\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07204796356766235\n",
      "    mean_env_wait_ms: 112.94424999099478\n",
      "    mean_inference_ms: 1.816813155558226\n",
      "    mean_raw_obs_processing_ms: 20.25822482921732\n",
      "  time_since_restore: 3319.5827116966248\n",
      "  time_this_iter_s: 523.7844893932343\n",
      "  time_total_s: 3319.5827116966248\n",
      "  timers:\n",
      "    learn_throughput: 259.328\n",
      "    learn_time_ms: 15424.463\n",
      "    load_throughput: 9852.188\n",
      "    load_time_ms: 406.001\n",
      "    sample_throughput: 7.445\n",
      "    sample_time_ms: 537267.036\n",
      "    update_time_ms: 3.745\n",
      "  timestamp: 1613829862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-12-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.35\n",
      "  episode_reward_max: 118.30713776466433\n",
      "  episode_reward_mean: -63.523381138135264\n",
      "  episode_reward_min: -106.50578201134127\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 435\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8848854899406433\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02142045460641384\n",
      "        model: {}\n",
      "        policy_loss: -0.13100093603134155\n",
      "        total_loss: 1744.0987548828125\n",
      "        vf_explained_var: 0.4920734167098999\n",
      "        vf_loss: 1744.2078857421875\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57983651226158\n",
      "    ram_util_percent: 42.138555858310625\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07175735216903688\n",
      "    mean_env_wait_ms: 112.58858042984367\n",
      "    mean_inference_ms: 1.8089444376977242\n",
      "    mean_raw_obs_processing_ms: 19.35233802635811\n",
      "  time_since_restore: 3833.387715578079\n",
      "  time_this_iter_s: 513.8050038814545\n",
      "  time_total_s: 3833.387715578079\n",
      "  timers:\n",
      "    learn_throughput: 259.526\n",
      "    learn_time_ms: 15412.732\n",
      "    load_throughput: 9930.622\n",
      "    load_time_ms: 402.794\n",
      "    sample_throughput: 7.524\n",
      "    sample_time_ms: 531642.14\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613830376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.72\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -59.63567158117983\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 475\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.893488347530365\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014194161631166935\n",
      "        model: {}\n",
      "        policy_loss: -0.11310682445764542\n",
      "        total_loss: 1079.6142578125\n",
      "        vf_explained_var: 0.5432910919189453\n",
      "        vf_loss: 1079.7060546875\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.78260273972602\n",
      "    ram_util_percent: 42.12671232876713\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07151093329723217\n",
      "    mean_env_wait_ms: 112.28665160518358\n",
      "    mean_inference_ms: 1.8033442706119143\n",
      "    mean_raw_obs_processing_ms: 18.502838213535505\n",
      "  time_since_restore: 4344.969002723694\n",
      "  time_this_iter_s: 511.5812871456146\n",
      "  time_total_s: 4344.969002723694\n",
      "  timers:\n",
      "    learn_throughput: 259.672\n",
      "    learn_time_ms: 15404.019\n",
      "    load_throughput: 10033.785\n",
      "    load_time_ms: 398.653\n",
      "    sample_throughput: 7.588\n",
      "    sample_time_ms: 527152.073\n",
      "    update_time_ms: 3.679\n",
      "  timestamp: 1613830888\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-30-01\n",
      "  done: false\n",
      "  episode_len_mean: 99.61\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -61.824132908364724\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 514\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8881871104240417\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014235087670385838\n",
      "        model: {}\n",
      "        policy_loss: -0.11436835676431656\n",
      "        total_loss: 903.1644897460938\n",
      "        vf_explained_var: 0.5682339668273926\n",
      "        vf_loss: 903.2572631835938\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.68016415868673\n",
      "    ram_util_percent: 42.191928864569086\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07130826269094545\n",
      "    mean_env_wait_ms: 112.04481898841567\n",
      "    mean_inference_ms: 1.7991444980096603\n",
      "    mean_raw_obs_processing_ms: 17.715990003541425\n",
      "  time_since_restore: 4857.632814407349\n",
      "  time_this_iter_s: 512.6638116836548\n",
      "  time_total_s: 4857.632814407349\n",
      "  timers:\n",
      "    learn_throughput: 259.793\n",
      "    learn_time_ms: 15396.888\n",
      "    load_throughput: 10105.322\n",
      "    load_time_ms: 395.831\n",
      "    sample_throughput: 7.637\n",
      "    sample_time_ms: 523776.26\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613831401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-38-31\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -57.32057116780643\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 551\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8375014662742615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016036443412303925\n",
      "        model: {}\n",
      "        policy_loss: -0.12444860488176346\n",
      "        total_loss: 1020.59912109375\n",
      "        vf_explained_var: 0.6986218690872192\n",
      "        vf_loss: 1020.6992797851562\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7113854595336\n",
      "    ram_util_percent: 42.184636488340196\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0711633401790614\n",
      "    mean_env_wait_ms: 111.87942778208779\n",
      "    mean_inference_ms: 1.796204792466029\n",
      "    mean_raw_obs_processing_ms: 17.068492334631227\n",
      "  time_since_restore: 5368.266561508179\n",
      "  time_this_iter_s: 510.6337471008301\n",
      "  time_total_s: 5368.266561508179\n",
      "  timers:\n",
      "    learn_throughput: 259.868\n",
      "    learn_time_ms: 15392.406\n",
      "    load_throughput: 10161.363\n",
      "    load_time_ms: 393.648\n",
      "    sample_throughput: 7.679\n",
      "    sample_time_ms: 520870.662\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613831911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-46-55\n",
      "  done: false\n",
      "  episode_len_mean: 107.74\n",
      "  episode_reward_max: 118.37779062602058\n",
      "  episode_reward_mean: -44.2649893294039\n",
      "  episode_reward_min: -106.6639466464975\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 584\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8471274971961975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017741737887263298\n",
      "        model: {}\n",
      "        policy_loss: -0.13405659794807434\n",
      "        total_loss: 949.0671997070312\n",
      "        vf_explained_var: 0.7107579708099365\n",
      "        vf_loss: 949.1742553710938\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71237830319888\n",
      "    ram_util_percent: 42.22141863699583\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07104209578305797\n",
      "    mean_env_wait_ms: 111.75151112031331\n",
      "    mean_inference_ms: 1.7937164648929005\n",
      "    mean_raw_obs_processing_ms: 16.50943981550422\n",
      "  time_since_restore: 5871.953165054321\n",
      "  time_this_iter_s: 503.6866035461426\n",
      "  time_total_s: 5871.953165054321\n",
      "  timers:\n",
      "    learn_throughput: 260.637\n",
      "    learn_time_ms: 15347.012\n",
      "    load_throughput: 10523.864\n",
      "    load_time_ms: 380.089\n",
      "    sample_throughput: 7.8\n",
      "    sample_time_ms: 512807.791\n",
      "    update_time_ms: 3.673\n",
      "  timestamp: 1613832415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 112.6\n",
      "  episode_reward_max: 118.37779062602058\n",
      "  episode_reward_mean: -37.80436355311525\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 620\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.833489179611206\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01759730838239193\n",
      "        model: {}\n",
      "        policy_loss: -0.13340024650096893\n",
      "        total_loss: 1048.4493408203125\n",
      "        vf_explained_var: 0.6537086367607117\n",
      "        vf_loss: 1048.555908203125\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 48000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61522633744856\n",
      "    ram_util_percent: 42.17366255144033\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07093759001518152\n",
      "    mean_env_wait_ms: 111.64461784042756\n",
      "    mean_inference_ms: 1.7913958009287085\n",
      "    mean_raw_obs_processing_ms: 15.962087600789314\n",
      "  time_since_restore: 6383.151445388794\n",
      "  time_this_iter_s: 511.19828033447266\n",
      "  time_total_s: 6383.151445388794\n",
      "  timers:\n",
      "    learn_throughput: 260.664\n",
      "    learn_time_ms: 15345.431\n",
      "    load_throughput: 10541.219\n",
      "    load_time_ms: 379.463\n",
      "    sample_throughput: 7.88\n",
      "    sample_time_ms: 507605.385\n",
      "    update_time_ms: 3.876\n",
      "  timestamp: 1613832926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-03-50\n",
      "  done: false\n",
      "  episode_len_mean: 117.99\n",
      "  episode_reward_max: 118.32474575086673\n",
      "  episode_reward_mean: -27.58161138389983\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 652\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7921907305717468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01740110106766224\n",
      "        model: {}\n",
      "        policy_loss: -0.13286353647708893\n",
      "        total_loss: 986.4422607421875\n",
      "        vf_explained_var: 0.7495697736740112\n",
      "        vf_loss: 986.5487670898438\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.74923504867871\n",
      "    ram_util_percent: 42.19179415855354\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0708550657451176\n",
      "    mean_env_wait_ms: 111.5553781191144\n",
      "    mean_inference_ms: 1.7895062860252369\n",
      "    mean_raw_obs_processing_ms: 15.49720560298924\n",
      "  time_since_restore: 6886.85665345192\n",
      "  time_this_iter_s: 503.7052080631256\n",
      "  time_total_s: 6886.85665345192\n",
      "  timers:\n",
      "    learn_throughput: 260.747\n",
      "    learn_time_ms: 15340.552\n",
      "    load_throughput: 10429.202\n",
      "    load_time_ms: 383.538\n",
      "    sample_throughput: 8.038\n",
      "    sample_time_ms: 497648.979\n",
      "    update_time_ms: 3.965\n",
      "  timestamp: 1613833430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-12-22\n",
      "  done: false\n",
      "  episode_len_mean: 114.17\n",
      "  episode_reward_max: 118.34763032056395\n",
      "  episode_reward_mean: -27.616167549093642\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 691\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7926270961761475\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016526449471712112\n",
      "        model: {}\n",
      "        policy_loss: -0.12517505884170532\n",
      "        total_loss: 1409.384521484375\n",
      "        vf_explained_var: 0.6078544855117798\n",
      "        vf_loss: 1409.4847412109375\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 56000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75342465753425\n",
      "    ram_util_percent: 42.14630136986302\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07078901034130622\n",
      "    mean_env_wait_ms: 111.47776106342957\n",
      "    mean_inference_ms: 1.7877140804958083\n",
      "    mean_raw_obs_processing_ms: 15.09152646575455\n",
      "  time_since_restore: 7398.7250781059265\n",
      "  time_this_iter_s: 511.86842465400696\n",
      "  time_total_s: 7398.7250781059265\n",
      "  timers:\n",
      "    learn_throughput: 260.776\n",
      "    learn_time_ms: 15338.848\n",
      "    load_throughput: 10544.393\n",
      "    load_time_ms: 379.349\n",
      "    sample_throughput: 8.054\n",
      "    sample_time_ms: 496622.122\n",
      "    update_time_ms: 3.964\n",
      "  timestamp: 1613833942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 112.11\n",
      "  episode_reward_max: 118.35346512980267\n",
      "  episode_reward_mean: -20.962442561296843\n",
      "  episode_reward_min: -107.14378950829905\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 725\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7813454866409302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017482509836554527\n",
      "        model: {}\n",
      "        policy_loss: -0.1358514428138733\n",
      "        total_loss: 1851.878173828125\n",
      "        vf_explained_var: 0.5138440132141113\n",
      "        vf_loss: 1851.9873046875\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.659862068965516\n",
      "    ram_util_percent: 42.23862068965517\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07073730141570324\n",
      "    mean_env_wait_ms: 111.41417937432274\n",
      "    mean_inference_ms: 1.7862244263998557\n",
      "    mean_raw_obs_processing_ms: 14.776521986543223\n",
      "  time_since_restore: 7906.858117580414\n",
      "  time_this_iter_s: 508.1330394744873\n",
      "  time_total_s: 7906.858117580414\n",
      "  timers:\n",
      "    learn_throughput: 260.787\n",
      "    learn_time_ms: 15338.184\n",
      "    load_throughput: 10444.494\n",
      "    load_time_ms: 382.977\n",
      "    sample_throughput: 8.077\n",
      "    sample_time_ms: 495219.611\n",
      "    update_time_ms: 3.916\n",
      "  timestamp: 1613834450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 109.96\n",
      "  episode_reward_max: 118.35346512980267\n",
      "  episode_reward_mean: -18.75715464557466\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 761\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7650612592697144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01819213666021824\n",
      "        model: {}\n",
      "        policy_loss: -0.13488051295280457\n",
      "        total_loss: 1805.126708984375\n",
      "        vf_explained_var: 0.504750669002533\n",
      "        vf_loss: 1805.23388671875\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 64000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.68347107438016\n",
      "    ram_util_percent: 42.208953168044076\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07069342223139513\n",
      "    mean_env_wait_ms: 111.3599021075677\n",
      "    mean_inference_ms: 1.7847514919566214\n",
      "    mean_raw_obs_processing_ms: 14.519880312636424\n",
      "  time_since_restore: 8415.256796121597\n",
      "  time_this_iter_s: 508.3986785411835\n",
      "  time_total_s: 8415.256796121597\n",
      "  timers:\n",
      "    learn_throughput: 260.81\n",
      "    learn_time_ms: 15336.824\n",
      "    load_throughput: 10583.22\n",
      "    load_time_ms: 377.957\n",
      "    sample_throughput: 8.102\n",
      "    sample_time_ms: 493684.154\n",
      "    update_time_ms: 4.014\n",
      "  timestamp: 1613834959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 120.49\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -14.285936706308428\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 791\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7496641874313354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019364701583981514\n",
      "        model: {}\n",
      "        policy_loss: -0.13387431204319\n",
      "        total_loss: 1098.99560546875\n",
      "        vf_explained_var: 0.661304235458374\n",
      "        vf_loss: 1099.0999755859375\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60835654596101\n",
      "    ram_util_percent: 42.167270194986074\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07065488171285099\n",
      "    mean_env_wait_ms: 111.3241307552929\n",
      "    mean_inference_ms: 1.7835782570333196\n",
      "    mean_raw_obs_processing_ms: 14.269352176899874\n",
      "  time_since_restore: 8918.76670885086\n",
      "  time_this_iter_s: 503.5099127292633\n",
      "  time_total_s: 8918.76670885086\n",
      "  timers:\n",
      "    learn_throughput: 260.854\n",
      "    learn_time_ms: 15334.221\n",
      "    load_throughput: 10626.154\n",
      "    load_time_ms: 376.43\n",
      "    sample_throughput: 8.119\n",
      "    sample_time_ms: 492661.291\n",
      "    update_time_ms: 4.04\n",
      "  timestamp: 1613835462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 123.46\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -16.785158096241034\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 822\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7540880441665649\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019368959590792656\n",
      "        model: {}\n",
      "        policy_loss: -0.14248614013195038\n",
      "        total_loss: 1216.87744140625\n",
      "        vf_explained_var: 0.6238676905632019\n",
      "        vf_loss: 1216.9906005859375\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 72000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7082402234637\n",
      "    ram_util_percent: 42.18617318435754\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07060540628940473\n",
      "    mean_env_wait_ms: 111.28075957730394\n",
      "    mean_inference_ms: 1.7825459579854874\n",
      "    mean_raw_obs_processing_ms: 14.023184899113176\n",
      "  time_since_restore: 9420.529680490494\n",
      "  time_this_iter_s: 501.7629716396332\n",
      "  time_total_s: 9420.529680490494\n",
      "  timers:\n",
      "    learn_throughput: 260.88\n",
      "    learn_time_ms: 15332.692\n",
      "    load_throughput: 10536.835\n",
      "    load_time_ms: 379.621\n",
      "    sample_throughput: 8.135\n",
      "    sample_time_ms: 491674.687\n",
      "    update_time_ms: 4.023\n",
      "  timestamp: 1613835964\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-54-28\n",
      "  done: false\n",
      "  episode_len_mean: 125.66\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -16.635151349911744\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 855\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7352050542831421\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01947021298110485\n",
      "        model: {}\n",
      "        policy_loss: -0.1371580809354782\n",
      "        total_loss: 1364.107177734375\n",
      "        vf_explained_var: 0.6220147013664246\n",
      "        vf_loss: 1364.2147216796875\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.838942976356044\n",
      "    ram_util_percent: 42.21223922114048\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07055628986635981\n",
      "    mean_env_wait_ms: 111.23097080172302\n",
      "    mean_inference_ms: 1.7815564425989334\n",
      "    mean_raw_obs_processing_ms: 13.76615522826784\n",
      "  time_since_restore: 9924.060046195984\n",
      "  time_this_iter_s: 503.5303657054901\n",
      "  time_total_s: 9924.060046195984\n",
      "  timers:\n",
      "    learn_throughput: 260.866\n",
      "    learn_time_ms: 15333.563\n",
      "    load_throughput: 10489.54\n",
      "    load_time_ms: 381.332\n",
      "    sample_throughput: 8.151\n",
      "    sample_time_ms: 490761.917\n",
      "    update_time_ms: 3.993\n",
      "  timestamp: 1613836468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-02-55\n",
      "  done: false\n",
      "  episode_len_mean: 122.28\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -19.05427828901017\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 888\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7261008024215698\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02093971148133278\n",
      "        model: {}\n",
      "        policy_loss: -0.13702255487442017\n",
      "        total_loss: 1568.1337890625\n",
      "        vf_explained_var: 0.5397771596908569\n",
      "        vf_loss: 1568.239013671875\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.70828729281767\n",
      "    ram_util_percent: 42.19530386740332\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07051613655744564\n",
      "    mean_env_wait_ms: 111.18505007432478\n",
      "    mean_inference_ms: 1.780629552901428\n",
      "    mean_raw_obs_processing_ms: 13.540986767124712\n",
      "  time_since_restore: 10431.394457101822\n",
      "  time_this_iter_s: 507.334410905838\n",
      "  time_total_s: 10431.394457101822\n",
      "  timers:\n",
      "    learn_throughput: 260.875\n",
      "    learn_time_ms: 15333.029\n",
      "    load_throughput: 10507.372\n",
      "    load_time_ms: 380.685\n",
      "    sample_throughput: 8.156\n",
      "    sample_time_ms: 490433.243\n",
      "    update_time_ms: 3.988\n",
      "  timestamp: 1613836975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-11-19\n",
      "  done: false\n",
      "  episode_len_mean: 120.9\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: -12.310829991559114\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 920\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.70824134349823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01423901692032814\n",
      "        model: {}\n",
      "        policy_loss: -0.12159629911184311\n",
      "        total_loss: 1377.1143798828125\n",
      "        vf_explained_var: 0.5997397303581238\n",
      "        vf_loss: 1377.2037353515625\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57621696801112\n",
      "    ram_util_percent: 42.23449235048678\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07049318642704192\n",
      "    mean_env_wait_ms: 111.14931717979958\n",
      "    mean_inference_ms: 1.7797591977790392\n",
      "    mean_raw_obs_processing_ms: 13.358750470278427\n",
      "  time_since_restore: 10935.541148424149\n",
      "  time_this_iter_s: 504.14669132232666\n",
      "  time_total_s: 10935.541148424149\n",
      "  timers:\n",
      "    learn_throughput: 260.831\n",
      "    learn_time_ms: 15335.624\n",
      "    load_throughput: 10536.602\n",
      "    load_time_ms: 379.629\n",
      "    sample_throughput: 8.155\n",
      "    sample_time_ms: 490478.487\n",
      "    update_time_ms: 3.98\n",
      "  timestamp: 1613837479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 119.66\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: -5.866658288115945\n",
      "  episode_reward_min: -106.86675580611211\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 955\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6930056810379028\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01464045513421297\n",
      "        model: {}\n",
      "        policy_loss: -0.12477900087833405\n",
      "        total_loss: 1798.8236083984375\n",
      "        vf_explained_var: 0.5352810025215149\n",
      "        vf_loss: 1798.9150390625\n",
      "    num_steps_sampled: 88000\n",
      "    num_steps_trained: 88000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71424619640386\n",
      "    ram_util_percent: 42.19128630705394\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0704745226511796\n",
      "    mean_env_wait_ms: 111.11939499798135\n",
      "    mean_inference_ms: 1.7788941975198371\n",
      "    mean_raw_obs_processing_ms: 13.19077736985796\n",
      "  time_since_restore: 11442.23236489296\n",
      "  time_this_iter_s: 506.69121646881104\n",
      "  time_total_s: 11442.23236489296\n",
      "  timers:\n",
      "    learn_throughput: 260.819\n",
      "    learn_time_ms: 15336.297\n",
      "    load_throughput: 10483.409\n",
      "    load_time_ms: 381.555\n",
      "    sample_throughput: 8.163\n",
      "    sample_time_ms: 490023.271\n",
      "    update_time_ms: 3.734\n",
      "  timestamp: 1613837986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 88000\n",
      "  training_iteration: 22\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 124.01\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: 6.998789734124133\n",
      "  episode_reward_min: -106.7017113793944\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 985\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6945086121559143\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014527100138366222\n",
      "        model: {}\n",
      "        policy_loss: -0.12096773833036423\n",
      "        total_loss: 1275.7939453125\n",
      "        vf_explained_var: 0.6098142862319946\n",
      "        vf_loss: 1275.8819580078125\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.636541143654114\n",
      "    ram_util_percent: 42.231659693165966\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07045896523118514\n",
      "    mean_env_wait_ms: 111.09149651191204\n",
      "    mean_inference_ms: 1.778265931415495\n",
      "    mean_raw_obs_processing_ms: 13.050278562975482\n",
      "  time_since_restore: 11944.09179854393\n",
      "  time_this_iter_s: 501.85943365097046\n",
      "  time_total_s: 11944.09179854393\n",
      "  timers:\n",
      "    learn_throughput: 260.827\n",
      "    learn_time_ms: 15335.839\n",
      "    load_throughput: 10589.766\n",
      "    load_time_ms: 377.723\n",
      "    sample_throughput: 8.166\n",
      "    sample_time_ms: 489846.579\n",
      "    update_time_ms: 3.607\n",
      "  timestamp: 1613838488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-36-34\n",
      "  done: false\n",
      "  episode_len_mean: 123.87\n",
      "  episode_reward_max: 118.3395831387293\n",
      "  episode_reward_mean: 15.293911476606176\n",
      "  episode_reward_min: -106.7017113793944\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1018\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6948832273483276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01476839929819107\n",
      "        model: {}\n",
      "        policy_loss: -0.12513484060764313\n",
      "        total_loss: 1115.804931640625\n",
      "        vf_explained_var: 0.6886588931083679\n",
      "        vf_loss: 1115.8966064453125\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 96000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.62991689750693\n",
      "    ram_util_percent: 42.211634349030476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07044008192298663\n",
      "    mean_env_wait_ms: 111.06321753615448\n",
      "    mean_inference_ms: 1.7776164476564702\n",
      "    mean_raw_obs_processing_ms: 12.909237082108405\n",
      "  time_since_restore: 12450.006348371506\n",
      "  time_this_iter_s: 505.9145498275757\n",
      "  time_total_s: 12450.006348371506\n",
      "  timers:\n",
      "    learn_throughput: 260.756\n",
      "    learn_time_ms: 15340.008\n",
      "    load_throughput: 10459.126\n",
      "    load_time_ms: 382.441\n",
      "    sample_throughput: 8.176\n",
      "    sample_time_ms: 489242.181\n",
      "    update_time_ms: 3.58\n",
      "  timestamp: 1613838994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 24\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-44-58\n",
      "  done: false\n",
      "  episode_len_mean: 126.73\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 30.233502197167073\n",
      "  episode_reward_min: -105.22484963962395\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1049\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6816383600234985\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015095611102879047\n",
      "        model: {}\n",
      "        policy_loss: -0.1279529482126236\n",
      "        total_loss: 1255.4622802734375\n",
      "        vf_explained_var: 0.6161641478538513\n",
      "        vf_loss: 1255.5557861328125\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.64283727399165\n",
      "    ram_util_percent: 42.207788595271204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0704241765388529\n",
      "    mean_env_wait_ms: 111.04518944599339\n",
      "    mean_inference_ms: 1.7770956349540592\n",
      "    mean_raw_obs_processing_ms: 12.775610119884405\n",
      "  time_since_restore: 12954.356755018234\n",
      "  time_this_iter_s: 504.3504066467285\n",
      "  time_total_s: 12954.356755018234\n",
      "  timers:\n",
      "    learn_throughput: 260.752\n",
      "    learn_time_ms: 15340.229\n",
      "    load_throughput: 10501.392\n",
      "    load_time_ms: 380.902\n",
      "    sample_throughput: 8.182\n",
      "    sample_time_ms: 488865.351\n",
      "    update_time_ms: 3.546\n",
      "  timestamp: 1613839498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 125.61\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 23.559431281202528\n",
      "  episode_reward_min: -105.22484963962395\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1082\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6820441484451294\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01384813617914915\n",
      "        model: {}\n",
      "        policy_loss: -0.11520286649465561\n",
      "        total_loss: 1187.2332763671875\n",
      "        vf_explained_var: 0.6505010724067688\n",
      "        vf_loss: 1187.31689453125\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 104000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7009735744089\n",
      "    ram_util_percent: 42.20639777468706\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07040890131315722\n",
      "    mean_env_wait_ms: 111.020601745741\n",
      "    mean_inference_ms: 1.77661679011248\n",
      "    mean_raw_obs_processing_ms: 12.648610157034309\n",
      "  time_since_restore: 13457.7450299263\n",
      "  time_this_iter_s: 503.3882749080658\n",
      "  time_total_s: 13457.7450299263\n",
      "  timers:\n",
      "    learn_throughput: 260.752\n",
      "    learn_time_ms: 15340.253\n",
      "    load_throughput: 10496.954\n",
      "    load_time_ms: 381.063\n",
      "    sample_throughput: 8.191\n",
      "    sample_time_ms: 488365.09\n",
      "    update_time_ms: 3.474\n",
      "  timestamp: 1613840002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 26\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 127.16\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 36.48697008197477\n",
      "  episode_reward_min: -105.02049054797493\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1112\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6504806280136108\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012804980389773846\n",
      "        model: {}\n",
      "        policy_loss: -0.11266468465328217\n",
      "        total_loss: 1185.9178466796875\n",
      "        vf_explained_var: 0.542258083820343\n",
      "        vf_loss: 1186.001220703125\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.65815899581591\n",
      "    ram_util_percent: 42.21924686192469\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07039732274589429\n",
      "    mean_env_wait_ms: 111.00094092547454\n",
      "    mean_inference_ms: 1.7761994000854702\n",
      "    mean_raw_obs_processing_ms: 12.53645227464082\n",
      "  time_since_restore: 13960.061575174332\n",
      "  time_this_iter_s: 502.3165452480316\n",
      "  time_total_s: 13960.061575174332\n",
      "  timers:\n",
      "    learn_throughput: 260.719\n",
      "    learn_time_ms: 15342.191\n",
      "    load_throughput: 10401.78\n",
      "    load_time_ms: 384.55\n",
      "    sample_throughput: 8.193\n",
      "    sample_time_ms: 488238.812\n",
      "    update_time_ms: 3.457\n",
      "  timestamp: 1613840504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 131.44\n",
      "  episode_reward_max: 118.36507583714197\n",
      "  episode_reward_mean: 36.23231503613656\n",
      "  episode_reward_min: -105.78551474080567\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1140\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6783497929573059\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013919226825237274\n",
      "        model: {}\n",
      "        policy_loss: -0.1166716143488884\n",
      "        total_loss: 1227.0704345703125\n",
      "        vf_explained_var: 0.5477025508880615\n",
      "        vf_loss: 1227.1553955078125\n",
      "    num_steps_sampled: 112000\n",
      "    num_steps_trained: 112000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.758426966292134\n",
      "    ram_util_percent: 42.23160112359551\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07038291347658035\n",
      "    mean_env_wait_ms: 110.98060862891019\n",
      "    mean_inference_ms: 1.775780173131198\n",
      "    mean_raw_obs_processing_ms: 12.425000683116933\n",
      "  time_since_restore: 14459.337463378906\n",
      "  time_this_iter_s: 499.2758882045746\n",
      "  time_total_s: 14459.337463378906\n",
      "  timers:\n",
      "    learn_throughput: 260.671\n",
      "    learn_time_ms: 15344.991\n",
      "    load_throughput: 10511.413\n",
      "    load_time_ms: 380.539\n",
      "    sample_throughput: 8.197\n",
      "    sample_time_ms: 487992.957\n",
      "    update_time_ms: 3.48\n",
      "  timestamp: 1613841004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 112000\n",
      "  training_iteration: 28\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 135.09\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 32.10021681225889\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1170\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6964059472084045\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013909266330301762\n",
      "        model: {}\n",
      "        policy_loss: -0.11934468150138855\n",
      "        total_loss: 1181.1661376953125\n",
      "        vf_explained_var: 0.5709272623062134\n",
      "        vf_loss: 1181.2537841796875\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.857697642163664\n",
      "    ram_util_percent: 39.77101248266297\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703686888714543\n",
      "    mean_env_wait_ms: 110.97097829864457\n",
      "    mean_inference_ms: 1.7753516723352671\n",
      "    mean_raw_obs_processing_ms: 12.302189914191656\n",
      "  time_since_restore: 14964.054445505142\n",
      "  time_this_iter_s: 504.71698212623596\n",
      "  time_total_s: 14964.054445505142\n",
      "  timers:\n",
      "    learn_throughput: 260.711\n",
      "    learn_time_ms: 15342.681\n",
      "    load_throughput: 10415.753\n",
      "    load_time_ms: 384.034\n",
      "    sample_throughput: 8.195\n",
      "    sample_time_ms: 488109.406\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613841508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 140.88\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 40.35233156049454\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 1196\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.674450695514679\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013536256738007069\n",
      "        model: {}\n",
      "        policy_loss: -0.1175597608089447\n",
      "        total_loss: 1170.9039306640625\n",
      "        vf_explained_var: 0.5870176553726196\n",
      "        vf_loss: 1170.9906005859375\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50622347949081\n",
      "    ram_util_percent: 36.924328147100425\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035949048792381\n",
      "    mean_env_wait_ms: 110.96037487540852\n",
      "    mean_inference_ms: 1.7749863169787523\n",
      "    mean_raw_obs_processing_ms: 12.184954414521753\n",
      "  time_since_restore: 15459.731275558472\n",
      "  time_this_iter_s: 495.67683005332947\n",
      "  time_total_s: 15459.731275558472\n",
      "  timers:\n",
      "    learn_throughput: 260.758\n",
      "    learn_time_ms: 15339.91\n",
      "    load_throughput: 10387.519\n",
      "    load_time_ms: 385.078\n",
      "    sample_throughput: 8.214\n",
      "    sample_time_ms: 486947.215\n",
      "    update_time_ms: 3.492\n",
      "  timestamp: 1613842004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 30\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 144.89\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 47.023250764741846\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1223\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6427279710769653\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011490685865283012\n",
      "        model: {}\n",
      "        policy_loss: -0.10050224512815475\n",
      "        total_loss: 756.8341674804688\n",
      "        vf_explained_var: 0.6174790859222412\n",
      "        vf_loss: 756.9085083007812\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.377387640449435\n",
      "    ram_util_percent: 36.87710674157304\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035092872158756\n",
      "    mean_env_wait_ms: 110.95021412938355\n",
      "    mean_inference_ms: 1.774614179317349\n",
      "    mean_raw_obs_processing_ms: 12.061422517334409\n",
      "  time_since_restore: 15958.507922649384\n",
      "  time_this_iter_s: 498.77664709091187\n",
      "  time_total_s: 15958.507922649384\n",
      "  timers:\n",
      "    learn_throughput: 260.83\n",
      "    learn_time_ms: 15335.636\n",
      "    load_throughput: 10336.547\n",
      "    load_time_ms: 386.976\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486409.376\n",
      "    update_time_ms: 3.548\n",
      "  timestamp: 1613842503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 143.39\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 45.02980851393272\n",
      "  episode_reward_min: -106.13181011328527\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1252\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6459044218063354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013180318288505077\n",
      "        model: {}\n",
      "        policy_loss: -0.10961834341287613\n",
      "        total_loss: 1246.991455078125\n",
      "        vf_explained_var: 0.6224071383476257\n",
      "        vf_loss: 1247.071044921875\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 128000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.74138418079096\n",
      "    ram_util_percent: 36.838418079096044\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034702179490523\n",
      "    mean_env_wait_ms: 110.92817621890161\n",
      "    mean_inference_ms: 1.774262699782484\n",
      "    mean_raw_obs_processing_ms: 11.937789569935498\n",
      "  time_since_restore: 16455.04742050171\n",
      "  time_this_iter_s: 496.53949785232544\n",
      "  time_total_s: 16455.04742050171\n",
      "  timers:\n",
      "    learn_throughput: 260.844\n",
      "    learn_time_ms: 15334.842\n",
      "    load_throughput: 10334.558\n",
      "    load_time_ms: 387.051\n",
      "    sample_throughput: 8.241\n",
      "    sample_time_ms: 485394.114\n",
      "    update_time_ms: 3.588\n",
      "  timestamp: 1613843000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 32\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 143.61\n",
      "  episode_reward_max: 118.37212468138358\n",
      "  episode_reward_mean: 42.767731893081546\n",
      "  episode_reward_min: -105.07795578663634\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1282\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6835929155349731\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015338728204369545\n",
      "        model: {}\n",
      "        policy_loss: -0.13167516887187958\n",
      "        total_loss: 1369.089599609375\n",
      "        vf_explained_var: 0.6222342252731323\n",
      "        vf_loss: 1369.1864013671875\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51510489510489\n",
      "    ram_util_percent: 36.884195804195805\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034467118532628\n",
      "    mean_env_wait_ms: 110.89991957438093\n",
      "    mean_inference_ms: 1.7738559267543803\n",
      "    mean_raw_obs_processing_ms: 11.822127288039512\n",
      "  time_since_restore: 16955.506905317307\n",
      "  time_this_iter_s: 500.45948481559753\n",
      "  time_total_s: 16955.506905317307\n",
      "  timers:\n",
      "    learn_throughput: 260.835\n",
      "    learn_time_ms: 15335.365\n",
      "    load_throughput: 10245.805\n",
      "    load_time_ms: 390.404\n",
      "    sample_throughput: 8.243\n",
      "    sample_time_ms: 485247.888\n",
      "    update_time_ms: 3.616\n",
      "  timestamp: 1613843500\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 133.63\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 32.1404880050737\n",
      "  episode_reward_min: -105.07795578663634\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1313\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6472254991531372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014062902890145779\n",
      "        model: {}\n",
      "        policy_loss: -0.1172453835606575\n",
      "        total_loss: 1262.2076416015625\n",
      "        vf_explained_var: 0.57198566198349\n",
      "        vf_loss: 1262.29296875\n",
      "    num_steps_sampled: 136000\n",
      "    num_steps_trained: 136000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61216783216783\n",
      "    ram_util_percent: 36.84965034965035\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033984018987388\n",
      "    mean_env_wait_ms: 110.87097809766998\n",
      "    mean_inference_ms: 1.7733750635766539\n",
      "    mean_raw_obs_processing_ms: 11.728371523588248\n",
      "  time_since_restore: 17456.943140506744\n",
      "  time_this_iter_s: 501.43623518943787\n",
      "  time_total_s: 17456.943140506744\n",
      "  timers:\n",
      "    learn_throughput: 260.908\n",
      "    learn_time_ms: 15331.056\n",
      "    load_throughput: 10305.266\n",
      "    load_time_ms: 388.151\n",
      "    sample_throughput: 8.251\n",
      "    sample_time_ms: 484805.591\n",
      "    update_time_ms: 3.648\n",
      "  timestamp: 1613844002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 136000\n",
      "  training_iteration: 34\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-08-26\n",
      "  done: false\n",
      "  episode_len_mean: 133.22\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 15.54194706711927\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1343\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6586072444915771\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015374414622783661\n",
      "        model: {}\n",
      "        policy_loss: -0.13172367215156555\n",
      "        total_loss: 1605.39208984375\n",
      "        vf_explained_var: 0.5467179417610168\n",
      "        vf_loss: 1605.4888916015625\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.994027777777774\n",
      "    ram_util_percent: 36.948611111111106\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.070340489915848\n",
      "    mean_env_wait_ms: 110.85563415838286\n",
      "    mean_inference_ms: 1.773001997473154\n",
      "    mean_raw_obs_processing_ms: 11.65145366998234\n",
      "  time_since_restore: 17961.057772874832\n",
      "  time_this_iter_s: 504.11463236808777\n",
      "  time_total_s: 17961.057772874832\n",
      "  timers:\n",
      "    learn_throughput: 260.897\n",
      "    learn_time_ms: 15331.723\n",
      "    load_throughput: 10218.106\n",
      "    load_time_ms: 391.462\n",
      "    sample_throughput: 8.251\n",
      "    sample_time_ms: 484779.773\n",
      "    update_time_ms: 3.654\n",
      "  timestamp: 1613844506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-16-43\n",
      "  done: false\n",
      "  episode_len_mean: 130.9\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 25.976085320763044\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1371\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6460509896278381\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013093412853777409\n",
      "        model: {}\n",
      "        policy_loss: -0.11080330610275269\n",
      "        total_loss: 818.1026000976562\n",
      "        vf_explained_var: 0.7011681199073792\n",
      "        vf_loss: 818.1834106445312\n",
      "    num_steps_sampled: 144000\n",
      "    num_steps_trained: 144000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60070621468927\n",
      "    ram_util_percent: 36.98601694915254\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033730600624276\n",
      "    mean_env_wait_ms: 110.84213018906237\n",
      "    mean_inference_ms: 1.772571484547563\n",
      "    mean_raw_obs_processing_ms: 11.580043678765687\n",
      "  time_since_restore: 18457.762900829315\n",
      "  time_this_iter_s: 496.70512795448303\n",
      "  time_total_s: 18457.762900829315\n",
      "  timers:\n",
      "    learn_throughput: 260.95\n",
      "    learn_time_ms: 15328.593\n",
      "    load_throughput: 10136.049\n",
      "    load_time_ms: 394.631\n",
      "    sample_throughput: 8.263\n",
      "    sample_time_ms: 484109.867\n",
      "    update_time_ms: 3.626\n",
      "  timestamp: 1613845003\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 144000\n",
      "  training_iteration: 36\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-25-04\n",
      "  done: false\n",
      "  episode_len_mean: 133.62\n",
      "  episode_reward_max: 118.37555030139066\n",
      "  episode_reward_mean: 29.844075293892665\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1402\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.666848361492157\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014040189795196056\n",
      "        model: {}\n",
      "        policy_loss: -0.1256057620048523\n",
      "        total_loss: 841.550537109375\n",
      "        vf_explained_var: 0.7548153400421143\n",
      "        vf_loss: 841.644287109375\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.59581005586592\n",
      "    ram_util_percent: 36.905726256983236\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033396749830349\n",
      "    mean_env_wait_ms: 110.82677575562188\n",
      "    mean_inference_ms: 1.7721333454132469\n",
      "    mean_raw_obs_processing_ms: 11.505523211637954\n",
      "  time_since_restore: 18958.79090666771\n",
      "  time_this_iter_s: 501.02800583839417\n",
      "  time_total_s: 18958.79090666771\n",
      "  timers:\n",
      "    learn_throughput: 261.019\n",
      "    learn_time_ms: 15324.581\n",
      "    load_throughput: 10157.973\n",
      "    load_time_ms: 393.779\n",
      "    sample_throughput: 8.265\n",
      "    sample_time_ms: 483988.533\n",
      "    update_time_ms: 3.616\n",
      "  timestamp: 1613845504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 133.4\n",
      "  episode_reward_max: 118.36373005371863\n",
      "  episode_reward_mean: 45.9344929154487\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1433\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6199125051498413\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01168330293148756\n",
      "        model: {}\n",
      "        policy_loss: -0.09821189194917679\n",
      "        total_loss: 510.17413330078125\n",
      "        vf_explained_var: 0.738914966583252\n",
      "        vf_loss: 510.2457580566406\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 152000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.09030470914127\n",
      "    ram_util_percent: 36.96204986149584\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032787706505493\n",
      "    mean_env_wait_ms: 110.81615481171275\n",
      "    mean_inference_ms: 1.7717424464307339\n",
      "    mean_raw_obs_processing_ms: 11.43692149765393\n",
      "  time_since_restore: 19465.000452041626\n",
      "  time_this_iter_s: 506.2095453739166\n",
      "  time_total_s: 19465.000452041626\n",
      "  timers:\n",
      "    learn_throughput: 261.036\n",
      "    learn_time_ms: 15323.56\n",
      "    load_throughput: 10089.997\n",
      "    load_time_ms: 396.432\n",
      "    sample_throughput: 8.253\n",
      "    sample_time_ms: 484680.927\n",
      "    update_time_ms: 3.594\n",
      "  timestamp: 1613846010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 38\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-41-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.59\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 46.317101289409294\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1464\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6443673968315125\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011803336441516876\n",
      "        model: {}\n",
      "        policy_loss: -0.10504046827554703\n",
      "        total_loss: 382.9107666015625\n",
      "        vf_explained_var: 0.8292127251625061\n",
      "        vf_loss: 382.9889221191406\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.601820728291315\n",
      "    ram_util_percent: 36.94327731092437\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032114966698425\n",
      "    mean_env_wait_ms: 110.8041680554541\n",
      "    mean_inference_ms: 1.7714408506252282\n",
      "    mean_raw_obs_processing_ms: 11.37802606642925\n",
      "  time_since_restore: 19965.705763101578\n",
      "  time_this_iter_s: 500.7053110599518\n",
      "  time_total_s: 19965.705763101578\n",
      "  timers:\n",
      "    learn_throughput: 261.01\n",
      "    learn_time_ms: 15325.089\n",
      "    load_throughput: 10215.797\n",
      "    load_time_ms: 391.55\n",
      "    sample_throughput: 8.26\n",
      "    sample_time_ms: 484282.824\n",
      "    update_time_ms: 3.587\n",
      "  timestamp: 1613846511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-50-10\n",
      "  done: false\n",
      "  episode_len_mean: 131.63\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 54.302023289065644\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1492\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6468275189399719\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011806544847786427\n",
      "        model: {}\n",
      "        policy_loss: -0.11051733046770096\n",
      "        total_loss: 671.3834838867188\n",
      "        vf_explained_var: 0.7356114983558655\n",
      "        vf_loss: 671.4671630859375\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.430294530154285\n",
      "    ram_util_percent: 36.95918653576438\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703123966149883\n",
      "    mean_env_wait_ms: 110.79749318914422\n",
      "    mean_inference_ms: 1.7712056836951258\n",
      "    mean_raw_obs_processing_ms: 11.324981364048007\n",
      "  time_since_restore: 20464.761628866196\n",
      "  time_this_iter_s: 499.0558657646179\n",
      "  time_total_s: 20464.761628866196\n",
      "  timers:\n",
      "    learn_throughput: 260.995\n",
      "    learn_time_ms: 15325.971\n",
      "    load_throughput: 10218.388\n",
      "    load_time_ms: 391.451\n",
      "    sample_throughput: 8.254\n",
      "    sample_time_ms: 484621.248\n",
      "    update_time_ms: 3.575\n",
      "  timestamp: 1613847010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 40\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 52.70478508017718\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1522\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.641582727432251\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011860525235533714\n",
      "        model: {}\n",
      "        policy_loss: -0.10475405305624008\n",
      "        total_loss: 674.5768432617188\n",
      "        vf_explained_var: 0.7677860260009766\n",
      "        vf_loss: 674.654541015625\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.861398601398605\n",
      "    ram_util_percent: 36.989090909090905\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703088672631849\n",
      "    mean_env_wait_ms: 110.7861624123223\n",
      "    mean_inference_ms: 1.7709939268138148\n",
      "    mean_raw_obs_processing_ms: 11.26685085159765\n",
      "  time_since_restore: 20965.715186834335\n",
      "  time_this_iter_s: 500.95355796813965\n",
      "  time_total_s: 20965.715186834335\n",
      "  timers:\n",
      "    learn_throughput: 260.957\n",
      "    learn_time_ms: 15328.172\n",
      "    load_throughput: 10266.039\n",
      "    load_time_ms: 389.634\n",
      "    sample_throughput: 8.25\n",
      "    sample_time_ms: 484840.9\n",
      "    update_time_ms: 3.537\n",
      "  timestamp: 1613847511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-06-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.94\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 48.804333945869594\n",
      "  episode_reward_min: -106.32114279569402\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1552\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6589558720588684\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014141380786895752\n",
      "        model: {}\n",
      "        policy_loss: -0.11567607522010803\n",
      "        total_loss: 1036.539306640625\n",
      "        vf_explained_var: 0.7052029967308044\n",
      "        vf_loss: 1036.62255859375\n",
      "    num_steps_sampled: 168000\n",
      "    num_steps_trained: 168000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51076923076923\n",
      "    ram_util_percent: 37.02181818181818\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030557654297072\n",
      "    mean_env_wait_ms: 110.77457488319823\n",
      "    mean_inference_ms: 1.7706725015214595\n",
      "    mean_raw_obs_processing_ms: 11.208994106094684\n",
      "  time_since_restore: 21466.86609196663\n",
      "  time_this_iter_s: 501.1509051322937\n",
      "  time_total_s: 21466.86609196663\n",
      "  timers:\n",
      "    learn_throughput: 260.938\n",
      "    learn_time_ms: 15329.292\n",
      "    load_throughput: 10276.51\n",
      "    load_time_ms: 389.237\n",
      "    sample_throughput: 8.242\n",
      "    sample_time_ms: 485304.007\n",
      "    update_time_ms: 3.501\n",
      "  timestamp: 1613848012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 168000\n",
      "  training_iteration: 42\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 129.75\n",
      "  episode_reward_max: 118.37743755854237\n",
      "  episode_reward_mean: 40.85230381990975\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 1586\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6482423543930054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013159703463315964\n",
      "        model: {}\n",
      "        policy_loss: -0.11065053939819336\n",
      "        total_loss: 1050.6982421875\n",
      "        vf_explained_var: 0.6948574781417847\n",
      "        vf_loss: 1050.77880859375\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.62097222222222\n",
      "    ram_util_percent: 36.95305555555555\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030399131913781\n",
      "    mean_env_wait_ms: 110.7607417073646\n",
      "    mean_inference_ms: 1.7702370076517295\n",
      "    mean_raw_obs_processing_ms: 11.158182205607885\n",
      "  time_since_restore: 21971.43261051178\n",
      "  time_this_iter_s: 504.56651854515076\n",
      "  time_total_s: 21971.43261051178\n",
      "  timers:\n",
      "    learn_throughput: 260.953\n",
      "    learn_time_ms: 15328.46\n",
      "    load_throughput: 10343.974\n",
      "    load_time_ms: 386.699\n",
      "    sample_throughput: 8.235\n",
      "    sample_time_ms: 485719.358\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613848517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-23-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.15\n",
      "  episode_reward_max: 118.37543209998196\n",
      "  episode_reward_mean: 42.897584452962874\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1615\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6413830518722534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010721690952777863\n",
      "        model: {}\n",
      "        policy_loss: -0.09945659339427948\n",
      "        total_loss: 531.45947265625\n",
      "        vf_explained_var: 0.7469833493232727\n",
      "        vf_loss: 531.5345458984375\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 176000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49859943977591\n",
      "    ram_util_percent: 36.96624649859944\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029959625995104\n",
      "    mean_env_wait_ms: 110.7510495015338\n",
      "    mean_inference_ms: 1.7698440937330673\n",
      "    mean_raw_obs_processing_ms: 11.118542366978442\n",
      "  time_since_restore: 22471.852631807327\n",
      "  time_this_iter_s: 500.4200212955475\n",
      "  time_total_s: 22471.852631807327\n",
      "  timers:\n",
      "    learn_throughput: 260.93\n",
      "    learn_time_ms: 15329.771\n",
      "    load_throughput: 10357.307\n",
      "    load_time_ms: 386.201\n",
      "    sample_throughput: 8.237\n",
      "    sample_time_ms: 485618.441\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613849017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 44\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 130.06\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 62.065262610967785\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1645\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6233407258987427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00898065697401762\n",
      "        model: {}\n",
      "        policy_loss: -0.08020798116922379\n",
      "        total_loss: 356.6605529785156\n",
      "        vf_explained_var: 0.7845202088356018\n",
      "        vf_loss: 356.7203369140625\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57478991596639\n",
      "    ram_util_percent: 36.95280112044817\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702960367516641\n",
      "    mean_env_wait_ms: 110.74041825539024\n",
      "    mean_inference_ms: 1.7694404392189858\n",
      "    mean_raw_obs_processing_ms: 11.07920669127588\n",
      "  time_since_restore: 22972.452386140823\n",
      "  time_this_iter_s: 500.5997543334961\n",
      "  time_total_s: 22972.452386140823\n",
      "  timers:\n",
      "    learn_throughput: 260.929\n",
      "    learn_time_ms: 15329.818\n",
      "    load_throughput: 10425.457\n",
      "    load_time_ms: 383.676\n",
      "    sample_throughput: 8.243\n",
      "    sample_time_ms: 485266.468\n",
      "    update_time_ms: 3.686\n",
      "  timestamp: 1613849518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-40-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.84\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 59.985331006414555\n",
      "  episode_reward_min: -101.4588881123555\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1673\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6626541614532471\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012667709030210972\n",
      "        model: {}\n",
      "        policy_loss: -0.11400982737541199\n",
      "        total_loss: 800.5023803710938\n",
      "        vf_explained_var: 0.7248692512512207\n",
      "        vf_loss: 800.5874633789062\n",
      "    num_steps_sampled: 184000\n",
      "    num_steps_trained: 184000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.70496551724138\n",
      "    ram_util_percent: 37.08303448275863\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029657900746815\n",
      "    mean_env_wait_ms: 110.74568080511251\n",
      "    mean_inference_ms: 1.769301121008906\n",
      "    mean_raw_obs_processing_ms: 11.034907993071792\n",
      "  time_since_restore: 23480.277863502502\n",
      "  time_this_iter_s: 507.8254773616791\n",
      "  time_total_s: 23480.277863502502\n",
      "  timers:\n",
      "    learn_throughput: 260.852\n",
      "    learn_time_ms: 15334.355\n",
      "    load_throughput: 10488.971\n",
      "    load_time_ms: 381.353\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486377.911\n",
      "    update_time_ms: 3.724\n",
      "  timestamp: 1613850026\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 184000\n",
      "  training_iteration: 46\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 144.04\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 74.52875837504715\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 1698\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6407293677330017\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009831038303673267\n",
      "        model: {}\n",
      "        policy_loss: -0.08865351229906082\n",
      "        total_loss: 250.5148468017578\n",
      "        vf_explained_var: 0.8557254076004028\n",
      "        vf_loss: 250.5811004638672\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53465346534654\n",
      "    ram_util_percent: 37.012588401697315\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029727781938253\n",
      "    mean_env_wait_ms: 110.74992239858908\n",
      "    mean_inference_ms: 1.7692241671302469\n",
      "    mean_raw_obs_processing_ms: 10.985394316609364\n",
      "  time_since_restore: 23975.74490594864\n",
      "  time_this_iter_s: 495.4670424461365\n",
      "  time_total_s: 23975.74490594864\n",
      "  timers:\n",
      "    learn_throughput: 260.761\n",
      "    learn_time_ms: 15339.736\n",
      "    load_throughput: 10497.116\n",
      "    load_time_ms: 381.057\n",
      "    sample_throughput: 8.234\n",
      "    sample_time_ms: 485815.988\n",
      "    update_time_ms: 3.755\n",
      "  timestamp: 1613850522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 142.98\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 67.98287444602884\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1727\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6419114470481873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008923264220356941\n",
      "        model: {}\n",
      "        policy_loss: -0.0866682380437851\n",
      "        total_loss: 338.417236328125\n",
      "        vf_explained_var: 0.8316975831985474\n",
      "        vf_loss: 338.4835510253906\n",
      "    num_steps_sampled: 192000\n",
      "    num_steps_trained: 192000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60056179775281\n",
      "    ram_util_percent: 37.017977528089894\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702983928846514\n",
      "    mean_env_wait_ms: 110.75403191743374\n",
      "    mean_inference_ms: 1.7691664603468693\n",
      "    mean_raw_obs_processing_ms: 10.928172516827154\n",
      "  time_since_restore: 24475.107447862625\n",
      "  time_this_iter_s: 499.3625419139862\n",
      "  time_total_s: 24475.107447862625\n",
      "  timers:\n",
      "    learn_throughput: 260.765\n",
      "    learn_time_ms: 15339.472\n",
      "    load_throughput: 10453.94\n",
      "    load_time_ms: 382.631\n",
      "    sample_throughput: 8.245\n",
      "    sample_time_ms: 485125.038\n",
      "    update_time_ms: 3.776\n",
      "  timestamp: 1613851021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 192000\n",
      "  training_iteration: 48\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-05-20\n",
      "  done: false\n",
      "  episode_len_mean: 148.73\n",
      "  episode_reward_max: 118.37884731579629\n",
      "  episode_reward_mean: 67.8799255374538\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1754\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.636057436466217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009555695578455925\n",
      "        model: {}\n",
      "        policy_loss: -0.08797115087509155\n",
      "        total_loss: 359.5047607421875\n",
      "        vf_explained_var: 0.8124749064445496\n",
      "        vf_loss: 359.57098388671875\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.45519662921349\n",
      "    ram_util_percent: 37.0685393258427\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029628939055829\n",
      "    mean_env_wait_ms: 110.75578300235905\n",
      "    mean_inference_ms: 1.7690876277659227\n",
      "    mean_raw_obs_processing_ms: 10.871889056857041\n",
      "  time_since_restore: 24973.8474817276\n",
      "  time_this_iter_s: 498.740033864975\n",
      "  time_total_s: 24973.8474817276\n",
      "  timers:\n",
      "    learn_throughput: 260.758\n",
      "    learn_time_ms: 15339.912\n",
      "    load_throughput: 10499.603\n",
      "    load_time_ms: 380.967\n",
      "    sample_throughput: 8.249\n",
      "    sample_time_ms: 484929.998\n",
      "    update_time_ms: 3.814\n",
      "  timestamp: 1613851520\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 144.17\n",
      "  episode_reward_max: 118.39421396908376\n",
      "  episode_reward_mean: 63.92768333430419\n",
      "  episode_reward_min: -105.11605887423045\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1783\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6578298211097717\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013607810251414776\n",
      "        model: {}\n",
      "        policy_loss: -0.12195522338151932\n",
      "        total_loss: 667.0701904296875\n",
      "        vf_explained_var: 0.7740439176559448\n",
      "        vf_loss: 667.1612548828125\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.572230014025244\n",
      "    ram_util_percent: 37.04431977559607\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029345552180817\n",
      "    mean_env_wait_ms: 110.74755407693898\n",
      "    mean_inference_ms: 1.7689476389640095\n",
      "    mean_raw_obs_processing_ms: 10.817247726676902\n",
      "  time_since_restore: 25473.063342809677\n",
      "  time_this_iter_s: 499.215861082077\n",
      "  time_total_s: 25473.063342809677\n",
      "  timers:\n",
      "    learn_throughput: 260.76\n",
      "    learn_time_ms: 15339.749\n",
      "    load_throughput: 10514.559\n",
      "    load_time_ms: 380.425\n",
      "    sample_throughput: 8.248\n",
      "    sample_time_ms: 484944.65\n",
      "    update_time_ms: 3.846\n",
      "  timestamp: 1613852019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 50\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-21-58\n",
      "  done: false\n",
      "  episode_len_mean: 142.79\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.382111297120936\n",
      "  episode_reward_min: -105.11605887423045\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1811\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6633873581886292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011062879115343094\n",
      "        model: {}\n",
      "        policy_loss: -0.1058695986866951\n",
      "        total_loss: 324.61956787109375\n",
      "        vf_explained_var: 0.883109450340271\n",
      "        vf_loss: 324.7002868652344\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.56047819971871\n",
      "    ram_util_percent: 37.102390998593535\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702925175851268\n",
      "    mean_env_wait_ms: 110.73998913003665\n",
      "    mean_inference_ms: 1.768822287760936\n",
      "    mean_raw_obs_processing_ms: 10.771063188632224\n",
      "  time_since_restore: 25971.54581975937\n",
      "  time_this_iter_s: 498.4824769496918\n",
      "  time_total_s: 25971.54581975937\n",
      "  timers:\n",
      "    learn_throughput: 260.797\n",
      "    learn_time_ms: 15337.601\n",
      "    load_throughput: 10527.517\n",
      "    load_time_ms: 379.957\n",
      "    sample_throughput: 8.253\n",
      "    sample_time_ms: 484701.47\n",
      "    update_time_ms: 3.849\n",
      "  timestamp: 1613852518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 133.19\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.00244247417059\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1844\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.650313138961792\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009966370649635792\n",
      "        model: {}\n",
      "        policy_loss: -0.09712912142276764\n",
      "        total_loss: 640.95947265625\n",
      "        vf_explained_var: 0.7460017800331116\n",
      "        vf_loss: 641.033935546875\n",
      "    num_steps_sampled: 208000\n",
      "    num_steps_trained: 208000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71061452513966\n",
      "    ram_util_percent: 37.14916201117319\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07028977365919233\n",
      "    mean_env_wait_ms: 110.72607899184827\n",
      "    mean_inference_ms: 1.7686210479903621\n",
      "    mean_raw_obs_processing_ms: 10.728863856971861\n",
      "  time_since_restore: 26472.941111803055\n",
      "  time_this_iter_s: 501.3952920436859\n",
      "  time_total_s: 26472.941111803055\n",
      "  timers:\n",
      "    learn_throughput: 260.83\n",
      "    learn_time_ms: 15335.64\n",
      "    load_throughput: 10540.876\n",
      "    load_time_ms: 379.475\n",
      "    sample_throughput: 8.252\n",
      "    sample_time_ms: 484724.861\n",
      "    update_time_ms: 3.85\n",
      "  timestamp: 1613853019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 208000\n",
      "  training_iteration: 52\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-38-49\n",
      "  done: false\n",
      "  episode_len_mean: 132.54\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.091052037477894\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6425826549530029\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011709527112543583\n",
      "        model: {}\n",
      "        policy_loss: -0.10362938046455383\n",
      "        total_loss: 691.9244995117188\n",
      "        vf_explained_var: 0.7485781908035278\n",
      "        vf_loss: 692.0013427734375\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.53287482806053\n",
      "    ram_util_percent: 37.163273727647876\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029267823481428\n",
      "    mean_env_wait_ms: 110.72434566450103\n",
      "    mean_inference_ms: 1.7685486715322718\n",
      "    mean_raw_obs_processing_ms: 10.697146182569476\n",
      "  time_since_restore: 26982.726992607117\n",
      "  time_this_iter_s: 509.7858808040619\n",
      "  time_total_s: 26982.726992607117\n",
      "  timers:\n",
      "    learn_throughput: 258.57\n",
      "    learn_time_ms: 15469.72\n",
      "    load_throughput: 10456.634\n",
      "    load_time_ms: 382.532\n",
      "    sample_throughput: 8.246\n",
      "    sample_time_ms: 485101.827\n",
      "    update_time_ms: 3.818\n",
      "  timestamp: 1613853529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-47-38\n",
      "  done: false\n",
      "  episode_len_mean: 128.61\n",
      "  episode_reward_max: 118.3323445817829\n",
      "  episode_reward_mean: 65.39139703471686\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1905\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6302710175514221\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008997817523777485\n",
      "        model: {}\n",
      "        policy_loss: -0.08477241545915604\n",
      "        total_loss: 500.035400390625\n",
      "        vf_explained_var: 0.7220929861068726\n",
      "        vf_loss: 500.0996398925781\n",
      "    num_steps_sampled: 216000\n",
      "    num_steps_trained: 216000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.83245033112583\n",
      "    ram_util_percent: 37.139602649006626\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032062926629683\n",
      "    mean_env_wait_ms: 110.75891469656686\n",
      "    mean_inference_ms: 1.7687999750663093\n",
      "    mean_raw_obs_processing_ms: 10.670978443075951\n",
      "  time_since_restore: 27511.451284885406\n",
      "  time_this_iter_s: 528.7242922782898\n",
      "  time_total_s: 27511.451284885406\n",
      "  timers:\n",
      "    learn_throughput: 256.256\n",
      "    learn_time_ms: 15609.362\n",
      "    load_throughput: 10477.919\n",
      "    load_time_ms: 381.755\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487789.587\n",
      "    update_time_ms: 3.665\n",
      "  timestamp: 1613854058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 216000\n",
      "  training_iteration: 54\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 133.35\n",
      "  episode_reward_max: 118.38506214263124\n",
      "  episode_reward_mean: 65.80513212460696\n",
      "  episode_reward_min: -106.74443176576358\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1935\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6315209865570068\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010787761770188808\n",
      "        model: {}\n",
      "        policy_loss: -0.09967464208602905\n",
      "        total_loss: 428.6216735839844\n",
      "        vf_explained_var: 0.8370494842529297\n",
      "        vf_loss: 428.6967468261719\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.20964332892999\n",
      "    ram_util_percent: 37.19075297225891\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07037049189297422\n",
      "    mean_env_wait_ms: 110.83342209570523\n",
      "    mean_inference_ms: 1.769447076085045\n",
      "    mean_raw_obs_processing_ms: 10.645196327199976\n",
      "  time_since_restore: 28042.300265789032\n",
      "  time_this_iter_s: 530.8489809036255\n",
      "  time_total_s: 28042.300265789032\n",
      "  timers:\n",
      "    learn_throughput: 254.037\n",
      "    learn_time_ms: 15745.751\n",
      "    load_throughput: 10468.624\n",
      "    load_time_ms: 382.094\n",
      "    sample_throughput: 8.152\n",
      "    sample_time_ms: 490678.066\n",
      "    update_time_ms: 3.695\n",
      "  timestamp: 1613854589\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-05-14\n",
      "  done: false\n",
      "  episode_len_mean: 126.14\n",
      "  episode_reward_max: 118.38506214263124\n",
      "  episode_reward_mean: 55.31096174174058\n",
      "  episode_reward_min: -106.74443176576358\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1968\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6478879451751709\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013791813515126705\n",
      "        model: {}\n",
      "        policy_loss: -0.12108524143695831\n",
      "        total_loss: 1167.9112548828125\n",
      "        vf_explained_var: 0.663340151309967\n",
      "        vf_loss: 1168.000732421875\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 224000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.46315086782377\n",
      "    ram_util_percent: 37.16234979973297\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07043649977748466\n",
      "    mean_env_wait_ms: 110.93319091066641\n",
      "    mean_inference_ms: 1.770354065129902\n",
      "    mean_raw_obs_processing_ms: 10.622040529207887\n",
      "  time_since_restore: 28566.90573167801\n",
      "  time_this_iter_s: 524.605465888977\n",
      "  time_total_s: 28566.90573167801\n",
      "  timers:\n",
      "    learn_throughput: 252.023\n",
      "    learn_time_ms: 15871.551\n",
      "    load_throughput: 10398.317\n",
      "    load_time_ms: 384.678\n",
      "    sample_throughput: 8.126\n",
      "    sample_time_ms: 492226.153\n",
      "    update_time_ms: 3.722\n",
      "  timestamp: 1613855114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 56\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-13-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.33\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 68.16007260489052\n",
      "  episode_reward_min: -101.23240739758147\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1995\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6253086924552917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00979804340749979\n",
      "        model: {}\n",
      "        policy_loss: -0.09172672033309937\n",
      "        total_loss: 141.4500732421875\n",
      "        vf_explained_var: 0.8915672898292542\n",
      "        vf_loss: 141.51947021484375\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.003099730458224\n",
      "    ram_util_percent: 37.12250673854448\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07047223222355245\n",
      "    mean_env_wait_ms: 111.01302383516594\n",
      "    mean_inference_ms: 1.7708231004163704\n",
      "    mean_raw_obs_processing_ms: 10.59936403226933\n",
      "  time_since_restore: 29086.573880910873\n",
      "  time_this_iter_s: 519.6681492328644\n",
      "  time_total_s: 29086.573880910873\n",
      "  timers:\n",
      "    learn_throughput: 252.296\n",
      "    learn_time_ms: 15854.379\n",
      "    load_throughput: 10465.866\n",
      "    load_time_ms: 382.195\n",
      "    sample_throughput: 8.086\n",
      "    sample_time_ms: 494666.712\n",
      "    update_time_ms: 3.682\n",
      "  timestamp: 1613855634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-23-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.2\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 66.33935965107635\n",
      "  episode_reward_min: -101.23240739758147\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2023\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6489342451095581\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012554348446428776\n",
      "        model: {}\n",
      "        policy_loss: -0.11330427974462509\n",
      "        total_loss: 1351.4207763671875\n",
      "        vf_explained_var: 0.45022523403167725\n",
      "        vf_loss: 1351.5054931640625\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 232000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.32729498164015\n",
      "    ram_util_percent: 37.1123623011016\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07046659993996357\n",
      "    mean_env_wait_ms: 111.15418143970867\n",
      "    mean_inference_ms: 1.7705213443087429\n",
      "    mean_raw_obs_processing_ms: 10.57231127310461\n",
      "  time_since_restore: 29659.22930073738\n",
      "  time_this_iter_s: 572.6554198265076\n",
      "  time_total_s: 29659.22930073738\n",
      "  timers:\n",
      "    learn_throughput: 252.608\n",
      "    learn_time_ms: 15834.826\n",
      "    load_throughput: 10554.629\n",
      "    load_time_ms: 378.981\n",
      "    sample_throughput: 7.968\n",
      "    sample_time_ms: 502023.27\n",
      "    update_time_ms: 3.668\n",
      "  timestamp: 1613856206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 58\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 141.39\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 70.29793638788594\n",
      "  episode_reward_min: -100.23973123547925\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2050\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6639514565467834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010656061582267284\n",
      "        model: {}\n",
      "        policy_loss: -0.10116995871067047\n",
      "        total_loss: 572.2363891601562\n",
      "        vf_explained_var: 0.7428793907165527\n",
      "        vf_loss: 572.3132934570312\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.33382352941177\n",
      "    ram_util_percent: 37.13541666666668\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07042244921524958\n",
      "    mean_env_wait_ms: 111.34900230644934\n",
      "    mean_inference_ms: 1.7695008968193702\n",
      "    mean_raw_obs_processing_ms: 10.539710406986257\n",
      "  time_since_restore: 30230.81455373764\n",
      "  time_this_iter_s: 571.5852530002594\n",
      "  time_total_s: 30230.81455373764\n",
      "  timers:\n",
      "    learn_throughput: 252.938\n",
      "    learn_time_ms: 15814.134\n",
      "    load_throughput: 10533.311\n",
      "    load_time_ms: 379.748\n",
      "    sample_throughput: 7.853\n",
      "    sample_time_ms: 509327.434\n",
      "    update_time_ms: 3.716\n",
      "  timestamp: 1613856778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 141.34\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 74.43891614908803\n",
      "  episode_reward_min: -99.9359350861686\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 2081\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.660055935382843\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010436595417559147\n",
      "        model: {}\n",
      "        policy_loss: -0.10442720353603363\n",
      "        total_loss: 374.71368408203125\n",
      "        vf_explained_var: 0.8304740190505981\n",
      "        vf_loss: 374.7943115234375\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.46243902439024\n",
      "    ram_util_percent: 37.222682926829265\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033987487465286\n",
      "    mean_env_wait_ms: 111.63979372562945\n",
      "    mean_inference_ms: 1.7676407091750688\n",
      "    mean_raw_obs_processing_ms: 10.503065870075869\n",
      "  time_since_restore: 30805.672479391098\n",
      "  time_this_iter_s: 574.8579256534576\n",
      "  time_total_s: 30805.672479391098\n",
      "  timers:\n",
      "    learn_throughput: 253.234\n",
      "    learn_time_ms: 15795.638\n",
      "    load_throughput: 10549.057\n",
      "    load_time_ms: 379.181\n",
      "    sample_throughput: 7.738\n",
      "    sample_time_ms: 516912.277\n",
      "    update_time_ms: 3.702\n",
      "  timestamp: 1613857353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 60\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-52-05\n",
      "  done: false\n",
      "  episode_len_mean: 141.05\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 70.01738176891863\n",
      "  episode_reward_min: -105.68695967977602\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2109\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6409180164337158\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011094327084720135\n",
      "        model: {}\n",
      "        policy_loss: -0.09974440932273865\n",
      "        total_loss: 499.4038391113281\n",
      "        vf_explained_var: 0.801602303981781\n",
      "        vf_loss: 499.4782409667969\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38492647058823\n",
      "    ram_util_percent: 37.204779411764704\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07025371107998246\n",
      "    mean_env_wait_ms: 111.92239434537707\n",
      "    mean_inference_ms: 1.7657413100059511\n",
      "    mean_raw_obs_processing_ms: 10.472746551317464\n",
      "  time_since_restore: 31377.506068468094\n",
      "  time_this_iter_s: 571.8335890769958\n",
      "  time_total_s: 31377.506068468094\n",
      "  timers:\n",
      "    learn_throughput: 253.487\n",
      "    learn_time_ms: 15779.897\n",
      "    load_throughput: 10510.437\n",
      "    load_time_ms: 380.574\n",
      "    sample_throughput: 7.63\n",
      "    sample_time_ms: 524260.903\n",
      "    update_time_ms: 3.69\n",
      "  timestamp: 1613857925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 141.05\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 71.77740101151602\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2137\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.647716224193573\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011794942431151867\n",
      "        model: {}\n",
      "        policy_loss: -0.10908807814121246\n",
      "        total_loss: 351.6716003417969\n",
      "        vf_explained_var: 0.8702437281608582\n",
      "        vf_loss: 351.75384521484375\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 248000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38235294117647\n",
      "    ram_util_percent: 37.1375\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07017104526738993\n",
      "    mean_env_wait_ms: 112.1944696480094\n",
      "    mean_inference_ms: 1.7639460613750333\n",
      "    mean_raw_obs_processing_ms: 10.444230884135225\n",
      "  time_since_restore: 31949.255333185196\n",
      "  time_this_iter_s: 571.749264717102\n",
      "  time_total_s: 31949.255333185196\n",
      "  timers:\n",
      "    learn_throughput: 253.781\n",
      "    learn_time_ms: 15761.617\n",
      "    load_throughput: 10554.807\n",
      "    load_time_ms: 378.974\n",
      "    sample_throughput: 7.528\n",
      "    sample_time_ms: 531319.258\n",
      "    update_time_ms: 3.698\n",
      "  timestamp: 1613858497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 62\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 137.19\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 59.12739302951584\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 2168\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6523399353027344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015450678765773773\n",
      "        model: {}\n",
      "        policy_loss: -0.13272224366664886\n",
      "        total_loss: 956.6912841796875\n",
      "        vf_explained_var: 0.767768144607544\n",
      "        vf_loss: 956.7888793945312\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.49\n",
      "    ram_util_percent: 37.12756097560976\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07008540600133706\n",
      "    mean_env_wait_ms: 112.47689126731144\n",
      "    mean_inference_ms: 1.7620962489760057\n",
      "    mean_raw_obs_processing_ms: 10.417165729232902\n",
      "  time_since_restore: 32523.346776008606\n",
      "  time_this_iter_s: 574.09144282341\n",
      "  time_total_s: 32523.346776008606\n",
      "  timers:\n",
      "    learn_throughput: 256.26\n",
      "    learn_time_ms: 15609.142\n",
      "    load_throughput: 10676.985\n",
      "    load_time_ms: 374.638\n",
      "    sample_throughput: 7.436\n",
      "    sample_time_ms: 537915.417\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613859071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 136.33\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 55.33395688133094\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2198\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6516956686973572\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0131781455129385\n",
      "        model: {}\n",
      "        policy_loss: -0.11240272223949432\n",
      "        total_loss: 1057.59326171875\n",
      "        vf_explained_var: 0.663433849811554\n",
      "        vf_loss: 1057.675537109375\n",
      "    num_steps_sampled: 256000\n",
      "    num_steps_trained: 256000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.41907090464548\n",
      "    ram_util_percent: 37.134229828850856\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07000277572387784\n",
      "    mean_env_wait_ms: 112.7419967737489\n",
      "    mean_inference_ms: 1.760387598784\n",
      "    mean_raw_obs_processing_ms: 10.393010508156653\n",
      "  time_since_restore: 33097.06607270241\n",
      "  time_this_iter_s: 573.7192966938019\n",
      "  time_total_s: 33097.06607270241\n",
      "  timers:\n",
      "    learn_throughput: 258.926\n",
      "    learn_time_ms: 15448.431\n",
      "    load_throughput: 10711.259\n",
      "    load_time_ms: 373.439\n",
      "    sample_throughput: 7.372\n",
      "    sample_time_ms: 542579.658\n",
      "    update_time_ms: 3.673\n",
      "  timestamp: 1613859645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 256000\n",
      "  training_iteration: 64\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-30-17\n",
      "  done: false\n",
      "  episode_len_mean: 137.77\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 53.52548591209393\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2224\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6383890509605408\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011560847982764244\n",
      "        model: {}\n",
      "        policy_loss: -0.11173100769519806\n",
      "        total_loss: 480.3727722167969\n",
      "        vf_explained_var: 0.7947722673416138\n",
      "        vf_loss: 480.45819091796875\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.11481028151774\n",
      "    ram_util_percent: 37.14039167686659\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06993340126743414\n",
      "    mean_env_wait_ms: 112.96682997525554\n",
      "    mean_inference_ms: 1.7589298887241482\n",
      "    mean_raw_obs_processing_ms: 10.37049473048591\n",
      "  time_since_restore: 33669.42586064339\n",
      "  time_this_iter_s: 572.359787940979\n",
      "  time_total_s: 33669.42586064339\n",
      "  timers:\n",
      "    learn_throughput: 261.575\n",
      "    learn_time_ms: 15291.97\n",
      "    load_throughput: 10783.415\n",
      "    load_time_ms: 370.94\n",
      "    sample_throughput: 7.314\n",
      "    sample_time_ms: 546890.711\n",
      "    update_time_ms: 3.698\n",
      "  timestamp: 1613860217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-39-47\n",
      "  done: false\n",
      "  episode_len_mean: 146.28\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 53.7095330284575\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2249\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6173250079154968\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011564599350094795\n",
      "        model: {}\n",
      "        policy_loss: -0.10615907609462738\n",
      "        total_loss: 386.08203125\n",
      "        vf_explained_var: 0.8317555785179138\n",
      "        vf_loss: 386.1618957519531\n",
      "    num_steps_sampled: 264000\n",
      "    num_steps_trained: 264000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.330996309963105\n",
      "    ram_util_percent: 37.14329643296433\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06986738502176004\n",
      "    mean_env_wait_ms: 113.1841719552211\n",
      "    mean_inference_ms: 1.7575292602693813\n",
      "    mean_raw_obs_processing_ms: 10.344066500444315\n",
      "  time_since_restore: 34238.99902796745\n",
      "  time_this_iter_s: 569.5731673240662\n",
      "  time_total_s: 34238.99902796745\n",
      "  timers:\n",
      "    learn_throughput: 264.128\n",
      "    learn_time_ms: 15144.152\n",
      "    load_throughput: 10874.314\n",
      "    load_time_ms: 367.839\n",
      "    sample_throughput: 7.252\n",
      "    sample_time_ms: 551540.589\n",
      "    update_time_ms: 3.637\n",
      "  timestamp: 1613860787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 264000\n",
      "  training_iteration: 66\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 153.63\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 72.57427585311832\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2274\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6286678314208984\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009843600913882256\n",
      "        model: {}\n",
      "        policy_loss: -0.09355968236923218\n",
      "        total_loss: 192.63748168945312\n",
      "        vf_explained_var: 0.8682405948638916\n",
      "        vf_loss: 192.7086181640625\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.22223587223587\n",
      "    ram_util_percent: 37.13353808353809\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06979846207047757\n",
      "    mean_env_wait_ms: 113.41209413425135\n",
      "    mean_inference_ms: 1.7561167436421823\n",
      "    mean_raw_obs_processing_ms: 10.311088908911454\n",
      "  time_since_restore: 34809.06482720375\n",
      "  time_this_iter_s: 570.0657992362976\n",
      "  time_total_s: 34809.06482720375\n",
      "  timers:\n",
      "    learn_throughput: 264.182\n",
      "    learn_time_ms: 15141.078\n",
      "    load_throughput: 10717.712\n",
      "    load_time_ms: 373.214\n",
      "    sample_throughput: 7.187\n",
      "    sample_time_ms: 556576.911\n",
      "    update_time_ms: 3.653\n",
      "  timestamp: 1613861357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 156.83\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 72.23397259447046\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2300\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.631923258304596\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011478865519165993\n",
      "        model: {}\n",
      "        policy_loss: -0.09653747826814651\n",
      "        total_loss: 591.7462158203125\n",
      "        vf_explained_var: 0.7493155002593994\n",
      "        vf_loss: 591.816650390625\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 272000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.23815950920246\n",
      "    ram_util_percent: 37.20539877300614\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06972687405379784\n",
      "    mean_env_wait_ms: 113.6544200247218\n",
      "    mean_inference_ms: 1.7546103799009267\n",
      "    mean_raw_obs_processing_ms: 10.272346092030155\n",
      "  time_since_restore: 35380.29538941383\n",
      "  time_this_iter_s: 571.230562210083\n",
      "  time_total_s: 35380.29538941383\n",
      "  timers:\n",
      "    learn_throughput: 264.19\n",
      "    learn_time_ms: 15140.642\n",
      "    load_throughput: 10734.354\n",
      "    load_time_ms: 372.635\n",
      "    sample_throughput: 7.189\n",
      "    sample_time_ms: 556435.211\n",
      "    update_time_ms: 3.696\n",
      "  timestamp: 1613861928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 68\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 153.58\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 76.41749330845737\n",
      "  episode_reward_min: -100.56077546933885\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2329\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.642822802066803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01272502075880766\n",
      "        model: {}\n",
      "        policy_loss: -0.10968878120183945\n",
      "        total_loss: 596.0990600585938\n",
      "        vf_explained_var: 0.8381652235984802\n",
      "        vf_loss: 596.1798095703125\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.50269277845777\n",
      "    ram_util_percent: 37.21064871481028\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06965382674759313\n",
      "    mean_env_wait_ms: 113.90630316099855\n",
      "    mean_inference_ms: 1.7530769794469412\n",
      "    mean_raw_obs_processing_ms: 10.235387185274998\n",
      "  time_since_restore: 35952.65245747566\n",
      "  time_this_iter_s: 572.3570680618286\n",
      "  time_total_s: 35952.65245747566\n",
      "  timers:\n",
      "    learn_throughput: 264.188\n",
      "    learn_time_ms: 15140.748\n",
      "    load_throughput: 10743.574\n",
      "    load_time_ms: 372.316\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556512.121\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1613862501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 146.37\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 72.25315348460688\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2357\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6185662150382996\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00849862489849329\n",
      "        model: {}\n",
      "        policy_loss: -0.08290470391511917\n",
      "        total_loss: 276.4397888183594\n",
      "        vf_explained_var: 0.8126450777053833\n",
      "        vf_loss: 276.5033264160156\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28716381418093\n",
      "    ram_util_percent: 37.147432762836196\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06958714884610312\n",
      "    mean_env_wait_ms: 114.13442536546694\n",
      "    mean_inference_ms: 1.7516627542151186\n",
      "    mean_raw_obs_processing_ms: 10.205676917041576\n",
      "  time_since_restore: 36525.324548244476\n",
      "  time_this_iter_s: 572.6720907688141\n",
      "  time_total_s: 36525.324548244476\n",
      "  timers:\n",
      "    learn_throughput: 264.169\n",
      "    learn_time_ms: 15141.83\n",
      "    load_throughput: 10747.316\n",
      "    load_time_ms: 372.186\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556292.137\n",
      "    update_time_ms: 3.573\n",
      "  timestamp: 1613863074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 70\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 138.47\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 70.33908638281463\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2387\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.620513916015625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0102561479434371\n",
      "        model: {}\n",
      "        policy_loss: -0.09688905626535416\n",
      "        total_loss: 486.55255126953125\n",
      "        vf_explained_var: 0.7785946130752563\n",
      "        vf_loss: 486.62603759765625\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.37048780487805\n",
      "    ram_util_percent: 37.14780487804879\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06952000873593146\n",
      "    mean_env_wait_ms: 114.36072750793537\n",
      "    mean_inference_ms: 1.7502122374436757\n",
      "    mean_raw_obs_processing_ms: 10.18208803001135\n",
      "  time_since_restore: 37100.08389925957\n",
      "  time_this_iter_s: 574.7593510150909\n",
      "  time_total_s: 37100.08389925957\n",
      "  timers:\n",
      "    learn_throughput: 264.18\n",
      "    learn_time_ms: 15141.198\n",
      "    load_throughput: 10789.537\n",
      "    load_time_ms: 370.73\n",
      "    sample_throughput: 7.187\n",
      "    sample_time_ms: 556585.99\n",
      "    update_time_ms: 3.57\n",
      "  timestamp: 1613863649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-37-00\n",
      "  done: false\n",
      "  episode_len_mean: 139.74\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 76.67791844425611\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2413\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6387255787849426\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009160628542304039\n",
      "        model: {}\n",
      "        policy_loss: -0.08888468146324158\n",
      "        total_loss: 340.0338439941406\n",
      "        vf_explained_var: 0.8237649202346802\n",
      "        vf_loss: 340.10186767578125\n",
      "    num_steps_sampled: 288000\n",
      "    num_steps_trained: 288000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28171779141104\n",
      "    ram_util_percent: 37.229325153374226\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06946422410688925\n",
      "    mean_env_wait_ms: 114.54833315283351\n",
      "    mean_inference_ms: 1.7490402840484245\n",
      "    mean_raw_obs_processing_ms: 10.161260996546233\n",
      "  time_since_restore: 37671.0840651989\n",
      "  time_this_iter_s: 571.000165939331\n",
      "  time_total_s: 37671.0840651989\n",
      "  timers:\n",
      "    learn_throughput: 264.143\n",
      "    learn_time_ms: 15143.286\n",
      "    load_throughput: 10806.218\n",
      "    load_time_ms: 370.157\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556508.3\n",
      "    update_time_ms: 3.563\n",
      "  timestamp: 1613864220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 288000\n",
      "  training_iteration: 72\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-46-33\n",
      "  done: false\n",
      "  episode_len_mean: 143.7\n",
      "  episode_reward_max: 118.38248894924733\n",
      "  episode_reward_mean: 68.12918005097758\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2441\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6250879764556885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012200719676911831\n",
      "        model: {}\n",
      "        policy_loss: -0.09789183735847473\n",
      "        total_loss: 1297.644287109375\n",
      "        vf_explained_var: 0.42024028301239014\n",
      "        vf_loss: 1297.71435546875\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.3661369193154\n",
      "    ram_util_percent: 37.14352078239609\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06940225042377678\n",
      "    mean_env_wait_ms: 114.75023934436805\n",
      "    mean_inference_ms: 1.747791142768952\n",
      "    mean_raw_obs_processing_ms: 10.138264605055625\n",
      "  time_since_restore: 38244.19073843956\n",
      "  time_this_iter_s: 573.1066732406616\n",
      "  time_total_s: 38244.19073843956\n",
      "  timers:\n",
      "    learn_throughput: 264.134\n",
      "    learn_time_ms: 15143.817\n",
      "    load_throughput: 10801.332\n",
      "    load_time_ms: 370.325\n",
      "    sample_throughput: 7.189\n",
      "    sample_time_ms: 556407.515\n",
      "    update_time_ms: 3.553\n",
      "  timestamp: 1613864793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39758531399424\n",
      "  episode_reward_mean: 63.93510598160217\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2470\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.634858250617981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013342119753360748\n",
      "        model: {}\n",
      "        policy_loss: -0.11227316409349442\n",
      "        total_loss: 958.5897827148438\n",
      "        vf_explained_var: 0.658909261226654\n",
      "        vf_loss: 958.671630859375\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 296000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.47836185819071\n",
      "    ram_util_percent: 37.15929095354524\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06934058052233977\n",
      "    mean_env_wait_ms: 114.95184865274535\n",
      "    mean_inference_ms: 1.746543330488703\n",
      "    mean_raw_obs_processing_ms: 10.115347232298536\n",
      "  time_since_restore: 38817.36667227745\n",
      "  time_this_iter_s: 573.1759338378906\n",
      "  time_total_s: 38817.36667227745\n",
      "  timers:\n",
      "    learn_throughput: 264.048\n",
      "    learn_time_ms: 15148.775\n",
      "    load_throughput: 10813.873\n",
      "    load_time_ms: 369.895\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556349.164\n",
      "    update_time_ms: 3.516\n",
      "  timestamp: 1613865366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 74\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-05-38\n",
      "  done: false\n",
      "  episode_len_mean: 140.98\n",
      "  episode_reward_max: 118.39758531399424\n",
      "  episode_reward_mean: 68.35963371424914\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2499\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6206836700439453\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008158518932759762\n",
      "        model: {}\n",
      "        policy_loss: -0.08408588171005249\n",
      "        total_loss: 402.3951721191406\n",
      "        vf_explained_var: 0.7547827959060669\n",
      "        vf_loss: 402.46063232421875\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.487132352941174\n",
      "    ram_util_percent: 37.5827205882353\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928106152625599\n",
      "    mean_env_wait_ms: 115.1479551787551\n",
      "    mean_inference_ms: 1.7452991217292035\n",
      "    mean_raw_obs_processing_ms: 10.093613805166735\n",
      "  time_since_restore: 39389.221237659454\n",
      "  time_this_iter_s: 571.8545653820038\n",
      "  time_total_s: 39389.221237659454\n",
      "  timers:\n",
      "    learn_throughput: 264.064\n",
      "    learn_time_ms: 15147.838\n",
      "    load_throughput: 10820.519\n",
      "    load_time_ms: 369.668\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556299.514\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613865938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 144.33\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 70.53637365108484\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2524\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6282891631126404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008960314095020294\n",
      "        model: {}\n",
      "        policy_loss: -0.09238934516906738\n",
      "        total_loss: 583.287841796875\n",
      "        vf_explained_var: 0.6873043775558472\n",
      "        vf_loss: 583.3598022460938\n",
      "    num_steps_sampled: 304000\n",
      "    num_steps_trained: 304000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34315659679409\n",
      "    ram_util_percent: 37.643403205918624\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692304309933987\n",
      "    mean_env_wait_ms: 115.30995820023833\n",
      "    mean_inference_ms: 1.7442220421493562\n",
      "    mean_raw_obs_processing_ms: 10.07362794284602\n",
      "  time_since_restore: 39957.19925880432\n",
      "  time_this_iter_s: 567.978021144867\n",
      "  time_total_s: 39957.19925880432\n",
      "  timers:\n",
      "    learn_throughput: 264.03\n",
      "    learn_time_ms: 15149.767\n",
      "    load_throughput: 10824.969\n",
      "    load_time_ms: 369.516\n",
      "    sample_throughput: 7.192\n",
      "    sample_time_ms: 556136.573\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613866506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 304000\n",
      "  training_iteration: 76\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-24-41\n",
      "  done: false\n",
      "  episode_len_mean: 138.2\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 74.77718520882522\n",
      "  episode_reward_min: -98.78478614366963\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 2556\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6217712163925171\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010317807085812092\n",
      "        model: {}\n",
      "        policy_loss: -0.09684766829013824\n",
      "        total_loss: 471.45892333984375\n",
      "        vf_explained_var: 0.8024389147758484\n",
      "        vf_loss: 471.5322570800781\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.57780487804878\n",
      "    ram_util_percent: 37.633170731707324\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06916814033471935\n",
      "    mean_env_wait_ms: 115.5077081205219\n",
      "    mean_inference_ms: 1.7428648770769166\n",
      "    mean_raw_obs_processing_ms: 10.053242277202832\n",
      "  time_since_restore: 40532.23022842407\n",
      "  time_this_iter_s: 575.030969619751\n",
      "  time_total_s: 40532.23022842407\n",
      "  timers:\n",
      "    learn_throughput: 264.061\n",
      "    learn_time_ms: 15148.015\n",
      "    load_throughput: 10993.946\n",
      "    load_time_ms: 363.837\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556641.082\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613867081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-34-14\n",
      "  done: false\n",
      "  episode_len_mean: 142.53\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 78.98087082098333\n",
      "  episode_reward_min: -98.7417065471983\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2584\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6119922995567322\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011394803412258625\n",
      "        model: {}\n",
      "        policy_loss: -0.09888093918561935\n",
      "        total_loss: 356.1640625\n",
      "        vf_explained_var: 0.8513246178627014\n",
      "        vf_loss: 356.23699951171875\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 312000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.410281517747855\n",
      "    ram_util_percent: 37.63818849449205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06911540389132194\n",
      "    mean_env_wait_ms: 115.67576647059974\n",
      "    mean_inference_ms: 1.741715638472674\n",
      "    mean_raw_obs_processing_ms: 10.034937057725308\n",
      "  time_since_restore: 41104.826088905334\n",
      "  time_this_iter_s: 572.5958604812622\n",
      "  time_total_s: 41104.826088905334\n",
      "  timers:\n",
      "    learn_throughput: 264.058\n",
      "    learn_time_ms: 15148.206\n",
      "    load_throughput: 10988.041\n",
      "    load_time_ms: 364.032\n",
      "    sample_throughput: 7.184\n",
      "    sample_time_ms: 556776.6\n",
      "    update_time_ms: 3.482\n",
      "  timestamp: 1613867654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 78\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 134.93\n",
      "  episode_reward_max: 118.38809567022436\n",
      "  episode_reward_mean: 66.23044507460551\n",
      "  episode_reward_min: -100.33457397895387\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2614\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6089362502098083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011843282729387283\n",
      "        model: {}\n",
      "        policy_loss: -0.10525768995285034\n",
      "        total_loss: 799.7393188476562\n",
      "        vf_explained_var: 0.6889356970787048\n",
      "        vf_loss: 799.8175659179688\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.479390243902444\n",
      "    ram_util_percent: 37.5989024390244\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06906043211441769\n",
      "    mean_env_wait_ms: 115.85209515094088\n",
      "    mean_inference_ms: 1.7405040158566727\n",
      "    mean_raw_obs_processing_ms: 10.01951022321941\n",
      "  time_since_restore: 41679.47191905975\n",
      "  time_this_iter_s: 574.645830154419\n",
      "  time_total_s: 41679.47191905975\n",
      "  timers:\n",
      "    learn_throughput: 264.04\n",
      "    learn_time_ms: 15149.244\n",
      "    load_throughput: 10991.512\n",
      "    load_time_ms: 363.917\n",
      "    sample_throughput: 7.181\n",
      "    sample_time_ms: 557005.718\n",
      "    update_time_ms: 3.47\n",
      "  timestamp: 1613868229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-53-28\n",
      "  done: false\n",
      "  episode_len_mean: 129.62\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 66.30857952219603\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 2648\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.612834095954895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011830639094114304\n",
      "        model: {}\n",
      "        policy_loss: -0.10811416059732437\n",
      "        total_loss: 721.0752563476562\n",
      "        vf_explained_var: 0.7420914173126221\n",
      "        vf_loss: 721.1563720703125\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.457506053268766\n",
      "    ram_util_percent: 37.61973365617434\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0690039489207212\n",
      "    mean_env_wait_ms: 116.03571795318099\n",
      "    mean_inference_ms: 1.73923570012803\n",
      "    mean_raw_obs_processing_ms: 10.009942111648098\n",
      "  time_since_restore: 42258.06580400467\n",
      "  time_this_iter_s: 578.5938849449158\n",
      "  time_total_s: 42258.06580400467\n",
      "  timers:\n",
      "    learn_throughput: 264.09\n",
      "    learn_time_ms: 15146.35\n",
      "    load_throughput: 10990.486\n",
      "    load_time_ms: 363.951\n",
      "    sample_throughput: 7.174\n",
      "    sample_time_ms: 557601.894\n",
      "    update_time_ms: 3.449\n",
      "  timestamp: 1613868808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 80\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-03-02\n",
      "  done: false\n",
      "  episode_len_mean: 128.4\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 60.033566095574386\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2677\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6140277981758118\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008003169670701027\n",
      "        model: {}\n",
      "        policy_loss: -0.08613423258066177\n",
      "        total_loss: 503.7268981933594\n",
      "        vf_explained_var: 0.7947396636009216\n",
      "        vf_loss: 503.7947998046875\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.43577533577534\n",
      "    ram_util_percent: 37.60830280830282\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06895626932661361\n",
      "    mean_env_wait_ms: 116.18808191371505\n",
      "    mean_inference_ms: 1.7382185606484102\n",
      "    mean_raw_obs_processing_ms: 10.002050044919022\n",
      "  time_since_restore: 42831.9421107769\n",
      "  time_this_iter_s: 573.876306772232\n",
      "  time_total_s: 42831.9421107769\n",
      "  timers:\n",
      "    learn_throughput: 264.097\n",
      "    learn_time_ms: 15145.95\n",
      "    load_throughput: 11019.773\n",
      "    load_time_ms: 362.984\n",
      "    sample_throughput: 7.175\n",
      "    sample_time_ms: 557513.472\n",
      "    update_time_ms: 3.463\n",
      "  timestamp: 1613869382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 126.19\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 55.84332330127691\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 2709\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6395218968391418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010636094957590103\n",
      "        model: {}\n",
      "        policy_loss: -0.1009235680103302\n",
      "        total_loss: 1037.17919921875\n",
      "        vf_explained_var: 0.5761825442314148\n",
      "        vf_loss: 1037.2559814453125\n",
      "    num_steps_sampled: 328000\n",
      "    num_steps_trained: 328000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.428883495145634\n",
      "    ram_util_percent: 37.59550970873787\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06890648467670632\n",
      "    mean_env_wait_ms: 116.34881545523703\n",
      "    mean_inference_ms: 1.7371903569719798\n",
      "    mean_raw_obs_processing_ms: 9.996829275702517\n",
      "  time_since_restore: 43408.906421899796\n",
      "  time_this_iter_s: 576.9643111228943\n",
      "  time_total_s: 43408.906421899796\n",
      "  timers:\n",
      "    learn_throughput: 264.108\n",
      "    learn_time_ms: 15145.311\n",
      "    load_throughput: 11021.604\n",
      "    load_time_ms: 362.924\n",
      "    sample_throughput: 7.167\n",
      "    sample_time_ms: 558111.411\n",
      "    update_time_ms: 3.453\n",
      "  timestamp: 1613869959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 328000\n",
      "  training_iteration: 82\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 134.56\n",
      "  episode_reward_max: 118.37185952922911\n",
      "  episode_reward_mean: 64.17353366881248\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2737\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6272621750831604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00920060183852911\n",
      "        model: {}\n",
      "        policy_loss: -0.09657780081033707\n",
      "        total_loss: 591.6361694335938\n",
      "        vf_explained_var: 0.675640881061554\n",
      "        vf_loss: 591.7117309570312\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38996328029376\n",
      "    ram_util_percent: 37.62325581395349\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688652520254107\n",
      "    mean_env_wait_ms: 116.4851184964402\n",
      "    mean_inference_ms: 1.7363364645416846\n",
      "    mean_raw_obs_processing_ms: 9.986971637905215\n",
      "  time_since_restore: 43981.41079258919\n",
      "  time_this_iter_s: 572.5043706893921\n",
      "  time_total_s: 43981.41079258919\n",
      "  timers:\n",
      "    learn_throughput: 264.109\n",
      "    learn_time_ms: 15145.289\n",
      "    load_throughput: 11025.657\n",
      "    load_time_ms: 362.79\n",
      "    sample_throughput: 7.168\n",
      "    sample_time_ms: 558050.636\n",
      "    update_time_ms: 3.474\n",
      "  timestamp: 1613870531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 139.17\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 74.64579489491926\n",
      "  episode_reward_min: -100.4791623546053\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2765\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5827945470809937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006520960479974747\n",
      "        model: {}\n",
      "        policy_loss: -0.06697624921798706\n",
      "        total_loss: 203.43817138671875\n",
      "        vf_explained_var: 0.8140708208084106\n",
      "        vf_loss: 203.49026489257812\n",
      "    num_steps_sampled: 336000\n",
      "    num_steps_trained: 336000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.3812729498164\n",
      "    ram_util_percent: 37.64088127294982\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688231221143372\n",
      "    mean_env_wait_ms: 116.62777605461848\n",
      "    mean_inference_ms: 1.735407625887317\n",
      "    mean_raw_obs_processing_ms: 9.974503712169184\n",
      "  time_since_restore: 44553.97675514221\n",
      "  time_this_iter_s: 572.5659625530243\n",
      "  time_total_s: 44553.97675514221\n",
      "  timers:\n",
      "    learn_throughput: 264.173\n",
      "    learn_time_ms: 15141.617\n",
      "    load_throughput: 11003.219\n",
      "    load_time_ms: 363.53\n",
      "    sample_throughput: 7.169\n",
      "    sample_time_ms: 557992.14\n",
      "    update_time_ms: 3.51\n",
      "  timestamp: 1613871104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 336000\n",
      "  training_iteration: 84\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.91\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 72.48419406469598\n",
      "  episode_reward_min: -100.4791623546053\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2795\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6341033577919006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01128568034619093\n",
      "        model: {}\n",
      "        policy_loss: -0.1100163459777832\n",
      "        total_loss: 805.0309448242188\n",
      "        vf_explained_var: 0.7002952694892883\n",
      "        vf_loss: 805.1151733398438\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.42576312576312\n",
      "    ram_util_percent: 37.62319902319903\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0687784308105397\n",
      "    mean_env_wait_ms: 116.77627190738745\n",
      "    mean_inference_ms: 1.7344180800662337\n",
      "    mean_raw_obs_processing_ms: 9.960494716418623\n",
      "  time_since_restore: 45127.50771832466\n",
      "  time_this_iter_s: 573.5309631824493\n",
      "  time_total_s: 45127.50771832466\n",
      "  timers:\n",
      "    learn_throughput: 264.164\n",
      "    learn_time_ms: 15142.128\n",
      "    load_throughput: 10999.194\n",
      "    load_time_ms: 363.663\n",
      "    sample_throughput: 7.166\n",
      "    sample_time_ms: 558160.031\n",
      "    update_time_ms: 3.479\n",
      "  timestamp: 1613871678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-50-50\n",
      "  done: false\n",
      "  episode_len_mean: 141.88\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 74.47919637461047\n",
      "  episode_reward_min: -100.33541309345999\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2822\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6619164347648621\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012647053226828575\n",
      "        model: {}\n",
      "        policy_loss: -0.11788468062877655\n",
      "        total_loss: 890.1051635742188\n",
      "        vf_explained_var: 0.667721152305603\n",
      "        vf_loss: 890.1942749023438\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 344000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31176470588235\n",
      "    ram_util_percent: 37.63468137254902\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06873833848833105\n",
      "    mean_env_wait_ms: 116.91226338279147\n",
      "    mean_inference_ms: 1.7335231801235562\n",
      "    mean_raw_obs_processing_ms: 9.945158745382983\n",
      "  time_since_restore: 45699.621527433395\n",
      "  time_this_iter_s: 572.1138091087341\n",
      "  time_total_s: 45699.621527433395\n",
      "  timers:\n",
      "    learn_throughput: 264.207\n",
      "    learn_time_ms: 15139.67\n",
      "    load_throughput: 11016.095\n",
      "    load_time_ms: 363.105\n",
      "    sample_throughput: 7.161\n",
      "    sample_time_ms: 558577.777\n",
      "    update_time_ms: 3.457\n",
      "  timestamp: 1613872250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 86\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 141.63\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 70.23463403469647\n",
      "  episode_reward_min: -100.48570400254098\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2849\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6279558539390564\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008916793391108513\n",
      "        model: {}\n",
      "        policy_loss: -0.08972213417291641\n",
      "        total_loss: 401.4216003417969\n",
      "        vf_explained_var: 0.7704207301139832\n",
      "        vf_loss: 401.4909973144531\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31370869033047\n",
      "    ram_util_percent: 37.6670746634027\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06869867081991787\n",
      "    mean_env_wait_ms: 117.04716744173258\n",
      "    mean_inference_ms: 1.7326487293140218\n",
      "    mean_raw_obs_processing_ms: 9.929296489515842\n",
      "  time_since_restore: 46272.038051605225\n",
      "  time_this_iter_s: 572.4165241718292\n",
      "  time_total_s: 46272.038051605225\n",
      "  timers:\n",
      "    learn_throughput: 264.183\n",
      "    learn_time_ms: 15141.005\n",
      "    load_throughput: 11017.058\n",
      "    load_time_ms: 363.073\n",
      "    sample_throughput: 7.164\n",
      "    sample_time_ms: 558314.856\n",
      "    update_time_ms: 3.489\n",
      "  timestamp: 1613872823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 145.91\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 78.59757373313865\n",
      "  episode_reward_min: -101.48718799048909\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.609645426273346\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010317403823137283\n",
      "        model: {}\n",
      "        policy_loss: -0.09546666592359543\n",
      "        total_loss: 51.94847106933594\n",
      "        vf_explained_var: 0.9522272348403931\n",
      "        vf_loss: 52.02043151855469\n",
      "    num_steps_sampled: 352000\n",
      "    num_steps_trained: 352000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.37235872235873\n",
      "    ram_util_percent: 37.65970515970516\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06866188360220725\n",
      "    mean_env_wait_ms: 117.1731756625959\n",
      "    mean_inference_ms: 1.7318602560513392\n",
      "    mean_raw_obs_processing_ms: 9.911490483068429\n",
      "  time_since_restore: 46842.017905950546\n",
      "  time_this_iter_s: 569.9798543453217\n",
      "  time_total_s: 46842.017905950546\n",
      "  timers:\n",
      "    learn_throughput: 264.185\n",
      "    learn_time_ms: 15140.929\n",
      "    load_throughput: 11015.432\n",
      "    load_time_ms: 363.127\n",
      "    sample_throughput: 7.168\n",
      "    sample_time_ms: 558051.999\n",
      "    update_time_ms: 3.523\n",
      "  timestamp: 1613873393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 352000\n",
      "  training_iteration: 88\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 151.03\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 86.74178242094577\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2901\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6083473563194275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006297805346548557\n",
      "        model: {}\n",
      "        policy_loss: -0.06047149375081062\n",
      "        total_loss: 84.03146362304688\n",
      "        vf_explained_var: 0.9165517687797546\n",
      "        vf_loss: 84.07758331298828\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.36279069767442\n",
      "    ram_util_percent: 37.65250917992656\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06862152295259255\n",
      "    mean_env_wait_ms: 117.31282317533726\n",
      "    mean_inference_ms: 1.731016450706324\n",
      "    mean_raw_obs_processing_ms: 9.890075394770157\n",
      "  time_since_restore: 47414.542248249054\n",
      "  time_this_iter_s: 572.5243422985077\n",
      "  time_total_s: 47414.542248249054\n",
      "  timers:\n",
      "    learn_throughput: 264.178\n",
      "    learn_time_ms: 15141.325\n",
      "    load_throughput: 10993.389\n",
      "    load_time_ms: 363.855\n",
      "    sample_throughput: 7.171\n",
      "    sample_time_ms: 557836.4\n",
      "    update_time_ms: 3.545\n",
      "  timestamp: 1613873965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-28-57\n",
      "  done: false\n",
      "  episode_len_mean: 152.05\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 95.47943811053409\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2927\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6245173215866089\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008704432286322117\n",
      "        model: {}\n",
      "        policy_loss: -0.07819437235593796\n",
      "        total_loss: 741.48486328125\n",
      "        vf_explained_var: 0.49536240100860596\n",
      "        vf_loss: 741.543212890625\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.23799019607843\n",
      "    ram_util_percent: 37.60428921568628\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06858305551282297\n",
      "    mean_env_wait_ms: 117.44568936548764\n",
      "    mean_inference_ms: 1.730216980502728\n",
      "    mean_raw_obs_processing_ms: 9.868999614297818\n",
      "  time_since_restore: 47986.192225933075\n",
      "  time_this_iter_s: 571.649977684021\n",
      "  time_total_s: 47986.192225933075\n",
      "  timers:\n",
      "    learn_throughput: 264.133\n",
      "    learn_time_ms: 15143.879\n",
      "    load_throughput: 10988.587\n",
      "    load_time_ms: 364.014\n",
      "    sample_throughput: 7.18\n",
      "    sample_time_ms: 557138.008\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613874537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 90\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 148.45\n",
      "  episode_reward_max: 118.36638515678655\n",
      "  episode_reward_mean: 86.87700961007907\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2956\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6059015989303589\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011917388066649437\n",
      "        model: {}\n",
      "        policy_loss: -0.10298958420753479\n",
      "        total_loss: 748.3084106445312\n",
      "        vf_explained_var: 0.6828364729881287\n",
      "        vf_loss: 748.38427734375\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.4583129584352\n",
      "    ram_util_percent: 37.63496332518338\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06854048496142572\n",
      "    mean_env_wait_ms: 117.58732035088931\n",
      "    mean_inference_ms: 1.7293595306129033\n",
      "    mean_raw_obs_processing_ms: 9.84859556894841\n",
      "  time_since_restore: 48559.266986608505\n",
      "  time_this_iter_s: 573.0747606754303\n",
      "  time_total_s: 48559.266986608505\n",
      "  timers:\n",
      "    learn_throughput: 264.152\n",
      "    learn_time_ms: 15142.82\n",
      "    load_throughput: 10967.227\n",
      "    load_time_ms: 364.723\n",
      "    sample_throughput: 7.181\n",
      "    sample_time_ms: 557059.872\n",
      "    update_time_ms: 3.568\n",
      "  timestamp: 1613875110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 147.16\n",
      "  episode_reward_max: 118.36638515678655\n",
      "  episode_reward_mean: 78.53596061698514\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2984\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6384892463684082\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014252190478146076\n",
      "        model: {}\n",
      "        policy_loss: -0.12938052415847778\n",
      "        total_loss: 1040.5548095703125\n",
      "        vf_explained_var: 0.6462556719779968\n",
      "        vf_loss: 1040.651611328125\n",
      "    num_steps_sampled: 368000\n",
      "    num_steps_trained: 368000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31528117359414\n",
      "    ram_util_percent: 37.71638141809291\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0685013111223692\n",
      "    mean_env_wait_ms: 117.71636245049473\n",
      "    mean_inference_ms: 1.7285761946448637\n",
      "    mean_raw_obs_processing_ms: 9.832269351667906\n",
      "  time_since_restore: 49132.35148835182\n",
      "  time_this_iter_s: 573.0845017433167\n",
      "  time_total_s: 49132.35148835182\n",
      "  timers:\n",
      "    learn_throughput: 264.17\n",
      "    learn_time_ms: 15141.759\n",
      "    load_throughput: 10932.693\n",
      "    load_time_ms: 365.875\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556670.702\n",
      "    update_time_ms: 3.56\n",
      "  timestamp: 1613875683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 368000\n",
      "  training_iteration: 92\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 148.59\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 76.27011604884156\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3009\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6160101294517517\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008099525235593319\n",
      "        model: {}\n",
      "        policy_loss: -0.08657196909189224\n",
      "        total_loss: 311.40777587890625\n",
      "        vf_explained_var: 0.7959339618682861\n",
      "        vf_loss: 311.4758605957031\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.257493857493856\n",
      "    ram_util_percent: 37.72186732186732\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684672460741856\n",
      "    mean_env_wait_ms: 117.83028991731415\n",
      "    mean_inference_ms: 1.727895503967211\n",
      "    mean_raw_obs_processing_ms: 9.816608724019238\n",
      "  time_since_restore: 49702.79315876961\n",
      "  time_this_iter_s: 570.4416704177856\n",
      "  time_total_s: 49702.79315876961\n",
      "  timers:\n",
      "    learn_throughput: 264.149\n",
      "    learn_time_ms: 15142.975\n",
      "    load_throughput: 10922.587\n",
      "    load_time_ms: 366.214\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556462.525\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1613876254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 144.0\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 76.09072176362433\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3036\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.620825469493866\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007575416937470436\n",
      "        model: {}\n",
      "        policy_loss: -0.07958129048347473\n",
      "        total_loss: 195.9188232421875\n",
      "        vf_explained_var: 0.8314293622970581\n",
      "        vf_loss: 195.98106384277344\n",
      "    num_steps_sampled: 376000\n",
      "    num_steps_trained: 376000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38223039215686\n",
      "    ram_util_percent: 37.66531862745098\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06843085041858095\n",
      "    mean_env_wait_ms: 117.94984110136356\n",
      "    mean_inference_ms: 1.7271565825316366\n",
      "    mean_raw_obs_processing_ms: 9.80010601973607\n",
      "  time_since_restore: 50274.3007338047\n",
      "  time_this_iter_s: 571.5075750350952\n",
      "  time_total_s: 50274.3007338047\n",
      "  timers:\n",
      "    learn_throughput: 264.177\n",
      "    learn_time_ms: 15141.335\n",
      "    load_throughput: 10932.309\n",
      "    load_time_ms: 365.888\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556358.174\n",
      "    update_time_ms: 3.595\n",
      "  timestamp: 1613876826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 376000\n",
      "  training_iteration: 94\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 154.13\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 90.7099485422507\n",
      "  episode_reward_min: -101.66335937256399\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3061\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6019314527511597\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00965670682489872\n",
      "        model: {}\n",
      "        policy_loss: -0.09145587682723999\n",
      "        total_loss: 34.35165023803711\n",
      "        vf_explained_var: 0.9595359563827515\n",
      "        vf_loss: 34.421104431152344\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28488943488943\n",
      "    ram_util_percent: 37.66216216216216\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06839668156279691\n",
      "    mean_env_wait_ms: 118.06309445303968\n",
      "    mean_inference_ms: 1.7264800011997932\n",
      "    mean_raw_obs_processing_ms: 9.781802359337073\n",
      "  time_since_restore: 50844.359786748886\n",
      "  time_this_iter_s: 570.0590529441833\n",
      "  time_total_s: 50844.359786748886\n",
      "  timers:\n",
      "    learn_throughput: 264.148\n",
      "    learn_time_ms: 15143.038\n",
      "    load_throughput: 10942.055\n",
      "    load_time_ms: 365.562\n",
      "    sample_throughput: 7.194\n",
      "    sample_time_ms: 556008.715\n",
      "    update_time_ms: 3.629\n",
      "  timestamp: 1613877396\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-26-11\n",
      "  done: false\n",
      "  episode_len_mean: 151.55\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 90.73738237431702\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3090\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6180492639541626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01009252667427063\n",
      "        model: {}\n",
      "        policy_loss: -0.0961713045835495\n",
      "        total_loss: 532.2601928710938\n",
      "        vf_explained_var: 0.7508637309074402\n",
      "        vf_loss: 532.3333740234375\n",
      "    num_steps_sampled: 384000\n",
      "    num_steps_trained: 384000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34731707317073\n",
      "    ram_util_percent: 37.65280487804879\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06835815682144136\n",
      "    mean_env_wait_ms: 118.19191298830596\n",
      "    mean_inference_ms: 1.725703411393963\n",
      "    mean_raw_obs_processing_ms: 9.76259727065554\n",
      "  time_since_restore: 51419.60346984863\n",
      "  time_this_iter_s: 575.2436830997467\n",
      "  time_total_s: 51419.60346984863\n",
      "  timers:\n",
      "    learn_throughput: 264.126\n",
      "    learn_time_ms: 15144.265\n",
      "    load_throughput: 10931.565\n",
      "    load_time_ms: 365.913\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556320.133\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1613877971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 384000\n",
      "  training_iteration: 96\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 148.99\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 95.00853702159911\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3117\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6246620416641235\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006574051920324564\n",
      "        model: {}\n",
      "        policy_loss: -0.06613514572381973\n",
      "        total_loss: 164.94639587402344\n",
      "        vf_explained_var: 0.8330784440040588\n",
      "        vf_loss: 164.99755859375\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.297188264058676\n",
      "    ram_util_percent: 37.675794621026895\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0683223278202251\n",
      "    mean_env_wait_ms: 118.30677647535566\n",
      "    mean_inference_ms: 1.7250091530794134\n",
      "    mean_raw_obs_processing_ms: 9.746823513430975\n",
      "  time_since_restore: 51992.47012424469\n",
      "  time_this_iter_s: 572.8666543960571\n",
      "  time_total_s: 51992.47012424469\n",
      "  timers:\n",
      "    learn_throughput: 264.124\n",
      "    learn_time_ms: 15144.379\n",
      "    load_throughput: 10917.265\n",
      "    load_time_ms: 366.392\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556364.217\n",
      "    update_time_ms: 3.558\n",
      "  timestamp: 1613878544\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 148.49\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 92.9885752701855\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3143\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6129283308982849\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007502316031605005\n",
      "        model: {}\n",
      "        policy_loss: -0.07701314240694046\n",
      "        total_loss: 418.00335693359375\n",
      "        vf_explained_var: 0.7102574110031128\n",
      "        vf_loss: 418.063232421875\n",
      "    num_steps_sampled: 392000\n",
      "    num_steps_trained: 392000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31176470588235\n",
      "    ram_util_percent: 37.693137254901956\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06828794418556879\n",
      "    mean_env_wait_ms: 118.41655315671734\n",
      "    mean_inference_ms: 1.7243705784511854\n",
      "    mean_raw_obs_processing_ms: 9.731387966899245\n",
      "  time_since_restore: 52563.917846918106\n",
      "  time_this_iter_s: 571.4477226734161\n",
      "  time_total_s: 52563.917846918106\n",
      "  timers:\n",
      "    learn_throughput: 264.134\n",
      "    learn_time_ms: 15143.824\n",
      "    load_throughput: 10913.187\n",
      "    load_time_ms: 366.529\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556511.074\n",
      "    update_time_ms: 3.511\n",
      "  timestamp: 1613879116\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 392000\n",
      "  training_iteration: 98\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 145.7\n",
      "  episode_reward_max: 118.33897899119724\n",
      "  episode_reward_mean: 88.84848190246228\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3170\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6175667643547058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006731769535690546\n",
      "        model: {}\n",
      "        policy_loss: -0.06991294771432877\n",
      "        total_loss: 247.48231506347656\n",
      "        vf_explained_var: 0.7953845262527466\n",
      "        vf_loss: 247.5369110107422\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.353545232273845\n",
      "    ram_util_percent: 37.635330073349635\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06825275092281008\n",
      "    mean_env_wait_ms: 118.52690351343179\n",
      "    mean_inference_ms: 1.7237184069547202\n",
      "    mean_raw_obs_processing_ms: 9.71665519707479\n",
      "  time_since_restore: 53137.459812402725\n",
      "  time_this_iter_s: 573.5419654846191\n",
      "  time_total_s: 53137.459812402725\n",
      "  timers:\n",
      "    learn_throughput: 264.145\n",
      "    learn_time_ms: 15143.219\n",
      "    load_throughput: 10953.005\n",
      "    load_time_ms: 365.197\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556616.653\n",
      "    update_time_ms: 3.54\n",
      "  timestamp: 1613879690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-04-24\n",
      "  done: false\n",
      "  episode_len_mean: 147.11\n",
      "  episode_reward_max: 118.33897899119724\n",
      "  episode_reward_mean: 93.14223227238632\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3199\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6179011464118958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011885471642017365\n",
      "        model: {}\n",
      "        policy_loss: -0.11724616587162018\n",
      "        total_loss: 561.7438354492188\n",
      "        vf_explained_var: 0.7938085198402405\n",
      "        vf_loss: 561.8339233398438\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.43780487804878\n",
      "    ram_util_percent: 37.717317073170726\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06821509692921657\n",
      "    mean_env_wait_ms: 118.64317735068947\n",
      "    mean_inference_ms: 1.7230314647557228\n",
      "    mean_raw_obs_processing_ms: 9.701350603621318\n",
      "  time_since_restore: 53711.56699895859\n",
      "  time_this_iter_s: 574.1071865558624\n",
      "  time_total_s: 53711.56699895859\n",
      "  timers:\n",
      "    learn_throughput: 264.16\n",
      "    learn_time_ms: 15142.316\n",
      "    load_throughput: 10965.797\n",
      "    load_time_ms: 364.771\n",
      "    sample_throughput: 7.183\n",
      "    sample_time_ms: 556863.546\n",
      "    update_time_ms: 3.559\n",
      "  timestamp: 1613880264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 100\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-13-58\n",
      "  done: false\n",
      "  episode_len_mean: 145.16\n",
      "  episode_reward_max: 118.3942711538609\n",
      "  episode_reward_mean: 87.0959860036248\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3227\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6058357954025269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01053436566144228\n",
      "        model: {}\n",
      "        policy_loss: -0.09249967336654663\n",
      "        total_loss: 812.6344604492188\n",
      "        vf_explained_var: 0.5682348012924194\n",
      "        vf_loss: 812.703125\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.33614163614164\n",
      "    ram_util_percent: 37.71672771672772\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06817984997533298\n",
      "    mean_env_wait_ms: 118.75171630927481\n",
      "    mean_inference_ms: 1.722390448427243\n",
      "    mean_raw_obs_processing_ms: 9.688252713676322\n",
      "  time_since_restore: 54285.57768249512\n",
      "  time_this_iter_s: 574.0106835365295\n",
      "  time_total_s: 54285.57768249512\n",
      "  timers:\n",
      "    learn_throughput: 264.144\n",
      "    learn_time_ms: 15143.28\n",
      "    load_throughput: 10978.317\n",
      "    load_time_ms: 364.355\n",
      "    sample_throughput: 7.182\n",
      "    sample_time_ms: 556955.563\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613880838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 147.48\n",
      "  episode_reward_max: 118.3942711538609\n",
      "  episode_reward_mean: 89.24138729586062\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3252\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6104090213775635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005886872764676809\n",
      "        model: {}\n",
      "        policy_loss: -0.06748391687870026\n",
      "        total_loss: 433.7013244628906\n",
      "        vf_explained_var: 0.6146568655967712\n",
      "        vf_loss: 433.75531005859375\n",
      "    num_steps_sampled: 408000\n",
      "    num_steps_trained: 408000\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.2123774509804\n",
      "    ram_util_percent: 37.689338235294116\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06814926838970166\n",
      "    mean_env_wait_ms: 118.84731336256696\n",
      "    mean_inference_ms: 1.7218322173745153\n",
      "    mean_raw_obs_processing_ms: 9.675675333114134\n",
      "  time_since_restore: 54857.00827693939\n",
      "  time_this_iter_s: 571.4305944442749\n",
      "  time_total_s: 54857.00827693939\n",
      "  timers:\n",
      "    learn_throughput: 264.127\n",
      "    learn_time_ms: 15144.202\n",
      "    load_throughput: 10984.24\n",
      "    load_time_ms: 364.158\n",
      "    sample_throughput: 7.184\n",
      "    sample_time_ms: 556790.183\n",
      "    update_time_ms: 3.583\n",
      "  timestamp: 1613881409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 408000\n",
      "  training_iteration: 102\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-33-07\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 80.92598589407584\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 3283\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5881627798080444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009681874886155128\n",
      "        model: {}\n",
      "        policy_loss: -0.09490907937288284\n",
      "        total_loss: 613.488525390625\n",
      "        vf_explained_var: 0.7268031239509583\n",
      "        vf_loss: 613.5614624023438\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.415188335358444\n",
      "    ram_util_percent: 37.6681652490887\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06811326274325878\n",
      "    mean_env_wait_ms: 118.9614087773805\n",
      "    mean_inference_ms: 1.7211691998654428\n",
      "    mean_raw_obs_processing_ms: 9.663272480891708\n",
      "  time_since_restore: 55434.1220228672\n",
      "  time_this_iter_s: 577.1137459278107\n",
      "  time_total_s: 55434.1220228672\n",
      "  timers:\n",
      "    learn_throughput: 264.149\n",
      "    learn_time_ms: 15142.988\n",
      "    load_throughput: 11012.724\n",
      "    load_time_ms: 363.216\n",
      "    sample_throughput: 7.175\n",
      "    sample_time_ms: 557460.417\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613881987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-42-43\n",
      "  done: false\n",
      "  episode_len_mean: 143.48\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 82.98365740609349\n",
      "  episode_reward_min: -97.20121284343826\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3312\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6338304281234741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00997522659599781\n",
      "        model: {}\n",
      "        policy_loss: -0.10173895955085754\n",
      "        total_loss: 616.504150390625\n",
      "        vf_explained_var: 0.6925467252731323\n",
      "        vf_loss: 616.583251953125\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 416000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.386026731470224\n",
      "    ram_util_percent: 37.688092345078985\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06808057343717405\n",
      "    mean_env_wait_ms: 119.06631584219063\n",
      "    mean_inference_ms: 1.7205515196110677\n",
      "    mean_raw_obs_processing_ms: 9.652490343340176\n",
      "  time_since_restore: 56010.4632897377\n",
      "  time_this_iter_s: 576.3412668704987\n",
      "  time_total_s: 56010.4632897377\n",
      "  timers:\n",
      "    learn_throughput: 264.144\n",
      "    learn_time_ms: 15143.269\n",
      "    load_throughput: 11032.888\n",
      "    load_time_ms: 362.552\n",
      "    sample_throughput: 7.169\n",
      "    sample_time_ms: 557944.608\n",
      "    update_time_ms: 3.504\n",
      "  timestamp: 1613882563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 104\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-52-19\n",
      "  done: false\n",
      "  episode_len_mean: 136.03\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 78.5377385374056\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3342\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6088712811470032\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006714586168527603\n",
      "        model: {}\n",
      "        policy_loss: -0.0737038105726242\n",
      "        total_loss: 247.77517700195312\n",
      "        vf_explained_var: 0.8366903066635132\n",
      "        vf_loss: 247.83358764648438\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.42153284671533\n",
      "    ram_util_percent: 37.645012165450126\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06804771686450926\n",
      "    mean_env_wait_ms: 119.17053416729992\n",
      "    mean_inference_ms: 1.7199192467552313\n",
      "    mean_raw_obs_processing_ms: 9.644637584509693\n",
      "  time_since_restore: 56586.31327319145\n",
      "  time_this_iter_s: 575.8499834537506\n",
      "  time_total_s: 56586.31327319145\n",
      "  timers:\n",
      "    learn_throughput: 264.127\n",
      "    learn_time_ms: 15144.238\n",
      "    load_throughput: 11031.408\n",
      "    load_time_ms: 362.601\n",
      "    sample_throughput: 7.162\n",
      "    sample_time_ms: 558521.569\n",
      "    update_time_ms: 3.565\n",
      "  timestamp: 1613883139\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.12\n",
      "  episode_reward_max: 118.37974768340268\n",
      "  episode_reward_mean: 78.33170541121916\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3368\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6366078853607178\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007359534502029419\n",
      "        model: {}\n",
      "        policy_loss: -0.07867537438869476\n",
      "        total_loss: 246.06504821777344\n",
      "        vf_explained_var: 0.7994463443756104\n",
      "        vf_loss: 246.12693786621094\n",
      "    num_steps_sampled: 424000\n",
      "    num_steps_trained: 424000\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38002450980393\n",
      "    ram_util_percent: 37.65894607843138\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06802034589653698\n",
      "    mean_env_wait_ms: 119.25600639206192\n",
      "    mean_inference_ms: 1.7194048049155586\n",
      "    mean_raw_obs_processing_ms: 9.636769088035123\n",
      "  time_since_restore: 57158.2123401165\n",
      "  time_this_iter_s: 571.8990669250488\n",
      "  time_total_s: 57158.2123401165\n",
      "  timers:\n",
      "    learn_throughput: 264.131\n",
      "    learn_time_ms: 15144.006\n",
      "    load_throughput: 11025.053\n",
      "    load_time_ms: 362.81\n",
      "    sample_throughput: 7.166\n",
      "    sample_time_ms: 558185.885\n",
      "    update_time_ms: 3.584\n",
      "  timestamp: 1613883711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 424000\n",
      "  training_iteration: 106\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 143.85\n",
      "  episode_reward_max: 118.37974768340268\n",
      "  episode_reward_mean: 78.0710623959597\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3396\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5976383686065674\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011524615809321404\n",
      "        model: {}\n",
      "        policy_loss: -0.11197109520435333\n",
      "        total_loss: 734.0401611328125\n",
      "        vf_explained_var: 0.7225897312164307\n",
      "        vf_loss: 734.125732421875\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.314268292682925\n",
      "    ram_util_percent: 37.653536585365856\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06799000126610652\n",
      "    mean_env_wait_ms: 119.35082608143959\n",
      "    mean_inference_ms: 1.7188636168057259\n",
      "    mean_raw_obs_processing_ms: 9.626542268431034\n",
      "  time_since_restore: 57732.9291408062\n",
      "  time_this_iter_s: 574.7168006896973\n",
      "  time_total_s: 57732.9291408062\n",
      "  timers:\n",
      "    learn_throughput: 264.133\n",
      "    learn_time_ms: 15143.884\n",
      "    load_throughput: 11038.27\n",
      "    load_time_ms: 362.376\n",
      "    sample_throughput: 7.164\n",
      "    sample_time_ms: 558371.727\n",
      "    update_time_ms: 3.582\n",
      "  timestamp: 1613884286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-21-01\n",
      "  done: false\n",
      "  episode_len_mean: 140.5\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 78.42548913021338\n",
      "  episode_reward_min: -103.57103560791688\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3425\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6155497431755066\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010168452747166157\n",
      "        model: {}\n",
      "        policy_loss: -0.09731052070856094\n",
      "        total_loss: 613.9942016601562\n",
      "        vf_explained_var: 0.6528792977333069\n",
      "        vf_loss: 614.0682373046875\n",
      "    num_steps_sampled: 432000\n",
      "    num_steps_trained: 432000\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.426431181486\n",
      "    ram_util_percent: 37.73580998781973\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06795917030188195\n",
      "    mean_env_wait_ms: 119.44732461749955\n",
      "    mean_inference_ms: 1.7183229932026485\n",
      "    mean_raw_obs_processing_ms: 9.615730870533078\n",
      "  time_since_restore: 58308.05718636513\n",
      "  time_this_iter_s: 575.1280455589294\n",
      "  time_total_s: 58308.05718636513\n",
      "  timers:\n",
      "    learn_throughput: 264.162\n",
      "    learn_time_ms: 15142.241\n",
      "    load_throughput: 11043.36\n",
      "    load_time_ms: 362.209\n",
      "    sample_throughput: 7.159\n",
      "    sample_time_ms: 558743.547\n",
      "    update_time_ms: 3.583\n",
      "  timestamp: 1613884861\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 432000\n",
      "  training_iteration: 108\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 144.48\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 76.40687688578578\n",
      "  episode_reward_min: -103.57103560791688\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3453\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6024710536003113\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008523493073880672\n",
      "        model: {}\n",
      "        policy_loss: -0.08596337586641312\n",
      "        total_loss: 467.1566467285156\n",
      "        vf_explained_var: 0.7673541903495789\n",
      "        vf_loss: 467.22320556640625\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.04768292682927\n",
      "    ram_util_percent: 37.73085365853658\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06793033424235004\n",
      "    mean_env_wait_ms: 119.54059989938149\n",
      "    mean_inference_ms: 1.717827526785704\n",
      "    mean_raw_obs_processing_ms: 9.605143538899718\n",
      "  time_since_restore: 58882.57932472229\n",
      "  time_this_iter_s: 574.5221383571625\n",
      "  time_total_s: 58882.57932472229\n",
      "  timers:\n",
      "    learn_throughput: 264.188\n",
      "    learn_time_ms: 15140.746\n",
      "    load_throughput: 11022.084\n",
      "    load_time_ms: 362.908\n",
      "    sample_throughput: 7.158\n",
      "    sample_time_ms: 558841.478\n",
      "    update_time_ms: 3.553\n",
      "  timestamp: 1613885436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-40-11\n",
      "  done: false\n",
      "  episode_len_mean: 141.72\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 74.62970423392105\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3482\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6014758944511414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012446741573512554\n",
      "        model: {}\n",
      "        policy_loss: -0.1125083863735199\n",
      "        total_loss: 926.1072387695312\n",
      "        vf_explained_var: 0.653423011302948\n",
      "        vf_loss: 926.19140625\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.57551766138855\n",
      "    ram_util_percent: 37.717783191230204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06790196336835012\n",
      "    mean_env_wait_ms: 119.63217729878222\n",
      "    mean_inference_ms: 1.7173653624665526\n",
      "    mean_raw_obs_processing_ms: 9.596482230104904\n",
      "  time_since_restore: 59457.173558950424\n",
      "  time_this_iter_s: 574.5942342281342\n",
      "  time_total_s: 59457.173558950424\n",
      "  timers:\n",
      "    learn_throughput: 264.167\n",
      "    learn_time_ms: 15141.953\n",
      "    load_throughput: 11015.528\n",
      "    load_time_ms: 363.124\n",
      "    sample_throughput: 7.157\n",
      "    sample_time_ms: 558888.116\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613886011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 110\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-49-46\n",
      "  done: false\n",
      "  episode_len_mean: 139.05\n",
      "  episode_reward_max: 118.38598378043406\n",
      "  episode_reward_mean: 76.65343491029904\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3512\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.590711236000061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009029347449541092\n",
      "        model: {}\n",
      "        policy_loss: -0.09848328679800034\n",
      "        total_loss: 387.76031494140625\n",
      "        vf_explained_var: 0.8040342926979065\n",
      "        vf_loss: 387.8382568359375\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.46406820950061\n",
      "    ram_util_percent: 37.733617539585865\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06787322891278114\n",
      "    mean_env_wait_ms: 119.7227312530466\n",
      "    mean_inference_ms: 1.716910321714039\n",
      "    mean_raw_obs_processing_ms: 9.589092465889095\n",
      "  time_since_restore: 60032.382362127304\n",
      "  time_this_iter_s: 575.2088031768799\n",
      "  time_total_s: 60032.382362127304\n",
      "  timers:\n",
      "    learn_throughput: 264.251\n",
      "    learn_time_ms: 15137.109\n",
      "    load_throughput: 11010.962\n",
      "    load_time_ms: 363.274\n",
      "    sample_throughput: 7.155\n",
      "    sample_time_ms: 559013.784\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613886586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 137.41\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 72.27378223507384\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3539\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5984408259391785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0075990972109138966\n",
      "        model: {}\n",
      "        policy_loss: -0.08635248988866806\n",
      "        total_loss: 253.9138641357422\n",
      "        vf_explained_var: 0.8253668546676636\n",
      "        vf_loss: 253.98289489746094\n",
      "    num_steps_sampled: 448000\n",
      "    num_steps_trained: 448000\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.209157509157514\n",
      "    ram_util_percent: 37.84822954822955\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06784796767137134\n",
      "    mean_env_wait_ms: 119.80372562977568\n",
      "    mean_inference_ms: 1.7165187067082488\n",
      "    mean_raw_obs_processing_ms: 9.58153597114176\n",
      "  time_since_restore: 60606.63854265213\n",
      "  time_this_iter_s: 574.256180524826\n",
      "  time_total_s: 60606.63854265213\n",
      "  timers:\n",
      "    learn_throughput: 264.217\n",
      "    learn_time_ms: 15139.074\n",
      "    load_throughput: 10981.592\n",
      "    load_time_ms: 364.246\n",
      "    sample_throughput: 7.152\n",
      "    sample_time_ms: 559292.284\n",
      "    update_time_ms: 3.547\n",
      "  timestamp: 1613887161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 448000\n",
      "  training_iteration: 112\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 141.31\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 78.43174718781738\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3568\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6062167882919312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00849900022149086\n",
      "        model: {}\n",
      "        policy_loss: -0.08769343048334122\n",
      "        total_loss: 283.53985595703125\n",
      "        vf_explained_var: 0.8445320129394531\n",
      "        vf_loss: 283.6081848144531\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.00335329341318\n",
      "    ram_util_percent: 38.13353293413174\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06782688799794695\n",
      "    mean_env_wait_ms: 119.89516835768752\n",
      "    mean_inference_ms: 1.716184160343747\n",
      "    mean_raw_obs_processing_ms: 9.573978922801206\n",
      "  time_since_restore: 61191.2335793972\n",
      "  time_this_iter_s: 584.5950367450714\n",
      "  time_total_s: 61191.2335793972\n",
      "  timers:\n",
      "    learn_throughput: 264.295\n",
      "    learn_time_ms: 15134.624\n",
      "    load_throughput: 10961.008\n",
      "    load_time_ms: 364.93\n",
      "    sample_throughput: 7.142\n",
      "    sample_time_ms: 560044.648\n",
      "    update_time_ms: 3.61\n",
      "  timestamp: 1613887745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 144.6\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 86.82461647095136\n",
      "  episode_reward_min: -105.0321410534626\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3594\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5918995141983032\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006438602227717638\n",
      "        model: {}\n",
      "        policy_loss: -0.06593605875968933\n",
      "        total_loss: 332.7830505371094\n",
      "        vf_explained_var: 0.6599776148796082\n",
      "        vf_loss: 332.8342590332031\n",
      "    num_steps_sampled: 456000\n",
      "    num_steps_trained: 456000\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34240196078431\n",
      "    ram_util_percent: 38.063357843137254\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06780827979209664\n",
      "    mean_env_wait_ms: 119.97759657799472\n",
      "    mean_inference_ms: 1.7158729855139294\n",
      "    mean_raw_obs_processing_ms: 9.564777671008347\n",
      "  time_since_restore: 61762.852212667465\n",
      "  time_this_iter_s: 571.6186332702637\n",
      "  time_total_s: 61762.852212667465\n",
      "  timers:\n",
      "    learn_throughput: 264.397\n",
      "    learn_time_ms: 15128.754\n",
      "    load_throughput: 10947.792\n",
      "    load_time_ms: 365.37\n",
      "    sample_throughput: 7.148\n",
      "    sample_time_ms: 559576.306\n",
      "    update_time_ms: 3.667\n",
      "  timestamp: 1613888317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 456000\n",
      "  training_iteration: 114\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-28-17\n",
      "  done: false\n",
      "  episode_len_mean: 144.62\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 86.80167187729789\n",
      "  episode_reward_min: -105.09060085253891\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3622\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6433344483375549\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010839796625077724\n",
      "        model: {}\n",
      "        policy_loss: -0.10590440779924393\n",
      "        total_loss: 570.0552368164062\n",
      "        vf_explained_var: 0.7485004663467407\n",
      "        vf_loss: 570.1365966796875\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.352841596130595\n",
      "    ram_util_percent: 38.07920193470375\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06778949191005351\n",
      "    mean_env_wait_ms: 120.07001042963421\n",
      "    mean_inference_ms: 1.7155426799237201\n",
      "    mean_raw_obs_processing_ms: 9.554230492816803\n",
      "  time_since_restore: 62342.62043309212\n",
      "  time_this_iter_s: 579.7682204246521\n",
      "  time_total_s: 62342.62043309212\n",
      "  timers:\n",
      "    learn_throughput: 261.992\n",
      "    learn_time_ms: 15267.62\n",
      "    load_throughput: 10942.687\n",
      "    load_time_ms: 365.541\n",
      "    sample_throughput: 7.145\n",
      "    sample_time_ms: 559828.975\n",
      "    update_time_ms: 3.615\n",
      "  timestamp: 1613888897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 147.86\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 93.33501276419842\n",
      "  episode_reward_min: -105.09060085253891\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3649\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5805870294570923\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009480483829975128\n",
      "        model: {}\n",
      "        policy_loss: -0.09276328235864639\n",
      "        total_loss: 34.91984939575195\n",
      "        vf_explained_var: 0.9700055718421936\n",
      "        vf_loss: 34.99101638793945\n",
      "    num_steps_sampled: 464000\n",
      "    num_steps_trained: 464000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.62633495145631\n",
      "    ram_util_percent: 38.1372572815534\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0677720796855766\n",
      "    mean_env_wait_ms: 120.15735014680446\n",
      "    mean_inference_ms: 1.7152309768018645\n",
      "    mean_raw_obs_processing_ms: 9.543755308827134\n",
      "  time_since_restore: 62919.88499903679\n",
      "  time_this_iter_s: 577.2645659446716\n",
      "  time_total_s: 62919.88499903679\n",
      "  timers:\n",
      "    learn_throughput: 262.086\n",
      "    learn_time_ms: 15262.151\n",
      "    load_throughput: 10951.716\n",
      "    load_time_ms: 365.24\n",
      "    sample_throughput: 7.138\n",
      "    sample_time_ms: 560371.214\n",
      "    update_time_ms: 3.602\n",
      "  timestamp: 1613889475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 464000\n",
      "  training_iteration: 116\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 151.34\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 97.33516881296664\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3674\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6057289838790894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00902612879872322\n",
      "        model: {}\n",
      "        policy_loss: -0.08407626301050186\n",
      "        total_loss: 47.36072540283203\n",
      "        vf_explained_var: 0.9562988877296448\n",
      "        vf_loss: 47.42424011230469\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.257720588235294\n",
      "    ram_util_percent: 38.134068627450986\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06775213187945846\n",
      "    mean_env_wait_ms: 120.23711540446456\n",
      "    mean_inference_ms: 1.7148622716953952\n",
      "    mean_raw_obs_processing_ms: 9.531843481668078\n",
      "  time_since_restore: 63491.65019154549\n",
      "  time_this_iter_s: 571.7651925086975\n",
      "  time_total_s: 63491.65019154549\n",
      "  timers:\n",
      "    learn_throughput: 262.208\n",
      "    learn_time_ms: 15255.09\n",
      "    load_throughput: 10960.437\n",
      "    load_time_ms: 364.949\n",
      "    sample_throughput: 7.142\n",
      "    sample_time_ms: 560080.637\n",
      "    update_time_ms: 3.619\n",
      "  timestamp: 1613890046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 146.86\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 91.05291780335374\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3704\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6012541651725769\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00911764707416296\n",
      "        model: {}\n",
      "        policy_loss: -0.09254691749811172\n",
      "        total_loss: 685.6951293945312\n",
      "        vf_explained_var: 0.6572573184967041\n",
      "        vf_loss: 685.7669067382812\n",
      "    num_steps_sampled: 472000\n",
      "    num_steps_trained: 472000\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.51634146341465\n",
      "    ram_util_percent: 38.13914634146342\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06772919668110616\n",
      "    mean_env_wait_ms: 120.32691297202932\n",
      "    mean_inference_ms: 1.7144107681494976\n",
      "    mean_raw_obs_processing_ms: 9.520671146772086\n",
      "  time_since_restore: 64066.185210466385\n",
      "  time_this_iter_s: 574.5350189208984\n",
      "  time_total_s: 64066.185210466385\n",
      "  timers:\n",
      "    learn_throughput: 262.137\n",
      "    learn_time_ms: 15259.186\n",
      "    load_throughput: 10969.156\n",
      "    load_time_ms: 364.659\n",
      "    sample_throughput: 7.143\n",
      "    sample_time_ms: 560016.439\n",
      "    update_time_ms: 3.648\n",
      "  timestamp: 1613890621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 472000\n",
      "  training_iteration: 118\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-06-33\n",
      "  done: false\n",
      "  episode_len_mean: 148.66\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 89.15732775802172\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3730\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6236892342567444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013307305052876472\n",
      "        model: {}\n",
      "        policy_loss: -0.1155630424618721\n",
      "        total_loss: 1010.5505981445312\n",
      "        vf_explained_var: 0.5766982436180115\n",
      "        vf_loss: 1010.6359252929688\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.30882352941177\n",
      "    ram_util_percent: 38.13970588235295\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06770796026275733\n",
      "    mean_env_wait_ms: 120.40130526884197\n",
      "    mean_inference_ms: 1.7140039793359307\n",
      "    mean_raw_obs_processing_ms: 9.510031471826066\n",
      "  time_since_restore: 64637.37950015068\n",
      "  time_this_iter_s: 571.1942896842957\n",
      "  time_total_s: 64637.37950015068\n",
      "  timers:\n",
      "    learn_throughput: 262.135\n",
      "    learn_time_ms: 15259.32\n",
      "    load_throughput: 10973.496\n",
      "    load_time_ms: 364.515\n",
      "    sample_throughput: 7.147\n",
      "    sample_time_ms: 559683.545\n",
      "    update_time_ms: 3.636\n",
      "  timestamp: 1613891193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-16-04\n",
      "  done: false\n",
      "  episode_len_mean: 148.73\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 87.00290944381177\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3756\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5877834558486938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009241716004908085\n",
      "        model: {}\n",
      "        policy_loss: -0.08691494166851044\n",
      "        total_loss: 67.36650848388672\n",
      "        vf_explained_var: 0.944295346736908\n",
      "        vf_loss: 67.432373046875\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.35693251533743\n",
      "    ram_util_percent: 38.141840490797556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0676864742568336\n",
      "    mean_env_wait_ms: 120.47292656211799\n",
      "    mean_inference_ms: 1.7135771052734765\n",
      "    mean_raw_obs_processing_ms: 9.499117822285328\n",
      "  time_since_restore: 65208.24702858925\n",
      "  time_this_iter_s: 570.8675284385681\n",
      "  time_total_s: 65208.24702858925\n",
      "  timers:\n",
      "    learn_throughput: 262.126\n",
      "    learn_time_ms: 15259.811\n",
      "    load_throughput: 10962.411\n",
      "    load_time_ms: 364.883\n",
      "    sample_throughput: 7.152\n",
      "    sample_time_ms: 559310.986\n",
      "    update_time_ms: 3.658\n",
      "  timestamp: 1613891764\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 120\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-24-37\n",
      "  done: false\n",
      "  episode_len_mean: 146.66\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 85.14329107139147\n",
      "  episode_reward_min: -100.99048036755502\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3785\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5510581731796265\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007981202565133572\n",
      "        model: {}\n",
      "        policy_loss: -0.08055435866117477\n",
      "        total_loss: 546.143310546875\n",
      "        vf_explained_var: 0.6825169920921326\n",
      "        vf_loss: 546.2056884765625\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.81270491803278\n",
      "    ram_util_percent: 38.12691256830601\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06767392832483515\n",
      "    mean_env_wait_ms: 120.5110071355082\n",
      "    mean_inference_ms: 1.7133055716367522\n",
      "    mean_raw_obs_processing_ms: 9.489400407951997\n",
      "  time_since_restore: 65721.15237927437\n",
      "  time_this_iter_s: 512.9053506851196\n",
      "  time_total_s: 65721.15237927437\n",
      "  timers:\n",
      "    learn_throughput: 261.767\n",
      "    learn_time_ms: 15280.742\n",
      "    load_throughput: 10970.308\n",
      "    load_time_ms: 364.621\n",
      "    sample_throughput: 7.233\n",
      "    sample_time_ms: 553057.905\n",
      "    update_time_ms: 3.717\n",
      "  timestamp: 1613892277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-33-19\n",
      "  done: false\n",
      "  episode_len_mean: 146.02\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 85.38652081386765\n",
      "  episode_reward_min: -100.4306152638022\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3813\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6183977723121643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010066812857985497\n",
      "        model: {}\n",
      "        policy_loss: -0.09824593365192413\n",
      "        total_loss: 581.5679321289062\n",
      "        vf_explained_var: 0.7129077315330505\n",
      "        vf_loss: 581.6431274414062\n",
      "    num_steps_sampled: 488000\n",
      "    num_steps_trained: 488000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.68375838926174\n",
      "    ram_util_percent: 38.153825503355705\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06767878007932275\n",
      "    mean_env_wait_ms: 120.51764218598193\n",
      "    mean_inference_ms: 1.7133476223797286\n",
      "    mean_raw_obs_processing_ms: 9.479803397885286\n",
      "  time_since_restore: 66243.28735876083\n",
      "  time_this_iter_s: 522.1349794864655\n",
      "  time_total_s: 66243.28735876083\n",
      "  timers:\n",
      "    learn_throughput: 259.26\n",
      "    learn_time_ms: 15428.527\n",
      "    load_throughput: 10958.238\n",
      "    load_time_ms: 365.022\n",
      "    sample_throughput: 7.303\n",
      "    sample_time_ms: 547694.19\n",
      "    update_time_ms: 3.689\n",
      "  timestamp: 1613892799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 488000\n",
      "  training_iteration: 122\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 139.65\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 89.45473524232285\n",
      "  episode_reward_min: -100.4306152638022\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 3844\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.577362060546875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007396557833999395\n",
      "        model: {}\n",
      "        policy_loss: -0.07415349781513214\n",
      "        total_loss: 183.14419555664062\n",
      "        vf_explained_var: 0.8363568782806396\n",
      "        vf_loss: 183.2015380859375\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.56627140974966\n",
      "    ram_util_percent: 38.189855072463764\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06770722321730716\n",
      "    mean_env_wait_ms: 120.4917917336477\n",
      "    mean_inference_ms: 1.7137769699131404\n",
      "    mean_raw_obs_processing_ms: 9.473527999217005\n",
      "  time_since_restore: 66775.34722495079\n",
      "  time_this_iter_s: 532.0598661899567\n",
      "  time_total_s: 66775.34722495079\n",
      "  timers:\n",
      "    learn_throughput: 256.674\n",
      "    learn_time_ms: 15583.947\n",
      "    load_throughput: 10864.259\n",
      "    load_time_ms: 368.18\n",
      "    sample_throughput: 7.376\n",
      "    sample_time_ms: 542280.96\n",
      "    update_time_ms: 3.653\n",
      "  timestamp: 1613893331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-50-51\n",
      "  done: false\n",
      "  episode_len_mean: 139.74\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 84.90426776366216\n",
      "  episode_reward_min: -106.0701544586116\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3871\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6015790104866028\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01063192542642355\n",
      "        model: {}\n",
      "        policy_loss: -0.10586980730295181\n",
      "        total_loss: 477.35626220703125\n",
      "        vf_explained_var: 0.7866230010986328\n",
      "        vf_loss: 477.4378356933594\n",
      "    num_steps_sampled: 496000\n",
      "    num_steps_trained: 496000\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.47857142857144\n",
      "    ram_util_percent: 38.21563342318059\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0677439447389491\n",
      "    mean_env_wait_ms: 120.45729120222786\n",
      "    mean_inference_ms: 1.7143439789547819\n",
      "    mean_raw_obs_processing_ms: 9.467971795851675\n",
      "  time_since_restore: 67294.9882683754\n",
      "  time_this_iter_s: 519.6410434246063\n",
      "  time_total_s: 67294.9882683754\n",
      "  timers:\n",
      "    learn_throughput: 256.069\n",
      "    learn_time_ms: 15620.818\n",
      "    load_throughput: 10857.938\n",
      "    load_time_ms: 368.394\n",
      "    sample_throughput: 7.448\n",
      "    sample_time_ms: 537043.94\n",
      "    update_time_ms: 3.594\n",
      "  timestamp: 1613893851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 496000\n",
      "  training_iteration: 124\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 134.12\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 84.80443379407956\n",
      "  episode_reward_min: -106.0701544586116\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 3903\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5771121382713318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008310528472065926\n",
      "        model: {}\n",
      "        policy_loss: -0.08232569694519043\n",
      "        total_loss: 534.6954345703125\n",
      "        vf_explained_var: 0.6438747644424438\n",
      "        vf_loss: 534.7588500976562\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.63836565096952\n",
      "    ram_util_percent: 38.17783933518006\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06778464054628712\n",
      "    mean_env_wait_ms: 120.4076427896925\n",
      "    mean_inference_ms: 1.7149836034740622\n",
      "    mean_raw_obs_processing_ms: 9.463932562409434\n",
      "  time_since_restore: 67801.0431239605\n",
      "  time_this_iter_s: 506.05485558509827\n",
      "  time_total_s: 67801.0431239605\n",
      "  timers:\n",
      "    learn_throughput: 258.103\n",
      "    learn_time_ms: 15497.712\n",
      "    load_throughput: 10813.376\n",
      "    load_time_ms: 369.912\n",
      "    sample_throughput: 7.55\n",
      "    sample_time_ms: 529791.92\n",
      "    update_time_ms: 3.559\n",
      "  timestamp: 1613894357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 138.5\n",
      "  episode_reward_max: 118.34709881053\n",
      "  episode_reward_mean: 78.08393089485901\n",
      "  episode_reward_min: -106.32775745859084\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3930\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6117790937423706\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010948827490210533\n",
      "        model: {}\n",
      "        policy_loss: -0.10564907640218735\n",
      "        total_loss: 647.387451171875\n",
      "        vf_explained_var: 0.6757882237434387\n",
      "        vf_loss: 647.4682006835938\n",
      "    num_steps_sampled: 504000\n",
      "    num_steps_trained: 504000\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61178918169209\n",
      "    ram_util_percent: 38.201386962552014\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0678116961064663\n",
      "    mean_env_wait_ms: 120.35627306923674\n",
      "    mean_inference_ms: 1.715379314195032\n",
      "    mean_raw_obs_processing_ms: 9.458864461888382\n",
      "  time_since_restore: 68305.61447262764\n",
      "  time_this_iter_s: 504.5713486671448\n",
      "  time_total_s: 68305.61447262764\n",
      "  timers:\n",
      "    learn_throughput: 255.586\n",
      "    learn_time_ms: 15650.32\n",
      "    load_throughput: 10791.392\n",
      "    load_time_ms: 370.666\n",
      "    sample_throughput: 7.657\n",
      "    sample_time_ms: 522369.037\n",
      "    update_time_ms: 3.582\n",
      "  timestamp: 1613894862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 504000\n",
      "  training_iteration: 126\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-16-29\n",
      "  done: false\n",
      "  episode_len_mean: 142.47\n",
      "  episode_reward_max: 118.32835011673706\n",
      "  episode_reward_mean: 82.36495306691775\n",
      "  episode_reward_min: -106.32775745859084\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3957\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5907235741615295\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008743084967136383\n",
      "        model: {}\n",
      "        policy_loss: -0.08979450166225433\n",
      "        total_loss: 294.9871826171875\n",
      "        vf_explained_var: 0.8123583197593689\n",
      "        vf_loss: 295.0570373535156\n",
      "    num_steps_sampled: 508000\n",
      "    num_steps_trained: 508000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.94388297872341\n",
      "    ram_util_percent: 38.37739361702128\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06784055093998786\n",
      "    mean_env_wait_ms: 120.30579860423741\n",
      "    mean_inference_ms: 1.7158013710289555\n",
      "    mean_raw_obs_processing_ms: 9.452628401740492\n",
      "  time_since_restore: 68832.49143481255\n",
      "  time_this_iter_s: 526.876962184906\n",
      "  time_total_s: 68832.49143481255\n",
      "  timers:\n",
      "    learn_throughput: 252.888\n",
      "    learn_time_ms: 15817.3\n",
      "    load_throughput: 10764.004\n",
      "    load_time_ms: 371.609\n",
      "    sample_throughput: 7.726\n",
      "    sample_time_ms: 517709.113\n",
      "    update_time_ms: 3.604\n",
      "  timestamp: 1613895389\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 508000\n",
      "  training_iteration: 127\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 142.03\n",
      "  episode_reward_max: 118.31354670270113\n",
      "  episode_reward_mean: 82.43069567717554\n",
      "  episode_reward_min: -106.80176523156126\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3986\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5881098508834839\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010245510376989841\n",
      "        model: {}\n",
      "        policy_loss: -0.09339163452386856\n",
      "        total_loss: 627.2103271484375\n",
      "        vf_explained_var: 0.6385515928268433\n",
      "        vf_loss: 627.2803955078125\n",
      "    num_steps_sampled: 512000\n",
      "    num_steps_trained: 512000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.81226666666666\n",
      "    ram_util_percent: 38.380399999999995\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06787463923392938\n",
      "    mean_env_wait_ms: 120.26053147584571\n",
      "    mean_inference_ms: 1.7163259572157061\n",
      "    mean_raw_obs_processing_ms: 9.44585488949249\n",
      "  time_since_restore: 69358.38308548927\n",
      "  time_this_iter_s: 525.8916506767273\n",
      "  time_total_s: 69358.38308548927\n",
      "  timers:\n",
      "    learn_throughput: 252.533\n",
      "    learn_time_ms: 15839.527\n",
      "    load_throughput: 10719.51\n",
      "    load_time_ms: 373.151\n",
      "    sample_throughput: 7.8\n",
      "    sample_time_ms: 512821.553\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613895915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 512000\n",
      "  training_iteration: 128\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 132.8\n",
      "  episode_reward_max: 118.34928746608047\n",
      "  episode_reward_mean: 82.31662489947415\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 4021\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5682926177978516\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007367397658526897\n",
      "        model: {}\n",
      "        policy_loss: -0.07760433107614517\n",
      "        total_loss: 376.2999572753906\n",
      "        vf_explained_var: 0.7548487186431885\n",
      "        vf_loss: 376.3607482910156\n",
      "    num_steps_sampled: 516000\n",
      "    num_steps_trained: 516000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.78049450549451\n",
      "    ram_util_percent: 38.393956043956045\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06791655003039965\n",
      "    mean_env_wait_ms: 120.20590265398637\n",
      "    mean_inference_ms: 1.7169823124501375\n",
      "    mean_raw_obs_processing_ms: 9.442055682272372\n",
      "  time_since_restore: 69867.91096925735\n",
      "  time_this_iter_s: 509.52788376808167\n",
      "  time_total_s: 69867.91096925735\n",
      "  timers:\n",
      "    learn_throughput: 252.141\n",
      "    learn_time_ms: 15864.164\n",
      "    load_throughput: 10711.439\n",
      "    load_time_ms: 373.433\n",
      "    sample_throughput: 7.895\n",
      "    sample_time_ms: 506628.024\n",
      "    update_time_ms: 3.567\n",
      "  timestamp: 1613896425\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 516000\n",
      "  training_iteration: 129\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 129.46\n",
      "  episode_reward_max: 118.34928746608047\n",
      "  episode_reward_mean: 80.40744834850254\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4051\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6039897799491882\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010948044247925282\n",
      "        model: {}\n",
      "        policy_loss: -0.10490277409553528\n",
      "        total_loss: 421.2901611328125\n",
      "        vf_explained_var: 0.8155714869499207\n",
      "        vf_loss: 421.3701171875\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53504867872045\n",
      "    ram_util_percent: 38.365507649513205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06794615383610282\n",
      "    mean_env_wait_ms: 120.15307269858904\n",
      "    mean_inference_ms: 1.7174442956596794\n",
      "    mean_raw_obs_processing_ms: 9.441340066067333\n",
      "  time_since_restore: 70371.77071595192\n",
      "  time_this_iter_s: 503.8597466945648\n",
      "  time_total_s: 70371.77071595192\n",
      "  timers:\n",
      "    learn_throughput: 251.831\n",
      "    learn_time_ms: 15883.643\n",
      "    load_throughput: 10696.796\n",
      "    load_time_ms: 373.944\n",
      "    sample_throughput: 8.001\n",
      "    sample_time_ms: 499906.446\n",
      "    update_time_ms: 3.558\n",
      "  timestamp: 1613896929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 130\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-50-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.5\n",
      "  episode_reward_max: 118.37421759265597\n",
      "  episode_reward_mean: 82.69939237282279\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4079\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5987846255302429\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005686358083039522\n",
      "        model: {}\n",
      "        policy_loss: -0.07071297615766525\n",
      "        total_loss: 285.1310119628906\n",
      "        vf_explained_var: 0.7715242505073547\n",
      "        vf_loss: 285.1888122558594\n",
      "    num_steps_sampled: 524000\n",
      "    num_steps_trained: 524000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.519860139860135\n",
      "    ram_util_percent: 38.37874125874126\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06796573233450409\n",
      "    mean_env_wait_ms: 120.09234682412965\n",
      "    mean_inference_ms: 1.7177408642111685\n",
      "    mean_raw_obs_processing_ms: 9.440449571341798\n",
      "  time_since_restore: 70872.90150022507\n",
      "  time_this_iter_s: 501.1307842731476\n",
      "  time_total_s: 70872.90150022507\n",
      "  timers:\n",
      "    learn_throughput: 251.725\n",
      "    learn_time_ms: 15890.363\n",
      "    load_throughput: 10678.404\n",
      "    load_time_ms: 374.588\n",
      "    sample_throughput: 8.02\n",
      "    sample_time_ms: 498723.017\n",
      "    update_time_ms: 3.481\n",
      "  timestamp: 1613897430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 524000\n",
      "  training_iteration: 131\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.54\n",
      "  episode_reward_max: 118.3795693239413\n",
      "  episode_reward_mean: 82.96836530942372\n",
      "  episode_reward_min: -103.76890862329319\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4108\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5838570594787598\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01188985537737608\n",
      "        model: {}\n",
      "        policy_loss: -0.10170167684555054\n",
      "        total_loss: 772.657958984375\n",
      "        vf_explained_var: 0.653910756111145\n",
      "        vf_loss: 772.7326049804688\n",
      "    num_steps_sampled: 528000\n",
      "    num_steps_trained: 528000\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53216783216783\n",
      "    ram_util_percent: 38.39090909090909\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06798371611601566\n",
      "    mean_env_wait_ms: 120.02619330508769\n",
      "    mean_inference_ms: 1.7180095488962615\n",
      "    mean_raw_obs_processing_ms: 9.436648742925328\n",
      "  time_since_restore: 71374.011282444\n",
      "  time_this_iter_s: 501.1097822189331\n",
      "  time_total_s: 71374.011282444\n",
      "  timers:\n",
      "    learn_throughput: 253.79\n",
      "    learn_time_ms: 15761.042\n",
      "    load_throughput: 10597.706\n",
      "    load_time_ms: 377.44\n",
      "    sample_throughput: 8.052\n",
      "    sample_time_ms: 496749.288\n",
      "    update_time_ms: 3.498\n",
      "  timestamp: 1613897932\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 528000\n",
      "  training_iteration: 132\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.58\n",
      "  episode_reward_max: 118.39521154807612\n",
      "  episode_reward_mean: 83.17846175221419\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4139\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5650530457496643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007939182221889496\n",
      "        model: {}\n",
      "        policy_loss: -0.08119844645261765\n",
      "        total_loss: 407.46173095703125\n",
      "        vf_explained_var: 0.7646421194076538\n",
      "        vf_loss: 407.5248718261719\n",
      "    num_steps_sampled: 532000\n",
      "    num_steps_trained: 532000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55833333333333\n",
      "    ram_util_percent: 38.338055555555556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06800290073032944\n",
      "    mean_env_wait_ms: 119.95183123516772\n",
      "    mean_inference_ms: 1.7182751771675613\n",
      "    mean_raw_obs_processing_ms: 9.432557149867971\n",
      "  time_since_restore: 71877.89301609993\n",
      "  time_this_iter_s: 503.88173365592957\n",
      "  time_total_s: 71877.89301609993\n",
      "  timers:\n",
      "    learn_throughput: 255.939\n",
      "    learn_time_ms: 15628.753\n",
      "    load_throughput: 10630.193\n",
      "    load_time_ms: 376.287\n",
      "    sample_throughput: 8.096\n",
      "    sample_time_ms: 494064.123\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613898436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 532000\n",
      "  training_iteration: 133\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 139.25\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 85.27356494809966\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4164\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.600960373878479\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006746595725417137\n",
      "        model: {}\n",
      "        policy_loss: -0.07783032953739166\n",
      "        total_loss: 314.6885070800781\n",
      "        vf_explained_var: 0.7607309818267822\n",
      "        vf_loss: 314.7509765625\n",
      "    num_steps_sampled: 536000\n",
      "    num_steps_trained: 536000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.494092827004216\n",
      "    ram_util_percent: 38.360759493670884\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06801850421276065\n",
      "    mean_env_wait_ms: 119.8919756049781\n",
      "    mean_inference_ms: 1.718506779837454\n",
      "    mean_raw_obs_processing_ms: 9.426981561005293\n",
      "  time_since_restore: 72376.05636382103\n",
      "  time_this_iter_s: 498.16334772109985\n",
      "  time_total_s: 72376.05636382103\n",
      "  timers:\n",
      "    learn_throughput: 256.104\n",
      "    learn_time_ms: 15618.666\n",
      "    load_throughput: 10530.235\n",
      "    load_time_ms: 379.859\n",
      "    sample_throughput: 8.131\n",
      "    sample_time_ms: 491923.513\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613898934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 536000\n",
      "  training_iteration: 134\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-23-58\n",
      "  done: false\n",
      "  episode_len_mean: 139.5\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 95.64621330132915\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4194\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5370206236839294\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004629514180123806\n",
      "        model: {}\n",
      "        policy_loss: -0.04861670359969139\n",
      "        total_loss: 137.58197021484375\n",
      "        vf_explained_var: 0.8455789685249329\n",
      "        vf_loss: 137.6200408935547\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.59679665738162\n",
      "    ram_util_percent: 38.40431754874651\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06803823480184848\n",
      "    mean_env_wait_ms: 119.82114675593346\n",
      "    mean_inference_ms: 1.718770904202886\n",
      "    mean_raw_obs_processing_ms: 9.42133230428674\n",
      "  time_since_restore: 72879.4960064888\n",
      "  time_this_iter_s: 503.4396426677704\n",
      "  time_total_s: 72879.4960064888\n",
      "  timers:\n",
      "    learn_throughput: 256.095\n",
      "    learn_time_ms: 15619.196\n",
      "    load_throughput: 10534.313\n",
      "    load_time_ms: 379.712\n",
      "    sample_throughput: 8.136\n",
      "    sample_time_ms: 491663.38\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613899438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 135\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-32-20\n",
      "  done: false\n",
      "  episode_len_mean: 138.83\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 95.68756577876341\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4224\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5466543436050415\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011059517040848732\n",
      "        model: {}\n",
      "        policy_loss: -0.08189653605222702\n",
      "        total_loss: 242.59808349609375\n",
      "        vf_explained_var: 0.8244056701660156\n",
      "        vf_loss: 242.66738891601562\n",
      "    num_steps_sampled: 544000\n",
      "    num_steps_trained: 544000\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.639191073919115\n",
      "    ram_util_percent: 38.38967921896793\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06805755736091408\n",
      "    mean_env_wait_ms: 119.75206377602635\n",
      "    mean_inference_ms: 1.7190400202641178\n",
      "    mean_raw_obs_processing_ms: 9.41560263759338\n",
      "  time_since_restore: 73381.71351766586\n",
      "  time_this_iter_s: 502.217511177063\n",
      "  time_total_s: 73381.71351766586\n",
      "  timers:\n",
      "    learn_throughput: 258.177\n",
      "    learn_time_ms: 15493.223\n",
      "    load_throughput: 10535.06\n",
      "    load_time_ms: 379.685\n",
      "    sample_throughput: 8.137\n",
      "    sample_time_ms: 491552.855\n",
      "    update_time_ms: 3.606\n",
      "  timestamp: 1613899940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 544000\n",
      "  training_iteration: 136\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-40-41\n",
      "  done: false\n",
      "  episode_len_mean: 139.2\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 95.88512579679904\n",
      "  episode_reward_min: -100.1750695215878\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4251\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5456653237342834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014115593396127224\n",
      "        model: {}\n",
      "        policy_loss: -0.0856579840183258\n",
      "        total_loss: 516.1102294921875\n",
      "        vf_explained_var: 0.619394838809967\n",
      "        vf_loss: 516.1798095703125\n",
      "    num_steps_sampled: 548000\n",
      "    num_steps_trained: 548000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.451468531468535\n",
      "    ram_util_percent: 38.343916083916085\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06807438256326685\n",
      "    mean_env_wait_ms: 119.68962361357994\n",
      "    mean_inference_ms: 1.7193031557236806\n",
      "    mean_raw_obs_processing_ms: 9.409635454162597\n",
      "  time_since_restore: 73882.23320555687\n",
      "  time_this_iter_s: 500.51968789100647\n",
      "  time_total_s: 73882.23320555687\n",
      "  timers:\n",
      "    learn_throughput: 260.521\n",
      "    learn_time_ms: 15353.831\n",
      "    load_throughput: 10524.565\n",
      "    load_time_ms: 380.063\n",
      "    sample_throughput: 8.179\n",
      "    sample_time_ms: 489059.197\n",
      "    update_time_ms: 3.631\n",
      "  timestamp: 1613900441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 548000\n",
      "  training_iteration: 137\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 142.07\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 97.81481651326742\n",
      "  episode_reward_min: -105.63298102378208\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4277\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5156704783439636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01677967607975006\n",
      "        model: {}\n",
      "        policy_loss: -0.09261477738618851\n",
      "        total_loss: 24.15653419494629\n",
      "        vf_explained_var: 0.974636435508728\n",
      "        vf_loss: 24.230031967163086\n",
      "    num_steps_sampled: 552000\n",
      "    num_steps_trained: 552000\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.479663394109394\n",
      "    ram_util_percent: 38.35035063113605\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06808918160052571\n",
      "    mean_env_wait_ms: 119.63162029126406\n",
      "    mean_inference_ms: 1.7195446712067508\n",
      "    mean_raw_obs_processing_ms: 9.403294456473589\n",
      "  time_since_restore: 74381.7987921238\n",
      "  time_this_iter_s: 499.56558656692505\n",
      "  time_total_s: 74381.7987921238\n",
      "  timers:\n",
      "    learn_throughput: 260.567\n",
      "    learn_time_ms: 15351.132\n",
      "    load_throughput: 10558.554\n",
      "    load_time_ms: 378.84\n",
      "    sample_throughput: 8.223\n",
      "    sample_time_ms: 486429.308\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613900941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 552000\n",
      "  training_iteration: 138\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 139.24\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 93.40331968238395\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 4309\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5389827489852905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014672734774649143\n",
      "        model: {}\n",
      "        policy_loss: -0.0996832475066185\n",
      "        total_loss: 407.98126220703125\n",
      "        vf_explained_var: 0.790763258934021\n",
      "        vf_loss: 408.0642395019531\n",
      "    num_steps_sampled: 556000\n",
      "    num_steps_trained: 556000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.656726768377254\n",
      "    ram_util_percent: 38.41900138696255\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06810755744305874\n",
      "    mean_env_wait_ms: 119.56045884890777\n",
      "    mean_inference_ms: 1.7198390813878144\n",
      "    mean_raw_obs_processing_ms: 9.39705959078869\n",
      "  time_since_restore: 74887.08270263672\n",
      "  time_this_iter_s: 505.2839105129242\n",
      "  time_total_s: 74887.08270263672\n",
      "  timers:\n",
      "    learn_throughput: 260.56\n",
      "    learn_time_ms: 15351.536\n",
      "    load_throughput: 10547.286\n",
      "    load_time_ms: 379.244\n",
      "    sample_throughput: 8.23\n",
      "    sample_time_ms: 486000.871\n",
      "    update_time_ms: 3.718\n",
      "  timestamp: 1613901446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 556000\n",
      "  training_iteration: 139\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-05-47\n",
      "  done: false\n",
      "  episode_len_mean: 144.46\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 93.42574276068312\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4336\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5067443251609802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010971568524837494\n",
      "        model: {}\n",
      "        policy_loss: -0.06811364740133286\n",
      "        total_loss: 452.9324951171875\n",
      "        vf_explained_var: 0.6769991517066956\n",
      "        vf_loss: 452.988037109375\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46736694677871\n",
      "    ram_util_percent: 38.378151260504204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06812365814838989\n",
      "    mean_env_wait_ms: 119.50133882905752\n",
      "    mean_inference_ms: 1.720096938446058\n",
      "    mean_raw_obs_processing_ms: 9.390908318085735\n",
      "  time_since_restore: 75387.62991380692\n",
      "  time_this_iter_s: 500.54721117019653\n",
      "  time_total_s: 75387.62991380692\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.824\n",
      "    load_throughput: 10501.801\n",
      "    load_time_ms: 380.887\n",
      "    sample_throughput: 8.236\n",
      "    sample_time_ms: 485666.887\n",
      "    update_time_ms: 3.724\n",
      "  timestamp: 1613901947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 140\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 141.74\n",
      "  episode_reward_max: 118.38747272626844\n",
      "  episode_reward_mean: 89.11573236867281\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4362\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5270000100135803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013160942122340202\n",
      "        model: {}\n",
      "        policy_loss: -0.08172133564949036\n",
      "        total_loss: 480.5737609863281\n",
      "        vf_explained_var: 0.6476766467094421\n",
      "        vf_loss: 480.6405029296875\n",
      "    num_steps_sampled: 564000\n",
      "    num_steps_trained: 564000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.1931081081081\n",
      "    ram_util_percent: 38.35702702702703\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06814497785539061\n",
      "    mean_env_wait_ms: 119.45281915560403\n",
      "    mean_inference_ms: 1.720415928621482\n",
      "    mean_raw_obs_processing_ms: 9.384962652788973\n",
      "  time_since_restore: 75906.1450073719\n",
      "  time_this_iter_s: 518.5150935649872\n",
      "  time_total_s: 75906.1450073719\n",
      "  timers:\n",
      "    learn_throughput: 258.701\n",
      "    learn_time_ms: 15461.872\n",
      "    load_throughput: 10395.127\n",
      "    load_time_ms: 384.796\n",
      "    sample_throughput: 8.209\n",
      "    sample_time_ms: 487288.568\n",
      "    update_time_ms: 3.87\n",
      "  timestamp: 1613902466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 564000\n",
      "  training_iteration: 141\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 139.19\n",
      "  episode_reward_max: 118.37581776245045\n",
      "  episode_reward_mean: 85.05349157386325\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4393\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4903784990310669\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012807418592274189\n",
      "        model: {}\n",
      "        policy_loss: -0.08418212085962296\n",
      "        total_loss: 243.77842712402344\n",
      "        vf_explained_var: 0.827601969242096\n",
      "        vf_loss: 243.84803771972656\n",
      "    num_steps_sampled: 568000\n",
      "    num_steps_trained: 568000\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.514027777777784\n",
      "    ram_util_percent: 38.35930555555556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06816904112888227\n",
      "    mean_env_wait_ms: 119.39716645914392\n",
      "    mean_inference_ms: 1.7207919127298095\n",
      "    mean_raw_obs_processing_ms: 9.379445230691656\n",
      "  time_since_restore: 76410.0078485012\n",
      "  time_this_iter_s: 503.862841129303\n",
      "  time_total_s: 76410.0078485012\n",
      "  timers:\n",
      "    learn_throughput: 258.661\n",
      "    learn_time_ms: 15464.238\n",
      "    load_throughput: 10496.982\n",
      "    load_time_ms: 381.062\n",
      "    sample_throughput: 8.204\n",
      "    sample_time_ms: 487564.424\n",
      "    update_time_ms: 3.868\n",
      "  timestamp: 1613902970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 568000\n",
      "  training_iteration: 142\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 143.68\n",
      "  episode_reward_max: 118.37902254097419\n",
      "  episode_reward_mean: 91.58540820396809\n",
      "  episode_reward_min: -102.28401878985044\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4421\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5134223699569702\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010403241962194443\n",
      "        model: {}\n",
      "        policy_loss: -0.064632348716259\n",
      "        total_loss: 142.81903076171875\n",
      "        vf_explained_var: 0.8575036525726318\n",
      "        vf_loss: 142.87185668945312\n",
      "    num_steps_sampled: 572000\n",
      "    num_steps_trained: 572000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.490934449093444\n",
      "    ram_util_percent: 38.3768479776848\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0681908187331111\n",
      "    mean_env_wait_ms: 119.34707099125372\n",
      "    mean_inference_ms: 1.7211543747880358\n",
      "    mean_raw_obs_processing_ms: 9.373413416440878\n",
      "  time_since_restore: 76912.78030776978\n",
      "  time_this_iter_s: 502.77245926856995\n",
      "  time_total_s: 76912.78030776978\n",
      "  timers:\n",
      "    learn_throughput: 258.631\n",
      "    learn_time_ms: 15466.04\n",
      "    load_throughput: 10541.963\n",
      "    load_time_ms: 379.436\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487454.452\n",
      "    update_time_ms: 3.895\n",
      "  timestamp: 1613903473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 572000\n",
      "  training_iteration: 143\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 142.24\n",
      "  episode_reward_max: 118.37902254097419\n",
      "  episode_reward_mean: 89.35394718694442\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4448\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.530292809009552\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013976650312542915\n",
      "        model: {}\n",
      "        policy_loss: -0.0955086275935173\n",
      "        total_loss: 412.23358154296875\n",
      "        vf_explained_var: 0.7463707327842712\n",
      "        vf_loss: 412.3132019042969\n",
      "    num_steps_sampled: 576000\n",
      "    num_steps_trained: 576000\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51969273743018\n",
      "    ram_util_percent: 38.37164804469273\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06820948582796282\n",
      "    mean_env_wait_ms: 119.29646149770547\n",
      "    mean_inference_ms: 1.7214731315585197\n",
      "    mean_raw_obs_processing_ms: 9.367935867080444\n",
      "  time_since_restore: 77414.37563896179\n",
      "  time_this_iter_s: 501.5953311920166\n",
      "  time_total_s: 77414.37563896179\n",
      "  timers:\n",
      "    learn_throughput: 258.62\n",
      "    learn_time_ms: 15466.721\n",
      "    load_throughput: 10471.65\n",
      "    load_time_ms: 381.984\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487792.196\n",
      "    update_time_ms: 3.898\n",
      "  timestamp: 1613903974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 576000\n",
      "  training_iteration: 144\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 146.42\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 99.8468263089411\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4475\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.49783721566200256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011227715760469437\n",
      "        model: {}\n",
      "        policy_loss: -0.07338139414787292\n",
      "        total_loss: 137.79476928710938\n",
      "        vf_explained_var: 0.8573033213615417\n",
      "        vf_loss: 137.8553466796875\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.584129213483145\n",
      "    ram_util_percent: 38.39999999999999\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0682249442096093\n",
      "    mean_env_wait_ms: 119.24202864447405\n",
      "    mean_inference_ms: 1.72173241233231\n",
      "    mean_raw_obs_processing_ms: 9.36173211631575\n",
      "  time_since_restore: 77912.99190068245\n",
      "  time_this_iter_s: 498.61626172065735\n",
      "  time_total_s: 77912.99190068245\n",
      "  timers:\n",
      "    learn_throughput: 258.612\n",
      "    learn_time_ms: 15467.174\n",
      "    load_throughput: 10505.049\n",
      "    load_time_ms: 380.769\n",
      "    sample_throughput: 8.208\n",
      "    sample_time_ms: 487310.161\n",
      "    update_time_ms: 3.911\n",
      "  timestamp: 1613904473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 145\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-56-17\n",
      "  done: false\n",
      "  episode_len_mean: 144.87\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 93.49306636159764\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4504\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5081709027290344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01671558804810047\n",
      "        model: {}\n",
      "        policy_loss: -0.09919644147157669\n",
      "        total_loss: 722.3006591796875\n",
      "        vf_explained_var: 0.5905051827430725\n",
      "        vf_loss: 722.3807983398438\n",
      "    num_steps_sampled: 584000\n",
      "    num_steps_trained: 584000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49304589707928\n",
      "    ram_util_percent: 38.400973574408894\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0682419435160842\n",
      "    mean_env_wait_ms: 119.18308159400847\n",
      "    mean_inference_ms: 1.7220153899542447\n",
      "    mean_raw_obs_processing_ms: 9.354646149701574\n",
      "  time_since_restore: 78416.43280887604\n",
      "  time_this_iter_s: 503.44090819358826\n",
      "  time_total_s: 78416.43280887604\n",
      "  timers:\n",
      "    learn_throughput: 258.609\n",
      "    learn_time_ms: 15467.359\n",
      "    load_throughput: 10529.166\n",
      "    load_time_ms: 379.897\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487433.854\n",
      "    update_time_ms: 3.808\n",
      "  timestamp: 1613904977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 584000\n",
      "  training_iteration: 146\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-04-38\n",
      "  done: false\n",
      "  episode_len_mean: 145.58\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 95.37161295857453\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4529\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.498735249042511\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013529784977436066\n",
      "        model: {}\n",
      "        policy_loss: -0.07950646430253983\n",
      "        total_loss: 100.89649963378906\n",
      "        vf_explained_var: 0.9133281111717224\n",
      "        vf_loss: 100.9605941772461\n",
      "    num_steps_sampled: 588000\n",
      "    num_steps_trained: 588000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.422797202797206\n",
      "    ram_util_percent: 38.3627972027972\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06825711379685977\n",
      "    mean_env_wait_ms: 119.13289466671448\n",
      "    mean_inference_ms: 1.7222499108562166\n",
      "    mean_raw_obs_processing_ms: 9.347165462326934\n",
      "  time_since_restore: 78917.3786187172\n",
      "  time_this_iter_s: 500.945809841156\n",
      "  time_total_s: 78917.3786187172\n",
      "  timers:\n",
      "    learn_throughput: 258.629\n",
      "    learn_time_ms: 15466.156\n",
      "    load_throughput: 10468.486\n",
      "    load_time_ms: 382.099\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487475.379\n",
      "    update_time_ms: 3.788\n",
      "  timestamp: 1613905478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 588000\n",
      "  training_iteration: 147\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-13-00\n",
      "  done: false\n",
      "  episode_len_mean: 147.43\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 101.79849403752138\n",
      "  episode_reward_min: -105.13455363035769\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4556\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5137531757354736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009980542585253716\n",
      "        model: {}\n",
      "        policy_loss: -0.059497371315956116\n",
      "        total_loss: 96.02701568603516\n",
      "        vf_explained_var: 0.8777271509170532\n",
      "        vf_loss: 96.07512664794922\n",
      "    num_steps_sampled: 592000\n",
      "    num_steps_trained: 592000\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.493994413407826\n",
      "    ram_util_percent: 38.389525139664805\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06827321060552413\n",
      "    mean_env_wait_ms: 119.07944373877535\n",
      "    mean_inference_ms: 1.7224923543115978\n",
      "    mean_raw_obs_processing_ms: 9.339152265753075\n",
      "  time_since_restore: 79418.83561849594\n",
      "  time_this_iter_s: 501.45699977874756\n",
      "  time_total_s: 79418.83561849594\n",
      "  timers:\n",
      "    learn_throughput: 258.656\n",
      "    learn_time_ms: 15464.54\n",
      "    load_throughput: 10408.79\n",
      "    load_time_ms: 384.291\n",
      "    sample_throughput: 8.202\n",
      "    sample_time_ms: 487663.005\n",
      "    update_time_ms: 3.748\n",
      "  timestamp: 1613905980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 592000\n",
      "  training_iteration: 148\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 145.03\n",
      "  episode_reward_max: 118.39018873968277\n",
      "  episode_reward_mean: 95.70636682832276\n",
      "  episode_reward_min: -104.57549434804909\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4586\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4809300899505615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010893009603023529\n",
      "        model: {}\n",
      "        policy_loss: -0.0727214515209198\n",
      "        total_loss: 324.16070556640625\n",
      "        vf_explained_var: 0.7522114515304565\n",
      "        vf_loss: 324.2209777832031\n",
      "    num_steps_sampled: 596000\n",
      "    num_steps_trained: 596000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.886445366528356\n",
      "    ram_util_percent: 38.41355463347165\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06829118105209747\n",
      "    mean_env_wait_ms: 119.02403248065319\n",
      "    mean_inference_ms: 1.7227890537873793\n",
      "    mean_raw_obs_processing_ms: 9.331793122015482\n",
      "  time_since_restore: 79925.64782118797\n",
      "  time_this_iter_s: 506.81220269203186\n",
      "  time_total_s: 79925.64782118797\n",
      "  timers:\n",
      "    learn_throughput: 258.702\n",
      "    learn_time_ms: 15461.835\n",
      "    load_throughput: 10365.983\n",
      "    load_time_ms: 385.878\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487820.742\n",
      "    update_time_ms: 3.736\n",
      "  timestamp: 1613906487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 596000\n",
      "  training_iteration: 149\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 139.82\n",
      "  episode_reward_max: 118.38711441765899\n",
      "  episode_reward_mean: 93.5739814396936\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4616\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4924875795841217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013687827624380589\n",
      "        model: {}\n",
      "        policy_loss: -0.0899907648563385\n",
      "        total_loss: 656.1348266601562\n",
      "        vf_explained_var: 0.5884491801261902\n",
      "        vf_loss: 656.209228515625\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50681502086231\n",
      "    ram_util_percent: 38.403337969401946\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0683084623806782\n",
      "    mean_env_wait_ms: 118.96917013579419\n",
      "    mean_inference_ms: 1.7230674166506368\n",
      "    mean_raw_obs_processing_ms: 9.325989084085018\n",
      "  time_since_restore: 80429.35766005516\n",
      "  time_this_iter_s: 503.7098388671875\n",
      "  time_total_s: 80429.35766005516\n",
      "  timers:\n",
      "    learn_throughput: 258.785\n",
      "    learn_time_ms: 15456.868\n",
      "    load_throughput: 10437.554\n",
      "    load_time_ms: 383.232\n",
      "    sample_throughput: 8.194\n",
      "    sample_time_ms: 488145.28\n",
      "    update_time_ms: 3.731\n",
      "  timestamp: 1613906991\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 150\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 136.29\n",
      "  episode_reward_max: 118.38711441765899\n",
      "  episode_reward_mean: 89.21912044415974\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4644\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47926148772239685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010709519498050213\n",
      "        model: {}\n",
      "        policy_loss: -0.07456857711076736\n",
      "        total_loss: 257.04217529296875\n",
      "        vf_explained_var: 0.8113617897033691\n",
      "        vf_loss: 257.1045227050781\n",
      "    num_steps_sampled: 604000\n",
      "    num_steps_trained: 604000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72726008344924\n",
      "    ram_util_percent: 38.4279554937413\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06832272952601366\n",
      "    mean_env_wait_ms: 118.92079189347946\n",
      "    mean_inference_ms: 1.7233032813045441\n",
      "    mean_raw_obs_processing_ms: 9.322109060917926\n",
      "  time_since_restore: 80933.29212784767\n",
      "  time_this_iter_s: 503.934467792511\n",
      "  time_total_s: 80933.29212784767\n",
      "  timers:\n",
      "    learn_throughput: 260.669\n",
      "    learn_time_ms: 15345.127\n",
      "    load_throughput: 10533.839\n",
      "    load_time_ms: 379.729\n",
      "    sample_throughput: 8.217\n",
      "    sample_time_ms: 486801.282\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1613907495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 604000\n",
      "  training_iteration: 151\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-46-37\n",
      "  done: false\n",
      "  episode_len_mean: 137.96\n",
      "  episode_reward_max: 118.37702578963545\n",
      "  episode_reward_mean: 91.00470087653838\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4672\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.483931303024292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00852456409484148\n",
      "        model: {}\n",
      "        policy_loss: -0.05814878270030022\n",
      "        total_loss: 143.52391052246094\n",
      "        vf_explained_var: 0.851458728313446\n",
      "        vf_loss: 143.57232666015625\n",
      "    num_steps_sampled: 608000\n",
      "    num_steps_trained: 608000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.409052924791084\n",
      "    ram_util_percent: 38.43802228412256\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06833577200353232\n",
      "    mean_env_wait_ms: 118.87303903000677\n",
      "    mean_inference_ms: 1.7235220631363324\n",
      "    mean_raw_obs_processing_ms: 9.317992589804787\n",
      "  time_since_restore: 81435.83357095718\n",
      "  time_this_iter_s: 502.54144310951233\n",
      "  time_total_s: 81435.83357095718\n",
      "  timers:\n",
      "    learn_throughput: 260.723\n",
      "    learn_time_ms: 15341.943\n",
      "    load_throughput: 10450.76\n",
      "    load_time_ms: 382.747\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486669.763\n",
      "    update_time_ms: 3.57\n",
      "  timestamp: 1613907997\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 608000\n",
      "  training_iteration: 152\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 141.33\n",
      "  episode_reward_max: 118.35859723926629\n",
      "  episode_reward_mean: 91.164402135341\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4700\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45184624195098877\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007745564449578524\n",
      "        model: {}\n",
      "        policy_loss: -0.06402236968278885\n",
      "        total_loss: 214.5061492919922\n",
      "        vf_explained_var: 0.8167248964309692\n",
      "        vf_loss: 214.5613555908203\n",
      "    num_steps_sampled: 612000\n",
      "    num_steps_trained: 612000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.58587412587412\n",
      "    ram_util_percent: 38.42741258741258\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06834859427636221\n",
      "    mean_env_wait_ms: 118.82406410294276\n",
      "    mean_inference_ms: 1.7237331875441542\n",
      "    mean_raw_obs_processing_ms: 9.31296374518676\n",
      "  time_since_restore: 81937.16941165924\n",
      "  time_this_iter_s: 501.3358407020569\n",
      "  time_total_s: 81937.16941165924\n",
      "  timers:\n",
      "    learn_throughput: 260.717\n",
      "    learn_time_ms: 15342.318\n",
      "    load_throughput: 10364.624\n",
      "    load_time_ms: 385.928\n",
      "    sample_throughput: 8.222\n",
      "    sample_time_ms: 486521.161\n",
      "    update_time_ms: 3.544\n",
      "  timestamp: 1613908499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 612000\n",
      "  training_iteration: 153\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 138.78\n",
      "  episode_reward_max: 118.35859723926629\n",
      "  episode_reward_mean: 95.12206202352436\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4729\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4588473439216614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009239591658115387\n",
      "        model: {}\n",
      "        policy_loss: -0.06830652803182602\n",
      "        total_loss: 257.38818359375\n",
      "        vf_explained_var: 0.7817555069923401\n",
      "        vf_loss: 257.4459533691406\n",
      "    num_steps_sampled: 616000\n",
      "    num_steps_trained: 616000\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.95006802721089\n",
      "    ram_util_percent: 38.445306122448976\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06836559118749184\n",
      "    mean_env_wait_ms: 118.7779867877806\n",
      "    mean_inference_ms: 1.724009615335417\n",
      "    mean_raw_obs_processing_ms: 9.308062446937843\n",
      "  time_since_restore: 82451.84921574593\n",
      "  time_this_iter_s: 514.6798040866852\n",
      "  time_total_s: 82451.84921574593\n",
      "  timers:\n",
      "    learn_throughput: 260.67\n",
      "    learn_time_ms: 15345.067\n",
      "    load_throughput: 10505.511\n",
      "    load_time_ms: 380.753\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487836.555\n",
      "    update_time_ms: 3.516\n",
      "  timestamp: 1613909014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 616000\n",
      "  training_iteration: 154\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 142.57\n",
      "  episode_reward_max: 118.33498898653042\n",
      "  episode_reward_mean: 93.09943605118976\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4754\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48156386613845825\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008385772816836834\n",
      "        model: {}\n",
      "        policy_loss: -0.061471596360206604\n",
      "        total_loss: 148.40931701660156\n",
      "        vf_explained_var: 0.8710538744926453\n",
      "        vf_loss: 148.46124267578125\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47201125175808\n",
      "    ram_util_percent: 38.43445850914205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06838140315100122\n",
      "    mean_env_wait_ms: 118.73755850186022\n",
      "    mean_inference_ms: 1.7242594547379972\n",
      "    mean_raw_obs_processing_ms: 9.302440959107404\n",
      "  time_since_restore: 82950.16076350212\n",
      "  time_this_iter_s: 498.31154775619507\n",
      "  time_total_s: 82950.16076350212\n",
      "  timers:\n",
      "    learn_throughput: 260.64\n",
      "    learn_time_ms: 15346.855\n",
      "    load_throughput: 10452.15\n",
      "    load_time_ms: 382.696\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487801.336\n",
      "    update_time_ms: 3.506\n",
      "  timestamp: 1613909513\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 155\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-20-14\n",
      "  done: false\n",
      "  episode_len_mean: 144.83\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 97.17337704752077\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4783\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4631302058696747\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022198306396603584\n",
      "        model: {}\n",
      "        policy_loss: -0.1054145023226738\n",
      "        total_loss: 4.604348659515381\n",
      "        vf_explained_var: 0.9934733510017395\n",
      "        vf_loss: 4.684477806091309\n",
      "    num_steps_sampled: 624000\n",
      "    num_steps_trained: 624000\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.636033519553074\n",
      "    ram_util_percent: 38.420251396648034\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06840029110874933\n",
      "    mean_env_wait_ms: 118.69003585615252\n",
      "    mean_inference_ms: 1.7245456448276337\n",
      "    mean_raw_obs_processing_ms: 9.29664632881619\n",
      "  time_since_restore: 83451.58774232864\n",
      "  time_this_iter_s: 501.4269788265228\n",
      "  time_total_s: 83451.58774232864\n",
      "  timers:\n",
      "    learn_throughput: 260.667\n",
      "    learn_time_ms: 15345.235\n",
      "    load_throughput: 10398.272\n",
      "    load_time_ms: 384.679\n",
      "    sample_throughput: 8.203\n",
      "    sample_time_ms: 487600.048\n",
      "    update_time_ms: 3.536\n",
      "  timestamp: 1613910014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 624000\n",
      "  training_iteration: 156\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-28-46\n",
      "  done: false\n",
      "  episode_len_mean: 140.43\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 86.73863290371777\n",
      "  episode_reward_min: -106.73063507915431\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4814\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4861518442630768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014259721152484417\n",
      "        model: {}\n",
      "        policy_loss: -0.1085641160607338\n",
      "        total_loss: 890.0173950195312\n",
      "        vf_explained_var: 0.6484097242355347\n",
      "        vf_loss: 890.1015014648438\n",
      "    num_steps_sampled: 628000\n",
      "    num_steps_trained: 628000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.30109439124487\n",
      "    ram_util_percent: 38.44856361149111\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684201847453603\n",
      "    mean_env_wait_ms: 118.64182070849293\n",
      "    mean_inference_ms: 1.7248468653481246\n",
      "    mean_raw_obs_processing_ms: 9.292025198467657\n",
      "  time_since_restore: 83963.45505332947\n",
      "  time_this_iter_s: 511.867311000824\n",
      "  time_total_s: 83963.45505332947\n",
      "  timers:\n",
      "    learn_throughput: 260.609\n",
      "    learn_time_ms: 15348.685\n",
      "    load_throughput: 10471.676\n",
      "    load_time_ms: 381.983\n",
      "    sample_throughput: 8.185\n",
      "    sample_time_ms: 488687.637\n",
      "    update_time_ms: 3.527\n",
      "  timestamp: 1613910526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 628000\n",
      "  training_iteration: 157\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-37-12\n",
      "  done: false\n",
      "  episode_len_mean: 134.17\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 82.49990093625473\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 4846\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4706670641899109\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010649780742824078\n",
      "        model: {}\n",
      "        policy_loss: -0.09022080153226852\n",
      "        total_loss: 630.833251953125\n",
      "        vf_explained_var: 0.6915320158004761\n",
      "        vf_loss: 630.9052124023438\n",
      "    num_steps_sampled: 632000\n",
      "    num_steps_trained: 632000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.651523545706375\n",
      "    ram_util_percent: 38.46246537396121\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06843881547686444\n",
      "    mean_env_wait_ms: 118.59046576565484\n",
      "    mean_inference_ms: 1.7251222264353583\n",
      "    mean_raw_obs_processing_ms: 9.290385136188767\n",
      "  time_since_restore: 84469.41310858727\n",
      "  time_this_iter_s: 505.95805525779724\n",
      "  time_total_s: 84469.41310858727\n",
      "  timers:\n",
      "    learn_throughput: 260.553\n",
      "    learn_time_ms: 15351.982\n",
      "    load_throughput: 10518.798\n",
      "    load_time_ms: 380.272\n",
      "    sample_throughput: 8.178\n",
      "    sample_time_ms: 489137.309\n",
      "    update_time_ms: 3.528\n",
      "  timestamp: 1613911032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 632000\n",
      "  training_iteration: 158\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 132.61\n",
      "  episode_reward_max: 118.36625902754591\n",
      "  episode_reward_mean: 73.9377834859567\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4453345835208893\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008407643996179104\n",
      "        model: {}\n",
      "        policy_loss: -0.06736180186271667\n",
      "        total_loss: 399.472412109375\n",
      "        vf_explained_var: 0.7319225072860718\n",
      "        vf_loss: 399.5254211425781\n",
      "    num_steps_sampled: 636000\n",
      "    num_steps_trained: 636000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49818941504178\n",
      "    ram_util_percent: 38.534958217270194\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06845410040293094\n",
      "    mean_env_wait_ms: 118.54950370540271\n",
      "    mean_inference_ms: 1.7253463498119288\n",
      "    mean_raw_obs_processing_ms: 9.289647632741172\n",
      "  time_since_restore: 84972.18417716026\n",
      "  time_this_iter_s: 502.77106857299805\n",
      "  time_total_s: 84972.18417716026\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.834\n",
      "    load_throughput: 10563.555\n",
      "    load_time_ms: 378.66\n",
      "    sample_throughput: 8.184\n",
      "    sample_time_ms: 488735.908\n",
      "    update_time_ms: 3.542\n",
      "  timestamp: 1613911535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 636000\n",
      "  training_iteration: 159\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-53-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.36\n",
      "  episode_reward_max: 118.34410772090696\n",
      "  episode_reward_mean: 82.48837827915752\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4902\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48138877749443054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006494223140180111\n",
      "        model: {}\n",
      "        policy_loss: -0.05838268622756004\n",
      "        total_loss: 196.99696350097656\n",
      "        vf_explained_var: 0.8003584742546082\n",
      "        vf_loss: 197.0442352294922\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44755927475594\n",
      "    ram_util_percent: 38.53626220362622\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06846836310301345\n",
      "    mean_env_wait_ms: 118.5073979587736\n",
      "    mean_inference_ms: 1.725555821609911\n",
      "    mean_raw_obs_processing_ms: 9.287606818681013\n",
      "  time_since_restore: 85475.04824829102\n",
      "  time_this_iter_s: 502.86407113075256\n",
      "  time_total_s: 85475.04824829102\n",
      "  timers:\n",
      "    learn_throughput: 260.487\n",
      "    learn_time_ms: 15355.868\n",
      "    load_throughput: 10579.935\n",
      "    load_time_ms: 378.074\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488648.57\n",
      "    update_time_ms: 3.521\n",
      "  timestamp: 1613912038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 160\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-02-22\n",
      "  done: false\n",
      "  episode_len_mean: 138.9\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 82.44115056898363\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4931\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.482185035943985\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009056269191205502\n",
      "        model: {}\n",
      "        policy_loss: -0.0668887123465538\n",
      "        total_loss: 415.8406677246094\n",
      "        vf_explained_var: 0.6967179775238037\n",
      "        vf_loss: 415.8920593261719\n",
      "    num_steps_sampled: 644000\n",
      "    num_steps_trained: 644000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.52962447844229\n",
      "    ram_util_percent: 38.519888734353266\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684830063540474\n",
      "    mean_env_wait_ms: 118.46261854802353\n",
      "    mean_inference_ms: 1.7257911941250763\n",
      "    mean_raw_obs_processing_ms: 9.284068747045817\n",
      "  time_since_restore: 85978.68153715134\n",
      "  time_this_iter_s: 503.63328886032104\n",
      "  time_total_s: 85978.68153715134\n",
      "  timers:\n",
      "    learn_throughput: 260.529\n",
      "    learn_time_ms: 15353.371\n",
      "    load_throughput: 10575.344\n",
      "    load_time_ms: 378.238\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488620.749\n",
      "    update_time_ms: 3.547\n",
      "  timestamp: 1613912542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 644000\n",
      "  training_iteration: 161\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 147.27\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 93.17703128492795\n",
      "  episode_reward_min: -105.14930449860003\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4957\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5064404010772705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008462098427116871\n",
      "        model: {}\n",
      "        policy_loss: -0.07593437284231186\n",
      "        total_loss: 485.3306884765625\n",
      "        vf_explained_var: 0.6405306458473206\n",
      "        vf_loss: 485.3921203613281\n",
      "    num_steps_sampled: 648000\n",
      "    num_steps_trained: 648000\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34888268156424\n",
      "    ram_util_percent: 38.46480446927374\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684963894114604\n",
      "    mean_env_wait_ms: 118.42176954953226\n",
      "    mean_inference_ms: 1.7260068639032915\n",
      "    mean_raw_obs_processing_ms: 9.278926797780018\n",
      "  time_since_restore: 86480.10954904556\n",
      "  time_this_iter_s: 501.4280118942261\n",
      "  time_total_s: 86480.10954904556\n",
      "  timers:\n",
      "    learn_throughput: 260.49\n",
      "    learn_time_ms: 15355.671\n",
      "    load_throughput: 10668.732\n",
      "    load_time_ms: 374.927\n",
      "    sample_throughput: 8.188\n",
      "    sample_time_ms: 488510.573\n",
      "    update_time_ms: 3.567\n",
      "  timestamp: 1613913044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 648000\n",
      "  training_iteration: 162\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-19-07\n",
      "  done: false\n",
      "  episode_len_mean: 146.68\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 90.83358563840925\n",
      "  episode_reward_min: -106.96458987683931\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4984\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4691942632198334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007456604856997728\n",
      "        model: {}\n",
      "        policy_loss: -0.06715694814920425\n",
      "        total_loss: 167.9293975830078\n",
      "        vf_explained_var: 0.876112699508667\n",
      "        vf_loss: 167.9838409423828\n",
      "    num_steps_sampled: 652000\n",
      "    num_steps_trained: 652000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44568245125348\n",
      "    ram_util_percent: 38.464623955431755\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06851008589635542\n",
      "    mean_env_wait_ms: 118.37968971116618\n",
      "    mean_inference_ms: 1.7262374059642367\n",
      "    mean_raw_obs_processing_ms: 9.273064479720702\n",
      "  time_since_restore: 86982.80327177048\n",
      "  time_this_iter_s: 502.69372272491455\n",
      "  time_total_s: 86982.80327177048\n",
      "  timers:\n",
      "    learn_throughput: 260.482\n",
      "    learn_time_ms: 15356.137\n",
      "    load_throughput: 10752.641\n",
      "    load_time_ms: 372.002\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488648.189\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613913547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 652000\n",
      "  training_iteration: 163\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 145.8\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 92.87013160735619\n",
      "  episode_reward_min: -106.96458987683931\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5012\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4480264186859131\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006355721037834883\n",
      "        model: {}\n",
      "        policy_loss: -0.05137742683291435\n",
      "        total_loss: 176.2694549560547\n",
      "        vf_explained_var: 0.8188726305961609\n",
      "        vf_loss: 176.30995178222656\n",
      "    num_steps_sampled: 656000\n",
      "    num_steps_trained: 656000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.84214186369958\n",
      "    ram_util_percent: 38.53407510431154\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06852427330376414\n",
      "    mean_env_wait_ms: 118.3369487778647\n",
      "    mean_inference_ms: 1.7264821033324285\n",
      "    mean_raw_obs_processing_ms: 9.266807857567928\n",
      "  time_since_restore: 87486.67959189415\n",
      "  time_this_iter_s: 503.8763201236725\n",
      "  time_total_s: 87486.67959189415\n",
      "  timers:\n",
      "    learn_throughput: 260.502\n",
      "    learn_time_ms: 15354.973\n",
      "    load_throughput: 10772.593\n",
      "    load_time_ms: 371.313\n",
      "    sample_throughput: 8.204\n",
      "    sample_time_ms: 487568.193\n",
      "    update_time_ms: 3.575\n",
      "  timestamp: 1613914051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 656000\n",
      "  training_iteration: 164\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 145.21\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 92.70610928211364\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5040\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46228596568107605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006902496796101332\n",
      "        model: {}\n",
      "        policy_loss: -0.059275072067976\n",
      "        total_loss: 207.67410278320312\n",
      "        vf_explained_var: 0.8182961940765381\n",
      "        vf_loss: 207.72158813476562\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.528351955307265\n",
      "    ram_util_percent: 38.51368715083799\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06853728558560826\n",
      "    mean_env_wait_ms: 118.29366629630957\n",
      "    mean_inference_ms: 1.7266945183978606\n",
      "    mean_raw_obs_processing_ms: 9.260610431761378\n",
      "  time_since_restore: 87988.05377340317\n",
      "  time_this_iter_s: 501.37418150901794\n",
      "  time_total_s: 87988.05377340317\n",
      "  timers:\n",
      "    learn_throughput: 260.559\n",
      "    learn_time_ms: 15351.598\n",
      "    load_throughput: 10820.894\n",
      "    load_time_ms: 369.655\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487880.544\n",
      "    update_time_ms: 3.574\n",
      "  timestamp: 1613914553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 165\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-44-14\n",
      "  done: false\n",
      "  episode_len_mean: 146.88\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 94.76799787769761\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5067\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4856013059616089\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00634542154148221\n",
      "        model: {}\n",
      "        policy_loss: -0.0633016899228096\n",
      "        total_loss: 289.1907653808594\n",
      "        vf_explained_var: 0.7325077652931213\n",
      "        vf_loss: 289.24322509765625\n",
      "    num_steps_sampled: 664000\n",
      "    num_steps_trained: 664000\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.39762237762238\n",
      "    ram_util_percent: 38.476083916083915\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06854874999601568\n",
      "    mean_env_wait_ms: 118.25243670852525\n",
      "    mean_inference_ms: 1.7268768816733582\n",
      "    mean_raw_obs_processing_ms: 9.255162367471213\n",
      "  time_since_restore: 88489.42773461342\n",
      "  time_this_iter_s: 501.37396121025085\n",
      "  time_total_s: 88489.42773461342\n",
      "  timers:\n",
      "    learn_throughput: 260.505\n",
      "    learn_time_ms: 15354.819\n",
      "    load_throughput: 10840.526\n",
      "    load_time_ms: 368.986\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487869.291\n",
      "    update_time_ms: 3.56\n",
      "  timestamp: 1613915054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 664000\n",
      "  training_iteration: 166\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-52-34\n",
      "  done: false\n",
      "  episode_len_mean: 147.78\n",
      "  episode_reward_max: 118.37371998946179\n",
      "  episode_reward_mean: 101.20822458460525\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5094\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4862886667251587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010524340905249119\n",
      "        model: {}\n",
      "        policy_loss: -0.07467919588088989\n",
      "        total_loss: 25.640653610229492\n",
      "        vf_explained_var: 0.9721167683601379\n",
      "        vf_loss: 25.697351455688477\n",
      "    num_steps_sampled: 668000\n",
      "    num_steps_trained: 668000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50560224089636\n",
      "    ram_util_percent: 38.51330532212885\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06855955403778359\n",
      "    mean_env_wait_ms: 118.21057267026022\n",
      "    mean_inference_ms: 1.7270392530979362\n",
      "    mean_raw_obs_processing_ms: 9.249604904265391\n",
      "  time_since_restore: 88989.29530453682\n",
      "  time_this_iter_s: 499.8675699234009\n",
      "  time_total_s: 88989.29530453682\n",
      "  timers:\n",
      "    learn_throughput: 260.548\n",
      "    learn_time_ms: 15352.241\n",
      "    load_throughput: 10808.73\n",
      "    load_time_ms: 370.071\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486675.69\n",
      "    update_time_ms: 3.592\n",
      "  timestamp: 1613915554\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 668000\n",
      "  training_iteration: 167\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-01-01\n",
      "  done: false\n",
      "  episode_len_mean: 141.56\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 90.63242252174445\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5125\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47574055194854736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008839340880513191\n",
      "        model: {}\n",
      "        policy_loss: -0.07316874712705612\n",
      "        total_loss: 419.13763427734375\n",
      "        vf_explained_var: 0.7200050950050354\n",
      "        vf_loss: 419.1956481933594\n",
      "    num_steps_sampled: 672000\n",
      "    num_steps_trained: 672000\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53033240997229\n",
      "    ram_util_percent: 38.537257617728535\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06857235438949527\n",
      "    mean_env_wait_ms: 118.1635145875799\n",
      "    mean_inference_ms: 1.7272286108516621\n",
      "    mean_raw_obs_processing_ms: 9.245073630018629\n",
      "  time_since_restore: 89495.47280859947\n",
      "  time_this_iter_s: 506.1775040626526\n",
      "  time_total_s: 89495.47280859947\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.74\n",
      "    load_throughput: 10819.157\n",
      "    load_time_ms: 369.715\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486700.839\n",
      "    update_time_ms: 3.745\n",
      "  timestamp: 1613916061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 672000\n",
      "  training_iteration: 168\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-09-23\n",
      "  done: false\n",
      "  episode_len_mean: 140.49\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 94.99584880547278\n",
      "  episode_reward_min: -106.97773984480573\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5154\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45154133439064026\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006227417383342981\n",
      "        model: {}\n",
      "        policy_loss: -0.05392485484480858\n",
      "        total_loss: 98.27760314941406\n",
      "        vf_explained_var: 0.9074139595031738\n",
      "        vf_loss: 98.32087707519531\n",
      "    num_steps_sampled: 676000\n",
      "    num_steps_trained: 676000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.48326359832636\n",
      "    ram_util_percent: 38.480334728033476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06858522124725461\n",
      "    mean_env_wait_ms: 118.1203477170672\n",
      "    mean_inference_ms: 1.7274251660541209\n",
      "    mean_raw_obs_processing_ms: 9.241736193590187\n",
      "  time_since_restore: 89997.56052470207\n",
      "  time_this_iter_s: 502.0877161026001\n",
      "  time_total_s: 89997.56052470207\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.742\n",
      "    load_throughput: 10824.405\n",
      "    load_time_ms: 369.535\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486632.964\n",
      "    update_time_ms: 3.733\n",
      "  timestamp: 1613916563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 676000\n",
      "  training_iteration: 169\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-17-45\n",
      "  done: false\n",
      "  episode_len_mean: 141.28\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 95.40361710728526\n",
      "  episode_reward_min: -106.97773984480573\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5181\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.456531286239624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00835502427071333\n",
      "        model: {}\n",
      "        policy_loss: -0.07291597872972488\n",
      "        total_loss: 438.1560363769531\n",
      "        vf_explained_var: 0.6468444466590881\n",
      "        vf_loss: 438.214599609375\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.589385474860336\n",
      "    ram_util_percent: 38.45991620111731\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06859723994206116\n",
      "    mean_env_wait_ms: 118.08135252751872\n",
      "    mean_inference_ms: 1.72762725266968\n",
      "    mean_raw_obs_processing_ms: 9.238742112961548\n",
      "  time_since_restore: 90498.98913621902\n",
      "  time_this_iter_s: 501.4286115169525\n",
      "  time_total_s: 90498.98913621902\n",
      "  timers:\n",
      "    learn_throughput: 260.605\n",
      "    learn_time_ms: 15348.918\n",
      "    load_throughput: 10734.402\n",
      "    load_time_ms: 372.634\n",
      "    sample_throughput: 8.222\n",
      "    sample_time_ms: 486485.14\n",
      "    update_time_ms: 3.781\n",
      "  timestamp: 1613917065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 170\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 141.21\n",
      "  episode_reward_max: 118.38904413532654\n",
      "  episode_reward_mean: 99.79128053003798\n",
      "  episode_reward_min: -106.6297525379055\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5207\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4708069860935211\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0068193464539945126\n",
      "        model: {}\n",
      "        policy_loss: -0.0499524287879467\n",
      "        total_loss: 160.94512939453125\n",
      "        vf_explained_var: 0.8235843777656555\n",
      "        vf_loss: 160.98341369628906\n",
      "    num_steps_sampled: 684000\n",
      "    num_steps_trained: 684000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.758750000000006\n",
      "    ram_util_percent: 38.46527777777777\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06860977762982276\n",
      "    mean_env_wait_ms: 118.04583679578282\n",
      "    mean_inference_ms: 1.7278293561979303\n",
      "    mean_raw_obs_processing_ms: 9.234586594223986\n",
      "  time_since_restore: 91003.42678427696\n",
      "  time_this_iter_s: 504.4376480579376\n",
      "  time_total_s: 91003.42678427696\n",
      "  timers:\n",
      "    learn_throughput: 260.542\n",
      "    learn_time_ms: 15352.597\n",
      "    load_throughput: 10778.832\n",
      "    load_time_ms: 371.098\n",
      "    sample_throughput: 8.221\n",
      "    sample_time_ms: 486564.373\n",
      "    update_time_ms: 3.729\n",
      "  timestamp: 1613917569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 684000\n",
      "  training_iteration: 171\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-34-33\n",
      "  done: false\n",
      "  episode_len_mean: 142.26\n",
      "  episode_reward_max: 118.38904413532654\n",
      "  episode_reward_mean: 95.59367805044093\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5236\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46796685457229614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008288552053272724\n",
      "        model: {}\n",
      "        policy_loss: -0.0786781832575798\n",
      "        total_loss: 511.0342102050781\n",
      "        vf_explained_var: 0.6987603306770325\n",
      "        vf_loss: 511.0987548828125\n",
      "    num_steps_sampled: 688000\n",
      "    num_steps_trained: 688000\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47246175243393\n",
      "    ram_util_percent: 38.506815020862305\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06862297427505894\n",
      "    mean_env_wait_ms: 118.0054659057309\n",
      "    mean_inference_ms: 1.728048772605677\n",
      "    mean_raw_obs_processing_ms: 9.229344434382437\n",
      "  time_since_restore: 91506.885689497\n",
      "  time_this_iter_s: 503.45890522003174\n",
      "  time_total_s: 91506.885689497\n",
      "  timers:\n",
      "    learn_throughput: 260.577\n",
      "    learn_time_ms: 15350.576\n",
      "    load_throughput: 10748.637\n",
      "    load_time_ms: 372.14\n",
      "    sample_throughput: 8.217\n",
      "    sample_time_ms: 486768.692\n",
      "    update_time_ms: 3.758\n",
      "  timestamp: 1613918073\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 688000\n",
      "  training_iteration: 172\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-42-55\n",
      "  done: false\n",
      "  episode_len_mean: 140.42\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 91.38592287765752\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5266\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5288376808166504\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008779721334576607\n",
      "        model: {}\n",
      "        policy_loss: -0.08225809037685394\n",
      "        total_loss: 244.55787658691406\n",
      "        vf_explained_var: 0.8416314125061035\n",
      "        vf_loss: 244.62509155273438\n",
      "    num_steps_sampled: 692000\n",
      "    num_steps_trained: 692000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71019553072626\n",
      "    ram_util_percent: 38.4645251396648\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0686358215296877\n",
      "    mean_env_wait_ms: 117.96378499799098\n",
      "    mean_inference_ms: 1.7282694910678185\n",
      "    mean_raw_obs_processing_ms: 9.224758524784436\n",
      "  time_since_restore: 92008.88655018806\n",
      "  time_this_iter_s: 502.00086069107056\n",
      "  time_total_s: 92008.88655018806\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.737\n",
      "    load_throughput: 10771.157\n",
      "    load_time_ms: 371.362\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486701.016\n",
      "    update_time_ms: 3.817\n",
      "  timestamp: 1613918575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 692000\n",
      "  training_iteration: 173\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-51-14\n",
      "  done: false\n",
      "  episode_len_mean: 146.02\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 95.39460807275515\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 5290\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5048798322677612\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015141325071454048\n",
      "        model: {}\n",
      "        policy_loss: -0.10032626986503601\n",
      "        total_loss: 8.430785179138184\n",
      "        vf_explained_var: 0.9881623387336731\n",
      "        vf_loss: 8.505240440368652\n",
      "    num_steps_sampled: 696000\n",
      "    num_steps_trained: 696000\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.36910112359551\n",
      "    ram_util_percent: 38.47724719101123\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06864618998927181\n",
      "    mean_env_wait_ms: 117.93039021822675\n",
      "    mean_inference_ms: 1.7284269435281094\n",
      "    mean_raw_obs_processing_ms: 9.220015783477972\n",
      "  time_since_restore: 92507.67228889465\n",
      "  time_this_iter_s: 498.78573870658875\n",
      "  time_total_s: 92507.67228889465\n",
      "  timers:\n",
      "    learn_throughput: 260.593\n",
      "    learn_time_ms: 15349.588\n",
      "    load_throughput: 10737.497\n",
      "    load_time_ms: 372.526\n",
      "    sample_throughput: 8.227\n",
      "    sample_time_ms: 486190.666\n",
      "    update_time_ms: 3.821\n",
      "  timestamp: 1613919074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 696000\n",
      "  training_iteration: 174\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.08\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 88.93002689290537\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5320\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48957180976867676\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016036346554756165\n",
      "        model: {}\n",
      "        policy_loss: -0.12040140479803085\n",
      "        total_loss: 1086.5328369140625\n",
      "        vf_explained_var: 0.608025074005127\n",
      "        vf_loss: 1086.625732421875\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46898470097357\n",
      "    ram_util_percent: 38.46773296244784\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06865828042400379\n",
      "    mean_env_wait_ms: 117.88816196702668\n",
      "    mean_inference_ms: 1.7286137726635369\n",
      "    mean_raw_obs_processing_ms: 9.215541094601642\n",
      "  time_since_restore: 93011.05297780037\n",
      "  time_this_iter_s: 503.38068890571594\n",
      "  time_total_s: 93011.05297780037\n",
      "  timers:\n",
      "    learn_throughput: 260.568\n",
      "    learn_time_ms: 15351.097\n",
      "    load_throughput: 10591.534\n",
      "    load_time_ms: 377.66\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486385.767\n",
      "    update_time_ms: 3.848\n",
      "  timestamp: 1613919578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 175\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 140.05\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 80.64052161749079\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5351\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4718606770038605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012582182884216309\n",
      "        model: {}\n",
      "        policy_loss: -0.09653011709451675\n",
      "        total_loss: 940.9229736328125\n",
      "        vf_explained_var: 0.5720846652984619\n",
      "        vf_loss: 940.9979248046875\n",
      "    num_steps_sampled: 704000\n",
      "    num_steps_trained: 704000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.56440443213297\n",
      "    ram_util_percent: 38.44349030470914\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06867086727106841\n",
      "    mean_env_wait_ms: 117.8463413084463\n",
      "    mean_inference_ms: 1.7288022408307484\n",
      "    mean_raw_obs_processing_ms: 9.211785975004664\n",
      "  time_since_restore: 93517.2189218998\n",
      "  time_this_iter_s: 506.16594409942627\n",
      "  time_total_s: 93517.2189218998\n",
      "  timers:\n",
      "    learn_throughput: 260.59\n",
      "    learn_time_ms: 15349.806\n",
      "    load_throughput: 10517.681\n",
      "    load_time_ms: 380.312\n",
      "    sample_throughput: 8.216\n",
      "    sample_time_ms: 486867.298\n",
      "    update_time_ms: 3.833\n",
      "  timestamp: 1613920084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 704000\n",
      "  training_iteration: 176\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-16-22\n",
      "  done: false\n",
      "  episode_len_mean: 141.13\n",
      "  episode_reward_max: 118.37493702248727\n",
      "  episode_reward_mean: 78.35876333657444\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 5376\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5256088376045227\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009462368674576283\n",
      "        model: {}\n",
      "        policy_loss: -0.08388345688581467\n",
      "        total_loss: 501.4094543457031\n",
      "        vf_explained_var: 0.6416015625\n",
      "        vf_loss: 501.4771423339844\n",
      "    num_steps_sampled: 708000\n",
      "    num_steps_trained: 708000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46357243319268\n",
      "    ram_util_percent: 38.43769338959212\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06868162348637416\n",
      "    mean_env_wait_ms: 117.8122085555477\n",
      "    mean_inference_ms: 1.7289530889830635\n",
      "    mean_raw_obs_processing_ms: 9.207677252935971\n",
      "  time_since_restore: 94015.06229805946\n",
      "  time_this_iter_s: 497.84337615966797\n",
      "  time_total_s: 94015.06229805946\n",
      "  timers:\n",
      "    learn_throughput: 260.6\n",
      "    learn_time_ms: 15349.207\n",
      "    load_throughput: 10478.372\n",
      "    load_time_ms: 381.739\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486663.405\n",
      "    update_time_ms: 3.768\n",
      "  timestamp: 1613920582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 708000\n",
      "  training_iteration: 177\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 145.63\n",
      "  episode_reward_max: 118.34340858200574\n",
      "  episode_reward_mean: 84.71461875629933\n",
      "  episode_reward_min: -104.54988999513048\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5402\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46560001373291016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006648436654359102\n",
      "        model: {}\n",
      "        policy_loss: -0.05807759240269661\n",
      "        total_loss: 155.2732696533203\n",
      "        vf_explained_var: 0.8444494009017944\n",
      "        vf_loss: 155.31997680664062\n",
      "    num_steps_sampled: 712000\n",
      "    num_steps_trained: 712000\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47549019607843\n",
      "    ram_util_percent: 38.48473389355742\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0686922814540443\n",
      "    mean_env_wait_ms: 117.77762267661575\n",
      "    mean_inference_ms: 1.7291099226470275\n",
      "    mean_raw_obs_processing_ms: 9.203317976424357\n",
      "  time_since_restore: 94514.89193749428\n",
      "  time_this_iter_s: 499.82963943481445\n",
      "  time_total_s: 94514.89193749428\n",
      "  timers:\n",
      "    learn_throughput: 260.619\n",
      "    learn_time_ms: 15348.096\n",
      "    load_throughput: 10483.485\n",
      "    load_time_ms: 381.553\n",
      "    sample_throughput: 8.23\n",
      "    sample_time_ms: 486028.273\n",
      "    update_time_ms: 3.601\n",
      "  timestamp: 1613921082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 712000\n",
      "  training_iteration: 178\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-33-03\n",
      "  done: false\n",
      "  episode_len_mean: 151.13\n",
      "  episode_reward_max: 118.31820820477397\n",
      "  episode_reward_mean: 93.03315928379716\n",
      "  episode_reward_min: -104.54988999513048\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 5427\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46588629484176636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007632530760020018\n",
      "        model: {}\n",
      "        policy_loss: -0.0638757273554802\n",
      "        total_loss: 280.8990173339844\n",
      "        vf_explained_var: 0.7463623881340027\n",
      "        vf_loss: 280.9498596191406\n",
      "    num_steps_sampled: 716000\n",
      "    num_steps_trained: 716000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.431232492997204\n",
      "    ram_util_percent: 38.42633053221288\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06870344171985562\n",
      "    mean_env_wait_ms: 117.74376743178331\n",
      "    mean_inference_ms: 1.7292855942561431\n",
      "    mean_raw_obs_processing_ms: 9.196971543897542\n",
      "  time_since_restore: 95015.25298166275\n",
      "  time_this_iter_s: 500.3610441684723\n",
      "  time_total_s: 95015.25298166275\n",
      "  timers:\n",
      "    learn_throughput: 260.664\n",
      "    learn_time_ms: 15345.419\n",
      "    load_throughput: 10469.57\n",
      "    load_time_ms: 382.06\n",
      "    sample_throughput: 8.233\n",
      "    sample_time_ms: 485855.474\n",
      "    update_time_ms: 3.592\n",
      "  timestamp: 1613921583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 716000\n",
      "  training_iteration: 179\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 154.2\n",
      "  episode_reward_max: 118.35405133032623\n",
      "  episode_reward_mean: 99.2754836086572\n",
      "  episode_reward_min: -99.1245036832122\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5454\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4846733510494232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006623440887778997\n",
      "        model: {}\n",
      "        policy_loss: -0.04771051183342934\n",
      "        total_loss: 155.57626342773438\n",
      "        vf_explained_var: 0.8229196071624756\n",
      "        vf_loss: 155.61268615722656\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.516363636363636\n",
      "    ram_util_percent: 38.38503496503496\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06871626289123954\n",
      "    mean_env_wait_ms: 117.70570302148782\n",
      "    mean_inference_ms: 1.7294751196604383\n",
      "    mean_raw_obs_processing_ms: 9.188781422176838\n",
      "  time_since_restore: 95516.08112931252\n",
      "  time_this_iter_s: 500.828147649765\n",
      "  time_total_s: 95516.08112931252\n",
      "  timers:\n",
      "    learn_throughput: 260.668\n",
      "    learn_time_ms: 15345.21\n",
      "    load_throughput: 10494.161\n",
      "    load_time_ms: 381.164\n",
      "    sample_throughput: 8.234\n",
      "    sample_time_ms: 485792.654\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613922084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 180\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 144.44\n",
      "  episode_reward_max: 118.39349617717478\n",
      "  episode_reward_mean: 86.86996045042459\n",
      "  episode_reward_min: -100.51393821107163\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5486\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4662671387195587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012708527036011219\n",
      "        model: {}\n",
      "        policy_loss: -0.09593574702739716\n",
      "        total_loss: 837.884033203125\n",
      "        vf_explained_var: 0.6079728007316589\n",
      "        vf_loss: 837.958251953125\n",
      "    num_steps_sampled: 724000\n",
      "    num_steps_trained: 724000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55773480662984\n",
      "    ram_util_percent: 38.398618784530385\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06872973339804499\n",
      "    mean_env_wait_ms: 117.66380970529775\n",
      "    mean_inference_ms: 1.7296831400305888\n",
      "    mean_raw_obs_processing_ms: 9.18345595904487\n",
      "  time_since_restore: 96023.5130982399\n",
      "  time_this_iter_s: 507.4319689273834\n",
      "  time_total_s: 96023.5130982399\n",
      "  timers:\n",
      "    learn_throughput: 260.725\n",
      "    learn_time_ms: 15341.832\n",
      "    load_throughput: 10326.081\n",
      "    load_time_ms: 387.369\n",
      "    sample_throughput: 8.229\n",
      "    sample_time_ms: 486088.784\n",
      "    update_time_ms: 3.581\n",
      "  timestamp: 1613922592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 724000\n",
      "  training_iteration: 181\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39349617717478\n",
      "  episode_reward_mean: 89.1879758260181\n",
      "  episode_reward_min: -100.51393821107163\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5515\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4440160095691681\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007366834674030542\n",
      "        model: {}\n",
      "        policy_loss: -0.052306752651929855\n",
      "        total_loss: 269.7047424316406\n",
      "        vf_explained_var: 0.7046312689781189\n",
      "        vf_loss: 269.7444152832031\n",
      "    num_steps_sampled: 728000\n",
      "    num_steps_trained: 728000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.6071129707113\n",
      "    ram_util_percent: 38.43179916317991\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06874115014425634\n",
      "    mean_env_wait_ms: 117.62692021537387\n",
      "    mean_inference_ms: 1.7298548942518515\n",
      "    mean_raw_obs_processing_ms: 9.18065413546429\n",
      "  time_since_restore: 96525.79550862312\n",
      "  time_this_iter_s: 502.2824103832245\n",
      "  time_total_s: 96525.79550862312\n",
      "  timers:\n",
      "    learn_throughput: 260.748\n",
      "    learn_time_ms: 15340.502\n",
      "    load_throughput: 10314.417\n",
      "    load_time_ms: 387.807\n",
      "    sample_throughput: 8.231\n",
      "    sample_time_ms: 485970.923\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613923094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 728000\n",
      "  training_iteration: 182\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-06-36\n",
      "  done: false\n",
      "  episode_len_mean: 137.64\n",
      "  episode_reward_max: 118.39542405339023\n",
      "  episode_reward_mean: 93.34721071568654\n",
      "  episode_reward_min: -105.70203195137316\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5543\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4430549442768097\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011044507846236229\n",
      "        model: {}\n",
      "        policy_loss: -0.07171367853879929\n",
      "        total_loss: 26.278682708740234\n",
      "        vf_explained_var: 0.9783812165260315\n",
      "        vf_loss: 26.331523895263672\n",
      "    num_steps_sampled: 732000\n",
      "    num_steps_trained: 732000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46541143654114\n",
      "    ram_util_percent: 38.35523012552301\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06875123018139143\n",
      "    mean_env_wait_ms: 117.59248582940604\n",
      "    mean_inference_ms: 1.7299942823507348\n",
      "    mean_raw_obs_processing_ms: 9.179147292354722\n",
      "  time_since_restore: 97027.63077235222\n",
      "  time_this_iter_s: 501.83526372909546\n",
      "  time_total_s: 97027.63077235222\n",
      "  timers:\n",
      "    learn_throughput: 260.734\n",
      "    learn_time_ms: 15341.324\n",
      "    load_throughput: 10289.052\n",
      "    load_time_ms: 388.763\n",
      "    sample_throughput: 8.231\n",
      "    sample_time_ms: 485951.319\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613923596\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 732000\n",
      "  training_iteration: 183\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 133.16\n",
      "  episode_reward_max: 118.39542405339023\n",
      "  episode_reward_mean: 89.21097575811257\n",
      "  episode_reward_min: -107.31346635462283\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5575\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47607260942459106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011482289992272854\n",
      "        model: {}\n",
      "        policy_loss: -0.09403268992900848\n",
      "        total_loss: 685.237060546875\n",
      "        vf_explained_var: 0.6918187737464905\n",
      "        vf_loss: 685.3115844726562\n",
      "    num_steps_sampled: 736000\n",
      "    num_steps_trained: 736000\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.605394190871365\n",
      "    ram_util_percent: 38.36528354080221\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06876275525910218\n",
      "    mean_env_wait_ms: 117.55433045998768\n",
      "    mean_inference_ms: 1.7301557845493607\n",
      "    mean_raw_obs_processing_ms: 9.178508671720747\n",
      "  time_since_restore: 97534.4449365139\n",
      "  time_this_iter_s: 506.81416416168213\n",
      "  time_total_s: 97534.4449365139\n",
      "  timers:\n",
      "    learn_throughput: 260.735\n",
      "    learn_time_ms: 15341.27\n",
      "    load_throughput: 10320.858\n",
      "    load_time_ms: 387.565\n",
      "    sample_throughput: 8.218\n",
      "    sample_time_ms: 486753.428\n",
      "    update_time_ms: 3.514\n",
      "  timestamp: 1613924103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 736000\n",
      "  training_iteration: 184\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 137.71\n",
      "  episode_reward_max: 118.39576053671243\n",
      "  episode_reward_mean: 97.43855135668205\n",
      "  episode_reward_min: -107.31346635462283\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5602\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44221940636634827\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007441571447998285\n",
      "        model: {}\n",
      "        policy_loss: -0.06500907987356186\n",
      "        total_loss: 71.3495864868164\n",
      "        vf_explained_var: 0.920139729976654\n",
      "        vf_loss: 71.40189361572266\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.482960893854745\n",
      "    ram_util_percent: 38.3731843575419\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06877308927909531\n",
      "    mean_env_wait_ms: 117.52232623149295\n",
      "    mean_inference_ms: 1.730301866684336\n",
      "    mean_raw_obs_processing_ms: 9.176635585619612\n",
      "  time_since_restore: 98036.24931836128\n",
      "  time_this_iter_s: 501.8043818473816\n",
      "  time_total_s: 98036.24931836128\n",
      "  timers:\n",
      "    learn_throughput: 260.707\n",
      "    learn_time_ms: 15342.9\n",
      "    load_throughput: 10445.603\n",
      "    load_time_ms: 382.936\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486595.992\n",
      "    update_time_ms: 3.48\n",
      "  timestamp: 1613924605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 185\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-31-48\n",
      "  done: false\n",
      "  episode_len_mean: 135.42\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 86.6814424293701\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5631\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4541889429092407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010883782058954239\n",
      "        model: {}\n",
      "        policy_loss: -0.08654586225748062\n",
      "        total_loss: 782.625244140625\n",
      "        vf_explained_var: 0.5522391200065613\n",
      "        vf_loss: 782.6931762695312\n",
      "    num_steps_sampled: 744000\n",
      "    num_steps_trained: 744000\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.54303621169915\n",
      "    ram_util_percent: 38.38969359331476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06878404687145184\n",
      "    mean_env_wait_ms: 117.48776817358333\n",
      "    mean_inference_ms: 1.7304641341571485\n",
      "    mean_raw_obs_processing_ms: 9.17493478224007\n",
      "  time_since_restore: 98538.78360366821\n",
      "  time_this_iter_s: 502.53428530693054\n",
      "  time_total_s: 98538.78360366821\n",
      "  timers:\n",
      "    learn_throughput: 260.682\n",
      "    learn_time_ms: 15344.358\n",
      "    load_throughput: 10556.637\n",
      "    load_time_ms: 378.909\n",
      "    sample_throughput: 8.227\n",
      "    sample_time_ms: 486232.038\n",
      "    update_time_ms: 3.471\n",
      "  timestamp: 1613925108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 744000\n",
      "  training_iteration: 186\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-40-10\n",
      "  done: false\n",
      "  episode_len_mean: 142.42\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 95.31215734591702\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5657\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.457278311252594\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0064457799308001995\n",
      "        model: {}\n",
      "        policy_loss: -0.06314153224229813\n",
      "        total_loss: 129.87037658691406\n",
      "        vf_explained_var: 0.8559269309043884\n",
      "        vf_loss: 129.92247009277344\n",
      "    num_steps_sampled: 748000\n",
      "    num_steps_trained: 748000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47458100558659\n",
      "    ram_util_percent: 38.437569832402225\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06879358209132469\n",
      "    mean_env_wait_ms: 117.45771841085211\n",
      "    mean_inference_ms: 1.7306100761494239\n",
      "    mean_raw_obs_processing_ms: 9.171618487810383\n",
      "  time_since_restore: 99040.21338009834\n",
      "  time_this_iter_s: 501.42977643013\n",
      "  time_total_s: 99040.21338009834\n",
      "  timers:\n",
      "    learn_throughput: 260.653\n",
      "    learn_time_ms: 15346.056\n",
      "    load_throughput: 10625.552\n",
      "    load_time_ms: 376.451\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486590.007\n",
      "    update_time_ms: 3.512\n",
      "  timestamp: 1613925610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 748000\n",
      "  training_iteration: 187\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-48-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.52\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 91.08862888743343\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5687\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44903984665870667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008460896089673042\n",
      "        model: {}\n",
      "        policy_loss: -0.07948212325572968\n",
      "        total_loss: 316.0011291503906\n",
      "        vf_explained_var: 0.800960123538971\n",
      "        vf_loss: 316.066162109375\n",
      "    num_steps_sampled: 752000\n",
      "    num_steps_trained: 752000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.88151724137932\n",
      "    ram_util_percent: 38.45862068965517\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06880546283073154\n",
      "    mean_env_wait_ms: 117.42320581612239\n",
      "    mean_inference_ms: 1.730811979971199\n",
      "    mean_raw_obs_processing_ms: 9.167845253267249\n",
      "  time_since_restore: 99547.9966533184\n",
      "  time_this_iter_s: 507.78327322006226\n",
      "  time_total_s: 99547.9966533184\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.827\n",
      "    load_throughput: 10536.616\n",
      "    load_time_ms: 379.629\n",
      "    sample_throughput: 8.207\n",
      "    sample_time_ms: 487376.937\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613926118\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 752000\n",
      "  training_iteration: 188\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 140.18\n",
      "  episode_reward_max: 118.38243891327723\n",
      "  episode_reward_mean: 87.11892782788351\n",
      "  episode_reward_min: -104.86896589473784\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5717\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4141284227371216\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00811158586293459\n",
      "        model: {}\n",
      "        policy_loss: -0.07657773792743683\n",
      "        total_loss: 425.97039794921875\n",
      "        vf_explained_var: 0.7353231310844421\n",
      "        vf_loss: 426.0330810546875\n",
      "    num_steps_sampled: 756000\n",
      "    num_steps_trained: 756000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.6038942976356\n",
      "    ram_util_percent: 38.409318497913766\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688166799210907\n",
      "    mean_env_wait_ms: 117.38973558548936\n",
      "    mean_inference_ms: 1.731003723660797\n",
      "    mean_raw_obs_processing_ms: 9.165262739863397\n",
      "  time_since_restore: 100051.91476297379\n",
      "  time_this_iter_s: 503.91810965538025\n",
      "  time_total_s: 100051.91476297379\n",
      "  timers:\n",
      "    learn_throughput: 260.44\n",
      "    learn_time_ms: 15358.647\n",
      "    load_throughput: 10481.852\n",
      "    load_time_ms: 381.612\n",
      "    sample_throughput: 8.201\n",
      "    sample_time_ms: 487723.613\n",
      "    update_time_ms: 3.524\n",
      "  timestamp: 1613926622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 756000\n",
      "  training_iteration: 189\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 139.42\n",
      "  episode_reward_max: 118.38243891327723\n",
      "  episode_reward_mean: 87.3092010228227\n",
      "  episode_reward_min: -99.1539639651303\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5743\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4504252076148987\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008290223777294159\n",
      "        model: {}\n",
      "        policy_loss: -0.06829310208559036\n",
      "        total_loss: 572.34716796875\n",
      "        vf_explained_var: 0.5892797112464905\n",
      "        vf_loss: 572.4014282226562\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.458379888268155\n",
      "    ram_util_percent: 38.467737430167595\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688263892342844\n",
      "    mean_env_wait_ms: 117.36105588966177\n",
      "    mean_inference_ms: 1.7311708017025933\n",
      "    mean_raw_obs_processing_ms: 9.16247071305064\n",
      "  time_since_restore: 100553.34527301788\n",
      "  time_this_iter_s: 501.4305100440979\n",
      "  time_total_s: 100553.34527301788\n",
      "  timers:\n",
      "    learn_throughput: 260.435\n",
      "    learn_time_ms: 15358.894\n",
      "    load_throughput: 10440.625\n",
      "    load_time_ms: 383.119\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487784.813\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613927124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 190\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 143.17\n",
      "  episode_reward_max: 118.37372136028051\n",
      "  episode_reward_mean: 91.30206714487505\n",
      "  episode_reward_min: -99.1539639651303\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5770\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42250144481658936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006526424083858728\n",
      "        model: {}\n",
      "        policy_loss: -0.05536552518606186\n",
      "        total_loss: 193.9767303466797\n",
      "        vf_explained_var: 0.8199180960655212\n",
      "        vf_loss: 194.0209197998047\n",
      "    num_steps_sampled: 764000\n",
      "    num_steps_trained: 764000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.48100558659217\n",
      "    ram_util_percent: 38.48701117318436\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06883584798012388\n",
      "    mean_env_wait_ms: 117.3310553603252\n",
      "    mean_inference_ms: 1.7313293135656977\n",
      "    mean_raw_obs_processing_ms: 9.159199007370155\n",
      "  time_since_restore: 101054.5346596241\n",
      "  time_this_iter_s: 501.18938660621643\n",
      "  time_total_s: 101054.5346596241\n",
      "  timers:\n",
      "    learn_throughput: 260.427\n",
      "    learn_time_ms: 15359.376\n",
      "    load_throughput: 10534.029\n",
      "    load_time_ms: 379.722\n",
      "    sample_throughput: 8.211\n",
      "    sample_time_ms: 487165.523\n",
      "    update_time_ms: 3.509\n",
      "  timestamp: 1613927625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 764000\n",
      "  training_iteration: 191\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 138.97\n",
      "  episode_reward_max: 118.33499069266497\n",
      "  episode_reward_mean: 84.75324872804698\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5802\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48007702827453613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012584340758621693\n",
      "        model: {}\n",
      "        policy_loss: -0.09932564198970795\n",
      "        total_loss: 728.4404907226562\n",
      "        vf_explained_var: 0.6476417183876038\n",
      "        vf_loss: 728.5183715820312\n",
      "    num_steps_sampled: 768000\n",
      "    num_steps_trained: 768000\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.90993103448277\n",
      "    ram_util_percent: 38.470068965517235\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06884751022889775\n",
      "    mean_env_wait_ms: 117.2953505584617\n",
      "    mean_inference_ms: 1.7315061560061569\n",
      "    mean_raw_obs_processing_ms: 9.156271346885227\n",
      "  time_since_restore: 101562.37695145607\n",
      "  time_this_iter_s: 507.8422918319702\n",
      "  time_total_s: 101562.37695145607\n",
      "  timers:\n",
      "    learn_throughput: 259.223\n",
      "    learn_time_ms: 15430.755\n",
      "    load_throughput: 10585.392\n",
      "    load_time_ms: 377.879\n",
      "    sample_throughput: 8.203\n",
      "    sample_time_ms: 487652.062\n",
      "    update_time_ms: 3.492\n",
      "  timestamp: 1613928133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 768000\n",
      "  training_iteration: 192\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 118.32947700638533\n",
      "  episode_reward_mean: 88.82997558811356\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5830\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47835829854011536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010771854780614376\n",
      "        model: {}\n",
      "        policy_loss: -0.08759791404008865\n",
      "        total_loss: 685.3577880859375\n",
      "        vf_explained_var: 0.5802308320999146\n",
      "        vf_loss: 685.4270629882812\n",
      "    num_steps_sampled: 772000\n",
      "    num_steps_trained: 772000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.510055865921785\n",
      "    ram_util_percent: 38.51578212290503\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06885747574321907\n",
      "    mean_env_wait_ms: 117.26444235467844\n",
      "    mean_inference_ms: 1.7316449178343003\n",
      "    mean_raw_obs_processing_ms: 9.153492962958348\n",
      "  time_since_restore: 102064.4938955307\n",
      "  time_this_iter_s: 502.11694407463074\n",
      "  time_total_s: 102064.4938955307\n",
      "  timers:\n",
      "    learn_throughput: 259.258\n",
      "    learn_time_ms: 15428.676\n",
      "    load_throughput: 10581.754\n",
      "    load_time_ms: 378.009\n",
      "    sample_throughput: 8.202\n",
      "    sample_time_ms: 487683.671\n",
      "    update_time_ms: 3.476\n",
      "  timestamp: 1613928636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 772000\n",
      "  training_iteration: 193\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-38-56\n",
      "  done: false\n",
      "  episode_len_mean: 139.6\n",
      "  episode_reward_max: 118.32947700638533\n",
      "  episode_reward_mean: 86.55391506173646\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5857\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46270233392715454\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00774323008954525\n",
      "        model: {}\n",
      "        policy_loss: -0.07308743894100189\n",
      "        total_loss: 156.12130737304688\n",
      "        vf_explained_var: 0.8850777745246887\n",
      "        vf_loss: 156.18115234375\n",
      "    num_steps_sampled: 776000\n",
      "    num_steps_trained: 776000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.477902097902096\n",
      "    ram_util_percent: 38.45314685314685\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688671396590762\n",
      "    mean_env_wait_ms: 117.23489272819705\n",
      "    mean_inference_ms: 1.7317737628743544\n",
      "    mean_raw_obs_processing_ms: 9.151175244274633\n",
      "  time_since_restore: 102564.99697709084\n",
      "  time_this_iter_s: 500.5030815601349\n",
      "  time_total_s: 102564.99697709084\n",
      "  timers:\n",
      "    learn_throughput: 259.315\n",
      "    learn_time_ms: 15425.279\n",
      "    load_throughput: 10581.729\n",
      "    load_time_ms: 378.01\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487056.506\n",
      "    update_time_ms: 3.485\n",
      "  timestamp: 1613929136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 776000\n",
      "  training_iteration: 194\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 97.17839582171707\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5885\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44672891497612\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015807699412107468\n",
      "        model: {}\n",
      "        policy_loss: -0.10444864630699158\n",
      "        total_loss: 4.103693962097168\n",
      "        vf_explained_var: 0.9922036528587341\n",
      "        vf_loss: 4.18113374710083\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50251396648045\n",
      "    ram_util_percent: 38.45167597765362\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06887643826364688\n",
      "    mean_env_wait_ms: 117.20436109499063\n",
      "    mean_inference_ms: 1.7318841697148941\n",
      "    mean_raw_obs_processing_ms: 9.14814497512818\n",
      "  time_since_restore: 103066.50950145721\n",
      "  time_this_iter_s: 501.5125243663788\n",
      "  time_total_s: 103066.50950145721\n",
      "  timers:\n",
      "    learn_throughput: 259.242\n",
      "    learn_time_ms: 15429.578\n",
      "    load_throughput: 10568.217\n",
      "    load_time_ms: 378.493\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487024.19\n",
      "    update_time_ms: 3.523\n",
      "  timestamp: 1613929638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 195\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 141.24\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 99.04113578713537\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5916\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4446447491645813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007330939639359713\n",
      "        model: {}\n",
      "        policy_loss: -0.06801272928714752\n",
      "        total_loss: 325.7757263183594\n",
      "        vf_explained_var: 0.7580990791320801\n",
      "        vf_loss: 325.8312072753906\n",
      "    num_steps_sampled: 784000\n",
      "    num_steps_trained: 784000\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.5625\n",
      "    ram_util_percent: 38.440416666666664\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688861500968792\n",
      "    mean_env_wait_ms: 117.16950231676245\n",
      "    mean_inference_ms: 1.7320091447873387\n",
      "    mean_raw_obs_processing_ms: 9.14526705178258\n",
      "  time_since_restore: 103570.86333155632\n",
      "  time_this_iter_s: 504.35383009910583\n",
      "  time_total_s: 103570.86333155632\n",
      "  timers:\n",
      "    learn_throughput: 259.316\n",
      "    learn_time_ms: 15425.214\n",
      "    load_throughput: 10555.77\n",
      "    load_time_ms: 378.94\n",
      "    sample_throughput: 8.21\n",
      "    sample_time_ms: 487211.327\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613930143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 784000\n",
      "  training_iteration: 196\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 138.77\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 90.86260867776606\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5944\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4569801688194275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010883398354053497\n",
      "        model: {}\n",
      "        policy_loss: -0.09370122104883194\n",
      "        total_loss: 565.4652099609375\n",
      "        vf_explained_var: 0.7109858393669128\n",
      "        vf_loss: 565.5403442382812\n",
      "    num_steps_sampled: 788000\n",
      "    num_steps_trained: 788000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.52175732217573\n",
      "    ram_util_percent: 38.50195258019526\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06889490639963572\n",
      "    mean_env_wait_ms: 117.13893273738398\n",
      "    mean_inference_ms: 1.7321253873039135\n",
      "    mean_raw_obs_processing_ms: 9.142997044733525\n",
      "  time_since_restore: 104073.42679667473\n",
      "  time_this_iter_s: 502.5634651184082\n",
      "  time_total_s: 104073.42679667473\n",
      "  timers:\n",
      "    learn_throughput: 259.252\n",
      "    learn_time_ms: 15429.024\n",
      "    load_throughput: 10559.05\n",
      "    load_time_ms: 378.822\n",
      "    sample_throughput: 8.208\n",
      "    sample_time_ms: 487323.336\n",
      "    update_time_ms: 3.489\n",
      "  timestamp: 1613930646\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 788000\n",
      "  training_iteration: 197\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-12-30\n",
      "  done: false\n",
      "  episode_len_mean: 137.05\n",
      "  episode_reward_max: 118.38534078592863\n",
      "  episode_reward_mean: 88.86870043619578\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5974\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43862196803092957\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006011617369949818\n",
      "        model: {}\n",
      "        policy_loss: -0.06377123296260834\n",
      "        total_loss: 181.75660705566406\n",
      "        vf_explained_var: 0.8628853559494019\n",
      "        vf_loss: 181.81011962890625\n",
      "    num_steps_sampled: 792000\n",
      "    num_steps_trained: 792000\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44396671289876\n",
      "    ram_util_percent: 38.54105409153953\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0689038510570063\n",
      "    mean_env_wait_ms: 117.1074986980277\n",
      "    mean_inference_ms: 1.7322632502674735\n",
      "    mean_raw_obs_processing_ms: 9.141648403708048\n",
      "  time_since_restore: 104578.01215744019\n",
      "  time_this_iter_s: 504.58536076545715\n",
      "  time_total_s: 104578.01215744019\n",
      "  timers:\n",
      "    learn_throughput: 259.323\n",
      "    learn_time_ms: 15424.795\n",
      "    load_throughput: 10560.106\n",
      "    load_time_ms: 378.784\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487008.488\n",
      "    update_time_ms: 3.502\n",
      "  timestamp: 1613931150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 792000\n",
      "  training_iteration: 198\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-20-54\n",
      "  done: true\n",
      "  episode_len_mean: 135.65\n",
      "  episode_reward_max: 118.37682836900566\n",
      "  episode_reward_mean: 84.91120274687219\n",
      "  episode_reward_min: -106.00795496124721\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6003\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43731579184532166\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011441821232438087\n",
      "        model: {}\n",
      "        policy_loss: -0.08611249923706055\n",
      "        total_loss: 731.3579711914062\n",
      "        vf_explained_var: 0.5641735792160034\n",
      "        vf_loss: 731.4244995117188\n",
      "    num_steps_sampled: 796000\n",
      "    num_steps_trained: 796000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49972144846797\n",
      "    ram_util_percent: 38.53398328690808\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0689123747585987\n",
      "    mean_env_wait_ms: 117.07826797938513\n",
      "    mean_inference_ms: 1.7324010880958718\n",
      "    mean_raw_obs_processing_ms: 9.140069862547081\n",
      "  time_since_restore: 105081.37180137634\n",
      "  time_this_iter_s: 503.3596439361572\n",
      "  time_total_s: 105081.37180137634\n",
      "  timers:\n",
      "    learn_throughput: 259.4\n",
      "    learn_time_ms: 15420.206\n",
      "    load_throughput: 10596.499\n",
      "    load_time_ms: 377.483\n",
      "    sample_throughput: 8.214\n",
      "    sample_time_ms: 486957.601\n",
      "    update_time_ms: 3.509\n",
      "  timestamp: 1613931654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 796000\n",
      "  training_iteration: 199\n",
      "  trial_id: c4001_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         584.968</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-93.4971</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -108.067</td><td style=\"text-align: right;\">           42.7742</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1148.25</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-92.2754</td><td style=\"text-align: right;\">             114.289</td><td style=\"text-align: right;\">            -108.369</td><td style=\"text-align: right;\">             45.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          1751.5</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-83.1377</td><td style=\"text-align: right;\">             118.275</td><td style=\"text-align: right;\">             -108.49</td><td style=\"text-align: right;\">             54.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2273.68</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> -76.314</td><td style=\"text-align: right;\">             118.312</td><td style=\"text-align: right;\">             -108.49</td><td style=\"text-align: right;\">             68.51</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          2795.8</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-74.5112</td><td style=\"text-align: right;\">             118.312</td><td style=\"text-align: right;\">            -107.928</td><td style=\"text-align: right;\">              80.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         3319.58</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-74.3607</td><td style=\"text-align: right;\">             118.266</td><td style=\"text-align: right;\">            -106.658</td><td style=\"text-align: right;\">             82.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         3833.39</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-63.5234</td><td style=\"text-align: right;\">             118.307</td><td style=\"text-align: right;\">            -106.506</td><td style=\"text-align: right;\">             87.35</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         4344.97</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-59.6357</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">             94.72</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         4857.63</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-61.8241</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">             99.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5368.27</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-57.3206</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">            105.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         5871.95</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -44.265</td><td style=\"text-align: right;\">             118.378</td><td style=\"text-align: right;\">            -106.664</td><td style=\"text-align: right;\">            107.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         6383.15</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-37.8044</td><td style=\"text-align: right;\">             118.378</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">             112.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         6886.86</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-27.5816</td><td style=\"text-align: right;\">             118.325</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">            117.99</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         7398.73</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-27.6162</td><td style=\"text-align: right;\">             118.348</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">            114.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         7906.86</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-20.9624</td><td style=\"text-align: right;\">             118.353</td><td style=\"text-align: right;\">            -107.144</td><td style=\"text-align: right;\">            112.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         8415.26</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-18.7572</td><td style=\"text-align: right;\">             118.353</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            109.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         8918.77</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-14.2859</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            120.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         9420.53</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-16.7852</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            123.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         9924.06</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-16.6352</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">            125.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         10431.4</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-19.0543</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">            122.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         10935.5</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-12.3108</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">             120.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         11442.2</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-5.86666</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -106.867</td><td style=\"text-align: right;\">            119.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         11944.1</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\"> 6.99879</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -106.702</td><td style=\"text-align: right;\">            124.01</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">           12450</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\"> 15.2939</td><td style=\"text-align: right;\">              118.34</td><td style=\"text-align: right;\">            -106.702</td><td style=\"text-align: right;\">            123.87</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         12954.4</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> 30.2335</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -105.225</td><td style=\"text-align: right;\">            126.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         13457.7</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\"> 23.5594</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -105.225</td><td style=\"text-align: right;\">            125.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         13960.1</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">  36.487</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">             -105.02</td><td style=\"text-align: right;\">            127.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         14459.3</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> 36.2323</td><td style=\"text-align: right;\">             118.365</td><td style=\"text-align: right;\">            -105.786</td><td style=\"text-align: right;\">            131.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         14964.1</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\"> 32.1002</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            135.09</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         15459.7</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> 40.3523</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            140.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         15958.5</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\"> 47.0233</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            144.89</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">           16455</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> 45.0298</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.132</td><td style=\"text-align: right;\">            143.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         16955.5</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> 42.7677</td><td style=\"text-align: right;\">             118.372</td><td style=\"text-align: right;\">            -105.078</td><td style=\"text-align: right;\">            143.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         17456.9</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> 32.1405</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.078</td><td style=\"text-align: right;\">            133.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         17961.1</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> 15.5419</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">            133.22</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         18457.8</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> 25.9761</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">             130.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         18958.8</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> 29.8441</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">            133.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">           19465</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> 45.9345</td><td style=\"text-align: right;\">             118.364</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">             133.4</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         19965.7</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> 46.3171</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            129.59</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         20464.8</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">  54.302</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            131.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         20965.7</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> 52.7048</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            133.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         21466.9</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> 48.8043</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -106.321</td><td style=\"text-align: right;\">            135.94</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         21971.4</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> 40.8523</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            129.75</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         22471.9</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> 42.8976</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            129.15</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         22972.5</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> 62.0653</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            130.06</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         23480.3</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> 59.9853</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -101.459</td><td style=\"text-align: right;\">            134.84</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         23975.7</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> 74.5288</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            144.04</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         24475.1</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> 67.9829</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            142.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         24973.8</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> 67.8799</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            148.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         25473.1</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> 63.9277</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -105.116</td><td style=\"text-align: right;\">            144.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         25971.5</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> 59.3821</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -105.116</td><td style=\"text-align: right;\">            142.79</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         26472.9</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> 59.0024</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            133.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         26982.7</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> 59.0911</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            132.54</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         27511.5</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> 65.3914</td><td style=\"text-align: right;\">             118.332</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            128.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         28042.3</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> 65.8051</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -106.744</td><td style=\"text-align: right;\">            133.35</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         28566.9</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">  55.311</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -106.744</td><td style=\"text-align: right;\">            126.14</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         29086.6</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> 68.1601</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -101.232</td><td style=\"text-align: right;\">            136.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         29659.2</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> 66.3394</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -101.232</td><td style=\"text-align: right;\">             136.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         30230.8</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> 70.2979</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">             -100.24</td><td style=\"text-align: right;\">            141.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         30805.7</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> 74.4389</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -99.9359</td><td style=\"text-align: right;\">            141.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         31377.5</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> 70.0174</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -105.687</td><td style=\"text-align: right;\">            141.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         31949.3</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> 71.7774</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            141.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         32523.3</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> 59.1274</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            137.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         33097.1</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">  55.334</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            136.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         33669.4</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> 53.5255</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            137.77</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">           34239</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> 53.7095</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            146.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         34809.1</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> 72.5743</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            153.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         35380.3</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  72.234</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            156.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         35952.7</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\"> 76.4175</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.561</td><td style=\"text-align: right;\">            153.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         36525.3</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\"> 72.2532</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            146.37</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         37100.1</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\"> 70.3391</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            138.47</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         37671.1</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\"> 76.6779</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            139.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         38244.2</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> 68.1292</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">             143.7</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         38817.4</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\"> 63.9351</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         39389.2</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> 68.3596</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            140.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         39957.2</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\"> 70.5364</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            144.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         40532.2</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\"> 74.7772</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -98.7848</td><td style=\"text-align: right;\">             138.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         41104.8</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\"> 78.9809</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -98.7417</td><td style=\"text-align: right;\">            142.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         41679.5</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\"> 66.2304</td><td style=\"text-align: right;\">             118.388</td><td style=\"text-align: right;\">            -100.335</td><td style=\"text-align: right;\">            134.93</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         42258.1</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\"> 66.3086</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            129.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         42831.9</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\"> 60.0336</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">             128.4</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         43408.9</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\"> 55.8433</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            126.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         43981.4</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\"> 64.1735</td><td style=\"text-align: right;\">             118.372</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            134.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">           44554</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\"> 74.6458</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.479</td><td style=\"text-align: right;\">            139.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         45127.5</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\"> 72.4842</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.479</td><td style=\"text-align: right;\">            135.91</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         45699.6</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\"> 74.4792</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.335</td><td style=\"text-align: right;\">            141.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">           46272</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\"> 70.2346</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -100.486</td><td style=\"text-align: right;\">            141.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">           46842</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\"> 78.5976</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -101.487</td><td style=\"text-align: right;\">            145.91</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         47414.5</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\"> 86.7418</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            151.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         47986.2</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> 95.4794</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            152.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         48559.3</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  86.877</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            148.45</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         49132.4</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  78.536</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">            147.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         49702.8</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\"> 76.2701</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">            148.59</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         50274.3</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\"> 76.0907</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">               144</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         50844.4</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\"> 90.7099</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">            -101.663</td><td style=\"text-align: right;\">            154.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         51419.6</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\"> 90.7374</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            151.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         51992.5</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 95.0085</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            148.99</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         52563.9</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 92.9886</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            148.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         53137.5</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\"> 88.8485</td><td style=\"text-align: right;\">             118.339</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">             145.7</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         53711.6</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 93.1422</td><td style=\"text-align: right;\">             118.339</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            147.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         54285.6</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">  87.096</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            145.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">           54857</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\"> 89.2414</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            147.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         55434.1</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">  80.926</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         56010.5</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\"> 82.9837</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -97.2012</td><td style=\"text-align: right;\">            143.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         56586.3</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 78.5377</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            136.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         57158.2</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\"> 78.3317</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            137.12</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         57732.9</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 78.0711</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            143.85</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         58308.1</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\"> 78.4255</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -103.571</td><td style=\"text-align: right;\">             140.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         58882.6</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 76.4069</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -103.571</td><td style=\"text-align: right;\">            144.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         59457.2</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\"> 74.6297</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            141.72</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         60032.4</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 76.6534</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            139.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         60606.6</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\"> 72.2738</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            137.41</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         61191.2</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 78.4317</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            141.31</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         61762.9</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 86.8246</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.032</td><td style=\"text-align: right;\">             144.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         62342.6</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\"> 86.8017</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.091</td><td style=\"text-align: right;\">            144.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         62919.9</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">  93.335</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -105.091</td><td style=\"text-align: right;\">            147.86</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         63491.7</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 97.3352</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            151.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         64066.2</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 91.0529</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            146.86</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         64637.4</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\"> 89.1573</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            148.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         65208.2</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 87.0029</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            148.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         65721.2</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 85.1433</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">             -100.99</td><td style=\"text-align: right;\">            146.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         66243.3</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\"> 85.3865</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -100.431</td><td style=\"text-align: right;\">            146.02</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         66775.3</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 89.4547</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -100.431</td><td style=\"text-align: right;\">            139.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">           67295</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\"> 84.9043</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -106.07</td><td style=\"text-align: right;\">            139.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">           67801</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 84.8044</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -106.07</td><td style=\"text-align: right;\">            134.12</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         68305.6</td><td style=\"text-align: right;\">504000</td><td style=\"text-align: right;\"> 78.0839</td><td style=\"text-align: right;\">             118.347</td><td style=\"text-align: right;\">            -106.328</td><td style=\"text-align: right;\">             138.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         68832.5</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">  82.365</td><td style=\"text-align: right;\">             118.328</td><td style=\"text-align: right;\">            -106.328</td><td style=\"text-align: right;\">            142.47</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         69358.4</td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\"> 82.4307</td><td style=\"text-align: right;\">             118.314</td><td style=\"text-align: right;\">            -106.802</td><td style=\"text-align: right;\">            142.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         69867.9</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\"> 82.3166</td><td style=\"text-align: right;\">             118.349</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">             132.8</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         70371.8</td><td style=\"text-align: right;\">520000</td><td style=\"text-align: right;\"> 80.4074</td><td style=\"text-align: right;\">             118.349</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">            129.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         70872.9</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\"> 82.6994</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">             131.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">           71374</td><td style=\"text-align: right;\">528000</td><td style=\"text-align: right;\"> 82.9684</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -103.769</td><td style=\"text-align: right;\">            135.54</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         71877.9</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\"> 83.1785</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            133.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         72376.1</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\"> 85.2736</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            139.25</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         72879.5</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\"> 95.6462</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">             139.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         73381.7</td><td style=\"text-align: right;\">544000</td><td style=\"text-align: right;\"> 95.6876</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            138.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         73882.2</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\"> 95.8851</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -100.175</td><td style=\"text-align: right;\">             139.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         74381.8</td><td style=\"text-align: right;\">552000</td><td style=\"text-align: right;\"> 97.8148</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.633</td><td style=\"text-align: right;\">            142.07</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         74887.1</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\"> 93.4033</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            139.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         75387.6</td><td style=\"text-align: right;\">560000</td><td style=\"text-align: right;\"> 93.4257</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            144.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         75906.1</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\"> 89.1157</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            141.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">           76410</td><td style=\"text-align: right;\">568000</td><td style=\"text-align: right;\"> 85.0535</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            139.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         76912.8</td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\"> 91.5854</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -102.284</td><td style=\"text-align: right;\">            143.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         77414.4</td><td style=\"text-align: right;\">576000</td><td style=\"text-align: right;\"> 89.3539</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            142.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">           77913</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\"> 99.8468</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            146.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         78416.4</td><td style=\"text-align: right;\">584000</td><td style=\"text-align: right;\"> 93.4931</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            144.87</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         78917.4</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\"> 95.3716</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            145.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         79418.8</td><td style=\"text-align: right;\">592000</td><td style=\"text-align: right;\"> 101.798</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.135</td><td style=\"text-align: right;\">            147.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         79925.6</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\"> 95.7064</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -104.575</td><td style=\"text-align: right;\">            145.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         80429.4</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\">  93.574</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            139.82</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         80933.3</td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\"> 89.2191</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            136.29</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         81435.8</td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\"> 91.0047</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            137.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         81937.2</td><td style=\"text-align: right;\">612000</td><td style=\"text-align: right;\"> 91.1644</td><td style=\"text-align: right;\">             118.359</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            141.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         82451.8</td><td style=\"text-align: right;\">616000</td><td style=\"text-align: right;\"> 95.1221</td><td style=\"text-align: right;\">             118.359</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            138.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         82950.2</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\"> 93.0994</td><td style=\"text-align: right;\">             118.335</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            142.57</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         83451.6</td><td style=\"text-align: right;\">624000</td><td style=\"text-align: right;\"> 97.1734</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            144.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         83963.5</td><td style=\"text-align: right;\">628000</td><td style=\"text-align: right;\"> 86.7386</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.731</td><td style=\"text-align: right;\">            140.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         84469.4</td><td style=\"text-align: right;\">632000</td><td style=\"text-align: right;\"> 82.4999</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            134.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         84972.2</td><td style=\"text-align: right;\">636000</td><td style=\"text-align: right;\"> 73.9378</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            132.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">           85475</td><td style=\"text-align: right;\">640000</td><td style=\"text-align: right;\"> 82.4884</td><td style=\"text-align: right;\">             118.344</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            137.36</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         85978.7</td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\"> 82.4412</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">             138.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         86480.1</td><td style=\"text-align: right;\">648000</td><td style=\"text-align: right;\">  93.177</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -105.149</td><td style=\"text-align: right;\">            147.27</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         86982.8</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\"> 90.8336</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -106.965</td><td style=\"text-align: right;\">            146.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         87486.7</td><td style=\"text-align: right;\">656000</td><td style=\"text-align: right;\"> 92.8701</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.965</td><td style=\"text-align: right;\">             145.8</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         87988.1</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\"> 92.7061</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            145.21</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         88489.4</td><td style=\"text-align: right;\">664000</td><td style=\"text-align: right;\">  94.768</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            146.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         88989.3</td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\"> 101.208</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            147.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         89495.5</td><td style=\"text-align: right;\">672000</td><td style=\"text-align: right;\"> 90.6324</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            141.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         89997.6</td><td style=\"text-align: right;\">676000</td><td style=\"text-align: right;\"> 94.9958</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -106.978</td><td style=\"text-align: right;\">            140.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">           90499</td><td style=\"text-align: right;\">680000</td><td style=\"text-align: right;\"> 95.4036</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -106.978</td><td style=\"text-align: right;\">            141.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         91003.4</td><td style=\"text-align: right;\">684000</td><td style=\"text-align: right;\"> 99.7913</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -106.63</td><td style=\"text-align: right;\">            141.21</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         91506.9</td><td style=\"text-align: right;\">688000</td><td style=\"text-align: right;\"> 95.5937</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            142.26</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         92008.9</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\"> 91.3859</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            140.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         92507.7</td><td style=\"text-align: right;\">696000</td><td style=\"text-align: right;\"> 95.3946</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            146.02</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         93011.1</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">   88.93</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            141.08</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         93517.2</td><td style=\"text-align: right;\">704000</td><td style=\"text-align: right;\"> 80.6405</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            140.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         94015.1</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\"> 78.3588</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            141.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         94514.9</td><td style=\"text-align: right;\">712000</td><td style=\"text-align: right;\"> 84.7146</td><td style=\"text-align: right;\">             118.343</td><td style=\"text-align: right;\">             -104.55</td><td style=\"text-align: right;\">            145.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         95015.3</td><td style=\"text-align: right;\">716000</td><td style=\"text-align: right;\"> 93.0332</td><td style=\"text-align: right;\">             118.318</td><td style=\"text-align: right;\">             -104.55</td><td style=\"text-align: right;\">            151.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         95516.1</td><td style=\"text-align: right;\">720000</td><td style=\"text-align: right;\"> 99.2755</td><td style=\"text-align: right;\">             118.354</td><td style=\"text-align: right;\">            -99.1245</td><td style=\"text-align: right;\">             154.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         96023.5</td><td style=\"text-align: right;\">724000</td><td style=\"text-align: right;\">   86.87</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -100.514</td><td style=\"text-align: right;\">            144.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         96525.8</td><td style=\"text-align: right;\">728000</td><td style=\"text-align: right;\">  89.188</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -100.514</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         97027.6</td><td style=\"text-align: right;\">732000</td><td style=\"text-align: right;\"> 93.3472</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -105.702</td><td style=\"text-align: right;\">            137.64</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         97534.4</td><td style=\"text-align: right;\">736000</td><td style=\"text-align: right;\">  89.211</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -107.313</td><td style=\"text-align: right;\">            133.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         98036.2</td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\"> 97.4386</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.313</td><td style=\"text-align: right;\">            137.71</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         98538.8</td><td style=\"text-align: right;\">744000</td><td style=\"text-align: right;\"> 86.6814</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            135.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         99040.2</td><td style=\"text-align: right;\">748000</td><td style=\"text-align: right;\"> 95.3122</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            142.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">           99548</td><td style=\"text-align: right;\">752000</td><td style=\"text-align: right;\"> 91.0886</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            141.52</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">          100052</td><td style=\"text-align: right;\">756000</td><td style=\"text-align: right;\"> 87.1189</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -104.869</td><td style=\"text-align: right;\">            140.18</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">          100553</td><td style=\"text-align: right;\">760000</td><td style=\"text-align: right;\"> 87.3092</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">             -99.154</td><td style=\"text-align: right;\">            139.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">          101055</td><td style=\"text-align: right;\">764000</td><td style=\"text-align: right;\"> 91.3021</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">             -99.154</td><td style=\"text-align: right;\">            143.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">          101562</td><td style=\"text-align: right;\">768000</td><td style=\"text-align: right;\"> 84.7532</td><td style=\"text-align: right;\">             118.335</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            138.97</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">          102064</td><td style=\"text-align: right;\">772000</td><td style=\"text-align: right;\">   88.83</td><td style=\"text-align: right;\">             118.329</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            140.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">          102565</td><td style=\"text-align: right;\">776000</td><td style=\"text-align: right;\"> 86.5539</td><td style=\"text-align: right;\">             118.329</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">             139.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">          103067</td><td style=\"text-align: right;\">780000</td><td style=\"text-align: right;\"> 97.1784</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            140.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">          103571</td><td style=\"text-align: right;\">784000</td><td style=\"text-align: right;\"> 99.0411</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            141.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">          104073</td><td style=\"text-align: right;\">788000</td><td style=\"text-align: right;\"> 90.8626</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            138.77</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">          104578</td><td style=\"text-align: right;\">792000</td><td style=\"text-align: right;\"> 88.8687</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            137.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">          105081</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> 84.9112</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -106.008</td><td style=\"text-align: right;\">            135.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">          105081</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> 84.9112</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -106.008</td><td style=\"text-align: right;\">            135.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path, analysis = train(stop_criteria=stop,\n",
    "                                  config=config,\n",
    "                                  restorepath='/home/dschori/ray_results/'\n",
    "                                              'PPO_2021-02-09_17-09-27/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_2f1df_00000_0_2021-02-09_17-09-27/' \\\n",
    "                  'checkpoint_201/checkpoint-201')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Restore Agent for Testing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [ERROR] [1613935483.013750, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [WARN] [1613935483.017946, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [WARN] [1613935483.019186, 0.000000]: END Init ControllersConnection\n",
      "2021-02-21 20:24:49,121\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-21 20:24:49,247\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-21 20:24:49,248\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_nr = 164\n",
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 16:25:11,270\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-22 16:25:11,270\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [ERROR] [1614007514.360105, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [WARN] [1614007514.364186, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [WARN] [1614007514.365176, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 16:25:22,346\tINFO trainable.py:99 -- Trainable.setup took 11.077 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-22 16:25:22,347\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 16:25:22,485\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-20_14-08-46/PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/checkpoint_199/checkpoint-199\n",
      "2021-02-22 16:25:22,485\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 199, '_timesteps_total': None, '_time_total': 105081.37180137634, '_episodes_total': 6003}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_nr = 199\n",
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-20_14-08-46/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m [ERROR] [1614060574.947639, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m [WARN] [1614060574.952567, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=24689)\u001B[0m [WARN] [1614060574.953872, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 07:09:41,141\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 07:09:41,272\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-23 07:09:41,272\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    }
   ],
   "source": [
    "# Video recording\n",
    "import time\n",
    "checkpoints = [1, 40, 80, 120, 164]\n",
    "checkpoints = [164]\n",
    "for checkpoint in checkpoints:\n",
    "    time_now = time.time()\n",
    "    print(checkpoint)\n",
    "    checkpoint_nr = checkpoint\n",
    "    checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "    agent = load(checkpoint_path=checkpoint_path, config=config)\n",
    "    env.img_prefix = 'check_{}'.format(checkpoint)\n",
    "    while True:\n",
    "        episode_reward = test_traj(agent=agent, env=env)\n",
    "        if time.time() - time_now > 150:\n",
    "            break\n",
    "    time.sleep(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-23 13:25:06,308\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-23 13:25:06,309\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m [ERROR] [1614083109.286636, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m [WARN] [1614083109.289912, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m [WARN] [1614083109.290800, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 13:25:17,155\tINFO trainable.py:99 -- Trainable.setup took 10.848 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-23 13:25:17,157\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 13:25:17,328\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_1/checkpoint-1\n",
      "2021-02-23 13:25:17,329\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 580.1686522960663, '_episodes_total': 92}\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m [ERROR] [1614083203.134913, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m [WARN] [1614083203.138443, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m [WARN] [1614083203.139224, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 13:26:48,869\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 13:26:48,986\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_40/checkpoint-40\n",
      "2021-02-23 13:26:48,987\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 40, '_timesteps_total': None, '_time_total': 20344.65621137619, '_episodes_total': 1464}\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m [ERROR] [1614083430.489609, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m [WARN] [1614083430.492503, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m [WARN] [1614083430.493301, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 13:30:36,152\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 13:30:36,283\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_80/checkpoint-80\n",
      "2021-02-23 13:30:36,283\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 80, '_timesteps_total': None, '_time_total': 40383.41257071495, '_episodes_total': 2641}\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m [ERROR] [1614083623.862277, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m [WARN] [1614083623.864978, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m [WARN] [1614083623.865669, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 13:33:49,116\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 13:33:49,250\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_120/checkpoint-120\n",
      "2021-02-23 13:33:49,251\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 120, '_timesteps_total': None, '_time_total': 60434.630679130554, '_episodes_total': 3790}\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m [ERROR] [1614083963.113173, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m [WARN] [1614083963.116241, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m [WARN] [1614083963.116994, 0.000000]: END Init ControllersConnection\n",
      "2021-02-23 13:39:28,685\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-23 13:39:28,812\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-23 13:39:28,813\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=68105)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=68108)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=68107)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=68102)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=68106)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "trajectories = {}\n",
    "success_rate = {}\n",
    "runs = 15\n",
    "checkpoints = [1, 40, 80, 120, 164]\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_nr = checkpoint\n",
    "    checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "    agent = load(checkpoint_path=checkpoint_path, config=config)\n",
    "    trajectories['checkpoint_traj_{}'.format(checkpoint)] = {}\n",
    "    success_rate['checkpoint_success_{}'.format(checkpoint)] = {}\n",
    "    for i in range(runs):\n",
    "        episode_reward, positions = test_traj(agent=agent, env=env)\n",
    "        trajectories['checkpoint_traj_{}'.format(checkpoint)]['run{}'.format(i)] = positions\n",
    "        if episode_reward > 0:\n",
    "           success_rate['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = True\n",
    "        else:\n",
    "           success_rate['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 30, Success Rate:       0.00%\n",
      "Episode: 1206, Success Rate:      20.00%\n",
      "Episode: 2413, Success Rate:      33.33%\n",
      "Episode: 3619, Success Rate:      60.00%\n",
      "Episode: 4947, Success Rate:      93.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAHHCAYAAADkj8/RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzde1iVZb74//d61oEzclDAA6KggpjkgUSbSUfcO9mZpzST6Jtbp3b5203NNqd2GuMOlKywIfraONNgu++eRB1F3eKUjphaBpQ6jpKAyUoUz8pBFqfFWuv5/fHoSuLgCYX087qudela9/3cz70e9eLjffroVFVVEUIIIYQQnYrS0R0QQgghhBDNSZAmhBBCCNEJSZAmhBBCCNEJSZAmhBBCCNEJSZAmhBBCCNEJGTq6A+2pvr6egoICunXrhl6v7+juCCGEEEK0ym63c/78ee677z5cXV2bld9VQVpBQQEJCQkd3Q0hhBBCiOv2ySefEB0d3ezzuypI69atG6B92aCgoA7ujfip6NevX0d3QQghxD1Ir9fTq1cvZ/zyY3dVkHZlijMoKIhevXp1cG/ET4XNZuvoLgghhLiHtbZESzYOCCGEEEJ0QnfVSJoQ7eXbb78lPDy8o7shRLvatWtXR3ehVUaj8Y7dy9/f/47d62Y1NDTcsXt15o12d/rPqrPNwkmQJoQQ94gxY8Z0dBfuKIfDQVlZGTU1Nc0+7+zuZNDamVVUVNzR+x06dOi2tOvh4UGvXr0oLCzk/vvvv+7rJEgTQghxV7pw4QI6nY7w8HAURVb3iI7hcDg4efIkFy5cuOFr5W+tEEKIu1JlZSWBgYESoIkOpSgKgYGBVFVV3fC1MpImRAvOnDkja9KE+Imz2+0ybXgP2Lt3b0d3oUVXn3tmNBpv6iQB+e+FEEKIu5ZOp+voLghx038PZSRNCCGEuANiY2MxmUy4uLg4P1u+fPk1dxROnjyZNWvWtJg26EZlZWWxc+dO0tPTb7mttuTn5/PWW2+RlZV1W+9zRUJCAhkZGdd8Rh999BHFxcXodDoMBgNPPPEE9913HwBVVVV88MEHXLhwAZPJxC9/+csOP+xcgjQhhBDiDklPT2fAgAE3dM2mTZtuU2/uPU888QTu7u4AlJaWkpKSwooVK9DpdKxZs4aIiAimTp1KcXExH3zwAcuWLevQ0VgJ0oQQQogOFh4ezgsvvMCePXuoqKhg3rx5jB8/3lm2f/9+3NzcSEpKIi8vD5PJhLu7O6tXrwZg48aNZGRkANC7d2+SkpLw9/fHarWyePFi8vPzCQwMJDQ0tMl9P/zwQ7Zu3YrdbicwMJDk5GS6devG9u3bee+991AUBbvdTmJiIjExMU2uzc/PZ8mSJQwaNIiioiL0ej1Lly5tNvpks9l47rnnqKiooKGhgaioKN544w1MJhOPPvooKSkpREVFAdpIl9lsJjk5GbPZTEpKChUVFTQ2NjJr1iymTZsGwLZt23j33Xfx8fEhLCzsup/zlQANoLa2tkkAlpeXx3vvved85kajEbPZfEPttzcJ0oQQQog75MUXX3ROd+r1+ibTgTqdjtWrV2M2m4mPjyc6OrrJYa5FRUXk5uby6aefoiiKc7fgkSNHSE1NJSsri4CAANLS0khOTiYtLY01a9ZQVlZGdnY2NpuNhIQE5/Tqpk2bOH78OGvXrkVRFFatWsXSpUtZtmwZ6enpLFq0iOjoaOx2O3V1dS1+n+LiYl5//XVGjBjBhg0beOWVV5pNcer1elJTU/H19UVVVV599VXWr19PfHw8CQkJZGZmEhUVhaqqZGZmkp6ejs1mY/78+bzzzjuEhYVhsViYNm0aQ4YMwcfHh8TERDIzMwkNDWXRokVN7vfhhx8ybNgwhg8f3mKf161bx549e6ipqeHXv/41Op2O6upqALy8vJz1/P39KS8vlyBNCCGEuN1+97cjvJfznfP95hd+DsDE//ul87OXxvXnP/55ACOWbOdctXbq/309vcn+1UO8lnWQzK9POOvmLxjHobIqDp2s4j/++fqmMNua7nz88ccBCA0NJTIykgMHDjBu3DhneXBwMHa7nYULFxITE8PYsWO1fuTnM2bMGAICAgCYOXMmkydPdpZNmTIFo9GI0Whk0qRJ7N+/H4AdO3ZQUFDA1KlTAW03rKenJwAjR45k6dKlxMXFMXr06Fb7HBISwogRIwBt7VxiYiIWi6VJHYfDwcqVK9m9ezcOh4Oqqirn2rEpU6awfPlyKisrOXjwIP7+/kRERHD06FFKSkqYN2+es53GxkbMZjOKohAZGekcFYyNjXWOKAI8++yzbf4ZTJ8+nenTp/Ptt9+SmZnZLMjrTCRIE0IIcU/4j38e0GIwdWzphGaffb3wn5p99uZjUbz5WFSTzwIjXfmnyMD26+Rlqqo2Wwvl5eXFli1byM/PJzc3l9TUVDZs2NBi3avbaesec+fOZfr06c3KFixYQHFxMXl5ebz00kvMnj2bGTNm3NR32bx5M/v27eOTTz7B09OTFStWcOzYMQDc3NyYOHEiWVlZfP311yQkJDj75uvr2+J6vO3bt99UP35s0KBB1NXVceLECfr27QtAdXW1czTt4sWL+Pn5tcu9bpYcwSGEEEJ0AuvXrwfg2LFjLaYPKi8vp76+ntGjRzN//ny8vLw4ceIEo0aNYteuXZw/fx6AtWvX8uCDDwIwatQoNm3ahM1mo76+nuzsbGd7sbGxrFq1yjltarVaKSoqAsBsNhMeHs6sWbOYNGlSq+mSSktLneeUbd68mQEDBjhH466orq7G19cXT09Pqqurm/QB4Mknn+Tjjz+moKCAhx9+GIC+ffvi6urKxo0bnfVKSkqwWCwMHTqUw4cPOwO9nTt3XtfzVVWVU6dOOd+bzWYuXbrkHIEcMWKEMwAsLi7GarU6g7eOIiNpQgghxB1y9Zo0gMWLFzN48GAATCYTM2fOpKKiwrnw/2qnT58mMTERm82G3W5n9OjRDBkyBEVRePnll5kzZw6gTYsmJSUBMGPGDIqLi5kwYQJBQUE88MADnDx5EtCmGisrK3nqqacALYiJj48nIiKCZcuWUVpail6vx9vbmyVLlrT4fQYOHEh2djYpKSkoisLbb7/drM6UKVPIyclhwoQJBAYGMnz48CYJ5IODgwkNDSUqKgqTyQSAwWBgxYoVpKSkkJGRgcPhwN/fn7S0NPz9/UlOTub555/Hx8eHQYMGNblfa2vSVFXlT3/6EzU1NSiKgslk4sUXX8TDwwPQpok/+OADvvjiC0wmE3Pnzu3wbBU6ta2x0J+YsrIyxo0bR05OTqfLZC86L4Oh+f9VcnJy7rlk1ELcbQoLCxk4cGBHd+O6XNnBeSVg+Clor7PQLBYLcXFxrFu3jqCgoBu+/qeQcQC0v48Oh6PJCKnBYCAkJKTVuEWmO4UQQgjRITIzM3nkkUeYM2fOTQVodzuZ7hRCCCE6WHFxcUd34YbFxMTc8ihafHw88fHx7dSju4+MpAkhhBBCdEISpAkhhBBCdEISpAkhhBBCdEISpAkhhBBCdEISpAkhhBBCdEKyu1MIIYS4A2JjYzGZTE0Os12+fPk1z/WcPHkya9ascea7vBVZWVns3LmT9PT0W26rLe11htr1SkhIICMj45rPaMuWLXz++eecOXOGefPmMWzYMEDLL5qenk5ZWRlGoxFvb2/mzJlDYGBgm2VttdkeJEgTQggh7pC2Eqy3pqX8leLmREREMHz4cP70pz81K3vooYcYOnQoiqKwbds2MjIyWLBgwTXL2mrzVkmQJoQQ4p7Q0OjAanM0+czNpGDQK9Rb7TTamybgcXfRo1d01DXYsTmalnm46lF0Omrq7Rj0OlyMt7Z6KDw8nBdeeIE9e/ZQUVHBvHnzGD9+vLNs//79uLm5kZSURF5eHiaTCXd3d1avXg3Axo0bycjIAKB3797OtFJWq5XFixeTn59PYGAgoaGhTe774YcfsnXrVux2O4GBgSQnJ9OtWze2b9/Oe++9h6Io2O12EhMTiYmJaXJtfn4+S5YsYdCgQRQVFaHX61m6dCn9+vVrUs9ms/Hcc89RUVFBQ0MDUVFRvPHGG5hMJh599FFSUlKIitIS13/00UeYzWaSk5Mxm82kpKRQUVFBY2Mjs2bNYtq0aQBs27aNd999Fx8fH8LCwq77ObdWV1GUJmmk+vfvz2effXbNsrbabA8SpAkhhLgnmM/UUnSypslnMQO60MPPlcMnLJSer29S9ov7/PD1NLLffIlzVdYmZf8yrCuuJj25xRX09HNlYHDTpOKtuTp3p16vbzIdqNPpWL16NWazmfj4eKKjo5vk7ywqKiI3N5dPP/0URVGcidGPHDlCamoqWVlZBAQEkJaWRnJyMmlpaaxZs4aysjKys7Ox2WwkJCQ4p1c3bdrE8ePHWbt2LYqisGrVKpYuXcqyZctIT09n0aJFREdHY7fbqaura/H7FBcX8/rrrzNixAg2bNjAK6+80myKU6/Xk5qaiq+vL6qq8uqrr7J+/Xri4+NJSEggMzOTqKgoVFUlMzOT9PR0bDYb8+fP55133iEsLAyLxcK0adMYMmQIPj4+JCYmkpmZSWhoKIsWLWpyv9Zyd96Ibdu2tTpt2VZZe5MgTQghxD0hNMidXl2brllyM2kjYJHBnvTv0TRvpruLHoBhod7NRtJMl0fORoX7YtDrrrsPbU13Pv7441o/Q0OJjIzkwIEDjBs3zlkeHByM3W5n4cKFxMTEMHbsWEAb0RozZgwBAQGAlih88uTJzrIpU6ZgNBoxGo1MmjSJ/fv3A7Bjxw4KCgqYOnUqAHa7HU9PLdgcOXIkS5cuJS4ujtGjR7fa55CQEEaMGAFoa+cSExOxWCxN6jgcDlauXMnu3btxOBxUVVU5145NmTKF5cuXU1lZycGDB/H39yciIoKjR49SUlLCvHnznO00NjZiNptRFIXIyEjnqGBsbKxzRBHg2WefbfsP4Rqys7M5efIkCxcuvKGy20GCNCGEEPcEF6PS6rSkq0lPa0vO3S4Hay3xcG297FaoqopO1zT48/LyYsuWLeTn55Obm0tqaiobNmxose7V7bR1j7lz5zJ9+vRmZQsWLKC4uJi8vDxeeuklZs+ezYwZM27qu2zevJl9+/bxySef4OnpyYoVKzh27BgAbm5uTJw4kaysLL7++msSEhKcffP19W1xPd727dtvqh/XY9u2bXz11VcsWLCgyQaPa5XdLnIEhxBCCNEJrF+/HoBjx45RWFjI/fff36S8vLyc+vp6Ro8ezfz58/Hy8uLEiROMGjWKXbt2cf78eQDWrl3Lgw8+CMCoUaPYtGkTNpuN+vp6srOzne3FxsayatUq57Sp1WqlqKgIALPZTHh4OLNmzWLSpEkcOnSoxT6Xlpayd+9eQAvGBgwY4ByNu6K6uhpfX188PT2prq5u0geAJ598ko8//piCggIefvhhAPr27YurqysbN2501ispKcFisTB06FAOHz7sDPR27tx5fQ/4Gnbs2EFOTg7/+Z//2ew7tFV2O8lImhBCCHGHXL0mDWDx4sUMHjwYAJPJxMyZM6moqHAu/L/a6dOnSUxMxGazYbfbGT16NEOGDEFRFF5++WXmzJkDaNOiSUlJAMyYMYPi4mImTJhAUFAQDzzwACdPngS0qcbKykqeeuopQBu9io+PJyIigmXLllFaWoper8fb25slS5a0+H0GDhxIdnY2KSkpKIrC22+/3azOlClTyMnJYcKECQQGBjJ8+HAaGhqc5cHBwYSGhhIVFYXJZALAYDCwYsUKUlJSyMjIwOFw4O/vT1paGv7+/iQnJ/P888/j4+PDoEGDmtyvrTVp2dnZfPbZZ1RXV/OHP/wBo9HI22+/jU6nY+XKlXTt2pU333wTAKPRSFJSEnV1da2WtdVme9CpbY2F/sSUlZUxbtw4cnJyrnnujBBXGAzN/6+Sk5PDmDFjOqA3Qoj2UlhYyMCBAzu6G9flyg5ODw+Pa1fuJNrrLDSLxUJcXBzr1q0jKCjohq+/MpLX2URHRzd5X1hYiMPhaDJCajAYCAkJaTVukelOIYQQQnSIzMxMHnnkEebMmXNTAdrdTqY7hRBCiA5WXFzc0V24YTExMbc8ihYfH098fHw79ejuIyNpQgghhBCdkARpQgghhBB3wI937F6LBGlCCCGEEJ2QBGlCCCGEEJ2QBGlCCCHEHRAbG0tcXByTJ092vsrKyq553eTJk6mvr79mveuRlZXFiy++2C5ttSU/P5/HHnvstt/nioSEhGs+I4fDQVpaGvPnz+e1117jzTff5OzZs83q7d69m4SEBGf6rLbKrrfNmyW7O4UQQog7pK3cna1pKTWSuDkPPfQQQ4cORVEUtm3bRkZGBgsWLHCWX7x4kR07dtCvX79m17ZWdq02b4WMpAkhhBAdLDw8nPfff5+ZM2cyfvx4tm7d2qSspqYGh8PBf/3XfxEXF8ekSZOYOXOms87GjRuZOHEiEydO5N///d+5ePEioKV6+u1vf8v48eN5+umnOXjwYJP7fvjhh0yfPp2pU6fy/PPPO1NLbd++nYkTJzJ58mQeffRR8vPzm/U5Pz+fSZMm8dprrzF16lSmT5/O0aNHm9Wz2Wz88pe/5LHHHmPChAm89tprWK1WAB599NEmffroo49ITEwEtNRUzzzzDNOmTWPSpEnOtFmg5dGMi4tj5syZbNiw4bqesaIoDB8+HEXRQp/+/ftz4cKFJnUyMjJ46qmnMBqNza5vqex62rwVMpImhBDi3pD/fvPPDG4w/Bnt9ydy4VQLp9f3HQsB94G9EfauaF4e86vr7sLVaaH0en2Tc8Z0Oh2rV6/GbDYTHx9PdHR0k9RQRUVF5Obm8umnn6IoijPn5pEjR0hNTSUrK4uAgADS0tJITk4mLS2NNWvWUFZWRnZ2NjabjYSEBOfJ9ps2beL48eOsXbsWRVFYtWoVS5cuZdmyZaSnp7No0SKio6Ox2+3U1dW1+H2Ki4t5/fXXGTFiBBs2bOCVV15pdnaaXq8nNTUVX19fVFXl1VdfZf369cTHx5OQkEBmZiZRUVGoqkpmZibp6enYbDbmz5/PO++8Q1hYGBaLhWnTpjFkyBB8fHxITEwkMzOT0NBQFi1a1OR+baWFutq2bdsYNmyY8/327dvp1atXi6NobZW11eatkiBN3NN27drV0V0QQtxD2prufPzxxwEIDQ0lMjKSAwcOMG7cOGd5cHAwdrudhQsXEhMTw9ixYwFtRGvMmDEEBAQAMHPmTCZPnuwsmzJlCkajEaPRyKRJk5zrqXbs2EFBQQFTp04FwG63O5OHjxw5kqVLlxIXF8fo0aNb7XNISAgjRowAtLVziYmJWCyWJnUcDgcrV65k9+7dOBwOqqqqcHV1BbS8nsuXL6eyspKDBw/i7+9PREQER48epaSkhHnz5jnbaWxsxGw2oygKkZGRhIaGAtpav9WrVzvrPfvss23/IaDl2zx58iQLFy4E4Ny5c3z++efNAr5rlbXVZnvodEFaRUUFr7zyCsePH8dkMhESEkJSUhJ+fn4d3TUhhBA/Zdca8Qoepb1aozfe0KjZrVBVFZ1O1+QzLy8vtmzZQn5+Prm5uaSmprJhw4YW617dTlv3mDt3LtOnT29WtmDBAoqLi8nLy+Oll15i9uzZzJgx46a+y+bNm9m3bx+ffPIJnp6erFixgmPHjgHg5ubGxIkTycrK4uuvvyYhIcHZN19f3xbX423fvr3J+6FDhzp/vZ7cp3/+8585cOAAq1atwsfHx9lHi8XC66+/DsD58+f57//+b/z8/HBxcWm17Mqza6nN9tDp1qTpdDqeeeYZtm7dyubNmwkODiY1NbWjuyWEEELcVlfWXB07dozCwsJmB5+Wl5dTX1/P6NGjmT9/Pl5eXpw4cYJRo0axa9cu53qytWvX8uCDDwIwatQoNm3ahM1mo76+nuzsbGd7sbGxrFq1yjltarVaKSoqArT1YOHh4cyaNYtJkyZx6NChFvtcWlrqTHC+efNmBgwY4ByNu6K6uhpfX188PT2prq5u0geAJ598ko8//piCggIefvhhAPr27YurqysbN2501ispKcFisTB06FAOHz7sDPT+8pe/XOcThjVr1rBmzRpWrlzZJJiaOHEie/bsYceOHezYsYMhQ4awZMkSpk+f3mZZW222h043kubj40NMTIzz/ZAhQ8jMzOzAHgkhhBDt4+o1aQCLFy9m8ODBAJhMJmbOnElFRQVJSUlN1qMBnD59msTERGw2G3a7ndGjRzNkyBAUReHll19mzpw5gDYtmpSUBMCMGTMoLi5mwoQJBAUF8cADD3Dy5ElAm2qsrKzkqaeeArTRq/j4eCIiIli2bBmlpaXo9Xq8vb1ZsmRJi99n4MCBZGdnk5KSgqIovP32283qTJkyhZycHCZMmEBgYCDDhw+noaHBWR4cHExoaChRUVGYTCYADAYDK1asICUlhYyMDBwOB/7+/qSlpeHv709ycjLPP/88Pj4+xMXFNbnfwoULiY2NbTJVDGCxWFi0aBE9evRg9uzZzmd+I0Hej92ONq+mU9saC+1gDoeDOXPmEBsby9NPP33N+mVlZYwbN46cnBznwkgh2rJr165m/5ABcnJyGDNmTAf0SAjRXgoLCxk4cGBHd+O6hIeHs3///uuaruss8vPzeeutt245ybrFYiEuLo5169YRFBR0w9dXV1ff8DVeXl43fM2tKiwsdAbkVxgMBkJCQlqNWzrdSNrVkpOTcXd3d0b5QgghhLh7ZGZm8vvf/545c+bcVIAG2g7Tzig6OvqW2+i0Qdpbb71FaWkpK1ascJ4/IoQQQtyNOmug0ZaYmJhbHkWLj48nPj6+nXp09+mUQdrvfvc7CgoK+OMf/+icnxZCCCGEuJd0uiDtu+++Y8WKFfTp08d5mnKvXr1Yvnx5B/dMCCGEEOLO6XRBWv/+/X+Sw75CCCGEEO1JFnsJIYQQQnRCEqQJIYQQQnRCnW66UwghhLgbxcbGYjKZmhxmu3z58mue6zl58mTWrFnjzHd5K7Kysti5cyfp6em33FZb2usMteuVkJBARkbGNZ/RRx99RHFxMTqdDoPBwBNPPMF9990HaGezrl+/nry8PIxGI/7+/vzmN7+5Zllbbd4qCdKEEEKIO6StBOutaSl/pbg5TzzxBO7u7oCW0iolJYUVK1ag0+n47LPPOH36NG+99RYGg8GZLgtos6y1NtuDBGlCCCHuCStL01otezr4BQyK9iPxkxMraHDUt1jviZ7P4GHQclP+5eR/U22rZE7Ir2+5b+Hh4bzwwgvs2bOHiooK5s2bx/jx451l+/fvx83NjaSkJPLy8jCZTLi7u7N69WoANm7cSEZGBgC9e/d2ppWyWq0sXryY/Px8AgMDCQ0NbXLfDz/8kK1bt2K32wkMDCQ5OZlu3bqxfft23nvvPRRFwW63k5iY2CRlI2ijZUuWLGHQoEEUFRWh1+tZunQp/fr1a1LPZrPx3HPPUVFRQUNDA1FRUbzxxhuYTCYeffRRUlJSiIqKArRRKbPZTHJyMmazmZSUFCoqKmhsbGTWrFlMmzYNgG3btvHuu+/i4+NDWFjYdT/nK8EUQG1tbZPE9H/961/57W9/i8Gg/T3o0qXLdZW11eatkiBNCCGEuEOuzt2p1+ubTAfqdDpWr16N2WwmPj6e6OjoJvk7i4qKyM3N5dNPP0VRFOdozpEjR0hNTSUrK4uAgADS0tJITk4mLS2NNWvWUFZWRnZ2NjabjYSEBOf06qZNmzh+/Dhr165FURRWrVrF0qVLWbZsGenp6SxatIjo6Gjsdjt1dXUtfp/i4mJef/11RowYwYYNG3jllVeaTXHq9XpSU1Px9fVFVVVeffVV1q9fT3x8PAkJCWRmZhIVFYWqqmRmZpKeno7NZmP+/Pm88847hIWFYbFYmDZtGkOGDMHHx4fExEQyMzMJDQ1l0aJFTe734YcfMmzYMIYPH95in9etW8eePXuoqanh17/+NTqdjtraWqqrq8nLy2Pv3r3odDomTpxIdHR0m2VttdkeJEgTQghxT7jeEa+E4Oevq97jPf/1hvvQ1nTn448/DkBoaCiRkZEcOHCgSW7h4OBg7HY7CxcuJCYmhrFjxwLaiNaYMWMICAgAYObMmUyePNlZNmXKFIxGI0ajkUmTJrF//34AduzYQUFBAVOnTgXAbrfj6amNEo4cOZKlS5cSFxfH6NGjW+1zSEgII0aMALS1c4mJiVgsliZ1HA4HK1euZPfu3TgcDqqqqpxrx6ZMmcLy5cuprKzk4MGD+Pv7ExERwdGjRykpKWHevHnOdhobGzGbzSiKQmRkpHNUMDY21jmiCPDss8+2+Wcwffp0pk+fzrfffktmZiaLFi3Cbrdjs9lQVZWkpCTOnDlDUlISwcHBuLu7t1oWGBjYapvtQYI0IYQQopNRVbXZaIyXlxdbtmwhPz+f3NxcUlNT2bBhQ4t1r26nrXvMnTuX6dOnNytbsGABxcXF5OXl8dJLLzF79mxmzJhxU99l8+bN7Nu3j08++QRPT09WrFjBsWPHAHBzc2PixIlkZWXx9ddfk5CQ4Oybr69vi+vxtm/fflP9+LFBgwZRV1fHiRMn6Nu3L66urvzsZz8DICgoiD59+nDs2DFiYmJaLbsSpLXU5siRI2+5j3IEhxBCCNEJrF+/HoBjx45RWFjI/fff36S8vLyc+vp6Ro8ezfz58/Hy8uLEiROMGjWKXbt2cf78eQDWrl3Lgw8+CMCoUaPYtGkTNpuN+vp6srOzne3FxsayatUq57Sp1WqlqKgIALPZTHh4OLNmzWLSpEkcOnSoxT6Xlpayd+9eQAvGBgwY4ByNu6K6uhpfX188PT2prq5u0geAJ598ko8//piCggIefvhhAGfQtHHjRme9kpISLBYLQ4cO5fDhw85Ab+fOndf1fFVV5dSpU873ZrOZS5cuOUcgR40axcGDBwGoqqri+PHjBAcHt1l2rTZvlYykCSGEEHfI1WvSABYvXszgwYMBMJlMzJw5k4qKCufC/6udPn2axMREbDYbdrud0aNHM2TIEBRF4eWXX2bOnDmANi2alJQEwIwZMyguLmbChAkEBUA59ygAACAASURBVAXxwAMPcPLkSUCbaqysrOSpp54CtCAmPj6eiIgIli1bRmlpKXq9Hm9vb5YsWdLi9xk4cCDZ2dmkpKSgKApvv/12szpTpkwhJyeHCRMmEBgYyPDhw2loaHCWBwcHExoaSlRUlDNft8FgYMWKFaSkpJCRkYHD4cDf35+0tDT8/f1JTk7m+eefx8fHh0GDBjW5X2tr0lRV5U9/+hM1NTUoioLJZOLFF1/Ew8MD0HZp/uEPf2Dr1q3OZ9ejR482yxwOR5tt3iqd2tZY6E9MWVkZ48aNIycn55rnzggBsGvXriZrPq7IyclhzJgxHdAjIUR7KSwsZODAgR3djetyZQdne/1wvxPa6yw0i8VCXFwc69atIygo6IavvzKS19lcvbEAtL+PVwLyKwwGAyEhIa3GLTLdKYQQQogOkZmZySOPPMKcOXNuKkC728l0pxBCCNHBiouLO7oLNywmJuaWR9Hi4+OJj49vpx7dfWQkTQghhBCiE5IgTQghhBCiE5IgTQghhBCiE5IgTQghhBCiE5KNA0II8VNgrQGrBWz12sthA6M7+PbVyhsuAToweYBO/v/dGcXGxmIymZqck7Z8+fJrHhk1efJk1qxZ40yldCuysrLYuXMn6enpt9xWW9rreI7rlZCQQEZGxjWf0eLFi7lw4QJubm4AxMXFOY9bqqqq4oMPPuDChQuYTCZ++ctfOpPFt1Zms9lITEx0tm+1Wjl37hy///3v2+V7SZAmhBCdieoAy1moOg5+/cDdH2rOQ+67zet694QRL2i//+5TOHNAC9DcfMEjEDwCoPsw8Oh2Z7+DaFVbuTtb01JqJHHznn76aYYNG9bs8zVr1hAREcHUqVMpLi7mgw8+YNmyZeh0ulbLDAYDb775prONTz/9lIKCgmZZF26WBGlCCNHRqk/BuW+1wKzqBNgvn8Y+YCL0flALuno/BK7eYHAFvSvoDaD/YUSGgMHg6quNqNVegAoznD8MgZcPz6wthzN/B//+4N3rnhxtazx7rs1yg78fOoP2Y9FRX4+96lKrdXVGAwY/v3brW3h4OC+88AJ79uyhoqKCefPmMX78eGfZ/v37cXNzIykpiby8PEwmE+7u7s7E4hs3biQjIwOA3r17OzMWWK1WFi9eTH5+PoGBgc6k5Fd8+OGHbN26FbvdTmBgIMnJyXTr1o3t27fz3nvvoSgKdrudxMREYmJimlybn5/PkiVLGDRoEEVFRej1epYuXeocfbrCZrPx3HPPUVFRQUNDA1FRUbzxxhuYTCYeffRRUlJSiIqKAuCjjz7CbDaTnJyM2WwmJSWFiooKGhsbmTVrFtOmTQNg27ZtvPvuu/j4+BAWFtYufwZ5eXm89957zmduNBoxm82EhYW1WXa13bt389hjj7VLf0CCNCFaJNkGxG2jqlBzFspLIHiUFixVHoPvd4DJE/zCoEtv7eV9eRpMMcCAR9puNyBSe119n4ZL4OKlvS//DszbtZfBTRul8+8PXcPBxfu2fNXO5ug1/l2Hbf0MU0gIAJYdOzg57+VW67pGRtI3a/0N9+HqtFB6vb7JdKBOp2P16tWYzWbi4+OJjo5ukhqqqKiI3NxcPv30UxRFcebcPHLkCKmpqWRlZREQEEBaWhrJycmkpaWxZs0aysrKyM7OxmazkZCQ4Jxe3bRpE8ePH2ft2rUoisKqVatYunQpy5YtIz09nUWLFhEdHY3dbqeurq7F71NcXMzrr7/OiBEj2LBhA6+88kqzKU69Xk9qaiq+vr6oqsqrr77K+vXriY+PJyEhgczMTKKiolBVlczMTNLT07HZbMyfP5933nmHsLAwLBYL06ZNY8iQIfj4+JCYmEhmZiahoaEsWrSoyf1aSwt1RWZmJmvWrCEkJISZM2fi5+dHdXU1oCWxv8Lf35/y8nJnHs6Wyq4O0sxmM5WVlQwdOrTF+94MCdKEEOJ2a6iG8qNw8TvtV6v2AwGfPtqUZdAQ8B8Abv6g07XPPXU6cO3yw/ueI8AnROvDxe/gQiGcOwQDHoXeP9OmWb/fAS4+4OqjXevqA3pj+/RHAG1Pdz7++OMAhIaGEhkZyYEDB5qkrQsODsZut7Nw4UJiYmIYO3YsoI1ojRkzxhlMzJw5k8mTJzvLpkyZgtFoxGg0MmnSJPbv3w/Ajh07KCgoYOrUqQDY7XbnNN3IkSNZunQpcXFxjB49utU+h4SEMGLECEBbO5eYmIjFYmlSx+FwsHLlSnbv3o3D4aCqqsq5dmzKlCksX76cyspKDh48iL+/PxERERw9epSSkhLmzZvnbKexsRGz2YyiKERGRjpHBWNjY50jigDPPvtsq89/7ty5+Pv743A42LRpE++//36zIO9m7dq1i5/97GcYDO0XWkmQJoQQ7U11QF05uHfV3hdv1gIinQJdQrQRNL9+4NVdKze6a6/bSacDzyDtFfIQ2Bu1ETwP7Qc7NefAnNP8Ot9QGH75h96Zf0BjrdZvz+5gcGlevxPrt2tXm+UG/x+mLz1jY9usrzPe3h+fqqqi+1HA7uXlxZYtW8jPzyc3N5fU1FQ2bNjQYt2r22nrHnPnzmX69OnNyhYsWEBxcTF5eXm89NJLzJ49mxkzZtzUd9m8eTP79u3jk08+wdPTkxUrVnDs2DEA3NzcmDhxIllZWXz99dckJCQ4++br69vierzt27ffVD8A58ikoijExcWRlZWFw+FwjpJVV1c7f3/x4kX8/PzaLLvCarWSm5vbZBNBe7j3FiUIIcTt0FirLdwvWAO7l0D+/wWHXSvr/TO4/2kY81uI/jfoOxa6BHfsujC9UZvuvDLa5hEAP38Vop+D+56AfnHQa6QWpF1xai8U/y/s/QPsfAO+WQHff67tPP0JMAYGtPnSXTUCori6tlm3PdejXbF+vTZ9euzYMQoLC7n//vublJeXl1NfX8/o0aOZP38+Xl5enDhxglGjRrFr1y7Onz8PwNq1a3nwwQcBGDVqFJs2bcJms1FfX092drazvdjYWFatWuWcNrVarRQVFQHa1F14eDizZs1i0qRJHDp0qMU+l5aWOhOcb968mQEDBjRbNF9dXY2vry+enp5UV1c36QPAk08+yccff0xBQQEPP/wwAH379sXV1ZWNGzc665WUlGCxWBg6dCiHDx92Bno7d+68rudrt9ud3xUgNzeX4OBgFEX7dzhixAhnAFhcXIzVaqVv377XLAP45ptvCAwMJDg4+Lr6cr1kJE0IIW7VP/4HzhcCqhZ4+fTV1nqpdkCvTTN2djrl8jSnT+t1ohK0nabVp+HSCbhQDCV/g54PaOUN1dr6OaPbnenzT9DVa9JAOxJi8GBtc4fJZGLmzJlUVFQ4F/5f7fTp0yQmJmKz2bDb7YwePZohQ4agKAovv/wyc+bMAbRp0aSkJABmzJhBcXExEyZMICgoiAceeICTJ08C2lRjZWUlTz31FKCNXsXHxxMREcGyZcsoLS1Fr9fj7e3NkiVLWvw+AwcOJDs7m5SUFBRF4e23325WZ8qUKeTk5DBhwgQCAwMZPnw4DQ0NzvLg4GBCQ0OJiorCZDIBYDAYWLFiBSkpKWRkZOBwOPD39yctLQ1/f3+Sk5N5/vnn8fHxYdCgQU3u19qatMbGRt555x1sNhuqquLn58cLL7zgLJ85cyYffPABX3zxBSaTiblz5zoDuLbKQNswcDvWMuvUtsZCf2LKysoYN24cOTk51zx3RgjQ1hBcvebjCpvN1gG9EZ2e3aqtKbtQrC3Mj7y8i+vIX8FWB/7h4N9P24F5L1BVqD3/w5Rp8WY4tQ+CH4SQn9/+KdxrKCwsZODAgR3ah+t1ZQenh4dHR3flurXXWWgWi4W4uDjWrVtHUFDQDV9/ZSSvs4mOjm7yvrCw0BmQX2EwGAgJCWk1bpGRNCGEaIvDDmV5cLEYKr7XDpFFpx0iq6raWq9r7by8W+l0PwRoAF0j4FIZHPscTnwFfX8BwT+TzQeiVZmZmfz+979nzpw5NxWg3e0kSBNCiKupDu28MlXVAjGdAqVfaGeXdYvUpjH9B2jHZYim/PtrGyIuHoGSbXB0K5z+O8S8CIq+o3vXqRUXF3d0F25YTEzMLY+ixcfHEx8f3049uvtIkCaEEKoKltNaQHHmH9oRGT59tUX+Op22u9HVRwKN66HTXQ5k+2vPs7Huh+fWcOmeOZNNiPYgQZoQ4t7WWAv7/qQFaaAdIBvyEHS7ai2Tu3/L14rW6RTocdXC7doLkPeeNhoZNh7c2393ZEvaOp5CiDvlZpf/S5AmhLj3qA5tJ6JrF+30fTdfbT1V9yFN11h1EnX2Wk7WlXKx8TwO1cEov18AUG+v4y+nPsJN74GH3hNfY1eCXHsS5NITV30n22GpN2kpqk4f0FJg9YqBvrFaQvjbxNXVlYsXL+Lv7y+Bmugwqqpy8eLFayZ/b4kEaUKIe0v1aSjaCFYLjPy1tqj9/v/T0b1qptx6nmO1RymtK+Fcw2nn50adkZG+Y9DpdOh1emrtNdTaa7jIOY7XmfnH5XSTPV1D+JfAaehRfshiUH0KrLWgKGDy0lJG6V3aL8tBW1y8YdAMLQfp0c+0jQWn9mnP3q99ci/+WK9evSgrK3OeHybuThcuXOjoLrSosLDQ+XtXV9ebOnVCgjQhxL1BVeHk13Dk8kGafX5xZ4KTm1Bvr2P9qf+HAwcA7noPgt1CCXAJwsf4w9SrUTHxbMjL1Nlrsdgvcb7hDGdrzJQ1nMBuOYW+5F3oEoJj0HQaHHW4Ff0vVJU2vZnRQ1tz5xmo7VzVKbf3kF2v7jB0tnaUybGdP2RdaLgEOn27jqwZjcYmB46Ku9NP5ZiVmyFBmhDi7mdvhMIsLSOAZxAMfhI8unV0r5yqGis4eGkv0T4P4qb3wFXvxiDvoZh0LoS4h9HVFNjqdJ2iU/AweOJhtRL47W7uqzmLHagzuYB7d/Doxnc1h/ny4nbu7xnK0OCR6B0ObSTReklLB+XmqzV29pAWxAYN0aYjb+fUr18/7XXF0a3a/Xs+oK0JbOtQXSHuERKkCSHufpdOwNmD0CMawid1mnO7zjWc5kDV13xfewQAb0MX7u+iJat+0C/22g00VIOtXgs4Xbto36vPWPRdB+DpHezcVVlTmYtDtbPPWkypqYKxXSfgZ+ravD2jO7h306YiT3ylBVH9xmubKW637sOgvkq7b1m+Fij2GdOpgmkh7jQJ0oQQdz/fUIj5FXgEdvgUp6qqnKj7ngNVX3O64QQAroobg7yGMsDzvmteX19URNWGLBpLDmE7fQKbxY7qMOKor0fnYsLUN5SAX79EfeEerOYSGo4dw99mY2xdDdX15dS7wV9/bSZq0EQGew/HYbFgr6rC2LMnuq7h2vEZlrPaAb6n9sLXy2HEr8C7x+19MH5h2qvqhDYNenofXCiEh17TUk0JcQ+Sv/lCiLuT6tDSNfWM1qY4PTvHaealdSVsPbcBAC9DF6K8own3vA+jouUsVFWVxpOnqC84RN2hQzQUH6H7G/+FsWdPVHsjVf/4jPKP/6flxqvhopud2qeeQtfCjn/Xyy9VVcmt+JwqWwVD/q6j7IVfYQgKwj06Gq/xD+M1Zgy6iMnaSNaZf/ywbqy+SttscDvXrHUJ1jYT1JzT8oReCdC+3wnePbXRvU66llCI9iZBmhDi7lSyDU7sAR0w4NEO64ZDdXCq/ji93PoA0NstlD7u/QhzjyDUIxxFp2D54ksqDxygruAQ9YcKsJeXN2nD/I/tnDD6cdpSjL1vNWEP9qbBzx1TZR1BJ1RcB0TgN3MGe059ioUaev15L8bKehoCPPH4vhyjxepsyxAUxOiyEHb2qMXfFEDjyQMA2M6c4VJ2Npeys9H7+NBl8iT8Zs/G2Ody0mhbA+z9g3Zm3H1P3P6MCx4BP6yJa6zVUk3Zrdp0bK8YbTr0Nh7fIURnIAnWxT1NEqzfpc4dhoP/o6Vvuv/pDskU4FAdmGuK2VeVS2XjRSYGzaS7oTsNR45gt1jwGDHCWff7adOp//bbJtfruvigHxiJLiSYfbEmKkOMoKr0OlSFz1+/x2dPAUpjIwCqwUiPlMWYxk9g+8ELGO019PnXCW32z947kJ6L3sDnwdE0lpVR+/U3WL74AsuOHahWLajTGY0E/GY+fk8/re38NOdoU5EuXSDqSejSu30fWlusFji5F07mQ33l5cNyo2HgVK1cddzeET4h2oHBYGj2XhKsCyHuGFVVqa+vp6amBovFgs1mw2azOU9+NxgMGAwGPD098fDwwNXVtX0PGq2vhMPrtEDivifueIDmUB2U1BSxvyoXy4VTeBeeI/JILTVHfkPx4e9Qa2txCQ8ndNNGTlc0UGlpxBo+BIdO4VJYV2oGu3O+nzuBLuMYXFVCT9t3nDDdR5+Mb/Dd8SX2i+XN7qmzNVJ38BC68b8gMsQI9kCsPYJRay3o7DZ0NTXgcDS5Rn/8LKee/3eObEjB+2gF1r/8heBHZ9L1Vy9Qm59PecZKGk+exNj7ciCmGLRNBD4hULAG9v4RBkyAXiPvzPSjyVNL2N5ntJYb9OwhcL9q80P++6AYtcDRp7f2q0sXmRoVP2kSpAkhbonD4aCyspLKykrKy8upqKjAbrejqip6vR69XguSFEXBcTlQsNvt2O127UBWvR5fX1/8/Pzw8fHBx8cHRbnJERFVhYK1WjL0IU9ruxXvoDP1J9l54VNsRUeJTPkct1OXnGVXj83arDbUxkZKLp7hlL2Ymme6YVUecJb72w1EnPobPWwO6D6ch3yH892632L/0cSHGuRPXVQIl/p04eAgC5Wn/8DQLiMZEfAQjpzPKLi0n9yKz1HsOvxr3fG4oMf9JBgOfg9lhVT3c+N7QzF9cvfS+0AJZw8sAZ0Oz7Fj6Z6yBFtFBZ5jxjjv13j2LDpTIIYRv4KDf9aO6/AN1c5Yu1N0ipYdomvEVQ/Coa05rDquTXGf2KN97uYLD87XrnHYJfeq+MmRIE0IcVPq6+s5e/YsZrOZ+vp6DAYDrq6udOnSxRmYXQ+73U5dXR0lJSXYbDZcXV0JDQ0lMDDwxtOo6HTQdyzUngefPjd27Q1quFBOzYEDNP7jANV/P0D1o/FcjBqIcugQYVnFzgBNBe2Ef50OnapCxCC8Mv4f1Y06jL4n8X/z9/T99iyKwYRLgwNj5SXU2kbq7CoXnv1XvHpEYuzeG7cxD1GXm4/bkCFU/TyMA4Os1Hf3ajJSpFPhH5X5HKzMx46KrtGOsdaKsdbGJX01F4NccPQxwM/96eGSQD/XcAy2Mk7//AL6GisBO80YLVYsO3Zg2bEDjwdH4RIWhmv//jgaGij79xewl5fT8/103B6YC5Xf/xCg2RrA4HJbn3mrdIo2agratGjVcW2XqK3+hynQ4s3a5z2GadOkhhtP0SPEnSZBmhDiuqmqSlVVFSdOnKCsrAxFUfD29sbb2/um29Tr9bi7u+Puro16Wa1WioqKOHz4ML169SI4OJguXbpc/5Sof3/t1U7sDhW9oqOy6CjHP/0cxzdfYThahP5SZZN69YFheA4dSWBtFIZ/bHN+roMmU401jiqKiqtwLzlEz/cW4FVd3WQn5tWTkhf++BHfuZdT5NEdj988hFv9w/Sf9jqm/HyGuxnB1xuLn4H6rh44XAzU9fDi1ORI7K5GXM5VE/P0X5p/H5Oeup7e1IT6kT9rOA0BnhDmT3BlPUaLlbO/6ItnlQGPv39HzVe5mKdMpeG3qXQP64H1+HEcly5R+mQCPZel4vVP/6Q1WnsRvlkOPUdAn7EdF6yBNi3aLVJ7Xc21C1ysgyNboORv2rlsfcbIobmiU5MgTQhxXerr6yksLOT06dO4urrSrVu325K02mQy0bVrV1RV5fz585SVlREUFMTAgQPbHlk7nAV+odquv1tQb7Vz+uwlLhws5GL3/rg11hH8599R/+VujHW1LV5j+cVIPGLHYZo1AbWyotW2q0N9OfPyGCa676Ch9kuOX6puVkc16LG7GbF2MdHo7UqZXy2NqpVK/Wnqqn+or69rhLqLdDkFXa66PnTmrzB16YbNtwa7cQO6xqabYPRWO57fV+D5fQXVT4/gtMME9jptqhgI3Pk9pQlD+C7hEfp/kI+7ReFSvyi+b1TouuRDAtNex1HyHWUv/Zqe77yN9yOPaKN5nt3h2C44/Xdt7Vrg/Z1rerHvWC0oO18EZV9p58Cd/Qf8/D+15O9CdEISpAkh2qSqKmfPnuXQoUMoikJg4J1Zf6TT6ejSRQs/ysvL+eKLLxg8eDCBgVelSLI1aOdpNVTDqW+0E/dvIkirq7OiHj6EZfduynK+xNVcjAfg8c+PwNbNNHB5RKwFbr/7LwY8NAG9pydHUnTYW6mn6sDHvSsPNFSjO18AAwbhNbYWq7sXnsFh0D8E+vbibyf/gtJg49J9P5zr5n6iCo/vL+JWWknVwG54HKvEUNfY7B52Hx+q6wfg5tDj4RKI8eFHaNjyvz9U8OtCbUR37OcuoGu0YdhexMDe/bjQXU9dD29UnTZlGvLJAeyuRva9PxHXsxaCe/+dPrqeFFTvp+63TxGWto7Gvx/i5Pzf4Giw4jN1Cgx7Bs4VaCNV3/5F2wl630zt3LPOQqdAQKT2unRSO7T3SoBmOasd+SEbDUQnIkGaEKJVV4+e+fr6YjJ1zIiDj48PVquV/fv30717d21UzaDT1hipKnz3V9C7QN/rSKV0maqqnNl7iDOfrMbw1U4Ml7QRMLcrFYwGfLv78+NxMVUHql4BvYLq7krlls1Yftafii/30m/6Y1Qf2Ie9spxaXQMoKi52Bya9J67/8i94Rw2jwXCJc+5uVP+f/4A6K4rdQQN/c7Y/7PKvll/GUFXtzoknIvDLO05oxjetfhdT7yB6/3YW3+vvx/XsSZTP1mA/cgBb0feAdpSG2tgI5VW4f1XlvM7zf/4O/J2ul7/X1dOuoRnfgAplMwbzXc1hFIrwPHyaHonbKHjmAbrbe+N98DinX3sN1WrF94kZEDhYW9B/6hs4kfdDTtDai9r6MK8enScI8u6pvUAL0PLf16bJBz6mHdgrRCcgQZoQokXl5eXs27fvjo6etcVkMhEYGEh5eTlfffE50f0C8fbx1UbS6i5C0BAaLHVUHCnCN3IALt6t/6AttzRy8Lty/P+/53CtrmxW7jC50O0vayk/fxDjjt40Hj/uLNOpoLM5wOaABgv2vd+ypzyH+9/NpvLwOWe9q/eV2jlPzeEPqAFOT7qPY/GDGWWpb/P7embk4wmcfcgLm6cJJagrCgbsVVUoehXVbsfRYAOHiv1iOSXPvYNqd3BlQvjqfaDq5fPU0Omwu3mg1NWgU1VM/cNQG6w0nijTNjX8SOjKb/A8a6DohYE4dA6C1x7EUNtIePpXlPzbCGwmO357T1L25U66PD5d25WrN0Lwg9Br1A8BWekX2vlmnt21DBBBQ8Ho1ux+HcbVRzsg90Qu5KfDoCfAv9+1rxPiNpOT/4QQzZw7d468vDzc3d3x8elcC6v9ungQ4NLAt0VFlFdZsJ49wFkXAxa3YMp3/Q1b+UXO5+2j4UfrvVRVpc6sjSwZFB0e58swtpQ7CTj/3C/Ym5WE+kxikwDtavWBnhx7aignpw4iQO+PV0BvdP4+qF1ccbiZcHi44vBwxebugs3VgM3NgN2kx2bS0ejtwsGU8Rx4dwI2t6bJ3lUdWH3dqA/xwxrVgyEXa3loUBAD3nmS/js/p8vkSSgeHjjqGsGh9d9eY0W1O1rqpkavXHkI6GstzoDMcfEUvZIex+9/3sf7355BVXRYvV0omT0ch1G7JmBLLgOX5OCh8+DIgodRHvo5AGF//Bo1dhTfPzuK756cT8Hxmqb3vHrELOQh6PMLaKzRdll+kQIFq6HhEp2CwQXCJ8LQ2dr7v6+Eo1u1YzuE6EAykiaEaOLMmTPs37+/Q6c3W6OojXjYylFNrngoLhwq/pZgHws6UwAXDx2mi7ELrqZa7A3VnN+TR7efjcTF24uG48f5fuEi7Af202v1Guq3bMbzo49oLeFKY1kZlWP6wsegdu+KY0Awjl5BNPq74OFl4oB3NR7uRir6+mHX6bDaLlL5bD8CPtdhuNSAsboBQ20jer2JRsWG3cuNuq6unJo4ENVowKiqcF8QXh49CV79MJ4XT6LrMYQq326YjCbcv3yXxov11J12oJ7vgu8vpkOXYFS7nfpvv6Xx7EUAdK6u6FxdcVgs8KMsGa5PTKXuaDG6fYehhQBOBWoMevL2fEnAh++iQ1t3Z7rUQOhH+2js4oJidWCoa6Trl6U0rNiBZdYTfDtrBgPqk9B/swe/1PV0fec3dI8KRlF01Ngs5P/19zww/jm8XK7a8evur20mCP0n7SDaU3u1Xwc+dvmB12pHYnR0xgD//hDzIny7Fk7tg94/l9RTokNJWihxT5O0UE2dP3+eb775Bj8/P4xG47UvuIOcARoKDp0BKw4uKDU0Vljodr4GNxc9usoKXHDQePw4Hv2jUP36ohwzU/XHP6Jr0KYXvSZMoHrLFkALVK5eIVUd5seRlx+iISwIh82GYqnD1uXyBKJDxfX0JR7JPU716Xoay6wUzI7kQoQvimrE7Xg5w59rfuSFkw56vz8ZV4woRg+q95VQvfd7jN3ccdTb0XXrR2OjG43HjtFw9DvUGm0nqeLujtsD0djOnafx1CkcVdqaMsXbG8elH41EuZho7OFHTYArpdMGYvVxY1i+AzbvRDlX2ermh+vV4O/O8f+fvfsOj6O8Gj78m5ntu+q92bLlKrljsDHYdFwwzZgaeucleQOElxACBEI+SgghEEICARLTO4E4YAJuuOGGK66yrF5WZVW2787M98fIkoULMqjaz31duiTttGfk9e7Zp5xz/xyiSaeQ+cQDxH1bjWpRcP/hWiaediPb3/8bsQ/Po37yIJJ+9wdGZucf+mRquH3S/uY3jHlhg8+AtDG9P29Ncy0B7wAAIABJREFU14zKFfZE43dvtZEsVxB+JFEWShCEH6SxsZF169aRkJDQLwI0jymA2R/FVlZHSziE4g8he+sJ7CwCJNRdpUg1LVDlRgLkrGyS77mLuinZRFZ9hbmhpUPQ0jgmnaarTseZm4tetB1nqQfXrjokCRK31mHbU48ciVC33zH5vywGi4mwrKLazQRTnHiHJuMob8YaiKI0+FtzpOmgQ+nPPjGGHF0WtIiOHtp/hWbRQe9d8/vxLf2q/QFJwjZqFEpSErLZjBwbS5VaRbO/DnOjH5vbh2tzPWNWFx88KJNlHJMnEzoxH8/WNThW7sQ7LJXGEUnkvmEUW9ck0C0mlJDxYUUHNJOMtd7PkDtfJ2p/m9pT87B4fNgrW0i+7zU+mBdlTJVRsirp6714b76Jpff+iilTZmE2HaSHbF+AputG4uHGEmMItGq90cPWm/nLJLk9QNtXBzZnCgydaZTHEoQeIp5tgiAQiUTYsGEDMTExfXeIc/8AzRzE5AuStGMDPj0WpaGJcMCLtLcEqaYek8eP7g8jYQQYaloSmuSn8PlHaVmYQmajt+38jaPSKLlyHGOLYpHmLSSz2IPZaxQYx6RA9DDzkkIhCIWwADQFiQxOIdliRmrwoe87x/5aBy7Ug207HJsVolH0GCdqRiINMRFitADmCjfBL77AQceFCvtTU+JQxuYTO3ES+rY9tHzyb/wrV8LKlSSkpoLJQdZ5N2CfO5vqaf/F/7s/IZe5IRQlkO5CNyvokkTDxCxyPvwWCTAHomR+thMATZYIDMokYWUxW6akEp9wGsOeXoarqAH7T+9l801bmPA/9yAdqgqFJMGAkyDreCNtR8kyWPU0DD/fqA7Q2xJyjcS4ZSuNQHL05cbwrSD0ADHcKRzTxHCnYdu2bZSVlZGcnPz9O/cwR7QeRYugyta2AE32hTAVVqKrGiZ3LXKwGW33HqQaD5bmACZvGAVQMVZH7etRUk0ysqYjaTqBVCfNQ5NJ2ObG7AkcdihQa01PoUsQSnVhq/F2aujQNzCeYKqL+E1VKGYL+AIdtuuAajMRyIlDtZhoyU8je1cQU1kdckwMwbAXzevF3BL6/r/TqdNQhgwinBFPla+YlAYT6eMnETNpLNGIH1Q7zZ8vwbd8BeE9e4hUVnY43pSWRvpvHyZcUor70UfbHo9aZYpumUz1rBFkvb+FwS+tPey977rvPMYMvoTgo/dCUbnx9xuUCTf9krzZZ2CzfE+C26YyI89a9mQYMOV777tH6LoRpO3+zOhJy59jDMsKwhESw52CIByRhoYGiouLSU1N7e2mHFRQicWpNxDVw3gs0UMEaEVI1Q2YG/3osoRqlpEiGt8NBxrHpuMsbcJa68PuNr46Q279KBt1Wtj58qWMeHAB5sYAktuL7GvtFdvv467vlAKiaXH4xuagRaMkrf0AwoEDzisBkdQYtjw3Fx0ddJ2EJ1fj2tSA2tCAAm33oCsy4TgrzSNS8A9KNFJvOC1EHWbCSQ4ax2Sg2RWgBVOLi+SvSgh8/CINzzTgr2hCCqnt5/nnxWRUBNGXlOH5YiOoGtGaGspvuRXHSVNIvPEGPK+9jh4KYQppDP3zSprGZlIxdzTNQxIZd+/nBwRq+/Ks5b6xnsbzRzD2o/ls+ek1WJZtQt5biXb/HWx+YxCWgrEMmHwycVOnosQcJE1KXA5M+ln7sGKwyVhU0Julpvb19sUPhC1vGZUVUgr6VkUF4agketKEY9qx3pMWiURYvnw5FovlyIuZ9yBVDxKiGlBQCqvB04Li8bQHaDV1mD1+Y+5ZRMMU1Q/a2xNMsGHxBA+ZeyjiMKPazfgHxGNLdNCSHUc0ORar3UlGWCehuR5fooPtSXZCgxJRZQXVHkvc/K1Y9rqxtYRJ9pvRohrRYBC/twHFF8Z9eh4tw1KQw1EsngCDX17X4bqaSUa1mYjE2VCtJhrHZxJOchCNtYHNij/BQsuwZDArxJsSSbdmEBeFsmAJlZIXk6ZjN8dhlx2kzltKwmsrOER2EaJOCys/uBKAlB21jPzFfFAP3NkyaBCS3U5o2zYAbCeOY9evz6HYVIW9vJHR932O7TBBbsvsiUi543H87WXk6EFWlyoy8eedR+Zjjx3yHKhh+PpZox7n+Gv7RlH0aND4ssUbKTo8eyBpWG+3SugnRE+aIAidtmfPHsLh8I8qkN7dNF2iUdGAWOKiXtREF6ZvdyNFfWjFpUjVDVg8Ri+VElExHWQKmd76ZfO0J5DVTDKSqlM/OYeyi0cTdVoI5MSBLJO0opiBr20gYU0ZSiiKElaJAPtS1caPTGHL76aj2mTQvWQu30HCBmP4cP/ZZvvmiZkyMlDOmkRjyI3a4jsgSJOjGrI33DYXrurZ66g2GbUOsv69k/G/+wJdltESXFhirFgkFU3VGN4SIt9lI+Wi04i5/qdoYZ09n754sJirjcls46TbP8eb7aJuWOxBAzSA8N69YLHgOuMMvAsXEly1kbz/aSDtuZ9TtPsT1r1wIfmPLiFxrTGkKY/JRM7IIrRuJ0p9MzHz1yHHF6KdMBV18wZaRg0nkKXjKK3DtakMJazS/Omn+GKTibvmclIyMg6sBatYjCSzuz81erDGXdP7aTpMtvZgsWIN7PzEmLM27Jz2xQaC0EVET5pwTDuWe9JCoRCLFy8mKSnJyBTfR4U0MxFJI2RuwOTzE7NzO7qnHlZuRKptwNJkBGi6rmEOaQf0kn03zQZAxGmmavow7FUtuIoasNb50E0yFRcUENMYxOqy4fhg8+EbZjLhvOAcTGnplPmLMK/ciqnBi26zoDnM6A4LmstCckwyscediXPyZHZGFuLxV2EuaUQORcGqYNLBFDOUdNMgbFXVRDf8B/nckUQliIlqNL+/hYaFhYdtipKSDFEV17Sp6JpOpLwcc+5A/CtXEa2pOeRxCY8+hCspneCuXfi3bKH5q8UowY7PfVN6Ckk33ETN758kduZZULOd5tV78Zw+km23TWD0A/8ldkctdZNz8PzyVMaU+PDf+eFBe/JUi0LFhQUkxQ3ANe8L9JAx1061W6k+ZywZe0MM+r97cYz7Tv3VwgXGEOPAqTB01uH/XXpSNGgkvS1fbQSP2ZOMQu4WV2+3TOijjrQnTQRpwjFt586dFBQUHPD4sRCklZSUsGPHjj65WGB/mi4R0s1oUhS1ZANSSxDLplWYt+7GUuttmwwlaYBq9KTtW9V5wLyp1u/fN+k/8YwhSM4kGr8uQlIUolXVh91/yNKl1D79NE3/+tch97EfP5H4iy7CkpONo2AIO6ecjuYPgCwjO+xIJjO6poEaAU0j96k7sA7MQlNlPAvW4n5+3ve0GsxZWQxZ+GXb7/5161C9XmPulySjBfxofj9qfT2hPUUkXXct5sxMAEoXvIvvjt+gSxDMisfeFAJvAHSQLAp6WAVJwpQSQ9Rt5GcLZsZRdVYeg+Z9A8DWh8+kYdIAktdV4VpfQtZnuw4I+gACGTGUX38WE7w5+F9/DbW+oW2bLkH89deS8fM7kfatNNY12PQq1O00etOSR3zv36JHtVQawVr9LqOG7JS7wNp3e6eF3iOGOwVB+F6aplFUVNSnhzn3kSUdKxFCuhkpdQRhz0rUhkbstfvmQ+lIqpGHDFkmio6iHjgnbd+sqEP2GUpgyUzCNnIYjnMvImb6OexbShHYstU4R8CP2txMpKyMSGUVWsBPtMaNKTmJ2HNmYcnNxbtsGYH16w84fWDtOgJr1+GcOpWcF19AC7QOvWoamvfAuV3lf/wAdJ30Bx7AOv5kkF5FSUpEravvsJ912DAcE4/DftxxOCZO7LDtu78fTmzAQiAxEa2hAXu5Uc80OmIgtromonWt9U113QjQZMlI7lvZxMDXN+DPjsVR3syIZ9ay4Yk0hj6xiKjLwvZfnoKjxMPA97ai+MNGujgJ7FUtDP1/H7L9/ALSXnuOzMXfUPu3v0KLD0mHppf/SeP6b4h//Fkyc9OMXqr8i2HNc0aS2b4mJtMoKdWwBxp2twdowUawxvV+cl6h3xI9acIx7VjtSauvr2fNmjV9dkXnwezrUfNv+YzYf32OubYRky9o9PToevsbYURj/1S8++ajqRKYW1/tNBlks4Jz2mm4TjwRR/5grMNHIdl//DBVxO02UlxU1xCtq0WtqyNaW0e0zvhyTplC2q/vI1JWhhYIUn777UTKyw95vqyn/0jMWWcBoDY1Uf4/t2OfeByO4ybimDAepQtrq+rRKL6VKyl/4Vn09d8ajwHm7Eyi5ZWHP5bW1aqjJ6Ds3IIcNhL1+vLTKbxmHKEkJ1M+2E7SwBHUbihEW70Z1apQdtlJDJn7Wwan2qh8/FEaNq3GXOxG0nRC6WlEHn6O0SeONFJ3qBGjgHt/EA3ByqfAkWyk7HD07R5roWeI4U4RpAlH4FgN0tatW4fP58Pl6l9zZzR/kNC2Lag7V2Ffvw1Lkx85ohk9O619Z0rkwHlpABEZ0EFzWeDE4Si3XE5q3mTSbBk9eQsHCGzejNrUhBYIoIdCxvdgEEwmZLsDx/HHY8nO6vF21Xy9iNKnHsW1pQKAmFmzaFmwoLWCwuE13/ZLkrasJLJ8WdtjnvGZmC6eyJh4hag0lbLb724/l81G4uWXk3D9tZjiE9j85T8x/frPKP4I0cQUKn/7AhOOzyMlrnX4019npOjozaoE30eNQPESYy6dbIKCuZA6qrdbJfQyMdwpCMJhhUIh6urq+vxctINRKstxmM34MuLRUlzo/jCaHkVWdSNJFxKqAqoKZiACYJJAltBl0G0WwrnJ6LJEUrmHhJG9nznePqZvJkVNm3w6zjcm4v3oEygsJe2+XxG48idozXVU3vdr1IbWqg1mM0QiHY6Ne/0vRCUZrFYUpxO1ocFY/brhExbdeiK2n2iUvHoxE2//BFNTAIJBGv7xD2rfeJWEy+cy+qe/wPf6JCouuwpTQy0ZbzyLb8wfSQEItcDXzxh5ykZf1uN/l05TzJB3FqSMhM1vGvVJB06DITPE8KfQaX13SZcgCN3C5zPmPx2Q7qAf0LOysOt+kl0JaOlJRJJdaFYzmklqrbikg6KARTZ6zswSuiyhKRjFxwelEM2MJTY5iWRnLha5b5XA6mtclljSL72S9F/fR1SPsneIhGPamaT8/G6UpDhjJy1K2v13YRuV2XZcSFHRm5shFEJt2G9RAGCpaqJsz2rCyU42P3ImvoyYtm1KWKV53jsU3X0LrrzhbT2Ipm9WEC75Ek3TqfSZjQCtZjP4O87P65Nis43kvMnDoXQF+A692lYQvksEaYJwjPF6vf0yQAPAbic4bBSyKYaEYcNRc1KIJjnRLGZ0k9RaCVwDpLaak7oCksVCeHAKkYwYEpLSSZtwFjHjJvX23fQri+rms7zhS3b84X6qf/MQ9omTjRFmVafm8WeIP+00LD+ZQNPIVNa+eAGey04Ce8eKohKQ9fE2jr/pIxxeSFpdhsPtI+owty300EwyK68axNfeFWTPewFlyECkUAT/nQ+zY/d6Vu9qosR5AqAbdT77A7MdxlwFE28BV3pvt0boR0SQJgjHmPr6+j5dXeD7aI5Y/CMmINsTiR9VgLZfoKaZJNB1dMkosaTLoJu+E6CNP5O4aWejuJy9fSv9yujYiUg6VDXsBsD7+ec4jj8ByeGAqEr1n98g/PZG4ooaiNlVz5Zrh6O9/wBq3vADzmVKSuKS1KsZtCmApGqY/O3DpXJUI2P+Dra0rOejlvewz8xBj7FjrfMR/NnPGREs5Bu3k2DMEKhaDxF/j/0NfhRZMUpeATRXQOWBK4AF4btEkCYIxxiPx9PjQZqqqgQCAVT1IOUAfoD9A7W4UfloA1JQk5yoVguqzYSuYQRoZguhQYkiQOsCmbYcjks4icJbjsd9udEL6V+zhviLLiLhqquMnVQNQlFG3/9fhjy7gi2blyCX7EE3dxxWVqtrcD/8CGlXXkfG758w5rXtJ/tf2xj2+6VEd1fjmbcOk0UyUneUNhB94BcMTbOyIVoAWhSqvumR++8yug675sP2D8Gzt7dbI/RxfTJI27t3L5deeinTp0/n0ksvpbi4uLebJAhHhVAoRDgcPmCFUXdeb8mSJTz55JM88cQTPPnkkyxZsoRQa6b5H6M9UEsiriAfdUAKWrIL1W5BtyroFgvhQYlE013EJqWKAK0LjI+bTJZ9IDuuzsd36SkAeF57DSUmhsEff4B1gJHSRQIyP93J8KeWIUWjSJEw1qFJOMcPApNRlNy7cCFV995LtLr6gIn0EpC2aA/OYg9yKIJa70dxGIGcqbYJ+7/+gj1jBL7cWZD+neoEfZ0kwahLjdJS294z6pMKwiH0ySDtN7/5DVdccQWff/45V1xxBQ8++GBvN0kQjgpdERx1VjQa5a233mLRokU4nU4yMjJwOp0sXryYt956q0vSnBwQqGUnocfb0ZJcBEekEsmIweSII2HkNBGgdQFZkjk9+RzsipP11w6Gi4z8bXXPP0/TZ18Qaa2haqREAVudH9VsBGWh3fX46j3k3j2VzFtPJfa04zFlpBNz6qlIuo4lLw85IaHtWhIw8M2NlF88Bt1iQvNF0BXjvP433mN0qgnnkKlElI7z3voFWzwMmw0BD+z5ordbI/RhfS5Iq6+vZ9u2bcyePRuA2bNns23bNhr2WyEkCMIPo3Uix1VX2bVrF0VFRWRmZmJpLe9jsVjIyMigqKiI3bt3d8l1OgRqw4ZDejLRgSkQ78QRk0g0eTj2SdNEgNZFHCYXp6ecQ4w5noRf30PchRcC0Dx/Pll/fhY5NhY0HdlhRnZaUSIqWmvQRmkjRX/4ijqPj4wLMhky/33832xAj0QI79mD7u84v8xe48Ve6mHPnacCIKk6qknG5A1R+epLRFWdteu/pb5oU0/+CbpG+jhIGgZlK8Ev3t+Eg+tzQVpVVRVpaWkoivHpS1EUUlNTqaqq6uWWCUL/15NB2qZNm3A6nQesJJUkCafTycaNG7vsWm2BWtoAYmZMRc5MJj42FVP2eHxDCsBu77JrCZBtz+XSrBtId2ST8btHSLrxBga+9iquyZMZOO+fKImJaP4IWlTHdeqp2E6ejNbaoyZHNcLvrGX9C+toNOskXHYp2Q/eguS0GwXX93++KAomv4K1sL12qhw1nsOeV/7BrurljA0txLn334Qj/SwBtSTBkOlgT4Bwc2+3Ruij+lyQJgjC0SEYDLZ92Pouk8lEIBDo0usZgdpxSNkjcZ1yDqFRU4mMGo/ej1ey9mWKZPzb6rJEwy3TMaUbqSVsI0cy4NV5WIbkQSiMd+lS4kePwPzS/1BxXj56awzm2lZB1U9uI+rxEDPcyeD/OxlzWpwxsV6WjS9VJXHdHhRfhJrTBgPGMKgOmL1hKp55mq+yneiSn5LdO3rhr/AjxWTCiXdBfG5vt0Too/pckJaRkUFNTU3bKjBVVXG73WRk9G7pFkE4GvRkfrTBgwe3Jc79Lp/PR15eXpdfU5PMeM1p+GMHog4d0daD1m/zwvUDy+q/YGn9AtY2LgcgVFRE2U03k3DZZThPPhl0nfrX32VgZSHO606h+KoJbcdKW7ay6+STKflwN5vm7yJ69Xis2XGgaUhWK1Lrqs/MBTuxNYRQR+Yax7Uen/Xv7TRt3YHfJKO4t9AS6Ge9aWAUj9f1/pNKROhRfS5IS0pKYuTIkcyfPx+A+fPnM3LkSBITE3u5ZYLQ/8my3GMBy7hx4zCbzXi93g6Pe71ezGYz48b1zKo8SZKQ5T73UnfUGBU7HrNkZkPT12xsWkPdX/9GtKqKmt/9PyxDh5Bw1VVk//VFrGNmcWJFFSNnTGDzC5fQNCrNKMquavg/+DeudSXoTy7BnexET3Kgh4K4zp3ddh2zKjHwzX+TeOMNbY9JOoy551O0hZUM0HZjM6loes8N6XeZTa/Cuhfg6CmlLXSRH/TK5fV6qaur67Yi1A899BCvv/4606dP5/XXX+fhhx/ulusIwrHGZDKh99AbQVxcHFdddRW6rlNVVdX2pes6V155JXFxcT3SDl3XeyzlyLEoyZLK2akXoEgmVnuWUvWLmcTMmAGA5x//JFxcjDk7G/LOhIJLyNiyl6nztxN4/AY2/mEW1WcPRVPaPzjEbaxEqvfjG5ZO5MJTkGOMslGOreV89d57mG7+Ga7LL27bX9Kh7p1VVP11Md+UvM+nNR8QUPtZr5QrHXxuCPSDMldCj+rUK1dDQwMfffQRy5YtY9OmTQSDwbZt2dnZTJw4kdmzZ3PSSSd1SaPy8vJ47733uuRcgiC0s9vtyLKMrus90qOWk5PDHXfcwd69e/F6vbhcLgYNGtRjQZOu68iyjF0sHOhW2fZcZqbOYYH7I9YH15F//0yGD8mj/rm/4Fu2jKJzzyP91/fhOvtsKt8pJFRUQtbyMnJvvBzf/XNRbjNT+crTpH6+iUiMFVu9H+eOKoJX3QGDs6ClBYCsl//MlyNsOGNKGTw8F313CbJmfOjQ47LYIXsJBpv5V9UbzEy7iHhzPxmBSRgMxUugsQQcyb3dGqEPkfTDfKx2u908++yzfPzxx9hsNsaOHUt+fj6JiYlYrVaampooLy9n06ZNFBYWtr0gz5o1qyfvoU15eTlnnHEGCxcuJDs7u1faIPQvO3fupKCg4IDHu6uXuC/4+uuvUVW1X5eG6qx9ixcmT57c2005JlQHy1ng/oioHmVOxlVYvt5G1f0PEHW7AYiZMQP76FHUvfACWrMReMlOJ7Hnnos6eBgtj/4WAN+siThKPEjf7kF2mNH2KxsViY/F3NiMZlaQI60VLBSF3Pffoyo5k6UN/yFsrcAq25ieeiEZtn7wXhANwZKHIXMi5M/p7dYI3ei7H1BNJhMDBw48ZNxy2I+z06dPZ9KkSTzzzDNMmzbtsJ9+Kyoq+OSTT3j00UepqqrihhtuOOS+giD0nqSkJEpKSo6JIC0QCDBw4MDebsYxI92WzZyMq2iI1JFoSYZp0xj0yce4f/8kTR99ROz0s4mdOZP4uXOpe/FFGt96C83no/HttwHQY11IzV6cn66j6KZJDNpZ3CFAAzA3Gukq2gI0AFWl7JlHke+ezek1sMsfQ3FuA5/WvM+M1AvJsvfx54DJCq40aC7v7ZYIfcxhg7RXX32V0aNHd+pEWVlZ3HbbbVx33XVUVFR0SeMEQeh6cXFxR3VP4f6i0WiPzX0TDLHmeGLN8W2/r1bXo//iNMZfexWOoUaxdSUujpjTTye4dSu2DBP+jdsJFnuwZWVjmpSF74uF5L68muozh5G2qLAtN5qqyChq+8IAnfaVnqG1m9kYGM6spdvIensT6dPGs/L/xrDA/SGXZF1PjKmPPw/iB0JAJLUVOjpskNbZAG1/NputW5bWC4LQNZzOYyvz/rF2v31JQPWzy/ctYS1EuaOY00KxpNkyAaj769/wr16DH3AeN5LM0/Mwp2dhO+9OimvqCG3eRPoXuwkl21GCKuaWEIqqdQjM9p9VqfjDaN4QVbEOFFXDtHg9U/IHY7p2bt8P0ABGXNDbLRD6ILEuXRCOMQ6HA6vVSjh8dBd2DofDWK1WHI5+WNvxKGFXHFyceS3ZtoE0RT18XP0mazzLUHWV5NtuxTnlRAB867dT+co6Gj5dS2TR3xjw/HOY0tORdB1brR9zSwhNMd6uJCCYeOBCEEmHrI++5duZQ0g8cwgA5hf/xeDq9n37ZXoO4ZjW6SVWuq7z/vvvs2DBAqqqqg4o1CxJEl9++WWXN1AQhK4lSRJ5eXls376d5OSjdyVZc3MzI0eOFIlse5nLFMustIvZ1rKRrz1L2dD0NaX+PZw++hwGvPIKvtVrqP3Tnwhs2EDLxkpaNr9LwhUmcv7yHMXXXIMeDIOuIavtc9BsDQEqZwwjY8GuDr1p6Z/vpnF0OoGZ47BucxOqbKb6kd8xYN4/KfLvYmPTamanXYJV6YPzMb01sHcR5JwoKhAIbTrdk/aHP/yBBx54gNraWoYNG8aECRM6fI0fP7472ykIQhdKS0tD1/UereXZkzRNQ9d10tLSerspAsYHg4LY8czNvIY0ayYNkToimrEgwDnpBAa++QY5L/wN68iRoGl4Fy/GEhNiwJMPMPjjjxjy5Rc4L7iwwzljd9QSGtCeYkMHlFCUgv+3mPq3V+O4/FQA/GvW4F26lO0tG6kL1/C5+1+oeh+ck6mGoGYz+Gp7uyVCH9LpnrSPP/6YW2+9lTvuuKM72yMIQg+wWq1kZ2dTU1NDfHz89x/QzzQ3N5OdnY3Vau3tpgj7iTMncF765VSHKtrmpmm6RlD14zrlFJxTp9L43vuYszKQyxfh0DzgHAjpeaQ8/AgNe8uxbloLQMWFBYSTHIx68AskTUeXjCFPAMfaMnbmzSDz1DOILllI7VNPceaH7/Bv9ztUhcpYUreA05PP6Vu9rKbWYVlRHkrYT6d70iKRCJMmTerOtgiC0INycnKO2nlp4XCYnJyc3m6GcBCyJJNpa/+32di0mvcq/0mJfw+SLJNw6SW4Tp4KE24ERzLBz/9O+U1Xo1SV4Wp0tx2nDxhG84gUSi4bg2pVkHWjN22flHdfIVQwBmSZSGUFUlkNM9MuwqG4KPRtZ3Pz2h68606QjYL1ojSUsL9OB2lnn302K1as6M62CILQg2JjY4mLizugtmZ/5/V6iYuLIzY2trebInwPXdfxqV6CWoAF7g9Z1bAYVW+de2aLRxt1NeUvr6Nl2VpKrrmKSElJ27GjXvmKybd8Qs4HW2keloo/KxYJI1CL2s1Imorp78+Sctlkhj5yFtZECZcplrNTz0dGYbXnK8oCe3vlvgWhszodpP3qV7+isLCQhx9+mC+//JK1a9ce8CUIQv8hSRIFBQX4fD7U/SZl92eqquLz+SgoKOhbQ1nCQUmSxNSkszgj5VzMkoXNzev4pOotmiONAMgxSaTe/UuQJKI1dSgJCW3HRrcUokQ9t/04AAAgAElEQVR0lJBKwpYqrE1Gr7AEmAIRIvFO9LBK/SffEK4Pw6bXwV9PmjWTaUlno6Oz17erN2774EQHWpfZuXMnJpOpz339EJ0+qr6+npqaGpYsWcLbrdmh99lXB3D79u0/qBGCIPSOuLg4hg0bRmFhISkpKb3dnB+toaGB4cOHiwS2/cwQ5whSLGl8Wftv3OEqPqx6jbNTLyDTlkPseXPQVZXK+36D6vEgx8WhNTUBoLhsqM1GT7DiDXY4p3dgLA6zhLXWS9XbW8i9cxKs+wfS5NsYHjMKp8lFlq0PVSKwxcJxN4PF1dstEfqQTgdp9913H7W1tdx7770MGjQIi8XSne0SBKGHDBo0iOrqanw+X79O/LqvgHtubm5vN0X4AeLMCVyQcQWrGpbwbcsGAmr7BPq4Cy9GVyWq7n8ArakJ2WlH8wXQWgJEBqRgLj1wRWTCpiq2/uoUcj/ZSfPckZg/KCW4eQF5zyQgTbyBbHtu274t0WacigtZ6sXUobIJEgb13vWFPqnTQdrmzZt5/PHHmTlzZne2RxCEHqYoCqNHj2bFihXYbDYURentJh2xfcOcJ510Ur9sv2BQJBMnJ53JcNcoUqzpHbbFz51LcPt2PG+8ieYPILucaC0+rC4nGh1LRO0z9PnV7Ln9RFIWFtK0qgRZ1WkqshI/sX2f6mAFC9wfMtSZz5TE03tvmNxbDUjgTAUxVC+06vTHhvT0dLGcXRCOUvuGPevq6tD72eoyXdepq6sTw5xHkf0DtO0tm1la9zmarpF2773YRg4HHWLHpyJZLcRMLCCcEnNAgAZgbQoy8rHFpCwvxjfImM9W9cjv8bz1FjQUghrBKtvQ0dna8g2rPUt77/m/50tY+zyIqgjCfjrdk3brrbfy0ksvceKJJ2K3H1iSQxCE/i0vL49gMEhpaWm/SgLrdrsZMGAAgwcP7u2mCF0sooVZ17gCv+rFp7ZwZsp5ZDz+BGp1GU7rNhJP2QUmicZlRmCjW0xI4e8kqm2NuVxFntaTRqh++Leo6/NJuuIcEsZdzczUOXxW8wGbmtcS1sKcnHRmzw99NpdBTFZ7Kg5B4AiCtDVr1lBVVcXpp5/OhAkTDljeLkkSjz76aJc3UBCEniFJEvn5+UQiEaqrq0lNTe3tJn0vt9tNRkYG+fn5YjXnUcgsWzgv/TI+q/mAssBePql+i5l5c3AOHw7RqVitb1H1l3eRGn3osoQ0cxrSp8vQZRn2K13ozU3AVexBU2Rk1QjoaudvQ/WFSL3ZTPrYK5idfhmf1rzHdu8mInqYU5Nnokg9FDD5aiHUDBkTeuZ6Qr/R6SBt5cqVAFgsFrZu3XrAdvECKQj9nyzLjBkzBlmWqaysJCUlpU/+39Z1ndraWjIzMxk1ahSy3IsTvoVuZSwo+Amfuz+iOlTBR1VvMDPtIpIsKeijriDuijiCJb8nWNYIHy/CNmECaQ8/RPFFcyEcBklCDkbRTDJytONQYsPiPaj+18m4SyFlzGWcl34582vepdC3nXhzIsfFT+mZm3S3vqem5PfM9YR+o9NB2tKlS7uzHYIg9BH7FhKYTCaKi4tJTk7+wTl+ukM0GqWuro7c3FxGjhwpArRjgE2xc07aJSyp+4w9/h18XPUmF/in4bnjV0Tr6hjw6E2U3vsXtECEwDffUPeHx8h84nGq7v0VhEI4qlvQWp8m+8pHSfE29MYgTatLCT72ErkPuEgoOI/z0y9nbeNyxsROPHyjupJ7K9jiITa7564p9Avi1U0QhAPIskx+fj5jx46lsbGRpta8VL2tqamJxsZGxo4dS35+vgjQjiEm2cQZKbMZF3sCQ135xA0Yhurzofl8tGxqJPe+c8BiDE96l66i4YU/kXDp3LbjZa11BagOmiJReNUElEvGABDaWEXJ9koAYs3xnJEyG7NspJnyqz5CasccbF1K1yFrEgw4WazqFA5w2Fe4+vr6H3TSH3qcIAh9hyRJZGdnM3XqVGJiYnC73USj0e8/sBtEo1HcbjcxMTFMnTqV7OzsPjkMK3QvSZKYlHgKJyeeieJ0knzzzQA0vPk28uQbcdx4ddu+wR2lNLz6BubsLCwjRqDJUtsKUFnVIayy8vrJNN97GcVXjueLiV62NK9Hr90OUWM+W1AN8J/qd1ng/pCIFumum4LsE2DASd1zfqFfO2yQdsYZZ/D4449TXFz8vScKh8N8+umnzJkz54CKBIIg9F8Oh4OJEycyevRoGhsb8Xg8aFrPpAnQNA2Px0NjYyOjR49m4sSJOByOHrm20He1BehzziCU4kIPBql+8RVybvk5mssGtFdZipRXEN6xA1nTO1ReynthNZkvrWLv1BQGXnYDEhIrGxbxVcX7hJc+C2EfkiQjSzLVoQoW1s7v+vQckQB49oqi6sIhHXaiybx583jyySeZOXMm+fn5TJw4kREjRpCYmIjFYqGpqYmysjK2bNnCypUr0XWd6667jhtuuKGn2i8IQg/Y16uWmJjI3r17KS8vB4wi7d1RfSQcDtPc3Iyu6+Tk5DBo0CARnAkHkK02aq6fyoAnPqPlg4+ovmQmSTOm4Hl/EarDjMkfMXqqWoOgfQXY9/Wo5by/heRle0ExM+ueaXw5Ip3wu6vZsayYvLu8OGf/kplpc/m46g1KAoVsbl7H2Ljju+4GylZC0Zcw4SZIFClkhANJeic+GmzatIn33nuPFStWUFVV1WGb2Wxm9OjRzJo1i/PPP5+YmJhua+z3KS8v54wzzmDhwoVkZ4sJmML327lzJwUFBQc83lvDev1FKBTC7XZTWFhIMBjEbrfjcDh+VLZ/VVXx+/0EAgFsNhtDhgwhNTVVJNEWDisUDbJ97rlYd5TTNDqDuEd+CRfeecjeqYNVJgCw5CaRcMNEKn6/FFNLECXGyoBfXojtwl9RG23gX1VvAHBBxpWkWLsgj2A0BMufAHsCnPBTMR+tCx3qdb23RaPRAxZhmUwmBg4ceMi4pVNLtsaOHcvYsWMBqKmpwe12EwqFSEhIICcnR9TxFIRjjNVqJScnh6ysLDweD6WlpdTV1aGqKmAsPLDZbIcsM6WqKsFgkGAw2DZ0qigKycnJjB49moSEBLEoQOgUq8nGsAd/T8kVVxC3pYqNRV8w4tTR2BZvRlMkY/7Zvt40WULS2oM3XZaRNA1dhnBxPY1vbWLQz06m8sX1qHUeSn73PumalZRL7uWEhKl87VnKV/WfMyfjqh8/J7J0OUQDMGiOCNCEQzridfVpaWn9Khu5IAjdR5ZlkpKSSEpKQtd1gsEgfr+f5uZmGhoa8Hg8qKqKrutIktT2XVGUtg95sbGxOBwObDabWAwg/CCOCeNJuesufKOzCWcV4YkdTMbizUaABu29apIMqPsdKbHrvsuJStWMfHQxoW3VeFx2Bt4+kbKXtxIpr6L8d69TGZvBmOlXU+jbTlAN4I02E2P+ESXIgk1QvBRic0RuNOGw+k7yI0EQ+jVJkrDb7djtdpKSkhg0aFDbNk3T2gI00UMmdIfkm28iGbgo2owl20r1KZvwfbWs47CnqnY4RtJUEpd8S9X5Aym8/USGPrcK75q9mNOyGfjGWxTeeA3y7hK0u3/PBm8DZ553LU5TDCb5R751ln8NWgSGz24NHAXh4MSzQxCEbifLMoqiiABN6HYuUyymCCT85EoS//goqs0MCe1lDC0jR3TYP3nlZob8cTHuUwfTWGCMEnn+vQzv0q8YNu8N5JEDkaMa2ovvsqF+Wdf09uadBRNuhLgBP/5cwlFNvGIKgiAIR43g9u3sPf8Cah56iIaxaax8/yesfWo6mmwEV+WTUrCOG9vhGHuNlxHPrCb+2xoAomNGsOw4L1rzZobcMArrKQXs/u1Z7Azt5L/uf1ERKGVF/aIjT8mha6CpRu9ZYl6X3K9wdBNBmiAIgnDUUBISiNbVEamsJOaJd5iWNotwgp3mfKOXLPG91ey6/QSIie1wXPzXRTSNTgcgWl2BO1jJEkczclY+gy8eyjlSLLFhldJAEUt3v8vWlvXUhCqPrHGlK2Ht80YxdUHoBBGkCYIgCEcNc3o6Gb97BICWzz8n9eNNnHTXIuK3VqNaFEy+MPKCVVT/YkaH45SIRsvIVKIOMzZ3C0NeWE+RfxdbYrIgLofYlnrOq2hmRFGIcbe8y8DXvmGvb2fnGxbwQNEXxhw5s7Mrb1k4ih1RkPbdrt1Vq1Yxb948duzY0aWNEgRBEIQfKnbGDOIvuxSAmid+j8VsB0AJqzSOTsdZ3UJpjkp4bF6H9Bcp/91J5TnGnLW0/25n+B+WoVx4F+WNKeBIwanCiA9WI3laGPjGRoJPv0xU7US5KC0KW98yvufPAfmH5xMUji2dDtLuvPNO7rnnnrbf3333Xa677joee+wxLr74YlatWtUtDRQEQRCEI5V2771Yhw+HSIRwaVnb43FbqklcUcLQt78l5oXnCV11W9s2a2OI7E+205SfCkDK1+XIEQ33M88RHX05ZE4k9X9vJf7iOQCkv/8N6x/73+9vTOHn0FQGQ6ZDrEi0LnRep4O0jRs3cuqpp7b9/ve//505c+awevVqTj/9dP761792R/sEQRAE4YjJNhtZT/8RyW6HYNB4UGovsp7wxQ7idtdTOu1clKz2wEkORXFWeNEB2RtAB+yFbvYsXQD5c5CGn0P6w7/FP3cqALGvL2HbMw8duiHeaiNxbfIIGHByd9yqcBTrdJBWX1/flsS2tLSUsrIyrr76auLi4rj44ovZufMIxuYFQRAEoZtZBw8m/TcPAiCZzaDryM72GrDVd9zKpNB7+M5pT8uhKyZMTX6iTgues4ejnTABANPLrQXWw16ktX8j/rqzqJoxzDj3X9+h9OXnDt4IVzqMvQoKLhY50YQj1ulnjMvlorGxEYDVq1cTHx/PiBHGE1tRFMLhcPe0UBAEQRB+oPgLLmDQhx8Qf/HFgLH6c988NLm+mW+/XIvllUVt+0tqFNVqwuwLY9nlJu1MY8VnePs2Ahs2AhK0lJNRupH0X/2C0FkTAfA9+Rd827a2X1iLQthr/JySD+b24FAQOqvTQdq4ceN46aWX+Oqrr3j11Vc55ZRT2raVlpaSmpraLQ0UBEEQhB/Dlp9P4tVXgSQRKa8gZkb7ys6Mj7bgz+5Y4km3mFEtCs5iD7VvrMQ2NAOA3f/8O81SBGIycaga+eW7GP2Hv9MydTh7bpnE1vT69pPs/gy+fhaCjT1yj8LRqdNB2t13301tbS0333wzPp+Pn/70p23bPvvsM8aPH98tDRQEQRCEH8uSm4urtXPBu3Qp9qlT27ZZ3d62nyWHDcXhoOqcEWhmBamkERljBaey5Cs2li2B1FHGzp49KM17Gfbcy9TMGccu37dEtDDUbIWylRCXA9YfUeNTOOZ1OkgbPHgwCxcuZPny5SxcuJCcnJy2bffccw933313tzRQEARBELpCzEyjB033+9F9PuNBCcqumUjUYQZAk3SkmnoSV5Wy63+noAP+3XUoKXFUzxpBcct2IgkDAVif6GRR7X+wmxxMT72ASzKvxxRopvHlJ9GkGMif2yHFhyAcqSOexZicnEwoFKKmpoZoNApAfn4+ycnJXd44QRAEQegq8eefT+ovfwlA8JtvwGwGHQa9tA7P+CxjJ18IAEd1CyZvmFCKkXg24SfXot95FUGHxLfRFjA7KHVZ2e3QCWshsu25WHSZiluuoerVNbgXN0FrfjZB+KGOKEhbunQpc+fOZcKECZx22mltKzoffPBB/vOf/3RLAwVBEAShqyRddy1JN91o/BIxhjGlSIRUNd74GdBb63zmvbgGW63R49a07msGPLeYgt8uZKd7Fww4mYjFCMLMstU4tqUCZZgxvOl5/xO8y1f01G0JR6lOB2mLFi3i1ltvxel0cscdd6BpWtu29PR0Pvzww25poCAIgiB0pZQ77yRm+vQOj+lfb2z7WdL3fW+vshNduxHtvc9JXFtO7q+eozFlCgFZQkLC2lgJahgSBrH9potoON7Iu1bzyCPoIvNBj9s3ync06HSQ9txzz3HBBRcwb948rr/++g7bhg0bxu7du7u8cYIgCILQ1SRZRrZZD9ygGOWaogNSCSUbw5z7wjQ9FCJ+1jQAYne6Kb3nF4S0ADZMSBtegop1AJyQcjZ7fzoVzawQLimh4fU3uv1+hKNXp4O0wsJCZs+eDYD0nYmQcXFxeDyerm2ZIAiCIHSTlF/8AiUpyfjFbDEm+KsqyDKmkhrqjzfmqEm0B2rukhK0xNYhzkULSV5ciGtfT9nu/0DYi8sUw6gR0ym/yFgBWvf880Tr6nrwzoSjSaeDNKfT2ZbM9rsqKipITEzsskYJgiAIQncyp6aS/aenjd6zSBhztjFEac7MBCB16V58GTEAbaWkLN+WoM5sTzc17OnlpO5tDcBMDrC4ABgdO5GmK08hlOxA83px/+lPPXNTwlGn00HaiSeeyIsvvojXu18+GUkiHA7z5ptvcvLJoiaZIAiC0H/YJk4k5a47AYiUGUXYI+XlRGKsmPwRbPV+9NYITbUYKTqiy3fgGG2USFTCKql/XokuKRDxgdqaT01SmJI1i73XHw9AuLICvXWRgiAciU4HaXfeeSdut5sZM2bwm9/8BkmSePnll7nwwgupqKjgZz/7WXe2UxAEQRC6VI0nxKrRs3FMmdLhcTloDGHKYRVJh2CKk41Pz0KzmGjMT6Hy1pnoSuvbZ3UL0cYAoIO/tu0c2faBOM+ZQeVT15D4wp+M2qGCcIRMnd0xJyeH999/n2effZbFixcDsGLFCqZOncodd9xBenp6tzXySA0ZMqTXV3ds2rSpV6/fl5hMnX6a9bhDPU/2pZfpatXV1d1y3v5o/9JygtAbmvxR7FaF7Gf+ROGpp6G1JrhVIjqazYwcjKApErZaHwPe2kTJiz+nLN2Yfz129lTiPl6KLinIFgnic0HuGIidkTob5ZwLevq2hKPIEb17ZmVl8cQTT3RXW44qY8eO7e0mCD9CQUFBbzdBEITv6OoP3x5fhHinGSUmhozHHqPif/+3bZscjJBw/fXssBST9rdFpCwvxjlwNZVzclGdFnb/ZBgTFq5DCoYJNMTgOukMcKZ0OL8idXyLVRsbUeLju/QehAMVFBT0ekdNV+n0cOf1119PUVHRQbcVFxcfkJZDEARBEPoqXdepb46QFGP0fsWcflpbCad9qzmbP/mEIZfehmYz9rG/uZyRT69EiqhEw834//cnDFm0ENc1vyFYq6EFgwe9zpblb7H57GkUXXAh+n651wTh+3Q6SFu5cmWHRQP783q9rFq1qssaJQiCIAjdKRzViXOaSI61ABCtrYXWAGpf2g21rg77p2uwFRjpNCQdElYUcdKFr1Hw2GLi8wZhSkmh8v/+j73nn0/TXx9sO8c+kiRR7PJgLq0lWl1NaPv2nrxNoZ874tqdB1NeXo7D4eiKUwmCIAhCt7OaZabmJxJjN4YkI1VVAG2rOfel3aj/+9+JlpS1HSfpIEc1XLvqyXMZdT7lGCNVR9OXK8Gz94BrDRx0Ai15Rk4277Ll3XE7wlHqsHPSPvroIz766CPA+DTw0EMP4XK5OuwTCoXYuXMnxx9/fPe1UhAEQRC6iK7rlNYGyUyyYm5dpbkvSDMlp6DWtq/SVJuaDugd0wEpohIqLMY8wEO0rh6AwJ56wmv/hWX6XR32H+QcxuqCVGL21BPcIXrShM47bJCmaVrb5Dtd11FV9YDJeHa7nblz53LzzTd3Xyt/pKNlAqHQ9b799tuDLvI41p4zS5cu7e0mHJK5B1MXJO3LQN9HhUKhHruW0loi6WjkbgrzTVEzSbFJmBWZsBZCbWlBsliQczIJNzWghFWUtFTiZs2i4R//7HC8bpKRohoNxfVkOBy0fPVV2zbfqjVYTqyE2My2x2JMsUTzMoDtBHfs6KG7FI4Ghw3SLrroIi666CIArrjiCh555BHy8vJ6pGGCIPQckQ5DOJbsrQmQGmfBZTOh6zpf1v6b6Ck6p1+0jI1VSzD9/CnitrtRa9zYRo0+4HhJ1QAINUWRrVYcY8bgX7MGgECxh4TKNRDbMfWGbcBgYBGRmppuvz/h6NHpOWlvvvmmCNAEQRCEfs0fUqnyhBicZtTg3O7dRFlgL161hbAWZru2G39ectv+njffbPs54jD6NaTW0c9Q2JiLZh87pm2fQJkPqjaCGu5w3djE1p41fwA93HGbIBzKEWcZ3b17N3v37j1ot/u5557bJY0SBEEQhO5Q4g5gt8ikJ1hxh6pYUb8ICYlTk2ZQFzF6uRJzhgPbAAisX992bOkV4xn80tq2RQWKZEyLsA4d2rZPpK4FfcxPkKSOw8W56ePY14emtrRg6uND60Lf0OkgraWlhVtvvZVvvvkGoC3XiyRJbfuIIE0QBEHoy4ZlOclMtBLQ/Hzh/gQNlUn2yfDQX0jMG8LFcy8lkvYVDc7/tlUg2MfkDdE4LoOEjcYiA6ceMB7fr+KOKTUN3Z6FJHcM0hKyhxG7fBl6KIQSF9fNdykcLTo93Pn0009TV1fHvHnz0HWdZ555hldeeYVZs2aRk5PDO++8053tFARBEIQfJRLVUGQJm03l0+r38KrNDHIMZUiZnaaPP6H2T38i1pZIymVXkP3nZ42DlPa3SbM3jHdIayqNiVlk/PxG4/G01LZ9ct9+C9mkQXXH0oCSomBKTsaclYXUh0vlCX1Lp4O0ZcuWccstt3DccccBRomoKVOm8NRTTzFp0iTe3G/cXhAEQRD6mlU7G/m21Itf9eJXfaRbszktaRZbF70KgG1UAXJrzk/7hAkMWfAh8VMHA0baDV9WLFnLSwAw1/kpdISpD9eiONrfStWmZihZBlvfhlBz2+MVgRLmV7/D9hZR11novE6H8263mwEDBqAoClarFd9+3cAzZszgrrvuOszRgiAIgtB7mvwR6lsi5Oe4SLC4OD/jCmyynZ2+rbB6MwDWSRPb9pfNMnL1F6jJTsBIbmsOasjVLQCYWsIs9nxBQXQ8J6npZF5zHFLeaZhSU8DbGpy1VII11vhx+1a05QvwjWyCs0RtZ6FzOt2TlpSUREuL8eTMzMxk06b2TwOlpaWiHpkgCILQZxXWNKPGbyfBZcwVizMnUBeuYf2u+cRuM6b0x087DYDGDz6k6o7raVq2Dvc2d9s5Yqv9bT8rLSEUX5gi3070YB2OYSl412yh/qWX0MwJxk6+9mPV1d8w9Pmvsb347+6+VeEo0umetOOOO45NmzZx2mmnce655/LnP/+ZqqoqFEXhgw8+4NRTT+3GZgqCIAjCDxOKhtgc+ZSwrZpvmkwcn3AyjZEG/lv7MSlf7UHSjcn/9tbpPN4lS2j5Yj3B0XlYqlrazmPfVmVUGwAIR8mwZFGu1VLhKySpIUTT/MVgNpNy202tF26vdx3ZWYgVMOXm9Nh9C/1fp4O022+/nZrWJHw33ngjDQ0NfPbZZwSDQaZNm8YDDzzQbY0UBEEQhB/CH/Xyac2HhC01xJuSGBU7npZoE/+pfo+wGmTgEmOlZuw5s5BkGaIhQrt2ARDcsof912hWn5rLoNc8xi8WM4PTx1Ne/18Ko24cVSoA5tRUJIsDZBOE2wM8eUshAPaDVDgRhEPpdJCWm5tLbm4uABaLhfvvv5/777+/u9p11PCGohS6vQxJdeGyihU9giAIPcUTruPTmg/wqs2kWjOYkToHu+Jgj28HXrWZoe54TLuM4unxF1wADYVo618nXFp60PNFXda2n2Wni4GOYSyv/5KqQIT0N43SUKb0NJAkyJ4M9kQAQnv3Yq5oMK5z/JTuvGXhKCOihm7kDUXZUOpB12FDqYfxAxIOGaiJYE4QBKHrlPj3sKj2P4T1EMkM5rT4c7ArNgDynP+fvfMOt+Oq7va7p53e7rm96qr3asuSew0uYIMJYAwOHRLiOAacfKGE0BIIJHQbMAEbiG0wxWCMjZFxr5Ity5Jt1asr3V5P71P298fcoqtukCDAeZ9Hzzk6Z8+ePXPu7PnNWnuttRCv4qexowXr3ovIP/44nqYQPPst0oNuQXUp3MoCU+5NwEhOr0lTPB68qo9Gbyv50Y1Tn3uXLnXfzL9s6rPEvfcAUGyLEZ6/9KQed5U/L16RGujv7+fXv/41g4ODh1QcEELwqU996oQO7k+ZSYFmqAp+Q6NQsY4o1F6JmKtSpUqVKsdGFRoVWWahbw3j3YspxcvsK/Qxyz8XgBZfu9tudiee5hhs+gZ5RbJ5rEAzYNeG0UYzU8XUbV2l9on9U/1Phsot1TooZQanPvcuXDRjHFJKCvf+GoDIJZfMSABfpcqxOG4l8OCDD3LddddhWRaxWAzDMGZ8fyL+8D75yU/y1FNPYRgGfr+fj370oyxbdmhx2z8aVtmN1gnUg+Y5ovXrYIEGuK+HEWqvRMydKA4e9yuy4h10DqpUqVLl98W0HbJFi5BPQ1ePO+nAIQyV+qn3NKEIhVZfB29sficjo15yngSPZ37NuDnKJfWvp90/G1mpIAwDzAI8fwtZJ889s5ppveUpADzhGuzRDFJx723Csgn0pqf2FbnkEihn6dxyN/2P7WMyI5p/zWr3zTNfg5o55IfCVLr2ghC0XXnN73xsVf4yOW4V8KUvfYlTTjmFL3zhC9TV1Z2UwZx99tl85CMfQdd1HnroIT7wgQ/wwAMPnJR9vWKsMqQn1imke8h5m3l+oHCI9etwAm2SA4XanNogu4eylG2HiF8/ppibGsPvKZAOttrNbwixaziLYlfYvbuHeZ1zCAYCxz4HiS53DOHWEyvWqiKwSpU/CX5XYVVxKiQr48SMOIZiYNoOiawJQCJrUhPSX7FQK9oFnk48zK78S6yPncfyiJvvLGbEeS61n7Ho/ZTMNI2eFpq8rRS3baP3/e+n9j3vJXbpGSTsDPd21FOwssS2uWkzyulxNECp2IfdZ/T1V8LIi4CksLMfACUcRiVRW5gAACAASURBVG9rAykhOwihZvynXUj9pz+F1bUXY2Jdd5Uqx8txXwm9vb28+93vPmkCDeC8885D13UAVq5cydDQEI7jnLT9HTeT4kTRQPdTsKC7azteYRHzGxiqwvM9SYYzJZ7vSWLbkt5EgULFOqQrv6FhWQ53Pz/AywMZBpIlnINyzPkNbarPXNmaOQarNPF6aIH76Xa9U9/nyhZbelPkytYMARnzG9i25GfP9SHNEnFzGI9TobtrO7mD6tUdcg6kA4k9kOx2xdqRxnIYTNshkatg2of5XY92jAcdV5UqVf54TAor05Lu6+GuZw693itOhZHSABWnxEhpgIJZIpE1UYTA0BQUIY7a38FIKdmR3cqP+r/DrvxLeBUffnX6IXOoMEK39x5KIk2br5NLG/4azRYMfuxfsUfHyNx3H8Q7eX7ucgqUmRtcRMeN38C+7Ey0MTcyU+C6NpUDpmklEsHo7IThrTh4MUfGAAi99nLXq2RX3K1UD1mR5+dr+9n73rWv+DxXqXLcIq2zs5N0On3shieI2267jXPPPRdF+d1N3yeEA8WJalCoWLwwWGAwbRIsDaDYZfyGNiV4cmWLnkSBQsVm51D2EKGWK5nsHyuSKpTJViwUBfaO5MmVzRntZgi1fH6GSETRDi/UDhI5uXye53uSZIomT+4Z46k9YzPcqj2JAiHNwhzfT9EW2KofITRXqGUS06LIKmMm95MuScxKGcZ2AAKsIuSHj1uoHWliz5Uttu4fpjjWffhjPIx4O1B8VqlS5Q/H5HV8LGF18PVeMF1hpggVr+pDSoU9qR5sTDTVdSlqqjhuoZY2k9w9dAePjN9P2SmxMLicN7W8i7lBd03YvsJu7h29A0ctMMe/kFfVvw5dMRj71s2Ud+4ETaXphvcihOCc+ss4veZ8zq9/DdaqeWy6pp3EmlYAHAG5BTONE77ly5C5cUjtpzDqQ9gOjq7g/fu3uw2sEtJ2kKqHHbltWNJEOf7bbZUqUxy3u/OGG27gc5/7HCtXrqSlpeV32tnrXvc6BgYGDvvdk08+iaq6GWl+9atf8ctf/pLbbrvtd9rPCeNwAq0vxVCqhK5p7EuWmUUvBW8zPYkyipA81TXO7Fo/EZ+HkukKtZ5EgbYaP/PqAuwayjOaLeH3GIBkPF8hHjDYO5Jndn2AoEef2r3f0FBKBbq7tjOnIYLfN7EOUJ14TfdApN11Cx481qK7ndffgqMa7BxyV0wsb4tSqFjsHMriExZNWpKSrTGYs2mIOBiKgWqZjOx8CqWpHX85i+lIMhUNxTEpj+4Cnwdd94JjQWU6WSM1c47oojxwYtdUgWW7E7fHUHi5d4RgaZBdQmVesw+/esAxJrrcV93nfmZXKI51szUdwhJGNdCiSpU/IAdfx8DE9TzTVXlwu6JVZk9qgJjfi67qWI6kUBRoQiNtD6EpTeiKccT+DsaWNvcM3UnOzlCj13JW/CIava0z2oyUhzBlhRXhUzktdg5CCHJPPMHYjTcCkLpyCeVwCg+gKwbLwm4i26hew2ktr0LsdSMye966muigCTtHp/rOP/Y4qe99k5rFEulrwZxVT65Go8YzYW6zywz/dBul3C66rl2J0hxkcXjlCf0tqvxlcNx3tm9+85ukUikuvvhiZs+eTSQSmfG9EILvfe97R+3jrrvuOuZ+NmzYwJe+9CVuvfVWamtrj3d4J56jCDSfoeHRFMqWwr5kGZ0uHCdOsiDwqgpDmTIeXcWru6c3XTDZsL2bzmiQJS0hPLqGrgpAYJk2ubJFzK9z3wtDnL+kjnjADRNX7DJxa5iiqrFztMyCRmN6nduBQi3Q4Fq0DhjrztEyhqoRLA3wfDpE0OMFJFt7UyAgqkmaGMVBRdV0VNthOF2iKaQSsNJIRWdgqI/mkI7pqKjeGJ5sN7aqU7I0UCW6MjGWYwi1I03subLNy10j1MsRPD4vRVuwcyjLgsbQ9HEWxieK5rkTcMFW2D1SJKbkcUJt5Gy1KtSqVPkDcLjreJIDhVXYr5Ip2FPtTKfiCjGhUSgKhNcmX3IQAjyqgSVNxs1B4vrxCzVVqJwRP5+hUj+nxs5CFe4DftEu4FPdAukLvafRsz/MkoYlCCEo7+1m4EM3gJSkVjSx9W2rKYUNzpvoM7tpI1ZXN+HLLqXuzk2MJTPYfp3I1kGiLwxyML7Vp+IEc+Qe2Uru0+/kpfAAjba7VCR9730kH+0GILQpStPVbyCkRQ7po0qVY3Hc9lfLsmhra2PZsmUEAgEsy5rxzzTNY3dyDB566CE++9nP8p3vfIfW1tZjb3CyOA6BBuDRFITqIV12sJI9aE6FoFdHE4L94wVKloVXV1nSHOayJU3MbQigKIItvSnG8mVM252oagIGuqoymivz1Qe62NqXQrHL+IoDOIqG4fEhgd5kceY4VcNdHza42X2dFGhDWTRV4Cg6+5JlGuUoQc0GBIOpIsl0jrg9jIOKLVzLnaEqGFhUUgOYCKTQ8VpZRsbGcewy3vEtSBQU3YsQglLZxnTk1Dmikjus6/NIE3vRtOkeGqfGHgah4aDh1TU01RVqhWIBckOu4FM9kBuiUCyycyiLohvohgdfcYCgah+6fq9KlSonlKMJtEk0VeBISc9ICcdhSqCNm4MoiopHM3CQDCUrOBLUyQc2oaMoKuPmIKZTmdHfga5P06mwPbt1qk70LP881tWciyrUicCBR7it71sMl11vzb7hMmHZQtCrUhkYYO87rsFOpSjXBtjxL+eyPHoqZ8YvBCBjpnjppk8x9IlPsP8tb2XsG98EoO/SBcQOI9DQdTynnEdqa4nUj39C9H1fBkdSsPMUt73I4Ge/CsD42XMYuHwRKyOnnZgfospfHMdterjjjjtO5jgA+PCHP4yu61x33XVTn916663EYrGTvu8pjiXQVIEqzSlxA5AoghAa9QyTtJowNA9YNvvHCzSGPaQLNrpQQAPbloS8Ko/sHKU26OGCRfV4Jty8f7W4ke1DaTbtGWJlQMPxeJCKTsm0EEBbzDdzrHYFiglQdCgmKNgqO0dLU5Po/vECmupBU20CxQF2Z8JEDUGDHGfXqKSzwYsxMd+q0iRKkopQSeQqNHkKWNJAEWWcsd3Y/jCqU8JxDBRFw3GgVLbBox7RomYK/YgCbc/AGDFrGE03sNAomw4eXcGra1ScIv19g7TGg/gm3L/Fsk1/XzeGtx5D9yIBB/AVB8DXTI6qRa1KlZPB8Qg0AMtxKJRtVEVQKNtIxSRtD6EoKprQsR1JqWKjCChVbFRFnRJqtqXiII9oURvO5Hi2dA/D5X5sabE07Ka5KNp5Xkhv4qXsFixpoqKSrIwTVRrZN1JgaXsIU5rcv/N7dBRyEPIw+JkruGzRu6j3NgMwWh7moU3fZunT7tKKyZJQAC13b58+QI+KUHRksUTg1JXIUp6xb33L/e71F+H4dMo7d9Fz7ZeRhQKyo4kd/7iezsACYkb8hP0eVf6y+D91N3v66af/2ENw0z/AlDtxz0iOvkSRkFdHkTbLMw9R0sLsCqwjX7F4sS9NS9QHqAirQMAaJ0UjhqZSLLpBAjV+D4ZHQbUVSqZFQ8jL3OUhBtJFEvkKsYCB40h0RWFZg49ANMnuEZPtI0kuXtYIMNMFCK5Ayw2BUMHwUiyXZoiY/WOuYPJoCjYKY8US7Qzg13QSFZUX+tMEvF7qI16GE1kWhQs4QkVRNQwzSbHs4DcgYCVwhEqpUsavGSiVDI4RPrJQK2dA0TGTGkmlEUXzHlmgaTqOoqMAjiMpmw4RexQfNiVFZX+yQkfcFWn7kxV0VSVij1O263BUA6noVaFWpcpJ5JUItEzBQkGg6oKyXaYvNzzhWXCv4dJEKgtdU3CkJF+yCXhdoWZognReEAyohwg1R5R5MvdzkvYwNXodcwILKNoFtqQ38vKEOFNQWBRczqrIOkJ6hBf3Z9BUQUe9D1URaIsXsP8rf8MyZrFs3WvdGp1AT2EvD4zeTeedGxESlFgUJ5lCKgLhSLSJMSs+nXk3vodd1/8vFEuEZzuMfuqD2OPjoKoYa1cT3fw03v+4AydXRG+oxfOF66mrybGqakWr8ntw1DvZ5s2bWbhwIX6/n82bNx+zs9WrV5+wgf3RCNS7ljS7QsFWKFQsNEVgWhZjeYs5ip85dg97C50MZv080z3OZcubiXhAotFnRtg1lKbGp+MzdKI+fWpy01WBZUFFSuoDfvJlm/n1QfaO5nh0zxiXLm1kvi+FrigomkbJKvDNR7r4+GuWuAItP+qKoHCr61oUKqg6RdNmf7KCR4FocTdK0aYUWeq6XE0bTRWE/QHUfAqfzFI2GokFDAbTJQzVJjPWS503RysDbDLOxBZBarQMQXMER4IlDMKaQNgl1EISRU9hhdoPFWoAKJiOQzZXQDfGINI2dWqLps3OoQxRO4muCmxl2hqpKAJPcZi2xP2k/XNwIouQls2e4QwCG4/hQdc84JQxzBQltR6gKtSqVDmJZIvuEoKDBVrPWBFNETTXeGcKtIl2RZKAg2mpTF6GXkNlpDBGUEZRVQUpHPrGS/gMhfqoh2jQnQ/KwiJjJYgbjZScAo+k7yJtj1KrN3BZ4xvwqj6SlXG2ZjahoLA4tIKVkXWEtDDgWsZ2KL+lbcTG7j0TNfUE57eeirH+dVNJ1x3p8FzqSTann8I7lKXht64Vzc5kEYBw5IxyULGzZpEfjiIzGdBU9LiXwduedL+0bSIyyPJ/3QC2g97aSvvfrcGwRmhrevdJ+V2q/OVw1LvY1VdfzZ133sny5cu5+uqrj1hVQEqJEILt27cf9vs/KTQPRNopjnWze6RIwGPQFvezaV8Cj6Lwor6EDjnMgtJz7OR0ZtcG6RlNsao1xJDWgIZKXzJNMm9yydIGimWJZUt3fYbtIFSF5qAHhCTu99KTLNBZF6Bg2fzkuT7OnB3irHoHTZpcvKSBPWM5/uNX2/nqm1ehBuogUOda0ABUd1IbzpQRjoWuq3hKKUL5LhKR5XTE/fxscz+OIzl3Xj22vwEn30NISTK7LsZYOktc5kjrBlJoaNLCcMp4gxF8pQEUp4QjvAQm/kqk5kdP78JCohaG0XL9mJFOLE8tpWIZDIEebKCcz6OSwamZO3VaJwWaYwlKei0+exDFMXEUnULZomI7LKj0IBGkPW0IwGsmqE+/TAWDVN1ahLRAQsWIzvjJpKKDtPCUx3D8LUdOBlylSpVXRMinkciaU3MYQKFs0z1cZG6jf+r/ML3GDMBHjBLDDKVyRH0+aiMGRZnhZeu3REQj8+TpjGZM0gWbhsj0w5olTYQUhPUaik6eh1M/JeskqDMaafS2TAUIxIw458QvptXXQXBCnJXtEk8lH2ZnbhuNv95F6GtP0tsUY9Y/rsMTaoL4gqn97MlvZ3P6KTShc9ptA0jbQXg8UC4jhUBIOZUfTQCetjoSd7mJ1UNLGxi682U3YS1gLFxI7UWXYb76Mcz+AZo/9wm0Hf/jRt5XqfJ7ctQ72C233MKcOXOm3v/FoHnYXY4hZA7FMRlKm7RGvYzlTDKWhy3aYk7RttGeeZFyfCGb9o7gi7cR8OmATcxnULZtvIaGoTqkC7ZrbVIF8YCBoghqwwaGojFStKhYkqVNEVqjfl7qT9Fv17IolGJxi5/1c2t59fJmFAFdoznm1PrBG3MtabYJqk5DUKGv7JBW6/FrwwhAtUt4dT/nL6znyxt2sbItStwjkP56cgWTiEfSVi/BcUhXICdd10KNYVJRBKHKMKpTphiIIOwyRSWEX9GQQgHHQph5VCuHbRVRPDa2dChpcXTbxKNDKrgIMKb+wHoTBRxHki9KHK+G4W8mUBpAcaBrrMBAskB04QpyWh26IokmnyNQGsRGpU+Nk8rkaYp4KHtcV+eBCMcECWWvGw3sNzTKhQp7RnKsbJsp6A5myZIlWFY14KBKlcOhqwo1IX1CqIGqwK6BPEGvSnONG8Xt96hkCha2LVFVge1IFGnQGmyhb7yLgNcEDPYUX0Aiieq19I+VKVUkLTUGdRG3H0uaOI495ersLXSRdRKEtSgpM8FoZQi/GmRlxE0KuzA0XTKwt9jNI2O/pphPMv+mTTT+ZgcAquYgG9dC5/kzjmteYDEj5UE6uwSZDe66MjlRj1pIOVWXc1J2jj/aT92H/gVRGkVaRSqDyam+IhdfjBCCxk9/GgF0Df+G59vCrA/6+SOGv1X5M+GoIm39+vWHff+XwOzGOM9kypRGu/HoHjTDg66pDKZKbLfaadGGuDA2wGC6mQFZxzMbh/BogoWNYdbNjtEc8zOrNsDOoSx+rySZc4h7NRRF0BEP4FEVvJqCavgYzpTAq+PTFZa2RDE8CjdtGeGL9SZ+o0LMbzCcKfHMkw8wp6kPlr8Vgo2uRa1i4lMVWlo72TlaooQrYFSnhI2fxoiPU2bVsGXfMOfMjZP3tmNpDk5qP0MVlWImz6qWKGgaWOCVJQq2pKJ4CckCjh6krPgoFYr4PTpS0VHsElolBYCwSkjbxvbWENAccCz05jVE9eDUxK6pgrYaP9t60tgOhHwqjqKR97pCzYuJgWtV84sCteObETikva28WGnDliptQX2GQOsdz7NrJMeFC2pQHIuirxlHdSf7QsVCCJhbH/zj/PFUqfJnxIFCbThRIZW3OGVueMqzoikKYb/mCjXT9aqE/RqKArIUR4/nGDeHGLP68QgfMXsuA3aFllqDWMCDqopDBJplSwJKFL8SJGO5c83C4DLmBRYdMr6Nycd4Pv00ga5x1vznk/h63Hxm4VNbafrgO1FWvgEbh42JR+nwzaHZ144QgvnBJWx74pM0MS3GJhk5axb1j+2b+n/0qmsInbqY0HtXktxmk3v5HnAcEILIFZezr7CHnsJe5gUW8UJ5NwmPhh2sPxk/R5W/MKq+oKPgKAajop52OY4qFTyqTlPUy2CqxNPWUlq0cUa985jTVCEaqtAY8RDzeTh9Xh3/9OOtdNT4OHNeHbGAQUvMz+B4iYaQF6/mmuwNXfBE1zg+XaE9LnBsaK/1sX5unP50iTffuZ9br2yiIQoNYS+XLG+F0T4e3jHIuSsXga/GrQ8XaMJv+FjQqDPc7QoV1S5NHcerl9RSLJfYU65B2CpCqFQCLdT7hnlmzM88x0ERGiUtgqVo2I5E1b0oloWonU+yf4iQR0FIGyk0xESYvASwy5ieGAGPRHcsaFoN3jA6zHgC92oKOAq67mA6Dqqq4ige8t5mWpSnuCTyHKP2+aBoVIwo6cA8skqYiGGjSIeCUYdxgAUtUTAZSmRQnPAhAq1iO1VXZ5UqJ5BJoTaWqdBR5yXonXltaYriWtTyFmG/m0qnWLFRpE690cTGkpsjs9O7mKjmIdRqEPKp5EsOZauCEA5xvYmENUTBKpB1kuwsbUQiafS0cmb8AuLG4UWPvyiY981NNN79IsKRCI+HxjcuI3LJeYgVb6ToFPjNyC8YKvfTW+zm9U1v44XMRrb0P8ySR16eFmhCgJQUG6PUbB6Y+lxrbyP2pjdRGRxk9BdJMhsenj7uxkb0piYGEg+yPfcCPqkypllEHY12/7wT+yNU+YvkqHexd77zncfdkRCC73znO7/3gP4vMFnjMuzTCbfX0zWo0miOoOngUXVaIypjaZWnrKUYXi+zQyWe7xqjMdLCpSua8E8kq436DX6yuY+GkMH7zpnLwiV17B3JU6hYrkvOdFjXVscPn+/m1Fk1RAMaKybExQcvmk9d0OBvf7mXn1zdigrEAj4YhUyhhLTKCKG4oig/DHYFv2HQFI9AGmyzBD7XFRjQIaO1sas/RUtMRQDz6muwy37aasvsSJvEfCo9obWYUqUpqOIkXdFjWjbDso7aiAH2OAgV4bjuQYkAaR8i0CY58Ak8X3AolB2WdQTpTeUpmeDVVSxHYznbURWo6BGKvmbSoflUKmU8hUHmxv04wRZ2jpZwTGsqQTB2Ba/mVAValSp/IDRFML8lcMgaNQDLlihC0F7vJVOwsWxJxXTLOpXUJCl7FMX2Qr4BGYZoUEdTBFLYJAsWtVozvZVdPJd70F0DpvhQhcra2NksDa0+ZD20LS1U4V7jc7N1qD/fBoAzbxFz/vtzeJsj4AkzZo5x/8hd5OwscaOeM2Lnc8/wjxgb6WLZv24gtGt0Spw5qobj9+AZy6BY0yWpPLPn0HXZpZh9A2DPLLbe+LGPAjBWdrMCjNmuG3RJcOUR13BXqfJKOOqdrFgszvhD6+npYWxsjMbGRuLxOOPj4wwNDVFbW0tHR8dJH+wfggOLkE+mvJjTFKdrEBrMEXTFQlcFWk07xYSFXinyXt/9/PWpHv72RYPiqjb8usby1ig+XeUzVywlV7ZY3hrlNV97nDXtMdbOqqE56puwqAnaogGaa7ysap+ZD+6a9bO4fGULQrUZGdhDvXQnjsuX1NKbyPL4iI83nx52gx3SPQB4azooBN9NYriAUS7iU6Hoa0a3NX6+5SX+4fw5tNcEQEgczeDMVSt57NktZEUQv52lMaSgCYmnaRGFVIjxPGiGBy3cgJMzqUTmoJg59PQ+wEGz8q5oO0igTTIl1DA5dW6EgFfF71XZOZShVCqzYvzn+JwsBS3mCkBpUbQFji2Z3dyKV1dBV1nQGGLnUJYSFj5VIh2LXqu2KtCqVPkDkMqbbNmbYf3C2AwL+WSJN0fKqcoAmqqQyJoEvBpnL47xRMaNgoyby4jV6Ph90o2Yd0yEcJgTaeOZ8afYXX4OgWBd7AKafS0IBDVG3SFjGdn5HM/s+BnLLnoHs/xz8S5YQOjKK0k3dTL3TefjqZ8NwGCpj3uHf4IlTTr98zmv9hI2jN5NZsdW1v7zr9GyE0m3JwIAFMtEybhJ2aUAIcG/ejH5hx+e2rcxaxbRN19F5t77cNJpgueeiy1tRiqDqGgMlHtRUZlXe/pJ/DWq/CVx1IoDd9xxB7fffju3334773rXu9A0jdtvv52HH36Yn/70pzz88MPcdttt6LrOu9/95xFqvGckh5TMyEnm1zXmNMX5ebfKr3YkSKgNaLqfjrgfSzF4UV9Jp5Hky/M3s6Onn0LFYnlLhC29KSq2w2mz40R8OndfewZzG4J89aHdPN01TrZkomlwzrwGOuKBw44n4tPZOlziDXf0kchNVByQNnpNB19/tI+fbe6bikjFsUDa+L1eFtR7cWyLca0BR/UgkVy6vIlnupOsn1tLxG9wSmcN0XCYeNNcgvY4s+w9GGYGf7QWT007+qx1xOMxOmtVhKJQaTwFM7aQUngOtieCECDaTj+iQJvEtiVBn4quuRO6T1eZX6OyfPTHhMt9OCi8fuNiir5mt4B7pcD8eh++hvlumSnHwq86LGgM4ZgVzEqZBfMX865z3fUpVYFWpcrJQ0rJ1n3ZqXxmkw9ejpRULGeGQIPpBzPbcciXbezhZdSUl7K2fjVzY+0I4VCyizjSpsao58nUhgmBpnBB7WtZFllF3KifIdCkZZH5zW/Y9TdXMX7FW2n9r/vZm5nOJtD6759hydlePNu+C4Uxxisj3Df8UyxpsjJyGhfVXY6uGJwROY+VX3thWqABctIQoapkZ8fciE4Jao2f4stdU+0C55xF5y/vJv62tzHrh3fQccftCFVltDyELS0iGFjSos3XiUc5fA3jKlVeKcddFurLX/4y11133SG50NasWcO1117LF7/4xRM+uD8Gc+uDCOHe+A9mdWcju4sxEpPXt4SmiBdt1ul0117IwmCW93h/jVEYpDnmY93smhnCIeo3+Pvz5vLgh87lDWtbsR3YMZLGtiBbOnKE4cq2KB+4eBlf35jFUb0QbKKxJsqt7ziV/7h3O0/sGZsWamYRBp7DXx6lc84iSlIjWahQsR2uv2Aee0ZzOFKysi1K1K9TE9JpqouwaziFN9+Lt3EBuqaBXUETgqhewqNKKv5WMMJUgrOQqh8R60BE2o8p0AB29OfZuCs9NbGbpRz1e75PxBwGoC+4iu6sSs5WSeqNzGmuw1fb6R7TAQLULyrMr/eR1BvZNVZh31i+KtCqVDnJ9I2XGM+aLJ8VmvKsTAoxXROHra2pqwrdI0X2jxSpMWKcVX8eDZEgft1LvbcZQ/ESM2r5zehd7C3sBEDiIMRMd6KdyzH2zW+y54IL6b/uH7E3vuD2H4lypu3ei/YOFRjY8gCMvgQta8FfS1iLUe9pYmloNQUrhylNpJSk//EjaC/vm+rfFWQTsZynLCHYnZxai2ZnKsiSO9nXvP0ttH/rZhTdTRcihECbqITTXXArFIRzaTwOzAlMp/qoUuX35bhF2v79+4nHD1/aora2lv3795+wQf0xCXo0VrXHqNjOlFArmG49TEURXLKskXTB5LmeBKYjWdAYAgl9geWUllyDVS6yYuTHNAck1184H005dF2Cz1CZXRdk3dwaLGz2J/O8+9ZnsWznkLaTvHZVC42LzuBr9tVQ45rz5zWEuOktawhMihPN4+ZR63sKyhmCgQCr2mOEfTqr2mPUh7088IFzCHun8xLpqsKazigLoiZSgl7TMSWK8i/dh/LiDwk1dGArBhXLATNHdN/P0FQNlrzRdbNmD1PbboKK5dAzWmRWvW9qYveWBtHKCZh7CWbjqfRH1mDa0nULz2rAXzdrZpH2SaGmefHVdrJ8VgOb9ifZsH24KtCqVDmJWLbkxZ4csxt8RPz6jO90VaEmaBwi0ADKpkOmUCESkizrDBEPT7czFIMGbxMexUPRLgAgEJwdfxWzJwSOdBwS3/8BXRdexOiXv4I1PIyjKYycOxv5P59kyS83YLS0IKVkvHcXTeMPuYmz51/qjk3RObPmQvYXutiVf4mtv7iJ4c99jvwjj7oDVLWJ/R7AM1sR8oD/T6TmCZ69joZ/+Rh2Lk/uscenaoeCa2XcV9gDwOljea6peQOdVZFW5QRy3CKtubmZn/zkJ4f97s4776S5ufmEDeqPzYFCbTxfZudQfA+GOQAAIABJREFUFl0RhL06QY9GrmLzs839qIpwk6tOCAVf02K+VbyYX1unsWxWE19/aA+3PN59xP1E/DofvnQRl66pY+9Yjn1jBWxHHrH9e86azXUXzGUgVZyaKNZ21rCiNcJXHthNumCC7iaYnJx9gh6NlW3RKREjBPz9bZsZSk9Hf77cm6NJjNFV9GMKY0oUpWQEVZroZmbqqTkSr4OJXGkg4eUfw8hLRxzz/tEiihC01bp1R3VVIdy6GHH6DTDrbPSlV7JsdhsXL2lkSXPkyGJL87iTsOYh6NFoCHvxG9ohAs20HRK5CuZRBG+VKlWOD0dKmms8LGw9/nQ2li15ckeShOhmo/MDhpyXZwg5RzqkzSS/GLqDjJXCI3y8pvEqFoWWz+gn+8AD2KkUhAPsu2Y1z//vNcz+0tdZfOYbpyx6yUSCpZl7kJoPe+mbeDz5MHkrS6Iyxi+Hf0S2kmT5D/YQ+PC3SH7v+wCIaBTsw3sunIMeqrW6Gpq/+DUAMvfcQ+973kPP298xNf8KIbhCLOXskTyhpnWo0VlTCXerVDkRHLdIe//738+GDRu44ooruOmmm7jzzju56aabuOKKK3jwwQe59tprT+Y4/+AEPRrzG0JsH8jg2M5UVKFX15hdG+CKlc381/07Gc6UZgiFS9ct5+MbDcqWzfpGh4uLP5uuEHAEOuMBLlrYSNmy+cjPtvGJu18iVz50EhHJbthzPx/+4dPc9Xz/9OdCkC6aXHvHZmw5McnIw4s9IQS1QYMfPL1v6rPRZJ4GNcmgrMWy3e0q6OxlomJAumf6qVnX3WS6hTHY8QtAHPH4pJTsHXKtaJoqYGjLtNUtsRsq+alzfeNbVtMY8R71PB2IIqAu5GHPSG7qXE3WGTQt6b5WhVqVKr8zUkoMTWHFrDAe/fhuFVJKNnelyZdtir492JgEtNDU94OlPn7U/x1+OfQjxirD1BmNvL7lGpq8M9O+CkWh6d8/Q/w972beht8S+bt38Zol76PN1zmj3fDwOEKoKMvexJOF53gp+zwPjP6SXw79CPHSXs540x1Eb3v0gI4FMpWaOeYDdFn50+/Fu2TxVNvm//oSatAVqOm73DQinrlzpwPq8qP4d91PSAkw1r5qhpWtSpUTwXGLtMsvv5ybb74ZwzC48cYb+fjHP86NN96Ix+Ph5ptv5tWvfvXJHOcfnFzZYtdwlkVNYRRFoWROr5Xw6hoL6oOsaI1i2nKGJWdufZBV7VG2D2ZZGq3QqKZh443Q98wRhVPJdHjVAjea6cOXLqRQsXjVlx7l8d1jMxumuhH7H+EjF8/h33+13U2CO8FHLl1I2XL49qOu6Z2jPM297fRZ/HBjLyXTxpESf6EHBcmWTIzRiQW1o+kKKbXBrTCQPsiVHah3035MlKUi08+RWNIWZHaj3xVnL/8UdtwF6T73/d7fTrV7/23PMZguHrGfgzlvQT3tNT4yRZPne5KkCuZUIWhDU1CEqAq1KlV+R6SUPL0rxZ7B/Cvabmd/nsFkmbktKqYxhEfx0uqbBbhVAe4d/jEZK0WLr4Nl4TVc0XQ1IS2ClJLRr99I9uGHMR2Tx8Y3MFYrqf/Qh9AiEU6vOZ+IPjP6XUpJSq1jcNHfs91OMfjbe+i840VqP/q/rLryZtZcfw9qrsxBGyG1abftZJAAQPSKi1l9wWtp/dSH8MyfT/0//ROB09zqBuW93RRfcNfDRV77WgAyZooCJjLUxGP1QX46fAdZK/2KzleVKsfiFS3kOfvsszn77LOxLIvx8XHi8Tia9ue3FmhGGg6fhs9Q2TmUBdzcXiXTRlEU3n76LFRVcN+Lg/zV4kbX/QncfM0ahBBIuZKvbMtzXfg5lB0/h9R+WHwlKDPPWcCj4jUUdEUl6jf4/F+v4LHdowxNiDDHkSiKANNdv7GgrZG3nFbks/du58tXrQJAUxW+fvUq7nraLYeCOLL+nl0X5JJljewfL9AS8TGsdJBc8j629/Xxra88ypMfuQDTljTXBhFKszvuAwk2wNh2d/0bEsopN2BB9x2yr9Zar1u+avMP3TEtfgPsfcB933HWVLsdQ1nyZfuQ7Y/0+wxnSnTE/QQ8MFYeY2N3mUWN8SnB7KYGgETWPOzC5ipVqhyZgWSZoWSFBc2Hjzo/HI4jGUqWWTk7TNnXBWVJh28OqlB5JvEIL2Q2IZGcGj2LVZHTpqxRUkqGP/tZkt//AcLvY/s3rmakQTJc6uf1zW87bL4xc+cmhFVk/eKzGCoP8NiW+zj14xsOPzCPB1kuIwBn1VqU5zdOfTXZs29hO00XeWHL99EVjVl3/ADhn7YApn/xCwCMuXPwLl2ClJJHxu9nqNTP6fPOJ5PcQFyvI6wfvQxdlSqvlOO6c1UqFdavX8+DDz4IgKZpNDQ0/PkLtIk0HH5DY0FjCNN2yJZc68yCxhDxoAdNCL7629188pcvzVin8Im7X+KlgQzXX3Emytr3Q9MaGHoetv3wkH0KIciVTTZ2TdeDO2teHX+9ppUnu8a46uanGcuVXZGmaKAaXHv+PD562eIZ/dSHvLzvvIUMxU8n5z96cd/PvHYZ8xuC5Eo2CEG4oYOb3n4mp3bW8OiuUWbV+zhlbgTi8133pl2Z3jjSBjXzwH9ADqNM34z+x7MVHtyawLQc2PcQ5Edg/mWu9W14G9QvBd/0k3HFctDVQyfjg5n8fb77RDcv9I2RtoeRmJjaOLtGEiTyFXYNZymaNpoqqha1KlVeIRXL4YXuLJ0NPmpCxrE3wBVaiiI4e0kNHXU+9mRdi36Lt4NfDN7OloxbPWBJaBWro+tmCLSRL/wXye//AIC+V81hpM6hxdvOxQ2vn27nOBQ2bWLwk59kzwUXsOeKvyHx3a+Ryo+wYfQXFBt8yOZa0A8IbhDCtZpNCDSxdAXeYmbmuIHs+rmkr1lEKWmCXYZlV6EEwjP2nb77bgCir30tQgh6eu5hoNRDUAuRc9w+OwPzf6fzXaXK0TgukWYYBlJKPJ4/79wvhxNok/gNjd0juSmBNvl90Ktzw0ULeHDHCF/csGuqfV3Iw61P7uOHG3v41uM9sPj10HkBtJx6+J0LiTyMjljXGWdtZw1XfP0Jstk06O6TraEpeHWFf/vFizgHBhtoXr7ZO5t/e+zYrsP3fP85KoPPc3nDLlRp8fPn+wl5NZ7cM04i6yZ1ZM5FsObdcGBR87rFsPqd7isCQi1uiaoD2NmXx2Mo6JUE7HsUYrOh+VQY3AJIaJtZC1ZV3AoNR+PA3ydTLhIKZ7EsgYYXn66TZ4Tf7ugjkS+zcyhTFWpVqvwOvNiTQwh3qcLxUKrY/HbrOOPZCooicByH/qKbXPuJxG8ZKrvLIZaEVnJm/MIZ2yZu/R6J734XgL7XLWHfe9exPn4+lzW8kaAWws7lGf/uLey54EL2X/M3pO74IWb/AADDAyqPpZ+gYOdp3mshBsfBNKc7lxJhmTjxenwf+TfmfeXf0KLTli6pCMTH/o5t16+Frz5Bz+c2UDAXunPVARSeeQZrcBAUhfBrLsdJ7uWZshssdVr0jKnoztn+qkircuI5bh/Q+eefz/33338yx/JH53CJbCeRUmI7kv95vPsQ11l92Ms/v2oBLw9kpoTA1Wvb2fDyMELAM90JN6xyzoVQOxGenRt23YATRIMa20cPXc+gKIIbXrWAD1+6kFQqAZ7piTPo0djSl+beF2emwLjhVQt4fM8om3uSB3c3g5WtYby9D6H2PQ5CwdAUxvMV1rXXsaU7c9RtATfiMtTsWsT80+lZkjmT4XSFhS0BKGfBG4EFl7vnYGiL2z4ys0LFI/90HhGffvAepjhQoOmaDUaSuM+Hgo6iCCxLIZG30H0pxgp5bEdWhVqVKr8D7bVe1swJo2vHvj2YlsOTO1JuUXWfO2+OF3PguO8rsoxH8bI2ejZnxi+asW32oYcY+fznARi8ZD6Ff3gdr295O8sjp7jehcceY8955zHy+c+7IkkI/GtW0vimlTT8+9sYvOGrrIiuRHUUEt486DPnbekPUPf//h+LNtxDS0eGfW95G4Wnn3a/FILm73ybl9YbLPn0bzGGc0ipoM47tFJAaiJgIHDGGejxMDv2/YSkodKg1xM16kmZ40T1GmJG7Ss70VWqHAfH7a88//zz+fSnP80HPvABLrzwQurq6g5ZK3DqqUewEv2JMLc+yPM9yanamgcihODNa9t59fImNEXw0M4Rzpxbi64qFCoWsYDBV968ikS+wlNd47x2VQtvO30WPkNla9/MaCJKKdj0DVewLb0KhGBhc4ifbZnpMjyQVy9vRjZeTrpk8sxLQ/zVkkaEEFx/wTw+f/9OLlvW5P4ehQTBjV/j5nNP4caHu7j5b045Yp9XdaSp3ZchXXshEUVldXuMj961DWO1Sm34AMHU8wQMPAun/cP0WrcX/heC9bD2/YCAcgY8blLbXQN5akI6tWED6ITTPzS93aq3QzHpCrYJ9o/n2bQvyV+vmRnhNcmBAs2jO4yWhzijsw6f7kEIKFYsxrIVDOFB1W0qMsFgFppCIXYOZVjQGManq9U1alWqHIXKRL1K97o9No4jeWZ3morlcM6SmilRl8gXkWoZgeCMmgtYGFyGetA63NGdm0nc8E8gJb51p9H88etZEF0x457imT8fp1RCCYeJXf1mYle9CX3fj7FTQzwxuoj6n36BwR2bWJEtEejPwKRHQdcpvuW9DJ51BXOX+1G23sLQD39D0XSYDKfyn3YaYwvDxD9+L5EXh0ERtHzly3jmzDnkOEMXXYSdShG98krKO37OsyEJCNbFL2RfYTcAnVUrWpWTxHGLtMkUG/fddx/33XffjItJSokQgu3btx9p8z8JJvOjPd+ThMMINYCQV6diOTy2e5T7tg1y3QXzCHqn83UlchX+e8NOBtMlPnjRfKSU3PrEfvJlazrprCcCjSugfyMEG6HzPNpq/Hzw/IWMpivURQ4/SYr6xYwMZ/nX/32GRL7CVWvbOWd+HTc9vIexXIW6kMddCWuVWNbu5yunrDrywUqHyNBjlPGRjK0mAjRGvKxoiVKsODy1b4zls8JTbckNuevOIhNr3TJ94FRc8bXrHlfInfsJpGoQ8KjMqvNAshuis2YGMXij7r8DeHZfkkd3jU6JtIrlptIolG28HoWusSy2Ccl8maIyClKhIxJj/2iRgKEjJRhCBxxAYAioGIcXahVLki1a1ASP70b0h0RKiWlLHEfiNVRKFZvBZBnbca8vRUDYrxEPGe5nuJbWKlV+X6SUbOnOUKo4nL2k5tgbAD1jJVI5k7OX1ODzTEeT5/MaAbuZs5rX0u6fmTIjZSZ4avRBzN/cy7xSCa25ifp/+AdEv07q/h9hJRL4V63Cf8op6A0NtN10E8LQKTyzkZH//BzllzZT7ktQ50ykwzhoTP7TT2fkA59hqKhydnMC7clvs+/rD1HcPTYl0HynnELzTV/jiS/8PY0bXJHV8LGPETzrnMMeZ/iiiwhfdBEkunhpzw8oBgPM8S+k0duCR/GQt3PVKgNVThrHLdJuueWWkzmO/zMcj1AzNIWPXbaY257Zz4fv2sYd71k3FVXYHvfz4/edzjXfeYZixcLQFC5YVD8t0MC1Ii14DeRHoes3EGiA+sU8152iKeblnMhhKjs4NpgF5tX5+eF713PVzU/REPZy3sJ6fvy3B5joJwSRgoMtJe/7wbN87c2rMQ52XQy/iF4apTt8DrMapkXT9ectZN9YgSf3jvG+cyfWZsTnw+57YXzXtEjTfW5Ep5Su6xYgP4yItLO0IwTDW2HbHW5VgqYJsdj7lOvmDM9MfLytP83SljCj6Qov7MuQLbpRnl5Dwe8VVGxJxTTJMQK2QtdonqBHozbooexU0ISGggIIsAVC6BgKFLRxkiWVxqAr1ObWhzBUhZDvjx/wMhmxWzYdtu7LkilaFEo2liNpjHlYvyBKoWzzcm8OTVWQUiIldNT7iIcM+sdLPNeVIezTiId04mGd+ohnRj4r0zEpOQUc6WBLN5ecR/FiKF40oR02aq7KXyb7R0v0j5c5a3HsmG0nH8o76rzUhXUCXo1CMcXerifpGA+Q2vpz6gd6GR+5E2vMxkqME/7gtew+u4Yd2a0omQKn3/gUANbAIPvf8tZD9jHvqSfRYjGCZ53J+K23MnbTTcccV+0HrmffeW9iKFXh9IVhKp/9ELt+/QKyOL2sRJs/l7Zv3MTO732ZhjvcKM+ad7ydmquvPvZJCjayOLoGf6yD+oA7N8aMWs46yI1bpcqJ5LjvVuvXrz92oz8TjkeolUyb16xo5nWrWljQEGI0W3YtWbgWqR+9bz0vDaRpivi44uuP0xH38+rlB4gTRYPlb3FzqL30I/C/n0ShjKocwQ1XGIWnvwLzX01n+xnc9JY1jGbdFB2m7fCe7z/LN9+6Bu9kULl087cVKjY/eraXa9bNXANmp3oxhR/Rto6/+tKj/Oh966kJGAjNYShfmEo5Arh50TwRGN8NsycW/qoGWCVXcJbdtk4hyYvJGHOb/Pj3PeoGOdQvcdubBdh5N7SeBmE3z5DjSHrHSyiOyvLWKH6PSlPMw+JWnWhQw+/ReOzlBJlCCbyjBAyNcgUe3D3IO85speDbgkDFKC4DbDdUSwqQAssWCBQ0I41p+1CEws6hDKd01hy/q1NKt7KCVXQFqWOB5p1ef2eVQNFBOXaGcSkl6YLFQKLMSLpCxXS4aGUcTRVuVveYh4BXRVUEgQmrhCNhTqNbQUJRBLoqaIi6f2P1EYPT5kdI5S3GMmX2JHqpbU4xJ9ZMuRBAkQq98jl25LcedjyrIutYG3NToPQWu9lf6MKvBvCrQfxqkIAWJKAG8Sjeqpj7MyeRrfBCd4ZFrYFjujoni617dIWFrUECXo20mWT3m68ksGOIPqDpgPaTWco277mX3lVL0YTGivjpwO2H34GiILxesA/ISzl/LoE1S9Da5jL+2INo49kZmwifj9Zvf5vgKWvIDmToqA2S/+fryT/87Myu62rp/O4tWENDiK+6+zfOW0r9P//zYYdS7uqi0ttL8KyzEKoKRgAx/zVM2gYd6aAcJdVRlSongldsUshkMrzwwguk02mi0SgrVqwgFAode8M/MY4m1A4u6i0nLFandtbwLxcvRAhBTcDgrHl13LdtEEURfOuRrpkiDcAIwIprYMutUMnSWuvHLisUKzY+46AbfyU3vQ2wpsN94r1zUy+XLGvEdiQPbB/m1fMn8hpN3Fdv+KsFvPcHz/KGNa149ek+i7NexQ7WsLI+wqKmMPdsHeCadR34PCq3bdzHxUvdPlVFuEKsZq6bQsQquwEDjjWd7y0+D/LDFEe66Co2Mj+YhGw/zDp3Oip0Mtda1J3iBhIltu3PUqo4XLSogVXtYRQEiiJ4bm+GBS0B5jdrrJ0X5eVEkv/e0Mfc2hgr26LU1pTIhZ8GtYRw/j975x1nR3Wf/e+UO7fXvXd7lXZVVl1CEhKSQEjYAlMNNg7Bxg5gO7YTt/gNcQt23OIkjuO8xAVejLHBBhcMmN4lUEES0qqX3dX2enu/d9r7x6x2tZLA2MGJ4+jRZz/avTNz5szMuWee8yvPT8EolhFNxbpmwUTVNTTTpMbvIVsoMV6KoagVOBWdXd0Jzm8L4SkMWJbMcg7U7MT/eUsmxF1p9Xf3nWCept0WnguL32f9vu8nlkvXWWEd46604vTCc0B2WFm3AoiCwCtHkoynyrgdEtUBZfJlWCjp+FwyyZxKz1iBomqwsNlLwGMjmdMYiBfQhTyqkKNo5qjDwJTz9KZH0HWw2yQynhFUd4lYGY6OnjaQTQFFsBNxVAJQMooU9SJuaSoBZajYz8HMHs6G+d6lLPavIFaOIiIgCRJVjrq35OVkGCYmTOoLnsN/D44N5akK2Jld98aaaIauc+jh5yk89hguIws/vIux0jBPjP6Kutkh3EdG0Fw2CjU+xIYaGttWUa7xs03YS2lGJcsOuYk8foC6r92M+eILxH5wJ4n7LbIk+nxUffbv8F911fRFgWkgeLpJrfQh3f0EcrFsCdBObA7eeCORv7uNwXgZdz5G3Y476P3nJ9Bjp8UB2+20/PRnyOEwspii5obFZA6OUv/5z77uIiT6H98l/dhjeDdtIvfJdUjeemYGraSGnJblV8P30u5dzLLAmckG53AObxV+J5L27//+79x1112Uy+VJTTCHw8Ett9zyJ1cWCs5O1E4naGAlFdz9/uXc9MOdfPahA3zl6vmTL54Nc6toq/RwaChNLFuiwnNaFIW3Blb/DUg21trLPLUnykCsSFvNaRPmJEmbTohf60uwpz/J5QtreGL/CJfPmskEWwFgUUOAyxfWMpgsMDPisfTOTAOPw8F5c6oBuGZpHd957jgNHi9tNS4Kqs7Na1qmvzxDMywXZm7Ucnnqp9QJrVkGfS8jJk8QDF2IY+xl6/ynyo0kJ2qYBpo51J/l6GCO5konQa9EqlhmIFriyIB1jXPq3bRUWsK4A8k8n7qvm8uWBZhf66cvWmTlwhRIRWxqJa78fIugAQYm27tjzI0orPSOYcumkbQMtYU8HjVNqlzNdulddI5laR/fghI/NNk9U5QRbC7LOgZWEkTVQrA5QHZaP5JsacadRGSeZWHMjUG8E8attPwTbX/FWMmFEetiidSBI1BNuxSgUBkmK4aIlwykrEptyEG+rNMbT6C40yiVCSQ5Q9ZRCSxjZrWTsvsYW+JTIp2xk8oqAiBDzgRMEUUPIiolHKITu2RHMzSyWo6yWUAqVXJh3TvI6AkyaprNsSc5lOngeO4wiXKUsnmaKjvgljzYBIWgEmag2MuL0ScmtwkIuCQPTc6ZLPavxEDnUGYvWS1NQc9bRNAoYhgGXjHMItsVzKx2UdQKPNq1BaEUQiyFEXQnLkXk7Usj6IbJk6+NW9IyiojHYblxGyPOafqD5/DWY3mbf9KFeTYYpRLJhx5i5K57kAZ68QMacKJrG89J29HRKLx/Ex3vXUvKXQZB4OLw5VR65gLQnt5DQ9zN8F+/j3wqxZjna2ixOLktWwBwr15Nzde+iq3amo+MfJ7SsWNkDu9ndPMjmDuPYctO6TROErT3vZfK225jf1+W7OAxHA9/k9hvDkwlEJyEXaHxrrtQ6uso5UZQ9t1HYFUz/vVLEGoXnfWaS93dpB9/3Dr8oiU8ox2jnOqkwtNCUAlzNLufvJ6jqL/5KinncA6/D940Sbv33nu54447uOaaa7jyyisJh8NEo1EeeeQR7rjjDgKBADfeeGZswf90nErUSvkygsAZRb0BAi6F+25ZyWd+3sFQskBDyCIwiizynT9bwtv+dTO3/Wo/d54t23KivFKw1M813t0oVdeeuc9plrST+Nw75rLp21tY1xYmlith2n0IG782bZ8vXN6OphuUNQOlbzNG3zb6Wj5Ac5MVqL+mNczWY3GSOY2Ax8bqmWE+/+v93LCyibfPsyZOKhdYpOWk9WzpzZYbECzrkahgV+NUuzXo3Q+hmdO10xInMB0hBIefupBKxKcQ8Svcubmb/niedS3VzKhy0Vrjmpb6/9zhUf5y7RyuXlZFb6bfmqC1RaRS3dQWJPzmHlxGFoeR5eHETPLlMDPCfirjuzEEgaBqx7QFSTlrycgVeNwirZUe0uI6eszFxEsKJcGFho1lrX4a/U4GY0WSORlX5HLsNhFRBJci4XPZyBU1evuzlDWDsjqXkjCbukYHM6qc9A2O0tfTR3pcwu3QaXCWsKcGIX0cnwDYJFSbiOlpI+tbyEvREQayx8j6Joihbv0Mlu0czu4hp2fRTCuexi15aXA24xBdGOgMFvuosdfT7GpD0UOMpws0VCpomsmevhHsvgSGPUtCjRIXx7h/8LsAOMr1SIqNuDo+bYwICHhlP/XOJhyCgxrNRr0qw9go/eVhGmSFcUmnKOqYmOT0DIeyezmU2UuV4GWU6S6ok9AKOTqjOZoiTjJ6iri9YzLa2y368dlaGCzMplKpY16jl5JqUCzrlsgy0BhxksxpbD2SwO+y4XPJ+N0WgfM4/vtjC/+nwjRNdnelqatwUBO0M0V9TtlH00g+9BDRO+5AGxm19hAE3OvWktuwkGfVFzAm5q4h50nLldVOQJ5azMwR2zhx6zsxUinEgB/R5yf3mEWAHIsWIYXDMBHmoRoqvQ/8APUfvw9Mf0EZNhHD60aOZxAUhfCH/5LDA3m0gd2sGH+MEy91ThI0QVEwyxaxq7n9S+iJOIO33cb2D0RwRSQuHgX7jItftzJL9I7/ANPEPncue+dlKUsi7c65BJUwqlHmQPo1ANq9Zyd553AObxXe9Cx3//33c+ONN/L5z39+8rO2tjZWrVqF2+3mvvvu+5MkaTBF1DrHsrRWes4gaKfu990bl6HpBr/ZNzQpi1EXcPLSZ9Zz6b9t5vkjowRcCksbzxKgO34Y+/getj6eYeklN+E49TwTxchRpgtMeh02vvbOBTxzaISfffD14wa/8PBBllaJXFfaTEYKM1Z00zyxTRYF1rRU4pywYHzj2gX805NH6YvlpxqQTtMwc/gBv/W7IFKefQ3S4V9QLcVg7tVgO6WfWhEzPcig0k64rON3W22NpUocGspwybxKLp5XMS1TsT+epy+e54PrZjKS7+XJwfuYqWziqUOd3NQwzrKcVf7KQKQouBg3vKjYuGZJHZLNpDO8CUVsJubwIIrCGRZQT10T4TrQdJNcUSNX0nEpEmWjRLao0T1aQNNN0r6t6HIaSTLwOCXyRRNdtSGZdoKlxSiGH7tNJKUlOZ5WydgaMDUoZlXSHg+97cuJlgaJa/FTbt4IbXKI41nLkufQDIqnENOyWaKsWdYtWbARsIVwSx4yWoojxf0AuCQ3A8UejmYPoJoTVoaTCi4KMFXW1TqH6EJAQLPFUA0dETuyJCALIqahUTTLVIkBzg+uZyC1n7G+RzmuiAw5beTsIuZpLkm3LoJLgA93AAAgAElEQVShUpRERoUMbekiggnlUAt+uZ06oY6INoatpgVpQtvPg5cLQhsYKw0zWhoirSXpLO2lc3Qv1fZ6rqr5szPGLYBTEWlv8JDKaSSyKr1jBVprXMxt8NA3XqBzOI/bIeG2S9htItVBO16n5ULOFqbc1SbmZHJFtqhhmuCwiW9KD+xPDft7swzGC9RXiiTKGfy20KQLe0f8JZJqnNCnfoBndw8Aul1m+NJZLP3gl/A3zWN3bDdG/gVk04lTryTk9BIf3If7tU78R3IcmjOD0vkXokgCjXd9FbW/HwAjmSJx772T/Sh2dFDs6MBxw3ux+0IcL7zGkUg/i0SBQp0PsSWMsuIKBiU/3lcfIvDCPpAk6n/wfbr3HKOoR1kqbKHnzp3oqQKmKKC0tiKoGuUTJ3CtXImeTjP8uc+BYeAInUf+qvnYFD9ULz7rvcnv3k36scesP26+hm7bCC5DYEXEShA4kN5DwcjT4pp1ThvtHP7geNMkbWBggIsvvvis29avX88DDzzwlnXqjxEeu8zihjdXly2v6nznueOMZ0p84IIWS55kOM3Na1r4+uNHiOXKfO2aBWyaXz39wFmXQSnF6rEDHNn5GHPWXDW1TbaDKzzlYjwFF86KcOGsCHv7Ejy5f4Db5ietKgChKeXs65bVMbb9PoQKlb32tSyqnyJRsYxKPKvy6sAYK2YFcNok+uJ5zigHn+i29NKaLoRCzIovm6jXaaueR97fis/lhtNe6AOxEiP2S6ioqpnMPuwZK7C3O41oiKybFcHEKiWVzGmMpUpsOdTD6opR9pRPsNOZwRQEMsN7WRyaTdnvo0sOUJIqOJqS6YsXaK3ysqDOARjopo5DbsWpOM5K0E4ininTlx5jqDBEXBumLI+hykluqPtL8iUHXqfMDjVG0UigAsUylvzzhCXIL1dQFgZwuxfz7PijRF2jcPrjOaU+tYCAXw6imRr9uRNISICJLksIpk57wU6XvUhEk0i43GT1DJqpEi2PEmUq2ExCJq/nyOu5Uz6TEAUR3TQwmB5HN09ZT8k2Qmfu8KQn3ECjbELZnOwcfeV+Hui/m5yZgfCZ4wxggXIxS6vaGRwzebbwfRCtrNHjPoe1gz4M+jD7gKZsmQU9RartNYg1y3BWLWS+b+lkW2k1SW+hi578cRqdU2N1JD9GspDHploLh9qQA59LZiBaxCYLVAUUiqrBeKqM1ylTFVAolA2iGZWyZuBxSHidMv3RIt0j+VMl+bhgbhC7TWF/b5aRhEWEbbKVrHH+7ABORSKWKU/U0/3tCSF/zNAMFVmcWlztSrxCSksQzafIaBmoLPBw3Hp+N9R/EK9sLbr6Ct3E1SjFNXW0dvQxdul8UjdejBKuwVZZT994gaGeBqrsVxMpiPi2PIHj5ftoOj5VcUWUm9CvuAjzF7+i9JTlKjdcDspBL7pLQXVJaG4RzSXj8kUYi0J8bwxNCqFVLyB+QZy2a1fg9c9j+J//nXkXXUT6BSsJpuKDt5J84AH0J57E/2d/jnHZAoRAH4YvS2pmgOAeS1bDf9116OkUY1//OgDJhTWMXt7O1WkFsXHlWRN+jEKB4S/+PQDOlcvZNt8S9V4ltWEX7ZSMEh1pKyt0eeCCt+5hncM5vA7eNEkLBAJ0dnayevWZQZJdXV0EAucKy56Ez2Hj/920nKvveIUljVaw+6/3DrK8KYRTkfjYipn8/SMHSOYtrbNJCCLMv57oliRzitsp9Tdgb5h4qTVfZP28DvJljY/9dA/ZfJHb7Fug/vxpJG1ZIAsVQwzYZmMLNRNwT03epgn1FXY+//ggf39VOw6bRG8sd6bFMB+D4T0g2WFgOyz/iFXHExC6n8Vtc1sVCAJNk5a34XiRXSeKzG5eTstEmZn+aIE93WnaapxURWpw2iSeeG0cVTOx20Sa4k/wV/6jbA65OOhSEE2B+aUWHj4UYdNCP0F3CMIx9vam0VRwSDYiHjt2BXTDxK5X4rRZBC1TUCmqBvUBF/1jRTIFjcUzfGxLPs2x9DEMsWR9CyYu1SE6OJLdixgSqfEsZJNxJZIg81L0ycnyNicxLO8EIG00YBft2ARlyqp1FgRsFYBAdppVzfJyIsBBVwkQcJrriScS2G1xJLmPvKxPE//VsV6sbeKFNNjbqAna2ZV+iaPZAwA4JTc+KUBQCeES/ERsfjri+/FqTZhyCdWIURJVTkcJnZKeBfFkaPYEgzslUtsuuHFITmrCZRjUznKV1nEm0ONR6PEoyEYWT/4F5u99kraat6HUWxZfny3AAtsy5nutMZ4v6Ww7kqTP/jxlRz92tYpW+zJqgu3YJBG/24ZumBPWT51cSaO50kUsU2Y4UaLCq1DpV6iYSMpY0ORlQdPZk5qWzfRNuFYNciWdfEnHPmFR23k8RaFs4LZLVPhs1ATt1ATtf/QxcbqpMVTspzffxVCxj6Qa570NH8EpWYS7M3eYlDZRhUS2rLR+KYhL8lDcf4DEv99N5W1/y+r6DQzFy/QtMej/Zo5yRS16sUhS3UysPEZ9uJWKkS4yd99F5vnnQdM4ORLKYTe5+fWMzo3jP3gPNd+/e7J/mWYf+75xKeYE+RWR8Nn81DuaOd/XzliqROf2XgL/9gsc/V0k9x8hlkoimFA6dNBaX1TXEPvu9ybblI8fpef27ZS7utDdNoJ7rJJRFbfeQm7rNooHrTjR+NtncfBjq1hRuZ6Qb7k16Z0G0zQZuf12yl1dCHY745+6kjQnqM+rzGxZB8Cric2UjCJt7vZzVrRz+C/BmyZpGzdu5Nvf/jahUIjLLrsMURQxDIOnnnqK73znO1x55ZV/yH7+j0NDyMVXr1nAlmPjLG4I0FrpoWs8yz0fWEHQZePiOVX0xfNnHijK+Fe8n/TW/4vz+G+gZp5lRfstcCkyl86v5vH9I2jYkNVT2jZNOPobNMHGIftalp9Wky/it+LD5tT42NWTYE1bmJtWN7O797SyUr6JigDJHkt6wjuVbF8c2Itpc+MsPjEtA7JvvMAC/zgzaq34tERWZVdnmpDHRvdogQvbvUhjHay3dSMuvIpMSeXlV0X2NofJihpeycfGyivRiwE0+Rjr51vyF6MZmReOHaO9MsTcaj/ZvEauqOM2K8kYAv5AhqIYI6bGKAoJTuSTVBfXEFGq0XSTklHCFMv45CA2wUbJKJLTMxSNIq+lLA2nansddU5LusQpuXFLHpySG6fkwim5UQQ7WS3FltjTZHUrJsstegkqFQwUewCwC06qxVnkSjopdRTVNhULJpgiIjKmcNL6ZSIh4/c6qHOez6BxkGN6D2eLF7IZbrIZFyPZfmz1o/SZ3YiGA9M0KRplCtogqVwCUSrymmhYY0COToyx6W2F9Xa0RCMRZ5ghz2/Im6kJmnWyoycPExGcCUzTxGVTuLnxEyTVOCOlQQaLvQwV+ykbJeyik7nuRRzI7kYzVTRRIKlIvBxxsU3bRls0zRxHG46RYU4wh3ge1i8I4VBEakJ2PPZWOktpsoxy0HickaGdLPavZH7T7LNmlYZ9CmXNJJYu0ztewDRh3bwgFV6FVE7FoUjT9OPAihVVZBGvEyKntXfJ4jCJrEosU2Y8pXJsKE9tyIGmG4ymylQH7H9UGamjxSEOZzvozh1FNafIt0N0kdUykyRtdWgDAqAWHdT5gyiinXJ3N+Pf/jeiz1jJKcPf+lfin/kGw7EisgDu5jD1oSL71KfI6Cn2pXfRXN1GKT5O5umnAShVuBi9pI3xdc3kWkIgCDhFF01ffQmMqTJs3spGLgy9Dbc7hF8O4pa9k89T0w26f/QA1T/6FpStazCSSYvySyLCRDk3c8QqgSc6ZASnm1JfH8bYGIYsYstZx7lWrSL+o3utmDRZovi+ZRx493wqpRALvcusxfDZHp+qYk7U/qz+4hdRW5pwJIdZE1yH4LTCU5qcMxkpDrIyeHbh23M4h7cagmmeZUlxFmSzWW655Rb27t2LLMsEg0ESiQS6rrNo0SLuuusuPJ43V5D3D4WBgQE2bNhAb28vmja1yj/19/8ODKcK7B9Icf+rfdzzgRXs7ImzozvGxy5u48fbekjkVf56Q9u0Y7q6+xgcz7BwQZtVePzYY1ZmZ/O61z1PNFti3TdfYOvaXQQqaqzg/pPIjUFujJxvDraJFxRAR0+a2qCDiF/h3m09hD12LltQw1MHhvnUgx3s/sIlU9Idhg4vWK4Agi2T7euGSfGFb6DYRGzlJDgrMFd/GkEQMDMjCDv+DVouptBwMYf7s/SOF/HLeYp9W9gU6kXU8iDZOd76QWoiEZ6K/5RoeZRmZysXhS/FLjkms890w3oZ98cKHIvGWbNAYDBWZCBeQiyFKfj2kLefwBDOzFhcHbzYCoyXXOimjl208+z4o/QVugFwiE4qlAghJYJPDtDkasUrW1UXTs1+M02TbYkXOJLZP2k5q7BFWOhbjk8OsSf5KqPlPqpsTYwldVT7MJIgUxZT2AUXIaWC4VL/tL4JmownrTKrXAsjDcTiOYqBEvH2AiBQ5bcjSSLxTBHdLOIXmmizLyeTeYBuaYzkWbT8TsKriwREP1lZIKHHz9guCzI+MUwwvoku370gvHF90/c2fASXdKZcg2EaDBX7yOs5ZnnmoRpldsS30FM4jiIqSEjE1SgGVvsVRY3LB0sUQ4vxtl2A5IlMa6s7d5Q9qR2TSQ4+OcB1te/HJr5+jVdNN4imVcI+BVkSeK4jRrqg4VQsEWOfS2Z+owdBEFB1401p5p189mOpEluPJJFFgYawg5YqFz7Xf3/ywmMjP2eg2IOERJ2ziUbnDBpdM/BIvskx2zteIFvQaG+YuPahIcbvuIPUQ7+eJFLFOQsZvfaDLL1yDV6HjCjC8UIHO2Iv4t/aRaB6Jg0r3kZaS3KefzV9X/wsu+YXiC6vRdIjLKyYQ42rhgpbBPFYHwMf/8RkLFrFBz9I5BMfR5hIEDBNk1jGii9s1GLk//Er5Ldtm3ZdmstGdO0sqp86OPmZWB2AdA4jP0VGNaeMXJia423Nzag9PdhbZ1Jx43weWh5El2xcO5AlEGyHede97r00TZP8tm24JzxGqqGeMd7eKBP2HM7ht0GW5TP+bmpq4rnnnqO+/szSiG96hvF4PNx///08//zz7Ny5k3Q6jd/vZ/ny5axfvx7x9URY/5dDN0xuuHMHn3n7bD650arv1hJ286Ef7+aS9mo2za/hhju3oxkmn9zYNvnlb2isZ8/4CH/z8w7uvLoGYXgv+OrekKSFPXa+/s4FuIrdUJywghk6iBKDRR8OZ4BP3Lebv7ighfVzKommy3SPFKgLWfFE71vVPNnWUKrI5QtrpmmrIUpWcfR81LKWTSCZU3FhIOtlSxetEOPwkW7cFbU0pTsAUCvm0jmUJ5pWudjbgWf4JSSfAc5aaLiMhGc277tjB//yLoWLG9/BQLGH+d6lCILAYLLA3zzYwScumsNIooRhgscpMLtJ5Xiui4i3iivrFlBWRZ4csJGljKwFkNQATsFrvUhtOTrSO9maeJ4LQhsmY6PmehdR72ymwdmCXw6+4eR7UrxSEARSagLNVHGKbgpGjqSa4oXoEyBMrXn6ykcnY9RM3YlcjuBQZJods6kXF2G+sh/hiYcQOntQxtKIpxR/dwPmknaa73mQbFGjM3eQwg/vpDaRodxST7ouzat14xR9OUxJnvBMmtPcogDNVHKJbxWiw0NcgqPFo2S1NOPFKHkjjY6GZmoUzDTXLghTM3ITx7IHGVNeRZyImTtJqiqVWiL2SmyCjYeGfkK7dzFe2Uet03LZi4JIvdMaQ6ZpUiyJ5IoGOT1DTreyOf22EEnVIooZhwM14CcQ20Ep8SrRcBOVLVcieGsQBZFWz1xmuufQX+hhb2oHDskx+cJUDRXd1HBIzmnXK0tW4sBJrJsfJJnVSOU1MgXL2nqS7D+2axy3XSLksRHyWhUb3I4z45ROjolKv51Ll0bojxbpGcvTPVpgxSz/5PfnvwK6qXM8ewi76KDFbS3sFvlX0OiaQZu7/Yz7AdA1nGdfb4b2Bg96Isng179B/onHYWLxWmxsZfy6W5FXrmbFDB9Bj5X9u3X0WdRnNrPoZx24e5OkFh7mxZlWvONczyIO/dVyooVubFoQ2WYw09tKyBYh+bOfMfq1r2OqKqLLRfU/fBn/O94BQEk16B0r0HdijNLoKOHeQ0R/9B0oTS2qTElk4J3zGLj2PNY33YTi+FdinT34vAUKO45xqpG37HdgS1tZMqYgIpgGzkULsa9fT80qGbkc5RrXOpKpowSK41A7FRN5Evk9e3AtsaqiCIKAvHJin9wYtlIG099Ib6mHJmcrgiCcI2jn8F+K32kZKIoiGzduZOPGjX+o/vzJQRIF/uGq+fyfX3Rw503nUdYMwh47n9zYxud/vZ8HP7SKn37wfG64cztNIRfXTtSvVGSRK5dV8+yevRg7f40k8KbcnlctruPQsw7mMIBYzsHuO1FrlrNnvI0Z1S6WNQXZ3h3jotkRDvRlqTpFWNU0TW69dxf/ev1iskUNn9PGXVu6uWXtVGzbZMp6eKqgcCyj4jE1BL1oaYeNH8QYP4KjuhZj6DWKSiXH4k4G4wU2LqrAHo2w+3gYo2kdyxcvZaQ0xI8P/ZxLF5zH6lYrziOoVJAuaIwlS/x8bx9za7yomsHL/f3UNQ4RCg3QXbQC5wU3zGURNlljQ+1aTowvRw4M0pHZStLoIWkwKX0ekCMk0ibjZhmHIlKnzEB2vv7Eq5s6B1Md7E/vIqREKGpFShpkjTimYFIwrD7olJnmQzkljkvKlgju7iay+QSliJt85z10feKdVIz00bRl71nPawLmvsN0rluOKYDDIeMfzyLqJrDb2kcUKFZ5kPMqxYibzNxK8i2V5Opc5JsCmD4HaXWIp3M/x6UZmGILJ1xFStKUG9tNACHbSEhoIpYpM682jC/fyLZEF0k1Ps3tOVYeQhEVOtI7GSsPMxazXE9O0cXq4EZ8ehMIApV+O33jRV7rTiOK86nzBUk7DpExRsmdYqQrY/CzCoMVDRuQk/28rEQJJR9jrrmUVlsDDsGG4AjQ6Gqh0dWCZkxZTw5nOtiZfJm53oUs9J2HZ8LieTpskjjpzj8VArB6doB41kqaOdiXZdhbYvWcIIWyTjKnEfHZkE+ztNltIq01LmZWO4llVPxuawrd15OhKqBMVoR4q2GRs4O8ltpORksRsFXQ7LJIQ72ziXpn0xnHmKbJvt4M3SMFwl4bw/EiR1N5mrdsxaZpqNV1ZK6/lcClm7iwzoN9YkFmlsuMPfhT6u6+H+eQFThvigLlCjczpBZmhhbQUzhOX6Ebm+lElRMgKDglN+lHH2XkS18GQJ41G+nvvkRfQUO691dEUkPkjnVS3HeAutFB5JYZ1Pzd39L/gxKSz4VpaBjZMoZNZOC6xcz2v5OALYTj/TdR+tRHKRwcnnZ9cm0tkiSgpwbBZkNQVZQZM6i5/XZePjqKN/4LxgNvx5vz0DRw1MrmDE7NZaauM/bP/0L8hz+k+va/J/ie91DUCzwweDctrjbWxlWEvpc5uPQKXkm/whzPQi4Mv/0P8nzP4RxeD7+zrX7z5s3s3LlzsuLAihUrWLNmzR+ib38yWNMW5sLZldx41w5+fPNK5tf5uWFlE8fHsqQLGmGPnZ99cBUuRSKZL+N32hAEAUUWec8Fy9nV3cNKdz8UEr/9ZMB9PX6qlXn81dFHIDfKYNLKYJtV6yatVvD1xw8zFC+RyKpsWDhVJ1QQBHIlnV29CWK5MrV+Bz98pYflzSEWncxsbb7IUuM/RdRVVQ1sWG4/vWYZWvQEjUIPYv4EYjlNzN5M24nvUzfjSuy2SqheTHlBI+c1BehI72RHYgu+kMHbWjRM02Q4UaJzOE8so+Kyi/x6zyA//dAyfrj/aWYsGUCUDAq6pR2miApDxX7u7vs2c72LWFtxCcFGN125KHkjQ0AOUWmvoUppoNndQjpjY++JNC8PTN3LBU0eWmvcdA7l6ByxYvkS0nGyrn0YcmaSbGWLqambfOq725AQEDGFKZeLcyBJ+OUewptP4DmROCMExt5/iLGFAeTL56LbJWqePo6kCwjFMoJhWEHSuomYOlMsU7XLyCUNwTBxDluxcLZUEW9nDDg8uZ/mlMnMinDwSxsx3A7mJU9QQsGtSoTKJfrdCkUjgVNJk9F7eL73OKiNhGyVtAfehcsJnfERYqUYXl8BuztHlaOaGns9+4Rdk67egpHnudgjYIKLEM1aI1WORjYsnInXKSEINcB5jJaGOJB+ja7ckUnyZ2CwPb8Hh8NJQAgS1xO8En+ObaZAc7bEbELUV6xArFqALE0RraJRwDB19qd3czC9h2ZXK3O9i6hzNL0pS4coClQG7FROkCrDNFE1q0/xjMqrx1MIAlR4bFQH7dSHHdOqgAiCMLm40Q2TQlln65EkNUE7C5q8Z7XI/T7QTZ1j2YPsmSBnALWORpYFVk+7Tt0wGUmUyBZ1sgWNdLaIq/MgxvNP01jI0P+hL2ICok3B94lPEfTZcW68BEWxUdQLnMgfYjjaw7zHRkjd91MYHsYJGJJA9u1LCN16M6tmr8EmKkRLo5bVGAHV1EGAubYL6ekYxfnTnwGWdW70uo/S+Bd/hjwRUTMREclJ56E2OEDykUdBltDTUzG05YCT8z/9LMP/5wp2dR6n4ZPvsWLFZInIRz9Kdv8+ilu3ow0NTd0oVUWw2aj95j8iOByUavfzSngW1dkWGnt/RElwo7RdBhM1cPXxcYY/9zlyL78MQGHPXgLXX8+OxEsUjTy6qSGk+ugLBNma3oqIyCzPvLfkmZ7DOfwueNMxafl8ng9/+MO8+uqriKKIz+cjnU5jmiYrVqzge9/7Hk7nmab2/0r8scakAWSKKp9+sIPLFtRw9ZK6yc8TuTKiKOB3WlPXh368i2qfgy9eMQ9JFDjYl6FvJMGm9PcQBBHW3naGVtrpeGTvEDtefpyvzumiGFnCE4ULOX+Wn5qQg6Kq86/PHOPdS5vIFjQWtUy3QPzL00cRgL9YY0mHPLizn4NDKb79niWvf0LTgP4dkOjkROQqpOMPU2d0E6WaSr0XARNVdCHPvxahsp1dPXGaK23szDxDX6ELEYnz/OtYHFjGgb4sncN56kJ2ZlS7SJfKPHt4lHedH+DBoR+ekjs4HU7RRatnLqtDlkzM67nDTqKsGZRUg8JEZl9Ppp9opkzQC33yFsqnaGcICATEKkJCI4PaMYpmFtG0gVTGQGet+12McpTO3AHaftVFxTOHkU+MnHlSQUBpbcC+tAmpPUxx/wlKzxxBO28xfZfOwxg6QX3PKJ5t/ZgOhZJDpoSJoyuGWH79MSx4XGiGSqYtjBLL4RxITyeFoojQVIMyowb9eA+ks2hzZjLW7CTR7CE9I0ShzgcTViOlWE9DJoIpzsHpdKGKWYbKnYiIzK4N4pXdDGrHJ7NJp9XpmcAs9zzWRy4DIKtlKOp5KpRKBEEgq2Xoy3fR4JrBjvhLdOUtzTufHGBV8CK688c4kTuKNiElsnE4w8yiYAkqz9wIDmvBkNOy7E/v4nBm32TVBJ/s57Kqd+G3/fZC4W+EsmZJfIymyowkSiyZ4aMmaGc8VUaxCficZxaoj6bLdPRkyBU1lrcFJkRif3+Ypsmvhn9MtGzJr9Q6GlngPh9buYp4ViWd11A1g3XzQ8TSZbbt6sNz+DVce7bh3b8DMW0JzJqCgPKLJwg31+J3yRjojJdGGC4O0JvvZrQ8ePKErP6rp5E7BxEUBde1V+L9i/cSbJiFYZhkizrpvMZB/Ul6CseRDSdiPErjL4cJ7RnF0XPUakcQCHz3Lrzts+lfN7GAt9lgIijf1tSI6HRROnJk8lolnwff1VczPDaO48mnrGdwyZXM/exNxH/wC/KvvYZn/UUkH3kEfWjCoiZJOOfPo9BhSXNUf+l2ArMLbPULHBDGcEkerjVm4zr+DLn2m3DXzrG0GX/yayrv+RZCxrIShj/2McIf/Qi9hU6eGvs1dtHB9dXvI7fjX3i43ocmmFxYsYk53gX/qed5DucAv3tM2psmaV/5ylf45S9/yRe/+EXe8Y53oCgKqqrym9/8hi9/+ctcd911fO5zn3trruL3xB8zSQP4pyeP8NShUR792JrJVflXfnOIkmbwD1fPByBVUPnQj3cRcCp8+z2LEQWBp/dE2ZC5C6eRgeolMP/db3gePdmP/up/UJACjM/+ENEcnD/7zUmkPH9klKcPjnLdsnpmV3sxTNj07c08+6kLcZdGreQFNWvFnrnCFMs6usGk5WAoXqSQzTAaTbA0/RAOLcmQbRb+pe/E7fVT1gyuuvMR3nPZMEUzi6m6CGTWcl5NK601LvIlHdMEl11kV2w3Q+UuxpIG/vwaFs5O4pLcdKR3UqlUE1Qq8NtCBOQQdul3jwsaSCbYPLSdrOMYplhGQp6UtwCwCQp+OUSrZzal0Zn09j2PGN2BY2CM+LI6Cs0h2guNLKhdy+gV14MJRjo9qXR+EoLDQcWtt+B2dqHFY8Sf66TQE+csXHMKooAgCiAKiC4beqZMKejEdEjYhzJgmGdY50wBDLcDKVs8a5NvBFMSKIXdDG+aRXx5A1VuhYuzKjsqKul1yaQdr9+mTwpS7ajjWO7AVPcRMSf+nUTQFma2Zz6trrn0FjoJ26sIK1UcTL/G1sQLANhFB1X2WgYKPVTaazFNncuFucjDHZDoZsuC1UScDcwkiK2UhUALqijSlTvC4UwHaS3Jexs+giiImKbJjsRLVDvqqXM0YhPfuHj4696bU8pSvXI4wdhEDdbGsIOmSuc0C5thmhwbzNEYceKy/+7WtIyaQhCESfft9vhmhvJDrAxdQJ2rgWc7omQLGn7FxOVxEvYp2I0y4zfdiH2gG+HU6VwQcK1YgWPTxQQvvwrFa+mg/fL49zB3HSD0aj+u/hQd/3QZCHwXia0AACAASURBVAICAku26TSN2AnecAO2qkp6xwp0jeRJFyzxX1GA82YpvNLxH1T+fBuVL3QjnFaGqeLDH8bI5cht3Uq5q2vaNntbK8E//3OKnV0kf/ITXCuW43v3u3DNX0DPbZ/D2Gsp+UuXXErrRzegH3iG/nuOYGubS/bJpyalM3Svg9rP/z1jn/8ipqrif+c7qX5POzv1LvYGnSiinSuqriesVEKqFwLN6Ok0Q1/6B7KP/QYANRAm+7HPMufqjcj2HL8cvpeyUeKSyJX4iwV+k3iKoiyy1L+K5cFz3qJzeGvwByNpa9eu5eabb+b973//Gdvuuece7r77bjZv3vz79fotwh87SevoT/KVxw5x/owKPv222QCk8iobvvUS93xgOfPrrEm0pOn83S/3895VTValg+EcoycOoYxuYYE/j2PtpydFZM+KXd/HSPaCZEe86AuYTMVcmabJj7b0oyhww/mNr9vE+n9+kTvfdx6tlR5Kmo5dlmDrt6zA9NyYpcM25yqODuZIDhxnZXsleGomjSrGru8jpAcQZl+OXrMCacJK8/j+QY5Kv8LlKhIRWxg8Mp96X5CZ1S4WNnsxTZPO3GG2xp+naFiuvmzOxnXVt9BU8Z/LHjYMk+FkiYHMAEO27YyVp2JcfJKftJ7CK1bgNepxnFAoHXgU97HjeHqTOPsSSMWpcZRZ2oQ3qiImMsx46kk6V//hhC1zi6rZ87VNGJJI3a8O0Pyj3Ugl/XX3L1/QRsnjwLF/AHlouqv15PORwhWYNRG0Q0cn4tzODtVvJzG/mkJjAMPnwJZWyC6cTbbRR9kroymWE8tRbKReXEi38iSiIFhSD6aKgICJabmDJxIQRKRJwV276KDO0YRTcjNSGiRWPr1CPFTZa5nvXUpAcPPLcUs0WzYFZmaKzM6oVCvVCL468NZRCDbgdFrF5GPlMX4x9KOJc4pUO+ppcDZT72ietOr9rjBNk1ReYzBWpHe8iCTA25aEz9pWOq9xsC/Dslb/ZDb167U5Uhpkf3o3PfnjzHIvYEZ/I7GtO8n19SEl4lQaWcxEDHUsipmMk1p7KaWP/C0XLahA0026L78c/UQ3usOJsXwRXDif6Hk1DLszFNJRNgzNwn1wkPyuXeT37JmUtACIXrkIX+NcnO4WirYASdFJTUsNbavmMxQvksiqiIU+/KUS3niGvrvvQdi5/dQcmUn433kNFbfeSvell01+JjidYBg0/OD7uFassLJLR0cxjm+G0gm2v3SI8EO7EVVtcnyGrt2I3Rlj/PFOtHgGZBnVa8eWsCzcvndfR8V738fgJz6JaLfT8IV3sV04zsGAA5ugcLm0kMrqVSBPLd6G/vZvST38CADeyy7D/qnbGCjbaa6WeT75c6LlMeqlBawJX8Qjo98jj8oceyvrqq/+nceKqhtkChpep/ymMojP4X8P/mDZnclkklmzZp11W1tbG4nEm4uX+t+MRQ0B/u09i3nHd17m2qX1NIfd+F02PnXJLP7xySP8+OaVANhliW9db5Us+d5LXaxoDmKvnIVcVcclP+vgwWVQ43+jE70Pup5BHNjG0SMHmD134eSmsVQZn6Kwe2j8dQ///kudDCULVPutCc4mivzDL7bzhcA4NK6x6oiWLFdBNF1mWeFp2JFgZ/VfktLdLJ/hxu/wk5dDlIPLCJwyST24a5BNS9dSqxQZ7Wkk4jbZuKgCr1NmuDDA5thTJCfEXk0TjnUHeVfLVf8pghbLlBmIFulM9ZG2H6Ds6IeTxi5TJEwzF8mLGHfaOdxlQ/N34vjxV6nf2nNGW6YgIJgm3td6ATCAQ5dtRAHGN8wiu7aNQOcIwZ/sft3+mEBmdoTkgipyzUEiL/fi7o6hu+3oHgXNKWMoEqYkYsoiY+tnYkoisikS2D86jaCZdhvpmUHyjX7EnIq3M4Y+EsPTHT/rS/Tkq0aPxiAaO6tc1KmwpUpUvtILr/ROffhTqzC2FPai5VRKXplMWwWlliU0NG2gYdVicsEj7Mlsm7SknSRoLtFL0ZhyJZeMEt35oxN9E5jhmo1DcnIksw8DA7voYLQ0xGhpCKfoYk1oI0PFfnryxznqs3PUZ8evZVgQf415/dtwLn4/OCshN4Z7z12s8yj0OwQGFUseZKjYxw42U22v46q4AokudNPSkZNMw3LdL73ZyqTOjsKxRy3rsd0PDh+Cu4qAt4ZAo5e59R5yJStbdDxV5shgljl1HsI+K6ZUFCFd0NhyKMEFcwJnVDDIaVk69z/D2KsvIB3u5cRfX4BddlIq2Dnx66epfPB7nKQYp9pmBcAxfpBM5SuMFJdS7agn/r6/ZkzZT8Y9imGXyTfpeLo6CO3op+n+vRQNc7JSmAAYNglRtcZR+JEOoAMdK14sApjNLfDk49SGHGSUTsY//hl4pYcUZ8jsTcK1YgXVt9+OYLPhXnMBWjxB6cgRzIK12CoeOIB7pTXHSXIOqfAaB7/+PJUTyQkn+yYoNuIPPwcTMYKCx4NqMycJWsWnP0nkllsRBIGWBx9AP/wML8oH6PI6sIsONglzqDzyNGQzMGdKvzPyyU+Sf20PkY9/HP/lVrZpBBgo9BAvR/FQhTm6iOcHU9S45yLKPaxtuOL3ImjxjOXajWdUQl7bOaJ2Dr833jRJq62t5cUXXzxrxYEtW7ZQV1d3lqPO4VRousHVd2zlk5fMYiRdpDlsaU2967x6Vs+sOOsxrREPt967my9ePoerZop8/u3NE40Vp60SAau+p+IGm5N+51Ka2EbnoZ3TSFrXiFXncGfvmXpZJ7G7N4koCJMVB0RRoFYYszYGmmHsIOglNN0klipg15IYgg1XvAOXpODK1MDoPuyIdI1vAiXD/vRuLght4HOXzaU+6CKZVenWRnn3+XW4FJnR4hBPjv1qMrYokXBTq13EFfVhVs04XW70jZEv6YynyrjsIqm8xr7x4xiGSTHwGmXiYJo4hjIEO2I0dog4Dj5KtFSAp+4kVb2ZkllAXliF5/g44tJ2zH3HsQ9b8T0n3UmGJExaoJSk9RKSEjmG53iJ/PCVM/qk2yV0hw096MbZE8N3dBzfUYsoG7JIdkaI5JJa4isbyLbX0FyS6FFUjFPeD5pg0PuehaTmhAntHsR3YASxpOI/NIb/0Bimx4Xx3suRvvvgWe+LIVoEE/OUEDJBAJcdcm/ORWqKApgmggl6NGMRhgI4xrITRO7XmJKMrWUWc9tb6X53BaXwxNlMyBtWooNX8mOoTlzRCxHdY5Qc/aSlE9gFJxVKJQYGbslDm3seDslJf/4Eo6VBFFFhQ+RyykaJjvROBgo9RBkl2rwc5DlTAsuCiMNTy1ytxNxkCUOAMcWkz+thyO0gYq8GuwquMP2KynPuLNWajRrdTrWRoNKoQtZLVpWNRA+Yp1guI+2w6L2IooA33w1mCEX2I4kCLx9OUOG1MafOTcSvsG5eiJcPR3nhaA/zZtiotFWg7z3E2FOPkXjucZwjGU6unUeuX4tR5WdAO0FtvYtSbTNGVQ1avU7cV6YccFIOOlEDDoSyjuPhRxnqfIpif4Jgby/+uPWdVmdUI+VVxJHYtGcntLbAqg0kZi4kLkjUPPYgEY+EoaqUMznEXAYjnUZPp1ECfnJahm3xF+nKH2HuxCM0JBnBNBBOitTKMmga9lmzaPjuf1A6dIjoD+4k9/LUd0BpaSF08824Fi4g/eRT+NYuQd91D927BjHTp4w7UQRJxCxPZfFKwSBaOoWcNdC9Duq+8Y8E1l40SZxEpx1R66NVCRCTnWyyL8G/75fgqUF1L6C0ZQuetWsBsFVXM/OJxxFOs2TUO5u5rOo6RCSqm6qJZVQG46tQtfMRJZmSatAftaSKnL/FhX2SoImCgCwJaLp5jqidw38Kb5qkXX/99Xzzm9+kWCxyxRVXEIlEiEajPPbYYzzwwAN85jOf+UP2808CsiTiscucP6OCmREPQ8kCtQEnNkkk7LXzvZe6+NC6GdNWbhvbq7gvtJLbf/oiV8W20epche/EAXLJE7jXfXqq/pyhwc47oHI+ZuulHI07CIoh2m0DJHMlAm472aLGaLLMijYfEa8d3TDPqpy+qN5P7rRA9SuaypAE3deIJCmglRlPl4loVmJAATvzylspe1uwDfdhCiKSaeDw9/PQ0LOUzTKppIuI3k613yBWKHHT2kbyeg7TdPNC9HHKZgmH6GRN6BIe6xJZs7CGGZE3Z0FL5lS6RvLEMyrZoo4mJcl6d6MpMQxfEaGsE3m+h/rXBqnYN448NpWpaU787N5zP6bfScWxcYaumMvQVe0gCMz6lyTVw8lp8fGnughNQJ7Vgqd7mFXv+dkZ1qnd37mC3IwQSBKRF7uoe/gQckHFlShCuoioGfiORfEdixLa3k98/SxKXgV/pROhfQ6tNSvJlcdxP7qD8a4u/MeiuPpTZ2jOCtk80sAArwfRMNGXtNJ7+wYyfSO4Do9iH8/CzAoubruAbX01hL/8cQRzesOCXcZWGaLcP3ZG/NH0HS3rp6BrODoPYe88RPziX5B3jJBx78XVE8U1kKI8s4ZslcDlkXeh+53kihX0F+0k6eRIroMavR4bLnJ6lr3pHQBIgoSOzvPRx9ke38wsTzt7068SsoVZ4F1Gq2cOplKDIAjsTmwnVkjRWHMZkuGmrBq4HRLNlS5ceQ2tN4NmGLxoCpi28zB9nZjmVgZsZQZsZUg+gZB4GqcRoW3m2zm/ehHJZIpcKoZXG8fpDVgZiqaBeeBBUHP43ZWsrlpEqnUee+Jpnu3dT0VViuT/Z++9w+Mq7/TvzynTm2bUe7VsS+69GxtjmxLA1JBCQgv8QpJNskl20zZZQrIJpGzYTUhIIHQIGAI2vZiAMe69SZasrpE0kmY0vZ3y/jGyZNmygWSzL9n4vi5dks6cOfPMc9p9vuW+1QGGXH7QNKQf7yL6thd8GfJ0omAhXuggVJdHSgiRFHUwQvFVa6m76WZkSWBfcAdaogOHaEXSLUgPbsLzwPqRaT+1/9fQMtq0kphQwODkLIamF6NNXIVdWEyh28QMl5HcK88bNw2b0lIcCuzize77kXwBqp47wrGvLKHli8uYfc8x5C3bAHBf/2nc112H7667Kbr7boaeeZa+H/1oZDtyURGWKVPQNRXfz3+ONkwiTXesIyWnUJ7YjUHRMg0ropRpLDjJocC6ZAmxd99FABKTiqj9r98hBuMcX3sh9jv/ldZJBha4lyPMuZUKTaE0GUTadR8Y7cSl2XRedz16PE7lc3/CWDpsXzdM0FRdpTveTpm1Ck3X6El0sTv4Hsuy1zDZVEFOiWlE8igUU2jsjnKwPYLHbqA420Rx9thuXzidoAHDRO1cRO0c/nJ8YJJ24403MjAwwMMPP8zTTz89slySJG644QZuuOGGv8kA/6+hJs9OU18EfzTFN589yCtfXopJlrAYJNbv7qKu0Mmy2rGRo0kFTu656QK0vQfJSnfSmZjAJCXAUMt2smqGI5tdOzISHdZc+oZSRJMqpqKpVHa9zfN7D3PZkln4hlJYhw2rH7t5wRnHOKfCwyuHx3Yn5gkBBhULQ2GBak0BgxWLUWSqlFEDt+oRQuZynJPWws57CUiFtDkD7Ay+BMBUxxze2ZLN5IIUu7s6aA52sGyBl7ga48rC65njXE6CMP7eIjZuiXCwe4jzavJp6Y1iTETISQWJ9/TRmzKSnjCZRFojHFfJ/82d2Po6SQ4FMaTS5Bk1PLJC2mpAtch0XjeD5PQqJFFl4j3bEBKjopmq087g3EKGJucgpVSqf70V12EfmiTSc3Edqeoysjc3YW73oYognUGIXwDUY62cqSx92jdfJe2xoJlkWj89k4M/XIOk66zb1E3vfZvRldEojb09gP3B7SP/xwq34luyCdViwPPwXkrH2b4OJHJtdF81lbRDZvLGM+5apH3HqfpclNjM+fTOOJ+8jb/H/PQhjpu2UjpzFonFsxgKduE41j+SVtWTCqlO32nbitdOBUXF3Hp0TIROvGQlHmOUwTcOM+HbN6BOm03PvBUYmvZT+FLG71Qzmegt2QI1FTjqJhMv8VJaW4HPFMab6Bz9YkLGAksTR/dbTIuwL7QDAQF/egB/eoCDod3YlFIWFc3kcHgPcS1Kq34IR6qGnPR0islEqiURrGYJSZQRhUyU2G2bwfKs2bSHujkeamdI6yFIDzGpF1WsAUFgd/QgHalWFCkMER2ir4GooJWbuFiZSL6vDUPL6+zIf482uwnNCOH4sLiwDogCziO+DEETRYwzZzEwaxrKklkU11dRJBuZIsjIogFJkDH0h4i+9CKxnTuxb9/O+b+7D0NpKa/sGcBergPrMyRo2jTM9XWYKisJvbmJ0J/+hFyQT/jiORw4z0Ey14pD9HBe3mqcFGI1SYjvk747FNrDzvAWLB1DTPvWq5gGohjyiph+1Rfob7gBFfDcfBOmyZMJb3qLrCuvQLLbcJy/kr677kIQRfRUCsXrJXyyTAYg5maTaOvmz+vOx/qxNnJ292Pu8IGqIWVlIRiN6KpK4Z134lhxHj3f/z5ydg7Zt34OQRQ5/qUrSXu9tN99Jwd+fjEFpiIqbbWg6EgHHgNdIxycQPcXbkdPJpFyclBDoTFjUHWVN/o30hZrYqF7Be3xZryJTmRBxiSaoPkV8B2Bpd8E2USuy8iFs3MZCKbo9idp7I5iMUoUZ0sMhlOYDCImg3gaQTuBc0TtHP4afODGgRPw+/3s27ePYDCIy+VixowZeDyev9X4PhQ+6o0DAI9sayfbZuSiqYXc9OBO5lZ6uG15NQDP7+vm4a3trL9t4fh1EIeeQu3Zx8vWm1gef5K0quJZ9c3Ma+/+BAxWWPBP7G2LEk+pLCpOEGzYhKF6BVZPEZCRFjDKIi8c8JJIa1w1+/RCxSd3dvBe8yD3XHeS7EbLJtAVqF4NR54FkwOqVsGm74KuMmQowb7wJuTmF1G8u9hQWEG/LYSEyHk5F3GsyUMkpjG1ysj9Dc8woTITyTJqTpz+lViELKZW2vj29x/i5lQrNm8bhkA/0pAfMT1akRNdsILA57+Npa8TW8yP6dc/Rug7c32d7nEhKjp6JDLmKR0y9WXBujycDf1j1P7/UqgmGd0oo8pgDCTGtwd0mDGEh1M8w6miM45dFM4euToJqYVzMfzsdgYHGiEQouzeV1GO95Dyx+AMjQGJ1QsxBzT0/XsRTupI1UWBdIGbRH0+aZeM2BvG2tCPpOo4Ch3Ej4wW9+uSiDqlgpSoY93bii5ApDoboSIb+6YmOGn8uiAAwmmRuhPouGYanTcsJUsvxWET6A4cJW0WQRPxDF6KLqRImNuQ7H2YZAODSuZBQkRGO6krN0vOxi476El0oaIgIDDBVsfMrAVkGcZeqzRdI6KEGEr7GUoPEkj7R/5e4rmAAnMxNtnO8z2P05vsHn/ydXCmapkcq6bV+mfCvl4KX27A0TjA/p9eNOICUfmuiq3DTHzRhchTWvElvdgkB3bZgX0wjWNfF/K+ZtRdB1E6x9qGOb71b5Rcfx2xSAJl51aCTz1NbPt2ql97FTknIwCd6uomevQQG6uPExejoEuU6LNZ5JqG02RAGrbt0xIJer//7yCKaEaJsBgnZdAoclUjmsz06f0czO5h8n/8GUMoiWK1YJkzH9pbSbe3cypsy5dR9tvfAhBva6fzW99BPbAPY0kJUU8hZLkwtzWj+wdw3/8IB2ODtDg2UfhuN1N2pkkdPEj28lLM884j8HYjed/5Nm+p71JsKafeMRNBEAikBmn67V04frUBTRI4+N/rmOQwMqXkUuSCmZkQbusmglub8P7ov0FVMU2cSOm9v8ZQVDQyVlVXeN23gfb4ccyiBU3XSOlJ3IZsVuVeike0wzs/Ak8VzPjsuLtbG34gEcXRbl+HRSI/y0RBluk0knYCiqqj6fo5ovYPjr9Z48AJeDweVq5c+ZeP8B8cn14wqgz+3UvqWPfrLVw9u4Rsu4lLphVx3zstdPhjlGef7o1Ibh1S717ig0dpzFrInNTrBJvfxeV0QToKtReBKDGj0oGi6SC5cc39JDc8uJOLp6hcPrNkJL2h6fDa4d5xSVokoRBLKQxEkuTYh7WeqlaiaTo3P7iTX378Y6TTOr1tfiYLIoIgkrXoxgyJ69nL6+UF9BtCWBWNta7ziMcriCf8RB1H+HP8ABMqMzdpQ8rF1OZa8ueVIEkCtzy8k9tcSXKfHj8UpEkyln3bsH7mgjFSAymXCSmpjum+PAHBHzyj0oWg62QdPr2b8GzQAQQQJuXhyDKjO0wELAYMzx9BSiqQVM56Uo0QNDgjQdNNBiz/cjvZE2cTf28r/t/8FtQzd3MqOfnE7aXENivMu+hThAsUNt92NUY9gUVuYVDtwtjZjOXQMWzN/Zj7wiSzbYglaWZeWkLnO1YiT701ks4VNB2j14/Rm0lPGWsqsF98EZYrP07y1TeIH7l35LMFVUPe34I8PDeCTkZUt3nwtHFm9tnYNLFqklGcJowDUaydAUrvfxtRURHTIvNfPko610Ei20RiViMTZlzJ3rw+uu2DlH33DQrTYIgk0bPsJPMchApMhCbmEM+JELYZUK1G8sxFDKR8HIsepjPeyjTnHGrtU7DKmfPr+d7H8SV7Th8rAgbRiE22E00o1BoWkqMP4k/7GNJ7SRAYscsCSMWD+N/YRfnmd7AcOziyfN7mLgyTPEQMMtnl+QyV1+KXLfh7vCTsA4RD3Zj6o0z8+WbUFj8n72XF7iQ9rQ55Vj3HBuP0fOFfse54e0T/DCC4YSOeGz6LhoqxpJh0TgFCS4yilmamHIyjb/sFvY2N6N/6Fp7rP01KS9GX9hJ57rkx39fIqNisANSbDUiJNGqWG/vUqSTe+fO4x55gNmMoLaMnkKRrIEFPwIxw8/eYN72IXAsM/Oa3DD7wAOrwsT549WXk1c+gqKMJgmHiQNHNC4ns9+L70z0A+IpE2q4pxJ/uZ6J9Ci2RY2w5/ixzH8hE5dPXreIy0YBFcUP+9OGBCAztCdBz5z2g61hmz6b0N/ciORyj+0hL8rpvA12JNgyCYaR7fLJ9Ggs9KzOWY107QEtD0Zxxvy+QiUQO87C5E5y09cXpD6Vp6Y3RNZBgfq1r3IfscxG1c/hLcFaS1tDQwI033sgdd9xxRiuoN954g3/7t3/joYceYsKECeOucw6jGIql+N6Gw/zy4zOpyLHx9G0L8dgyiTJJFNj4hSWI49SJAZA9AUSZdWVDfPtYCVMLPLj6tkLIA7IF8qaSTGsYJGHMBcCgp9nX3IfbaB1xGJhd7uaOjUfGNQsOJRSafRH2tAdYXV8wslwUM9IKbxztozLLyVAEAjmfwymnmDosCRKZeguTxUFiiX2sMdRic9Syw99KIO8dVCmMCMixNHM3pbBueIN0Rwfi4+vJmTaZzywqx9oG6d4LME6qRi9xEM+R4ImNWN49jKgqoJ5ObIzBsWbqgtuNnJuNweMm5e0ladCJaVEs3hDyWaQrToVtagHGPDvpYgetx/14DviQwvFMWm9GIfsuqaPXLFN973vkv0/UK33LPzEYaMN2cA+mvoGRZoPxICTTBJvClF8zg+bv3Ik6cQa6JGE/uCPz+vB6mtmCmIgjD/Thev1ZhuIxBpfOpiAro5Df7U2SFuqwyHWYJ65h+oVWBEOUnlA/ciqAQ1VIJ1VEy5voBhkhPTq3ukBGO0vTSTW34W9uI7+kFr28BMfdX0V7+hWiO46Mrn/SuE4gke/Erkoog0NY51YQMziQGr2oAwMj30NOKsj9mc/N2doJjI0gmfqCmPrAdcRH6NHNVOW6Kc53YDrceRJRzxDtU9tLdFFg26PXonkyBqp6dy8tbz3IgYn5WEsrcBtykAUZjyEHjzEPh+iGtAM94SQRs5Ire9B0jZ3NIQIRK2lzgEDWqNm3Tc8j64CI5+W9OLc9iZQYVc1Xy6pIrl1HrHY5dqWHsvARsjr3k930Gtl7+wglrGAyYmptOuNx4PriP9He8zauBx+hMHJSpFOAdEkxzvOX0FQtcWzb3ZiZQJ19DvbNrzJ/wzOobW2c3AqSbDqGpmk80vlrFD1N1bp6xLSKmDrxo1AkFCEMhUk2NCAl0mC3I4WCJDafIq0kCFgWLcJ6zXXknr+crqE0uxqHyHUZmV7hpNCdQ/KdP3P8zh+i9JxCgDUN+eCe4Z1rwuix4H1g20jEVZhVz9GZBmTBwIX5V2EQjZRYKqh5/AhyXEHKy2XaxYsQB/fDtI9lOs2PrMe/J0nf3RmSZ1u0iJL//i9Eq3XkY0PpIV7x/YlAegCX7GaCvZ6G8AGW56wZ8ZvNiHJvAZMTciadcb+cQFrVCEQU3HYjuS4TiqoTTSoIgkAopiCJYDOfEjU5R9TO4UPirCTtkUceoaam5qxenatWreLRRx/lkUce4Y477vgfH+D/NTjNBjYd9TEYSZJtN1GT5+C5vd0UuMwsqMpGFAV+8foxqvPsXDq9aOybZRNUrEC2ZvOTGdPR+iRe3HmMWqOBCVXTQDLQ0BkiHFdZMnlYcT3m5zdlL7M5OQ1BHvWtK3KZcZhl+sNJ8pxju0RL3Raqcu20DQ5LJfgOQ9NLMOXjXFerMqH3CfzxBRS48zg65MJe6CStpZAFA9t6bOS63FxRPpNwXOGNhiBeUwOqJQwJnbKXjlH59CH0QJA0mRRY4ytbGMwp5vhAlH7ZTNXcSl5blQQxc2PKW5RD9X4TgVlFWLwhHE2ZKI0uDuu/qRrIEs7pBWQtraQvrdLqDTE0yUaicAZlj+7FvS+EmPrgBC1eloXY6id6MJNSO40APLGf2OQ8mFmN51BgXIKmCyCIIoIoIb+2kbZfryMlZeM80Eftf23H2jlw2ntOwPTkAzS/sQFL/2gqVwd0oxlBV0FRENIp1Ioa5FVrELe8Rda7rxC+cCtRmw2P3Y6tuYmUx0ao1kOkJoeNa2tJuy0gCHy8+OYRVf73sY4sWgAAIABJREFUru8keOnHyXmvnbw3m8na35OR7xgmQfF507F7Shm8/36U3l50IWPdY5BFNKcVKRgb0d2K15dg9YXR+4P45xQRWlePwySRbPYTebmR4HWTsE2fTOGTWzBHzSihFPFgBKGvGzE92tWHIIwSv5OipkJ/AHP/WLmfkejmKbtA0HScR31oFhPunR1ICYXClzNyH8lsK4MLy4gtriA4tYBUoJg+VQNxANHYRlpK0taVaRYp19bhsIjE07mk4jZK3HWYYlWEQ1byn/gaxn2ZGkLNYiUyfyX+pReRqJiIJ9CJccOzsP3PDPV0EDwp3W4CYrWjXdcYDWhmK7ooY3DYEJMJhnQJsSuNIZIaQ4IFHYyd3SQe/COuB2Hu8BxoZpn4SdFkTc6kM0Wzg6F3txJaexEzCKKLAgMLy2i5dT5OKYsiSznO7z1FuHUAU3tzJmorihCJjJ3Q/AKUC9cRnLWMWJcXR38K8xtvYg2HWRQMwUA/ydZW2o4eRfWdXsMImfPdPG0qgqqROHqEVE/mActYWUnq81fwzpQhdEFH1FVM4rAEUO8QuS9mhJLzPvcZxMEDkDcl02m+/yEYbEayZWoH7StWUPyLnyOaxro9HIscJpAeoMhcygW5l2ESzUxzzh4rcDx4LKMBWbMWxPdPMoXjmbk+uUnAZc04x0giZxQzliWBlKITjit47H+ZwPI5/OPgrEfi9u3bue222953I5deein33nvv+653Dplo1ILqbDY3DYzYQ5kNEt957hAvfmkJJlliUXU2X31qP6sm52E1nrKLqkZTzT3GCSSzc/mPw53cP38OAjAUUXDbDaPrW9wIJgfT6OAxb4BldZmaHEEQ2PTPy8cNy189p5SEonHEO9wBGeuHuB9kMzPcCXJifkpjLyHEIFcsxFB4I8+030uFmkc4toKZ1Tb6Iy2EQx6iCZU392ZzhdJD7m8fxRPJ3Pg0mwP/+ZfhWzOLfSYvU/2PY7p3Pyvbd5BIJsizr0ZaMpPsbV6OLKrAt7wSJBH3ri7KntxPz9qJDC4opWjDUbIO9JL2WEkcGyD0nxkvviKgkNOjOy03zqFgaztZokDqqI8TGSsdEGZOwjLVTdbkLOKvNDLUMZpW0gFBltB0baSz09NaRPVD76CYjfium03JE2O10QQdUDV0VQOfF1mzYRBMSNNKiZ6fwPT8NixllVhqJyPZbUTamkjt2AfRKOg6av/YWjsBEFKj8RFBVYk5VQ5ebsSTlcOko6AFg2jB4Mj6poEIuQMRct/roPLhPWiSgOq20Wd+hUGLFVPtRMrKBaLGNGmTg4HrFtJ1TRzHoR5ytrRhbx+i5LJ5bHdfijvWRtbQIFIijSmQiQSK/tEbuQ44BtIINjep/iBFLzagvdxIKsuMFE2RnVTJ3tEJvEvSZqTpM7OQlk6jvnQl0n/8kURbO0GHh7hbZsYtt2OZNIk9vcdo2nUfpc83YD/Wn+lGBYKT8wjMLkZKKGiFBQiLv4lBA6H5GDl3fwN52PKn/gebxq3tMw3GKHqhgaIXGkjbDPSt3knv2lpiZVnkvXkcs6ohKhpSVEXuOY59IEBxdzOaz0fTvS+C0YhR1kmt/hguKY1z3ZX0VU4le/dWnG8/g/qLnUiRsQXrAOQV4LpwDfF559EZFnAldiJ79+Pf3Yp5nxdR1fEuL8R6LIH9p3fgUbSRfQngvXAihnASky+CtSuEHEuNvC4mlIzXZrWHtN1E9h4voqJBLJO21oATsSVpwnRSA1dh6Q+i7duJ/M7OMbWfp9ZvZn/5yxyYvw6TUcbVeYzsu/4ZgDNU6Y2BuaYMqbyGrsUFHJ0qMFOZhOW67wIgF3qIfu4Kdi+0ECVDviVkprpmj7w/8MgjoKoYy8txzckHbxtMuAh69sBAI5QuxrXqEuTyyVjnzEEwjF7/FE3hQGgn+0KZKPQM1/wRqziDcApBsuZByUIonvcBvhU4LDL+cBpF1U+rQzs1gnYylOHrh8PyoauNzuEfEGc9Svr6+qioqHjfjZSVldHbO45X4TmMixUT82jsC4/8v6Y+n/W7O/nt2y186fwJzK/KZn6lh7tfbeR7HxvH1FdTITZAsTufPLvCNVU6r7y7nbVL5hOMpanMP8mNQBBQsutxd7/LJ6aNdSk41B2ieyjO2ikFY5b/7LVGpha7mDl/uH4u6gNBBIubHG1gpKpIAILWMg4OPEtQSNGn9GFw+Hmu73kEIcSq7hTx/HpKdhxl4lsPZ95jsWD6+DXsv6Aev7sDLbaHxc8couTZQ0wdjgIk3Wbs+7vw/GE71s4ghd84H/mCRbiffwfjH3dx6K6LiRXYKNp4lMqH95xxnk8laJokUhN0YckqIX6oCQQJhquABCB7/nLMVWUYC5zoC/JhSxvpKQX4Fi8iZVDJfW0r9iOZ4zw0fTrFf8io2euCgO8rcxlaXY8SlZFVCatux4mdIkMeByKvk04niBky8hhRIHBNGXy8nE8U3IT+9i4Gf/97UgdHa5miZS5i1blYuoKYvUGs02dgcrpJdXSSPDKaZrQdbmPalx4iUeYhUeTBHIghiBKqoiKkU6N6VsMQVR1xIIJiVlETXpJNzTiBsQ6uJ0+igP/7DzLvq9m89K3l5K63UP37nWecb6Uvk3pM1xRhbPYiajpm/+mpXUM0RfWvt6H/Zjuxig3ICYG0dxALGWmKjpc3Ibg9pOqqMS6zcfTrS9DMBqxtASpebEG7ZjVaiQNfug85mGbWz74HK1YjLF5Cwx2XUNQcw7m7DW3PYYSTdLfGgyGapuRPh1HsJjo/4WHST8/snCIClXEvQXcNsdZ2eorrkH9wAWVFRiIvv0H05/8BwMkxFNVqIjKtnMSKW/DVl+Mu9DFw/HVytzcQfesoxqH4iByHDhQ8P2qvpYsC8SIniQI7iQIHrZ+djWo3YRiKU77RgvvIUcy+bujuyJB4Vcd5bDjSXFuO5dZP4xRdyJpA2udDCUUINbVg7B+g6vZPIgVPFyE/EbVTLTZiE6cjppMULVnGqil5bDowSLc/SanFNqy3IiKqaRSnm3jlJOSCAtwhH4K/G6MjhZg3kfixdpTyXA4uMmMWLdQXX0LwlnbMU6eyud5PV7oThr1yTaKZjxffgvkkmzfb0mUkGo/hXLsGYeLFUDqP2P5DBO79IUU3rUCoWZ1Zb+HCkfcktSSv+57Hn+onrsUQEZnunEuB6Sx6nlbPGPHb94NBEvE4DMNEjTM2DJyMc80D5/BhcVaSZjKZiMViZ1sFyJivm0x/nZnwPxKum1c6JoIlCAJ3XDaFn77aOFIj9m8fq+PZPWd4Tj30JAw2wfLvsDjwMLoaxafkkFbmomqnh9mVnCkYut9l4+uvIlat4NMLKwDoDSV4YkfHaSRtR6ufBVUenGZDZjwhL9jyMykAf/OwyXnG2qexVKA33Ud2UkGJT6Y36yUQdHITGm8VmkjITRR9agLBfXnY66cw8NVlNFm70FOHKXqugbInDmAIZW7iyWwL/UsqyDrYR8nzGSKiiwJTvG7SX3ke5VDGSLnksT00//My3O0ZonsyaTwjBAFR1dCeefMk6/SxGPxNpkPNkGPD8MM17Pn5JeS9dZyCB55Hjo/e6HVRwLl/f2bMk6ah3PZFrjx/Nseih2mMHMKf7mdF4WXkmPIBCAcdaLqGTXJgk+0Yxcy5oqhpetZcgdo3tnlh8ILJHP/aClRUVE1B0zWuLb2ZLIOH2J69HP/VjxGOtSP1BxFVHXuLH3vLqDixzviq8HJREVlf/wbd/XH0Q/swb/jj2WZseGM6ejqNGI9xPVPxlRxj4NOLkR57L9OtKQKqjniipshmI2nU6F6QR2Wz9+zbJpOS1Fv89K6uRb94KnprD/aD3Vj6IugBP+4tftxboPO7N9G6UCBW4ebI7bOBQbLSBi7OuoXEyw8Q3rYZtm1GN5vxzC2ge34ZB79SB+ZZFBxMUHYwgHH7UVRvD0NfvAaLN0GqN46x6QhyKIAu6rjcFTj6cxCrqyGdRvX1kXIaSRY4iJQ6kYsKqTNPIfnaesw7dqD5fIgrl2LQDDTu2IZqspAocRKpycE/vxTVYiDlthCpzQFBwKB6SUtHyf3JZma8NlqLphlEBhaW07eqlpLnjmD1QWzuSoyz5hAu20nKakCTCzA7S5lvsWPc8A7arzYg2J1o9z2FLyEgJuLMEXoJ7drD4Hs7EI/sx7F8LUUXfoJQTKGlL4bpX5YiKJnj+EzHh+r3QyKBobycyoceRszJQdN0VG83nfc/TP6ho2hNjUhKGk6KvBlESJaXI3S3EWpvx9jTTkLXgVYAYol+uOZSCk0ldPdtpuorXwZRYkrsOO5EHpNs0xhSBpEFwxiCBmBfshj7ovnouo4aDjPw6wfwP/QQ6CBXDpG/bGxErCF8kHcGXxtxuSg2l7HYswq3cXzBcHQdurZC/jQwfjhnkw9D1M4RtHP4S3BWklZTU8PWrVtZtmzZWTeydetWampq/kcH9n8ZgiDwyqFeQok018zJKF8VZVn4+bUzGIgkybYZybIauXFJJZub+plRmoXDfFIKM7sWfIeg7wBCKkzaWkRBzIuv+xj5WQWnkTRLThmYs5hr7+XaVxpZO6WQXIeJSQUOGnvDnIpQQsFlMbLu11t48QsLKIj1Z4zdUzFIBlF1kASVQ9nZdKSPYVE0XIqNFvdRBATqQsUMbX2LxJpaSow1zJl6Pk2/mE27bMPs2Y+U7MWxTaH6t5lanrTdiG9lNbYWPyXPHx2eJKA4i1QsCY+uHyFgkfIsxHCSOdf/EVN/dGTV94WuI1gsyHX1GD1u9HCIsBIlaU4TkWVQYxiH4ji7QoQqchl67hCzXj42/v7TdLDZcVy4lrwVS2itjPCk9/cktQRiIk1Bl0akcztmzYUy6KfUP4jS30+y+Ti62UzOz39G6KWXiT766BiCJmZl4b76aqqvuZolpaOKaCer5FhnzWTq/RlypQaDJI8dI9F4jETDUeK79yC5XFjnzSPd04MWjRLbuRMtnNnHiteL/9vfwj1lCnJ+PuMk40Y/UxAZWnYRhdddjct7HN8vfsHgfSkM2U7chSYsl9dDzWw61AIGQ0MYYwayli+jtq6YV9OvkOjvxRvXyX7rGKZxImknQzVKNNw6D3Sd7O0aru1tACTybGgGCUMwwcAEhUpLPa3JBjxbOyh8pZHBhbW8PCuJJT9J3vIZ5OxoQIgnyN3cRu7mthE5kJ6LJvLeDZMwfHIac9S5HDS+AJKDAmkWdb9QUV56GQD3Pc8CmbSgYLUiJJKYEklMvjCOA14EGhjgrTFj1zZt5kTbihSLYQtA6IJlOBetJiemEGzchePmZxicW0J4Yi7pohIsgVESIlithH71OIOCCwMCvlsTyFYLggDptMLkRIjKyCGM+mFiO3bR8cQhtLbMw5tqsGDqaWfJ5DL8R9pp3bYHpaMdNRhGlgyEHnyQpoQVs7eVeMVEipQzRxTF/HyMCxcTe+ZpBKcTtbyaZF8fVjXN4e3HSPz5LTyvPY3IOARPlnHOnwXrHxq7XJIwTZ1C2wwHPbMzZRat8SbCCYWqpAyVKyi3VlNuzUgQeUw5Zxyf1vgmgcceZeC1RrRQ5ni21Ffj+uzn6Et4Cashqq0TaYwcZMvgJnQ0DIKR5dlrqLa/TxPA4DFo3AjJCAxH5T4MPghRO0fQzuEvxVlJ2iWXXMLPfvYzLr74YqZMmTLuOgcOHODJJ5/ka1/72t9kgP9Xkesw8sOXjnD5jOIxqt9ffnIfa6cU8KlhqY5XD/fy6LZ2fvOp2aPRt9w6aHgOvJlUn6FkNuqxPhp3bGTaJV85jaSFEypy9nTC4R4mFtq5580mfnD5FIqzLESSCsFYeqTgFSCZVnFZDNQXuzje3kmBIIGjCLyZmqu0YCIip9nuztgM5SQVWmxJZIzM2y2j//guPNEUWn4pxycM0DvwNkWGBSyZ5EI2LWDzy7m0K0lq5r2Hr9KCd1oFC779/NgJ0oGuIUynLLK3D2FvP6lWTICOa6fjPNyLajEgmyw4mwOIPaNF+Wp1LUMXf4KBaYvJpxNL1n72WUIkhy+mZm+InB1eei+ch2qMoqspKp9qACBRVgOShLmnHRIn9ctFI4TXrye8fj2t/34ByfmlVFknUtdvI/SFLxDnsVP6FDMQrVYCjz2G7667R5ZZZs3Cc/31OM5fOaae5gTO5B0ouVxY587FOnfuuK8D9P34J8QPHCB1/DhqMIgWixHbsWPkdfdnP4ueTBLfvZtUWxv6sF6aoGvku80ULJxN9OH96MNEL9XdT6obwru6gEOYgRMJpODkOkxLp3CRfw2tnQdQn/ndyOfopxT2izYbuseJ1tVDotiFMyGR9c5xSn/77khk1OwbjXnOvP4hEnk2zBNyhslcJ9nbO9HFTQRmFOE7v4amz6/DvW+Qoq0BrLsPYAgncTQPMhBKIiIimaN0SodYtuYRdE1DM4gkAGnYj/Vk6KdkED6Me2PhH16AP7wAQN7wspLuI+Oua6ysZGaZgwVF+Siqzp6WELVFNtx2A6GYQrtvFf3aXLSffJfI29tHBqNUT0LL8iDc+mmahscuwmmCyoWP/AKA8iuvJPH5fyL67LNooog05EeKhUe9XPv6iD2TESnXQyH0dzbhfWcTkKljs3I6pJwccm65Gdfyaag7HkNtysNQOwXTtEUI9TVsz26jQ+sc8W8VVBN14Sg1MVBmL0Amo1PXnWinxFxx2nGe7vMR27mT+L6dhJ57DjWSocNClgv1pstp/NgE3kpuJNWbRBYMHDLsoS+VIbCT7NNYkr0KSTi7jRNqGho3ZDQmy5ecfd2z4GxE7RxBO4e/Bmcladdeey0vvPACn/zkJ7nuuutYsWIFRcPCgF6vl7feeosnnniC+vp6rr322v+VAf9fwexyD9W5dh7d1s6NSypHln//0jqu/s1WFtfkUJlj47uX1HHtb7fxm7db+H/nZZ44MdrAUwOBFgAEVwlKwWyWsoOn3tvD1efPG3PBa/PFCWjzSFekmaEO0uSLoKgasiTy0peWYj+lyHXT185D13VmlWWxuUdj8Zrvga6SSOs0dMTI0vrw27woaNQnrASMBoxxnXm/a0R8KRNpSGdbiQlDmGwWSAkUbb6Pxl++x/6v3kqPkuDyC1Jo05dx/ICRubOuw7qoHy3YT/xw0xlviKctz3bTe91sLNdeTI6llEJTCdF7HyGw+VdAphU/esVVtFVZyRLNrAq8jT16iIaoGUNPjNpX23Hs6kIe9ji0NvcjR5O4j/qRhiIkbrid4ltvIS/LhKYo+H//e6TCQtJNTSRb20h0thHv66bYU8sFxZ8gy+AhEWgkREY/SjSbEd1uRJMJuSAf86RJmCdOxDp3LoP3/Q7H6tW4P/lJzBNr/6Jj6IMg/1//ZeRvZXCQxKFDxPcfIL5/P/G9e8m55Wbk7EwaKH7kKIHHHsM6cwYAxvJyLCYJafVqAn0BUk8/gZBMjLsvDMXFTK+0IAgCbZ+5AbW5aUwa+jSzd1Gk6KVnOXr7TTjfOcKUTz6U6UbkzAbeZl8UQzDF4W+fh2o3kb21A0M4iWdPN5493WiiQMpjJVaehX9eKcakjiDJCE4HBS8cwdQTIm97NygqAowxqn8/qHYLaZNAym3GOJQADEjT5yI1HCCdimHsj4x/3NptoKhjCf5JSDU1ofb24PP2E3dk43juGbybXqNL1xFjEeQhP0FVHbttHeTmhg88diSJ8MaNyIWFGHrHe3Q4aX+azchZWWixGFrozLFWQ3U1Zb//HZLagb/tT/Q5jPh/eTtLy65GEARUXcXbsRUJCQSBBe7lTGhvwjiwlx3WyzGlZdwmaI4e4a2Bl5lsn87S7AtId2dS5MaSYkIvvIDv7tGHGcFqwXv5JFqurEe1SZBoQUSk0FSKLMh0JlrJMmSzLHs1hebT9R/HRcsbmaaouqsyRO2vwHhE7RxBO4e/Fu/rOBCNRvnBD37Ahg0bOHVVQRC47LLL+M53voPNNo746v8y/h4cB05GY2+Yh7a28aN1U8csf+DdVt5q9PHITfMB6AnG+ZdnDnL/Z+aMnuje3XBk2L9v6TdBU9G23E27XE/OgmvGpEf3toQyDgST3CPLTpC09sEoaVWnJi9Ti6FqOo9ua+cziyo47A3SMRjjwqkZ0+qGrggtfXGSaQ2HRaKwOERjs5mJSS+pf/8mZm+mMN53XhXNty8kbLBiHHQx4/5ncb+XIZRH/nklqkOk4tG9mAIx8qYXU/iFG0iWruTxwQfJfWYPFQ/uIeU2Y/GNXz0mFxZiX30Byf0HiB84QNXzzxErrKB5XzPxlzbi2PUmogUIDiEPRDIdboChpAjLnDpC7x0E3/uL2Obcfju5X/wCAHE1yqHQXlqijVxRdH1G+BKIqzEs0ujF/cQ5oicSBF94gcBjj5NsaMB9/acp+Na3RtbTUilE4/+/7fd6KoVw0hh677iDwONPAGCdN4+sK6/AvnLlGEHQUFyhuydIav8BCpp3E92zh3iXF8fPfklp7HmweGi85XcjEblxP9fhRJo9j+y7fkby3nsI/eH+DzRexSITqcpFSiZRbCZUqwHX0QEMQ2eumw3OKMa174P0IGYQXbMEsTeO+XgDQmT0+Gu5898Jz0mzIG8++XIFJlka0TPc0P0E8e3bkeJpTH0RTAMxsiIyFocH6eu3Yv/BQ0RffAkcTgifmfiE5yzDoKYw7932gcYqL16Iw+DDmG8jLGUT2daO2NmZ8cAcB6baWsxTpxD803OZ7k1JypQBmIwgSpno4YlrvChSfM89aOEQij9A4sABUh0dKP39qAMDxG67jM6rJjGQ8qECi656FDGtYppQi6WiEjm/gES2GYenCNFmxzm1DPHII1Awnbh5Loldu0j6/Rzp2Izc7yffb4TuXrRQGOHK1YS+dhXGm+/EdLgDQ2kWnrUrcM3OZ0NBDMXipshei1kyM805B4NoRNM1GsIHmOiY+v7RsxPoPQCHnsjoT864YcQZ4q/FCQ/PEzhH0M7hZHxYx4EPbAvV29vLtm3bRro4CwoKWLBgAQUFBe/zzv89/L2RtBPoDyfJdYwm9jRNpy+coNA1thszlEjjCyUzhCodh933ZX4v/jqIEnv37KU9mc/MGhfluaOkeV9riGhCZXH8GY4MqJhmfIKvPLWf/7hiKttb/LQMRLjz8gxRHIqlWHrXWxz8/ppM0XjD8+jZEyExhK/lMClzDnv0+QhZPRDOonLXu8i/+TlCKolmNtL0+fn0rZ6AHi3A7G1j2o82YunJpMq8H6vD3D2EZ89JBeVGCd9NS+ickoUuClh6wnhKpxB0uZl0zffHTpTVimSznSZNkf31r7N96iVkHX6NnJ/88IzzrJksiMnR+qi0w4QcS6OZLKQ9+eh5BXhqK3HPnYl11izIz6E91kxT9Chd8VY0NAQE1uZdSZm1ctzPSPf0EHjsMQJPrx+RwgBwrFlDyS//84xj+ygg8NRT+B9+mFTz8dGFBgO2RQtxnHce9pUrMeTnj3lPKKZwoD1MMBiiJrmLyvRBolsa6Xv6ALoyvv2TUlRKx12PklJ0DL5uqv/zG+D9YERqPNHcUxFfOw/NIhOJDmAP69i2H0fOy0OrLUPr8GI0WtFkI4qqkYwMIgaHMAyn0k7eviaJmWYTkwVp9lyyV63AfeEaZLcbTdfoirfREDlIW6wJHR0RCUcQ3H/aSfsnpqEbZdDB0hejPGAj7Q1iPtCFtT+KwR9GGvQjJBKgpEfIkWXGDCzz56OFwww9/vjYL2Y2YywqwlxXh7GiAvfHr0W2G9Da3kHo3oGgKwxIxTSI8yl0ZlEkxtCSSZT+AdKdnaR7vAw99TToOobqatLHj3MaZBlTbS2mmdPQb1xH0KHiTw8wJ2vxyMPIMwfvYUgLorjMSIjkDojUfuq+s+6T4ifvIBlvJFJ3GbE/bkT8+SNnXDcws4jGry1jwSefzMzJD9ZRUVEKwQ4CNctpyXLSGDlEWAmyrvBT5JkK3+eIOAM6t0LXNphzGxgs77/+h0Ba1QjHFRwW+RxBO4cx+JuRtL8H/D2SNF3XufS/t/C5ZVV87BTx2u89f4iVk/NZPmy4/ubRPr773CGe/fxiClzm07blCybZcnQIj1Nmed1oJ9PB9jCBSJpl8acZGPCxregmfKEk21sH+eyiSn76WiPP/L+MUXunP8bH79vGln9dmZHe2PoLvO75FAb3IGhptmdbCAkuWlxpXOEEs770KmrvAHpFNYF//SINpS3Mcayk4b2HmHznixgiKTSrmY5LaindcGTEukkXIG0zYoyk0CQBQdXRJQFR1ZHz8sj79rdQevsYevxxVIOE2twy7vwN3LqWxV+4i7gqIu59hsN3/Cc4TJhiGqI/SfFdd2POyeVwTxJxz3aE916lZ3E+fUtySebaKDFMRvDNZ3q5k+Ls0TndFdjCvuB21GGJDqNoosY2mWnOOSMisCcj3deH76c/I/TyyyN2T6LViuvyy3F/6pOYqqpOe89HEbquE9+7j6H16wm//vpI0wFAya9/hWPYEk7x+4lt3455yhQMJSUoms5gKE1/IEqZfhxn8CjJpr34wrmE1XJsqTC9ga0ElThlWWVMvvnLpIzZxFQZZcMzpI8cIaHopDra0RqOQvQkIVVZwlSaT6qrD8EgoiWUMZ6gJ2NgQSlN/7QEPE6M8SLqv3Qf5o4MAdRkkaFphfgXlBOvrEcuP48CWz4Dph1kf/NePDszqcB4kRPvxRORVZnyP2wbI6aLJGFbsADb2jW8NLmNmD2jt1WTnMCEVxoZ+sOjEI8RvPkGBq6ZhiCl6FVaUPT0iQnGebiP/DePk7O5FcNJTgKCyYSuKBkh2RPRMFnGuPpChmYvY9LkIvRIBC2ZzEQqNR3LxauJqRFicR/hF/9IausekmkzjrAJud9HqqcXUhkCGppbgXNnG5H6IgxDcUzdARAErAszJPxoWYz2UoWYnELVx14zXbLw5PHTAAAgAElEQVSbywo/gUWy0tDxHNv1DhL6qNOHFEliP57pMjb5Ipj7YxSGrESCveixBDsfuArdkIlw5b51nJL1h9BcVpIOGVf+dHpcaZJFBkyTK3GWVJG1YQ/iXX9AynHj/tlVtBoidHty8TF6XBSYSljkWUGu6UMGCnQtIykEoCkfSLj2o4JTb/AfBXyU768fRfzNvTvP4X8WgiDwo3VT+ewfdjCjNItSz2jq7KKphdz++F7W37aQihwb50/Op6E3zC0P7+KpWxdiMUqgpjLWKBYPRlkkW+2msm8vLe4rqCrMkIkcpzEjnDiYT85QG62+IW5eNpF73z7OTUugoSeEpumIokA4oWA3DR8W/mYAvIE4RaQZMErszzKjkwIBJqZUmr+5CtOre7F86SsM+iZxdV8Lg8/+nvqHXkFSFPSCPIaKZMqfOjASoUhkWzEOxTEOK6mfEIcVhn8rPh/er3yVqhc2EnnrLVLbTk//aAaRaIWH3iKVYLIHc7OfrvU7sPUnoXVU+2kwpFK9ZBKCo5X9hU6SVy4AwKzmsDp3OaKo47UcYUeqiwmhOqY4Z2VelyyIgkiZpYoJtjrKrFVIwplPF9FiIfLmm6AoGEpK8Fz/aVxXXDFiav33AkEQsM6aiXXWTPTvf4/o9u2EX3+D2PbtmejiMGI7d9H9la8CILpcmOsmY6mvp7y+HnN9PcycQ7jySoKDYXwxA6Fomjo9yv4ijXg8zeQdv8IIyEYnwjVfR5BkiPRBYghsuaQGoyQaGjFVVaOFQ1imT6f7q18m9NKrZxy7Dlh8MSwdQ4QcRip/9cgIQdMBUdFG6tfgPSJV6zl+6wKC0wpJrZmAYnMQP/88XMumEkw1ElFDdK+txL2/j6w9XWS/144xmCC6ZQvRLVuoW7mA3rVr8Gzchmv7HxgaJkNyXh6TJ9bhKlsLQFpL0x5r5nB4L4mdu5n2jZdGxqxJIqlsC+ZACj05HM3TNQTAP6so467x0kasL22k45Tvqxkk3p16dOT/isajlL12LFOQD5yccFasBkIlNgI10yl6sQFDKIlqlnHf82OKl10MgL/3ScKJTiRdQhYMo8QSCCoBvPEOkkPNBPwHMTpsKPLoOk53EclZHrqnRxEQ0NHpkJyk1TiaAGbBgFmy4JI95KxbTODiQY7HGsg25FHsmkd2PExPOITVqRJJ9uN5M3POO89bSrsxxl63BYhgk+zU2OqotdfhMZ7qA/IBMNQGR5+DGZ8Bi/vviqD9PeKjSCrh74tYfjRn8B8MU0tcfHFlDd9Yf4AnPrdgZPn8qmz+eXUt1z+wg41fXILLYuDz51XTOhBlW+sgK2ytGbsmZynMvhmzQcQhhChVm3nj6A6qCtcAUOgeTqXGM9G1aMCHxVjHnZdPwW018uMrp6FoOkZRoNRj4SdXDdvVDDSSFoy4kl5UI2zJtWIcyNTpGExZtNiNDOTImCafzxSbgTSbsB3roOvtA0iKgmnSJJLxJJ49Ga0kTRJIVuRgOT6arjxT6irtsqAMDWEsLSW2bRuKy0Jgaj6h+nyCdfnYit2UJ5IseO4wvt9+Bs07KqasiyKxutmkF60gv6YWXddpZTNJcx+SbkZK5CKYErw28MyYz3RIrhGSNsk+lTrHDETh9FSFlkwS2rgRdWiI7JtvBkByOsn96leRc3NxrDofQfqAdTEfYQhGI/alS7EvXXraa1okgpSdjTo4iBYMEtu6jdjWUTJtW7SQsgceINedSbsnYwmGUrdjC/0ByW6hyVWCGBvEoCXYv9uPwyqz3LgboWMzAAZBRrZmI4T7EMoXZ5aVVmCaPInksaZxDecFwNYyyIx/eRnVZUYKJsa8dirsLQFUkwQCVK76PDW1MdRjjewaaCdiy9SOKU4z/UvL6V9aTtPtC8g60EvuO63kvtOKYfcBqjad9AAhihirq3CsugDBZCS6axfpjk4Ek4nSyZOoqfoEiQsvp/We3QjxFHowjKgoo12sBhnXuitonGkgnCUSzZKYcd2Do3MuCYgOJ4pkQpcNqOYkTsmJVXZglexkTZdQh6zIrixc2WWoh/eTam0i/6ZZCNkOLG/0k3rqPQRVRcrPw3L3T8iZNWokvir3Ul73PU9Psgt0FUmQKDSVUm2bRIG5mCO+P3NQOQ5ZZkAFXcUsWjGJJnQgpkaxiFYm2Os5FjlMRB2uv9MhraeJazGqbBOZ6VrAH7szdYiDaR9vDrwwPH/QGwHDUJzSvQ0IgOOSdZRMyMWg+ikyl5FtzB33nHxf6Dp074RjG0EygTJ+I8c5nMNHDedI2kcEn1lUwaUzilH+P/beO86uus7/f55ye507d3rvySST3gMJKYSEEpoUaSJYcNVVv+7uV1f5IqKsBWQVcf2tK01FlyJdCJCQAgnpdZJJJtN7vb3fc87vjzOZ9ECoEeeZxzySmznlc84999zXeX/e79d7pAeiPJLH8NlZxZR5bTjN8qjR7c8/MwlBEPBvX4NbSepVnnE/ZrOb8dPmEFz7BrnJvaSVZciSQCKl0jkUp8TsQQb+7wLdj+iiCbkEoimcFgPxtIJRFpFEgTyXWY/Q+ZrBVUaVv5FGuxFfKMGk//sKINB2z3L6C/UoUYbBy/bQ24gI+MwSf77kGpZ0vMnuxTdx5R8fJ9opIhR6UBURS9Ope/odi2qUCHzzCiIT8vB4bkP5zE20F3QSi7ZT2d1CSTSF2g+t8jT6O7qxdutO/ebp04kvuAjP8mWYM0OYZROZBg++1BDFwkziwT4yzA46LLq1gFm0km8uJM9cRJ65EI/h6JO5LJ5shaH4/Qw/8QS+Pz2BMjSEYDbjuvpq5Aw9Yum56cb39+b/HeK++ipcV11Juq9PrxitrydeX0+8fj/K0BDG0uNz9rpuvAHSaRbPnIF95kws0ycherMIxdJMjqZJpFQE92wUewGNTW3YlGHscR+O6EEOKdXUTivFcdvNZNf1EZVmE+hSCT+9hlRD1ykFmBSIg9WMmmdFbBpGE0VUiwXFbECWTYgDA5CdgVhbRbWliDpPDZ1fuYbEgQaKgEJRQLWaSdpl0FSkuELjN84nY/ElxOYF2X3VXqZ/SbessEybhnlSHb5HHyPZeJihxsMnjcdQXEzla6swG6zUvPA3ur/3PUKvvAockweXShMwxbjgih8gCAKaphH+9XTk0hLk3GywWJBFA2lFY197mNb+GONSFqYWjfSLuBK0KzRCq15j4Je/JNmiPxylkuNxuU2I21cjKArmCTV4HvgNq/v6iTW8hMngQDRGSck+gsox1jWagsfoZZyjDkI9lLTvQ7IayShajNtWhMvgwSAYeLbnjwwm+3AbPKzIvhqnwc1cikntepiwzUVk/GV0xaL4EwESgUz2ByJUa5cRse1FE1RSKRGrZMYdbMMycAjhtUZiqobqykCcNJVcq4lcKt7/xZqK6jYbvbvBngt1N4DtfUThxhjjE2BMpJ0jCIKAx2bk12sa6fLHuPfKulEbjTnlmRzuD3P3i/X85sZpOMwGEmmF1w4GuDYbQIPu7WhlixmMQNBYw0R5P63tnZSW6aaoe1pDeMoyyAB2HW5nao7ue/ebdYfZ0eZjcqGb719ay6amIf74ThuPXOoANY1kMJMUYJsEk/7tFSw9IdI2E9FYHDQ7ctpFr9aBvT3GYk8BvXKQ8SUHCQhWzKX7ybw8l6HLcylJKHTdtw5EEE+dT44GBCflsf87C0h5TKj+vRQOGmhMFjIxUof5xb0EX1zHru/9hD5DKYIoUHi5DdPEWgquuxKxMJeG0B7eCD5LZDCEiIxKGo/By8rsz1HhqMRh09gTTFBsKcdrzDmtB9mxpAcHGX70UXxP/Bl1xD9LsFhwX3nlST0O/5EQBAFDbi6G3FwcS5cCek5buq/vuPOi+P0kGhpA00g0NhIYqSCVc3IwT5yIZUItBTfeCNZMJGsmNXmTSCka0YTCQELBO+LfIYgCg86pWBJ95OT1k/e1mXRHJrN/fTN5qw6NVvEewbloDggWgk2vIKgqUiSCNBK0UkwyJm8OU/5m5EBtFS8bh6joG+aINBdUDSkcw3JMapxrTyeH5+2hwjqO68/7f/TdU0XW7IUYi4sZaN5D1+BmMnZ0YekJnWQ5cuS6SfX10Xv3Dwm/edQUVwBUi4n+84vpnaJyuO9JFnsvwSbbR8/rsRhkganlTgozzcRTekQxFkuSWL8W33//N/H6en1BWSbzji/jvO52BKOR7Acm0/r8w+y4eQZR4XmiWfrBSSkICIACsiDjFHOIhxyYVA9DoVw2dA8wd+gxClQFZ8UNDKWzSEcE/CKIQpoq6yQMwgGmmy+hvVtACOylpv8pFMGEXHkLhc4cOnv8CLE0KVlkSEghYGR+8VIkUWDD1oOMC76CR9MrroP5WfgumEufu4K1DUHmVLuP70d8NqgKbHlIt9nInwE1K0F6n9saY4xPgDGRdo5x6/wyrv/vTfxq9WG+sbRq9P/LvTaKPVY+9/AWHrttFg6zgWWTy6CnlYjkwta1FaFsETuaAsyqnA+H9qN0bUUpKcRkELEYRYYUG+rMf+fzv9zELn0GiZtml/DHd9pQRhKxYylFb+rurYGZX6EnZmdzIkbF3Y+MCDQje/7jIsJVXmyqgYjoo+ZX28h64xBN35qL+c+7mNwdRNDAa5F56rxSEpLIVk3DeecSUiGNGT969bhj1gD/pFzq774Q1WIgx5BDcUCkqnkT1nAQcVMS/6p3kKL6l0pmawcFKyaT7zEhz15MJD2TbYEt1Lc/NdoKBkAljYyZDIMXWda9igCmu+e95/ej//5fMPz446P5QlJmJp6bb8J93XWjEbQxjnJEuB2L6HBQ+tRTRLduJbptK5GtW9GCIdJ9fYT7+givXo3n5ptHlw+vWUPg+RcwVVZgGzcOy+TJgAWzw4N51rX6QpoK0UHyQ920Tj/MO7c2UPVaG7nP7MBa4ibe5idnvpl4T5Sw3YoajR8nHKVEmvS+/bBvP+OFnyHm5mH77f+wp+tZku2H8GzpxNUwiHHoqA1HobmUoDGbAmMhW/reoHrlMoa1NOn+eiLX3k5B+KiiS3ts9Cyrom9RGZbcYlaaV9D7w3vwPfnkaGEJgJqfhfila3GuWIYoxukPbKU73s4z3Y+xJOtSCiwlpz3XWS7dPiW8bh2td92D1Hu0QtZYWUGqo5NUeS67oztpGTzIgL0PbiwFVY+WZYhOqhMGcnxDRJUQmUkFpyqjjFvGcH4liZRKPKWSSKmErBeR4bIxmPayt2OYqNSDKaE/AE6vqOHS3Ekc6ooS8g8xa/BpNMmAv+pWPC49YjWnxs1Aoo+dgbdYmLkc0zGtn+bnhxECukDzO+voXLyEiV/MITOWZl39ME09USaXOTDI73GaU1Mh0A7uUhAlKF8CBpt+TxtjjL8z3pdI0zSN22+/nbvuuouSktPfRMY4e+wmmYdvncnV/7WR86oymV6it1MRRYEfXTGRO5/fx78+tYff3jwdd4YXemCjP5MLHc0w2IBRzqJP8xKIOPCKnbQPxCjLseK2GfBFFMpynYTi6VGftCKPlQl5LnZ1+EmmVaJJBbNB0qufXMUEgyHyH1yN4/AQqiyz7+6l+MuzMWlGIsQYf/9mstboycvuX709Wr0ZLXaR2NkN1V4ym4bwTy3A3OzHuPDrJOcnMWxai+BwIk+uZfO1XmKV2dRYx1PnT+Bu3oEWi9Ozvp+O1/chRKN6w2qnC++tt2BcMZtOUwNrhzs5P2MZ/9v1MCltJE1aE7CoWZSYq6jNrMRrynpP0bLToaVSaIkEcm4umbfdhvuazyBaPtxy/U87giRhmTgBy8QJuG+9mYdbHsDeFWGFbyqJ+npS3T3HebFFt+8g9NprhF47ug05JwfrzJk4Fi/Cdv75+vK2bLBlM1OtpVMIcuBqE6YbrqAqZoGeXQixAdTDQ6jhd+k/rGmoPd1kZ1opu/YRcNpJeCyjAk0VBQRRRH5tM3Wrt+qRwQWl7DUZ8F87l/5cmOWUMKUMyAtmk7XyalwLFlGTiDGw4XWUoJvo/p34Riw1NFEgVJlJ05dmE5qYA8TA9zweg5er8m9mw9DrNEb281LfkxgFEwbRiCzIGEQDsmDALjtZknUpoBclHEg1YO/tQhMEYoVezP2+URuV9kcfYk/txaOHahLN5JkLqXVMOd7lPzoEw40w0IDoyiPHaoLBg9CzAfKng3ccGCwI0UZCOWsIK0GWZV1JobkcSRAQBYFxhXYotEP7heCpJNd+VKzHlCiv9T9HWAmSbypkYkQENQmFcxCzaqAjFyqX4/bW4B5ZRxQFsl1Gun1xun1xMuwGppY5sVtO87WVDEPPDujcokfO5nwD7DmQN+3Uy48xxt8B70ukqarKxo0bCR/z5DjGh0e2w8wLXz0Pt9VANJnWI1voUYp7Lp/IYDhJMq2iynbMwNKZk4j7MumP2zAbRGRB4FuHJjOttIQF3VFKsi147AZa+qNIwwf5RkUX/lgKr10vKPj3S8bzwq4uosk0FVl2vGJY9w9Kxch++lXYuhOAgS/9O7Vz6vjhC6386/JS4j+9Z1SgKSZpVKCFyjLQjDJ5rx4ie00TUlIhbZKQEwrqozvY/cCNTPjWr5k07nwEWUYN7aPYWs5wfwR354OEG1N0PbIBzR/Qc3Vcbly330L/ZRNYox7GH/lfjnRJD3ZWYjBUUeA2MDGzhhxjPrJ09pe14vcTWruWwLPPUXD/fchePW/P8/nPYywvw3XFFZ+4+eynAUmQcJo8+Is0TPOW4l658qRlbHPnoKVTJA83EauvRw0ESPf1EXzpJYIvvYT7mmvIu+eHo8sbRCMXZl3Osz1/oEsbRi27Aal8McT8mHiGzL40oX1dJNtOnw/pr8uhZ+PL+otgGFPw6L1NVDVQFb35+AjZDQHErgFy/naAorJMQkUuhuuysfQeJnLPnZgGIwiyDMkUzksvxfGDuxj+w+Nk3HAD5mWLiZrT5KSDRNIhwukgYSWEVbJhEI0s8l5MnqmIzb71pLUkSUWP4oqJNJ7N7dhWt+G/PIXryisYSvaxJ7uf8VPzcR7ox9qhF+UkPBb6b5hD9NJZTHNVUmQpxSV7sMincdW3Zuo/hSOFS8Eu2PtnUBLga2LAJLM1202HSY9GFlsqyDR6jzfXzqwGkwOKj2+vlFKTvNr3V8JKkDLBy4R9ayE2pDv8F8zSm5rP/meS7e1E3nwK1+WXIxqNWE0SM6vcpBSVxu4IB7uibD4UYN44N0aDnj8L6GKyc7Peg1NT9KrNqhX632OM8XfO2HTnOUqGzUgkkWbZA+u5/9rJzCnXKzMFQSDLYeKxja1sPNDDgyuux5hZzrpACXf/sZ57L5tCPKUyrriA1Y19XDerCDSVgkwzbpuM1vM2Xy9pJiEfrY6bUuQm02ZEEgWml2QAe6HhFXwDcfof1S0PYhdOwPSZWiZ7J7I8o4viBx4isGoPAIrZgBTXS/FD5RkYggnMgz40QErq+5FHWvCIiQSFT6xm+51GarXZGFo2UJmMs5VCenwqNstNTJ8WQXvgeQSbHe8XbmPvxbms1w5DYvPomOWUh0JtJuW5BRR4qk/qV3om1GiUVG8viYYGPeF99x6iO3eOVgz6n34a7x13AGDIySbj2mvfxzs4xumwSlb8qaGTujUc4diKUk3TSLa2Etu1m8iG9YTXb8C+eNHosmosRv/Pf47zkktYXns1XlPOUcd5ixvT0tvJXno72UCqt5vY498l2jRIrHmYeKcf+4xyojNzSefayEnsoVkSEZR3zzNMXzQH45OrEcJRbC1D2FqGTl4omUKwWBBMRl6PvI7td18hbszCKQex4SDLmEOeqRCjaDou2isIAuOdkxjnqCMeGKL19ScZeu1vZG7rhJgu2Jpi/8We6R0IPYPM+urzyBE9kpxyW3B84VaKrv0cU5wuWvqiuA0GMsxnkYc12KALNEEkWHcNmxJ7aVX7ARV7SmGeeRKl2SsQNFVvTB7q1q0t8qbBhGuO25Sqqbwx8BL9yR68CZVFnYcQjljZyGa9d6ZsAkGg/777CL3+BqFXV1H8+/8Z3YYBhVpviiI5QHtbNx2bfTg1H10FVzGh2IE5OqjbBWWNh4KZesu891MBOsYY5yBjIu0cxmaS+flnJvFPf9rB726ZPjr1CXDTnBK2tg7zrTcVHvysnYsmOOjuH2Lvvne4bPEiltbmYFNDVHc+hmA4D2veVGxmE4RH3LlDvWA+arD6jb/sRNPguplFzA/tIctg5IXpTgo/Oxn71k4OfG02ieRrxPu7WLntBYZfXAeAYLcjjURUw0UubN0hxHj6tM7wgapM2r69jGWGqRg2/xriPoYjTnwxG5TWIFg8yFVl5N57Ly3jqnjDeIiA2jS6MbNoodo2kUrbBLLMer5L/NAhOh98EMXnR43FUONxUBQ0TQVNN5Utf+7Z0TH0/cd/4H/q6ZPGJrlc2JcswXYKy4kxPjwsom7LEVMigPeMywqCgKmsDFNZGe4rr9BNXI8RNKHVa/A98Wd8T/wZQ1ERgZUrcV2+Eq0gm1A6gNd0tEOCITcfwzd+jfPAX2HwIFpaQU2DNG4JNZ4KtKFGzONbiLV0I0bObNGwZ5ZMcUchWWubQFERjjXXFQQM0ybjveY6nBddRMKo0dbx0KmPD4Evlnx79PUfOn5DWk1jq++m9L/ext40hKBqHLGmVo0y9gXn07DYRlpLkVFUjlZeAB2D2G+7ifwbb0caadGnaRq9/iS7W0PUlTgoz7GceepfU6F5NbS8CSYnTL0VTGbautZglWxMdc1hnKEYWbbp70H7JujYeHT9nl0QaNOnRvNnoIV6WJ/cR7vWizMNK/pTGARZN5DNnwE1l+mVl93bCG/eTej1NwDIWFAC7W9D8Uji7JZfQ6QfBzBhZFdJTBz0D/OGL0ld4QSKF8xEkMci3WN8+nhfIk0URe644w6ys7M/7PGMcQLzKr08cN0U7nqhnue/et5oiF8SBe6/djJ3PPwWW/fsZvaUKdyasY1UupFtQ3VcXFfMxbVetLc3EG9YRdRazWBEwJryUgS0Nh9gXNZRkXZhbS6/XH2IoWCMHK2P7R47caPI4RunwmengARo0Fn/NjnPrkcAYgUZWLp041jJZcbeGRx1Zz/xq0ADei+swnznP3Fd7yDG/a+A0c7+nirSDz1MgWk1yYf+SFCKsCO6FXmBnVC/SEBuwhBOU95qpKglifHAfuL7nsL2nw/AtJEy+nR69AZ/KsQTDGXlLH09KcuLpXYCptrx2GbPwTpjuj5FNcZHypHoWUx5l1yxUyCcMOUsZbixzppFdMsWUh0dDD70EIMPPUR0YiG9SyqY8Zl/ISer8ugKJoduZJoII9Q/hTR8CPr3QeUyBE8F5U9dxGbfevb2vIWpJ0jBW21kbu7A0OZD8Fgp+efLiSR7MXss2A72I6RO0aRd00jtP0ho9RrcV1wBDQ1ctiuLwFAnycF+EmZIJWNoiQRiLEVH6Muke3rx/su3iZfEEAQRxW7C0agn+Cs2E5HJRSTNItZDfSQO7iTnBz9mecZcLJKF5C+WIHs8iCf0TxYEgTnVLg73RNnTGiIYTTO51DHac/REkqFuDvo2cbDUy2UFt2CyeHECy7KvoMBcMtqvFoD6J6FnJ8gWXXDJJgj1QKgLundA+9uEjQZaC51YVJWLu4JYU8dEKIvng2QEfzvK7mfp/U+92tU+KRdHUVI3Nj5CwSxIJ8DsAotH/5HsnCeJ7G4JsrMtTlIzUJU/JtLG+PRxxm+kP/zhD9x8TNXVEQRB4Jvf/OZHNqgxjmdhdRbzKjJRVI0DPUEmFrgAMMkSv5s3gNy7imi0AmvRXIyDDVTE97Ovy8UPXqjnwoxqvuzdTqDpTWKehfRHXXg1I7Zw63H7uHZGIT99tQFzop+YVWGfXUDQNDRBAGnkpi5A3L2Erm/7EQ9007+wjNofvcnQnGLyVh067fg1oOPmC5j9bz/G0bIFqb+eFnkizsMxuP8XGBSFtMPB4b5HCZTLENEoeLODyQdMlO3ZCa161VqSoy7q8QMHRh3wDUVFZH7hdiRPJqLVgmAyI8gjxQ8CCIbjp3o8t96K53OfQ3K5PuhbM8b7wCLpYiKqRN5lyXfHPn8+9vnzSXV1EXjxRQLPPU+ytRXrvk7K93VyoHkI+ccPkWk84YHSZIdpn9cTzNURoRXph52PMrtqBSUVt7Ip400aK7003jqdsoiFmX1xrGIM6+R/xdL3EtbOwEnjGSUWY7D7IJlKhNCzzxF47DEAjCM/x3LkLKTbO/jiwm/rU7xSF4OXxUBTSTQ1IW1sOG6d+r2v01p1mOsKbsdYVHTaYQiCQFW+DYdFZtvhAEVeM17nMSPQVEKBZvapnTSE9pD0WgCFNqWP6pEoZ6l1ROSGesAxEol3l4NsHamctMDeJ2BgxPrDnAGFs3HkTuYyIYmgqbgKnND0BhTNAYMdzCPebq4i+t5MkhqKItqs5N73eygqO77Z+ZGI2jEcOQKnVUYDBkNJilMWFFU7q9SHMcY41zmjSLv33nt59dVXuffee8eqOD9hDJLI/u4gtzy8hZ9cVceyCXrllOytgt7t3PP4S3zp6ssoteXiGt7KXTs9hBNpfrHPys0risjybUbJmkR7xMyAoZDcVNtxfesy7SZml3kokrppfGYvFZJIz3V1hPOPCpnQUA5KcgD1gmKE84vQjBJbfv8ZVJsBhyYg7O/B1hk8btwasGbeYi79/I/YcUAhFKkj05iB8PRLxF97GgGIVmbRduV4AhV6uK7YUkHt9hbCb7w+uh3BZMJcW4tlUh3muklYZ0wf/Z3kcJD9L//yns+l5HSe/RswxoeGy+DGa8zBKJo+tG0aCgrw3nEHmV/+MvE9e/A//wLDLz1H96JS2nuf4vK8G7CFNHrvuQfH0qXYFy7UW3ZZjqYQ0PQGxH2w9wlynYVcUXUJjc4Im33rabGF6a40c2PeP2EwWFlh+QJ93zd/43IAACAASURBVAkxvHcbidZhjM3Do3lho5u7soLt7b9hdroNg82GFjlBlBoMiFYLktOFubYW2/wRaxhVpWXl5WjR4yONhsJCnBdfjHjZInJd7bgMGaP5d1ElApqGVT51G7LcDBPLpnoxyiKKqpFIqUQjB9g58AYtxiSaICAgUGkbT51z+tGm5ekE9O2Bri0Q7ISZXwFXsW5nIRmPNia35UCBlUTuBPYLQ0yxTUFoW0dmqBum3KqLrokn53b6n3+ZwN/0z3nuXXdhKD67HreVeTbcNgM7moK8tmsARYVp5U6Ks8YqsMf4dHDGBuubN2/mzjvvpL+/n69//evcdtttH8jO4KPm77HB+tmyp9PP7Y9t49sXVnP9rGJIRmD9j2mUa/j2vgqevcKM1PAM++wXcu3fkgjAC5+vprTpYdK2fP7GVdR5huka8rNwzmzdR2gEVdXo2rWG0E1fR1A1DnznAgYWliMm0hQ9uY9ts66nIGsH+c/V497VzYHvLyGRY8cbSzFkEEHVmH3Lkxj88dHpTtvnbsFxnptkGjaarwBFoezxn2Far9+YExkWTL4YKaeJLX+5mcU5l1Fuq8b/zDNEt27DMnkS5rpJmGuqT4qIjTHGmVASCTYEV3MwUo9dcrJkow3fXT8G9Oiqde4cHEuX4liyBDkzU28VtP+v0L/36EZy6khVXMiOxAFMookprtkAo90/0DSI+0n7W+k5vJXBA/Xk9zoY6Grk7e8ebblU8vh2Sp7YfdqxOi5eQcH994/eX9tuuplEczOWujrMkyfhWLwYU03Ncfff0TEAbw+tZn9oN9X2CUxyziDDmHnK/WiaRnNzO6bOdURNzbyZa8OoSYx3TmWiazp2eeQBJtyn55v17tK7jxhsuhWHPVcvLOiv13PYzvs3MOumGb7kEK/3P48vPcQcv8LkwQC4y2DyzUfF3DHEdu2i9aabIZ3GedllFPz8Z+/2lp6WtKKyty2EL5wmEE0zvtBGTYHtnP6+ej+ci70wz/T9ei6OFz5ZTXC2DdbPKNIAEokEv/rVr3jssceora3l3nvvpbKy8kyrfGL8I4g0gOaBMKsP9PPFBSNPndv+Gy3cw62Hl3JBTQ43K08SUw38YHApqw8M8D+fm0HGwE6cniy2B/KozrdRlmNB0zguP+Xfnt7NvNf+g5r1u4mVetj60EoQRcoe3krRU3vxT8zBEEpgbfPrDaCn59N5VR3hKv0LQZNEEARy3ummvPAaoo0tjJ8wgD09TDB3IWsDExn3q/+LsnvHSceUyHVS9PijZBaP/zhO4Rj/IOjVhS/SEj1E2SGNCav6Ca9bh3qsfZAgYJk2jYzrr8N12WV6rtWBZ/VIsyDAvH85yc5h4/AaUmqKORkLjzNmPYKmaXQF9vPm8GtEhTS25iEchwYxBOOI8TSmgQilnSrJji5c88rYOCOXwQVleLd3U/K7LUSmlxI+bxyp2nyWR+yYDE4w2uiUElgMLpz2Igz2fH1nyTCbQ5vZF95DWtPvdSWWCia5ZpJtzMOXGmIg0UNnvI1YrJ+VjS0IaLTL1XSWlzOzcC4G0aiLVMmopwl074D9T+mVkgWz9Gnhjo2QCOq/z6rV7ToyykEQOBjex1uDq0ijkh9NscwnY6pcDtl1x09dHnuOkkm6//17pLq6KH7kYUTzyefxbNE0jfbBODuagmQ7jcwb7/5UCbVzUfSMibSz40MXaUeor6/n+9//PocPH2bp0qUYTohqCILAT3/60w8w9A/OP4pIO8LuDj8Pv93Cz+elMR76K77yq9FyJmEPt7K2GWqri8h1m5BEYfRGlUyrCGKaH7+6mpllfgyZVoIpH5flfZYf/Gk71//8KxiTSQ5+6zz6LqrG1jTEtK+/gKBqDE/Lx7Oj+7gxaIAqC8QK3Vh6gvQvriBx0y8xJWLMif0VsxbFX7ISqbiK7nvuhmdeHy0uwG7FfcmlRC+aTv6spaf3cBrjU4WmaYTTQSJKmFxzwUe+P0VLs25wFVNcs/EYvajJJNHNm3W7hzVrUAb1BP3ML3+Z7G+N5NpGh0i+8VsM42ciVC3T/6/lTZCMJPKn8JfuR4irMSyilXmZS6iw1pxWDMTSUd4YfIHueAcApUkjUjLK0t4gCVFEliz8pcBEWhQofvAtcl85OLpu2mrAXZWFfVwWtom5/HF6PqmRByuLaMUuOzEHejCnkswdjHLAbWGfy0RMOvVYZE3ghgEj5oxqWqjg4IDItIwBcvzv6Dl5WeN1oRYZ0EXb/JE0guY3dD+y3CmQO1n3Nov7CQ/sYaNpmJZoIwDTIjLTMxchZtcdF6U/HZqqokZjSHbbuy77XtE0jS2NfrqHk3jsBiaXOXDbPh1R+HNR9IyJtLPjIxNp4XCYH//4xzz77LNkZWWdUqStXr36Awz9KJs3b+bWW2/le9/7HjfddNN7Xu8fTaTFUwrfeWYPPcNBHp3fh6VyEYOak0febuHL51fgsMj84vVDPL6xlde+tYDO1EF6ozvpUgbRTriHX5V3Cxt/+geqn/g9qsVA0+8/g2gykn/vaizbO0mW5iC39+vGniOogoB4issnftFKxq+0I2tJNpsvJlas0aZtpvLeN8he14yYm41yyyWMu+6rJ1WkjfHpR9VUHm77T0RB4vPF//yxRzoUTSGmRLHLDjRFIbZbt39wXXE55hq9dVCqp4fDixZjKC7CsfRCHPOnYVG3IyR8YHYTLZjKRkuEprjeTL3YUs75mcuwy47T7jeUDqBqKk7ZjarE6R7YzMbYTizJBHUpFyUTv0yqqZngk78lvGUv8UOdJ/WGjdyyiJ6bphPUYkS0OBpHP3+3R4qRNUgrCR5z9JEWQdAgN5YiO6GQE09RGE1hOLKKbIF07OSBCtKIuW0WTLpBj5xpmm5sG2gHXwsMNqCGe/nfYhdBo4RVsrEocwWFltLTRs4Agq+9huL3fyzeg8Foml0tAYZCaSYU2aku+HjuNUo4QqKpCVNFxYcqPuHcFD1jIu3sOFuR9p7O4OrVq7n77ruJx+Pcc889XHPNNe++0vskHA5z3333sWDBgo9sH58WzAaJB66bwi9XN/KFrSb+NDkLl6Lyxv5+6nIszLHupESTCMZFfvLKQeqm7SFlHMSoqjgVD5XBbrzeabgLL8AsWina+w4Ajsl5FMazKN+7l57tnSN7cyKqR8viNYMRMZU8eVCSTPeyG7CJBxjaM8DAvH2IL76Dcsl4rF+9FeOiIdbNipISFTySn1zGRNo/GqIg4jJkMJwaJKpEsJ0m2f2jQNM0Ngy9Tnu0ieU5V5FtysM6bdpopfARolu2AJBq72D44YcZfvhhJKcJx/RKHFMKsIWHWWqQqS4czwZrhPZYM091PcIF3hWU2apOtWsc8tEinG3BLexKbMUgGfCbJXrMYRxd/8PErGnUrBhP1iwjSnQikYMDRA70E97fR9ofp2bWVcww5cLeP5FKpOl+eg9ipRe1MhMmlkHp+ci7/8Bn/H5EVUMA7IquyrrNMvWTLmSybTJCfz307QbPDHCXEhPtHOiFCeVeTGazLswSQRhuhsxKXXgdepl0zzYSooDN6EEsms9Ml41+WWVGxnlnLATRFIWBBx9k6Lf/n+4jl5c3alj8UeG0yowrsPN2g5/UiEHxcCiJ1SRhNn40FaBKOEJs927QNGK7d2OZPPlDF2pj/GNxRpE2PDzMD3/4Q1atWsXChQu5++67ycnJOdMqH5if/OQn3H777axdu/Yj3c+nBUEQ+ObSanyxCO3+Rjr6dvPFKw3sC++kzZhkjkfFYZrE+sYB5tZMosSQYlrLc4RNGUgxAavSgVzqoG1gH6YGvcy/YXEFLflhwg+3kAUkirIxtTYe3anVjBA9tdlnzve+y4DNiP83z+PeswvLny2Y/DEmMZ705yayxvk3VFSmuuaQY8r/6E/QGOckboOH4dQgvtTgxyvSRv7E1Cgv9v6Fxd5LKLNVn7Sc6/LLsUydqk+JvvEGsV27UIIJ/G/W43+zHuuEUkruuolinFxbcC2bfevZH9yJuW0j2Pv1qlGzC0wuvf3RCdGlbFMeZtEyOmVqlWwMpQbY5HuTbR4Dk4svYrqhEudsH864Dw2BuN+GKccCvgaw5xFvOER0UztsagegyfoW5okTsWQpmKsKMU8cjyE3H2QTqmRinbqNYGQ7ncoAiwovwVZ69EFYiacZSvrYsa+JaY4uTP6DEO7Vq78vuAtFgIZMFzuteWQas1iR/1kAKkd+zkSyo4Oe799JdLPeMcR2/nlYpk59/2/iWZDtNlFbZOdAZ5jcDBP17WF84RSl2Raq8m0fql3HEYEmGI2IFgtqLDYm1Mb4wJxRpK1YsWI012zlKXrsfdisW7eOYDDI8uXLx0TaMWiaRkyJEFZChNJBwukg2aY88sx6aHS7fyPb/G/rC488zDrsYEubsaiDXJXbTzx7KplyPkpCIpE5lYyh7ajZ4xEGGyAZprv+bRySgCLLtM4pwjgUxbuxDQA1edQKQJOF0wo0sTgLcWALrp/dhzGuT6OY/DEEi5nQhDw2Dr4EwHzPEiY6x5oe/yOTZcqlOXqI3kSXPkX2MSEKIhdkLsclu9nqf4vXBp5nWnIu093zEE9oJWQsLibz9tvIvP020gMDhFavIfTqi0S27sRWZtEbek+6EQNQdu+rlFqHcBU1oRbWIxglQrKIM63C4h/pU4jd23SbD6BMEMgRBdZ6oMMcJa7GqLHXofbupMmmobStg+FXAei3WAhNuY6CwmLEtrf1PpUISDYjzrk1xJr7SfX5UKMxolu2on9ad2CqOUj588/pxw0s7nCwVt1IV7ydZ7of48Lsy8kzFYAgYDfLLEk9hRjsgACkTR7kovlEXPk0BreyL7SbiBICIFMyklbTyOKZJ2K0ZJLhP/6JgV/9Ci0eB0HA+7Wv4v3KVxDEj69tU3W+lUAkxZZDARZO9NAfSHKoK0Jrf4yqfBu1RR/8IeFEgQboQg3GhNoYH4gzfspmz57NXXfdRWbmqcu5z5Yrr7yS7u7uU/7u1Vdf5f777+eRRx75UPb1aaA5cpD60C4GEr2ktOOnFic7Z42KNKtkxyG7yJDcZPQ2kgyKxLKvY0llIam2+/ju+F5MCyZwoDvGwa4IhtrFqEM7iYcDWNFQ+g/SXAGRJ2/E0hUAg0TGji4EVSPpMmPpCx/NfEmfPoXR5jXQ81+rMAKaLCGkFQSTidDP7mBHaTciEouzLqHCVvPRnLAx/m7IM+kGrD3xzndZ8sNHEASmuefilN2sG1rFjsAmehOdLPJefNSC4gTkrCwyrr+OjOuvQwkGoWc3eHSz12RHB8GX9ebsIQBJRC3NYaDCQUFlFYU5+zHX1iJIJrDnABpoYEVjRVTlgD2HTUoTB8N7KTU7uSmWBVYJ7BYQZQ5IXTQMvACA0+Aia+IMMkw5uOZkkndzIQWyg/TgILG9e4nv3Utsz15ie/dimTz5uGOIfvMuprS1EZ1aTMcUN69P72OaM48J4+9AEATE3MmoWbUcTBbjU93EPJtoiqxBi+uf+SJLGdPd895TBDzR3Ez77V8g3dMDgLGkhNx7foht1qz38Y59MARBYGqFk3ca/CRSKqXZFoqzzHQMxFFHcmqjCQVZEjDKZy8eTyXQjjAm1Mb4oLznwoGPmm3btvH1r38dy8hF7vP5MBqN3HzzzXzta197T9v4ey4cUDWVrngbEhL5lmIA6oM7eWv4DUQk3IYM7LITu+zEITvJNRWQaz45yZDWdXD4VdbKF9BmrKEovI/F4ts8GZmJp2o+L+/q487LxyHVP4NFGeavrUYqp89iu/E15BSkj6kHsbcNYxiIoholnPv7cQ5E8LzcgACjvTmP/C3ajKgjZp5CphdtaBDBaKTwN79h/wSV+uAOlmVfScHIsX2aOHjw4Lsv9DFTU3NuC2FFU3is/UFUTeWW4q9hFD+Zlj6+5CCvD7xAIOXjqvybT+5M8B5IHdiE76H/INIcIN46eFKyv2aUqdm2Dcmoh7kTjY2oiSTm6qrRNlf+1DBrBl5mdsYCCizHG4e3RhtpjhyiJ95BeCSadYTF3kuostcCsNm3nu5YO1bZjk20YU0asDkysckOMlI22udeACc0j48WONFm18HcyQxM9jIteyE55nxUVWP14It0xNqotI6j1jnpuD6oJ6IlkyiBwGjLNS2Voumi5aSHhvDccgver/7Th2Kx8UE44iunqtpJrbG2HQ7Q60tQnW+jPNeKfJrq2BM5k0A7FjUWQ0smP7BQOxcT8ccKB86Oj6y68+PmO9/5DhMnTvzUV3eG00Eawns5GNpHWAlSYC7h0ly98imqRAing2Qas0edxd8VJQUb7wNR5kXrdfzo5f2smb+bR5rdaKWL6PDF8NpN/NuFFSAZuP+1g2iWbhxF24jFZSzm058re7eE4O+m8M+70KxGMje2IWZnIHQNjS6TmDgB0z69PUzBA7/AuWLFqOWCw/DpbMN0Lt6IzuVr/gjrB1eR1tLMzliA7QxVkR81KTVFb6KTIkvZyOskgZTvjKLkOJIRvSF4x0bUaIR4X4q4z8JAxwDh/fWkbEb8v/0mS7IuwSAa6f7Odwk89xyCwYCpqgo5Nxc504OUkYEgG7AvXox5Qi3bAxsZL1YT+vXvQNVAVUilE8RTUZJKjKSSwC1lUPLDexHNZl7pe4bQhvXkvK7njyoWA2mbkbTdSEXRbHKGmlFCSVoHBxG3N2MeOL4DwuY/XMv0mpXUOaejpdOE1Aib9scRNInZ1S5cNgOapqFGoqQ6O0g2N5NobiG2axfR7duxTJlMyTEzIdGdOzEWFo4Kt3OBVFpl7b5hJpU6yHEfLXRIKxpNvREOdUeRRIHqfCsVudYzVh6fTqCp8fgpBemHIdT+3u415+J44e9LpJ2bZ/AcJ6km8SWHyDBmvq8IgKIptEebaAjvpSPWMlpGn2sqoNJ21MzVKtmwSmf5YZYMULYIDr5Ivm2AUBLu7FvK1qEA6f4OHrt1Jv+zrp2YIjLsjzO3xEvHpr+S85e38U/Kp39ZNZqggaohhxMYhqIIqkagMIehDAlTfg4HfrgcUMlqhPPyp7C9dRVZv96E78qZFD+6BRUY/txCMhbV4USfbvi0CrQx3j8LvBd90kMAwCAaRgUawK7AFnYENlFjr2Ome/67C0ijDSqXQekCxJ6dWLu2Yg334Ln5/+BzZ/NK95OEYod5ofMRVmSsQAn4AT3aFN+/H/bvP25zck4OLcUptvs3cii4iamP/+GkXYqAGYgD2p13g5DkwmHoP+AnsK7lpOVVdtADWOfMQfrlt+mMtmBqHyb7Zy8gdwwiArOf7Ccq/YZOezGpXftItrVRu3gx3bMuYl28mklaP/Evfw4tlTrlaYht247i9yO59Q4E1o+pOOBsMMgimQ4D25uCLJmUicmgT2/KkkBNgZ2yHCuHe6L4I2kEQUAZqZA9MfJ2rEATZBklEDjaC1gUUUIhJMfx183Y1OcY74dzVqT95Cc/+aSHcEqSapL+eDcaGv3xbrLN+Wct1NJqitWDL6NoacyihWr7BMbZJ522lctZkz8DPJVMt3r5ylAjf97azlfmVbOzpYN4Ms3c0ixSaY24r4epnU8gH9iBY3UThmCC0OJysh/fgSGQIHNzO4aA3uIpZTGx5/7lSJEUwQk5JBN2yFrBO5mb6bHn0vizG/li7edJXtrDrt/dQ8O1Zfj8G7kk55pPleP3GJ9+rJINo2jiYHgvjeH9jHPUMcU1G8dp8tVGkc1QNFd34o/0gyWDDMnIldbzeHX4ZfrNQbrrf0/ltdko13+JeNBJwmckPTSE0t9N2h8EFQx5uVTYx9OX6OZwbBd9iypwmNxkm/ORRAlBS4MSQ0jHwJqJIMsgqMjdO3CXFyFd7QBTBmpaQA1HUPw+0oNDpAcHkbOymOKarbe3yoPm1CoSwZGI2otrsQIhNo4eUvj553E+/zwOh5P+igk4jhFock4OxvIyzDXjsM6ZjXXGDL0f6jlOXamDgT3D7GoJMqvKddz9ySiLxxUSNHZHaBuIU1tkozDTPLpsvKGB2O7dxPbsIbplC9YZM8j6538GQDQaUZKnsCdCF2pKIkGiqQnr5Ekf4VGO8WnhnJ3ufD981NOdRwSaKEgYRAMpNYWqKWcUaik1SWv0MAfDe7nAu2I0MXlXYAt22UmZtRJJ+Oi0sqaq/Ofqw5znDjEt8CzChGt4o7eANn+YSydl4t35c7ofXEv04ACW5eNwXlJD3/95GVInn7Mj+WeKSULI9dDwjZUM1moEAhY+X3ULRoPCy31PEUoHyDcXc1H2FR9qE+1zlXMxpP/3MN0JEFOi7AvuwCJZz6mK35gSZVdgM/tDu0hraURExjnqmJ1xwdlHzzWNdGyQzsBeSmNAuEf/yaqFqov1Zd7+ud56STLpfS5lM0gmmscv5K3hNcTUKGZF5byBKOXh5GhvXMqWQMVS/d+p2Cl7ZB4/FO04URJ85RWSHZ0oPh+paIj+UDvB+BBSPIVlOIldtaAdbjspz877k5+SdcVHX/H/UTEYTLJhv485NW7yMk5/j4onFRq6IrT2xcjQolS270TbuJ7whg1o0aNV76LTSdHvfocgnTkt5YNMeZ6L9xkYm+48W8amOz8iThRowIhQ46SImqIpdMZaORw5QGv0MGlNf/o8HDkw2qB5iutjqHJqXY8wsI8phVfzy/W9/L7CiH/vKjLLv4gvauSpXb1ca64kNahXppmzXBgP9J9SoAGjXwxSQoG2AcZ/+/fs/M9rWeg8D3WwjedZT0yNUmatYrH30nct0R9jjLgSY0dgE1bJxjh7HbJ4brTvsUhW5noWMcU1i92BrdSHdtEd60D2vI9rWhCQrVmUWheP/ldT5CB2yc5o1lvxfF2kxYN6F4B0HNIxyi2V5BeUsrHneRrpYEOOk8Lc6ZgcBeDI09szHeFdBJo+lOOj2s4VK457XQj0J3rYNLyW3oReeVuU9DKvIZPIhreIbNiA4vez01bJzHCKDLuB2K5dDD36GPbzz8N23nkYPmIvzQ8Dr9PIrCoXWc4zX29mo8SUMidFvlb6br6BoKIc/aUsY54wAdvcudjmzTtJoKVVlWhCwWqSkEXxQyseGOMfi7Fv0ffAqQTaEU4Uai3RQ2wafpOEqnuJSUiUW6upsk+g2FL+MY9cg0AHC4oH+WZvnDdzq1hu28PbLbswOWpZs7+fqy4oJeXTPc18OXaGd7fxXicnU4UZXDTnS/hu/BIDne3Yvn0+JSsu5/zMC0/ynBpjjFORYcyk2FJBe6yJvcEdTHXP/qSHdBwWycYczwVMds0inA6NXtd98W664u1Mck4/a2HpSw6yZuAlJEFiec7V5JuLoGjeaZc3Y2Bx4fVURltIaylMI+a7KTWJfEJk7MMg25THytzraY0eZrNvHXZ7Pu6VF+FeuRJNUYgcaCBgyGfDfh+zq10Ia94k9OqrhF7Vfd1MVZXY5uuCzTp92hmrHj9JCjL15P5UWsUwYr2haRrJ5mbCa9dhHj8O2zz9ffHUjWfQbgdNw37BQtQ5C4hMnEFhnp3Enj0nmRWnVZVgVH/YDUbT2IUUUjo9JtDGOGvGRNq7cCaBBnp+WVQJY5Xs9Me7MQomkmqCQnMpVfbxlFqrPrkpv8LZ0PImUsdbXDJpHquCVhZb6ykKbqNi3nxeaTTRh4x1pB/njgoH1f87wHvKKpEEWv/pboqee4P04WZEWSJvwjzmZi4by0Eb46yYk7GAjlgzuwLvMM5Rh0WyftJDOgmLZD1uXO/41tKb6OJAaDdzPYsos1a95+vebchkims2OwKbeKXvaS7KvvI9GfoWW8uOe71ucBUxNcp8zxI8Ru9ZHc+7IQgCZbYqiq3lKNrRyHpj7ADmciuzLS52tYTYdNDPlPFTcV15JeG3NqAMDJJoPEyi8TDDjz6KYDDg/epX8d7xZUAXQUe2fy7Q0hfl8P4OZkYOE9v8DpGNm0h1dQHguHDpqEgTDAZK//RHjCUlCAYD7QMxGltDdETjTCobj63lACp6ztkRgSYiIEkC6XCUUCpB1pzpYwJtjLNmTKSdgTMJtFA6QHPkEO2xJoyimWVZl5MGJE3luoIv4DK4P5lBH4ts1oVa23rumLyAPnE8f92wm+vzOtnTdphfXTcV32ATvpHFVVXD1hF4T5sOXrqYixdOp/mi7wHgufVWxk294Zy5+Y7x90OG0UuNvY6G8B42+9ZzgXf5Jz2kd2VB5jI2+dbSEWvh9YHnKTAXMyfjgvdk2yEIAjMzzkMSJLb63+LV/mdZ/h6F2hESSpzBZB+BtI+nux9lgmMq093zMEsfbtRKEqRR+59IOsyGoddJa2kmOKYyt/QCrCYR14T5ZKy4AE3TSBw6ROSttwhveIvY9u1oqRTyMdOfit9P04XLMOTnYygoQM7KQnK5kNwuRKcTyWbDMdLpBnT/NWT5rDoUaJqGFouhhMKo4RBqKDT6b+ucOcgZGQCE3nyT1J3/j8LBQXpO2IaxvBxj5fENr0zHvC7OspDlMrK3NcTG9gQlrjKqAs2kVZWwZhgVaFoshqimkCZOxq8a8SgqBmlslmGM986YSDsNZxJo+0O7aQjvAUBAINvgIaWlRnPSQik/Fsn6iRl0HkfRPGh/m+LQNlxV11Ow5HIGe7bj9XhZs3eYjvZGjrQ5trb7j5vqPFIocCKpbDsV3/kR++/7LsZQCMnrJeuOr4xNcY7xvpmVcR6t0UYOhvdSaRv3sbaKej9kGL2syL6atlgTm4bX6K2Weh6nxl7HwsyL3tPDyjT3XERBZLNv/VkLNZNk5jP5t7I3uJ0dgU3sC+2gMbKfKa5ZjHdMwfQRRO9tsp2F3hW8NfQ69aGd+FNDXJh7OSbJQDyp0D4Yp6q6GnNNDZm3344aixHdsQNzbe3oNlJd3ajhMIlDh0gcOnTSPgSDgXEXXzz6evB3v2PwwV8jWCyIViuiST8uTdNAVXFeegk5//qvRbtPbAAAIABJREFUo8sfXryE1Gm62gCU/PEPyDNmACC53CiDgwCodieueXOwzZ2Dbf58jMXvbrptMUrMqnbT60sQiqUxFk+if9M2JKMZyW5Fi8XQUkkMEych2mykFY3hUAqPwzAm1MZ4z4yJtNPgSw6hoZ1yitNrzMYsWimzVlFqrTxuGsQgGograXzJIXLMeR/nkE+N2QUFM0DTeOD1BjLtZlyGafRvD1DksWJyWWm/bhKqQcJxcGB0tWMF2oliLes7X6W1ZRXWZ9fpr/9/9u47PK76zPv/+5zpRdKod8uWbcm23Bu44UI12JgSMJAGZEPJj4Sw2V3YbEieJPuQkE1CaHkgGwKEkpCY3rGxAYMBG/duIzdZvUvTyzm/P2QNliXLki1pRtb9ui5f9sycOeee0Vj66Ft/8INB2Yx/splHg2Vm5NnEZnAwO2URXzR9glGJj8kDp6IoCsPto8i3DWdny2Y2NX+GitKr1uT2iUSfN35EqWdvr8KpUTUyxXUORc4S1jd+xD7PTj5v/IjGYD0L0y899QlOwyjHGDLMWbxd8xLl/iO8XPksizOvxu+1s7vMTas3zOTCRAyqgmqz4Zwzp8PzzcMLyP/znwmVlxMqLyfcUI/W3EyksYmI291p8H2kqa1lX/f5iPh8ROgo0nxCy39X772qoiYkYHA60Y+bpWodU0zuA7+nJWckGzwJXDI9A5u59xuuZyVbSE000dAa4nDaaOylu8kKBVANajSgQdtabOEIEtREr8gSHCfRXUuaruvo6F22HPVkWY4Bp+ugKGw83Mh/rNjK9dMKyDWF2HyglBHjU2lJbgtb1ooWkjdXQESjfmoBo/+4FufBBjzDknHtqEaJaDTk5XDkgV9S8JufkbLhKMbiUYx66ZVTTj2PR30V0uJxmvlgDJq6rhPRI4N2VnAg4kdHj3Y5bm76HL/mZVLiDOzG7kd6HvaWkm8bcUat0Q3BWrY0r2di4vRot+ue1u0oKBQ6ijD14fejgBZgVc1rHPUfwm5wcFX2t/B6zKzf34TVbGDG6CQSbWf+dQzX1hKqqkbzedG83mMbtauggKKqmHJzsY79agFw386doGmoNls0mCn27ncO0DSd7YdbGZVtx2Htfc2hiEZDawhVUWhwB9n3ZR2JdUcYPbMEW3LntfXCER1N13sd1OLx+wzIEhy9JUtw9BGzaibDmkONv4KQRoegpigKShcdgXEZ0CD62+XULCMug4+RmTamlb/AtHSNVSyIHubPSaQy59g3FV1n531tY4NsYQ2fUSVlXx0fbS9ghu99EndUAZDznz8ZlAFNxB9FUTAeWzNQ0zWaQw0k9/GA+P5kMXy1FVBED7Ot5Qv8mpedrVsY65zE5KSZOE4S1grsI6P/bgzW49d8ZHe1N283UszpLEq/LHpb0zU2NH2MN+Lmk4ZVjHSModg5gUxLzhmPHbWoFhZnXs0HdW9jUIzYDQ4cSQqLJqbyxf5mdhxuZfaY5DO6BrRtbN+bbaVsJSW9voaqKkwacYqFik/i+IBmNChkJFlIGJ/FzjInG6silJjalik5nrSoid6QkNaN7oLaieI2oLULeVHW/Y4/zhxBMDORzYdGMt+0CadeTyt8tVilDqhqh24Dw7HG1nEuGzWXBvHZrAT/eT+5nzfiODe+lkwQg19YC/NG9Qs0hRq4JuemkwabeGZQjFyd8y22Nq9nd+tWdrRuZHfrFsYkTGRy0jk4T7LVlC/i5fWqvxPWQ1yaeQ1Z1tzTrkFBYUHaJexp3c4h75fscW9nj3s7LmMKxQnjmZA47YwW0lYVlQVpi1GO6+K1mBTmjksmFGn7nlFW58NuMZCaEIffE4/j8Uc4Wu+nKKf7VrcTtfraWmSO35DdZjEwpTCRA9VezMauA5jRoBAM67T6wqQ44/u9EbElIe0UehLU4j6gAZjskDaGzOptVPpqmDZ7EfqGzczTW6m64lnwB9FyE6HajRLW0FUI5rnwZyfgvm4ihpFpVNlsGG0hCmwjmZqxGGWUzOQUfc+oGkkxpVEdqGBN3ZtclnntoJw17DQmMCf1fCYnncPWlrawtrN1MxX+Mq7JubHL12Qz2BmbMCm6PMeSrOWkW7JO6/qKopBvG0G+bQT+iI8vPbvZ07qN+lAtu1u3MSmxbUFtXdfR0KKzOHvj+O7Z+mAtq2pf54L0JaSaMwCobgpSVudnWJqVkmFOrKcx5msgBEIau8rc5KdZsVt6XmOCzUhDa4hwRO8Q1Ayqwujsk4/TDR8LsQl90CUszm7SztoD7UFN0yOEtI6bCw+KgNau8HxQFA6tf4VtdTplegbU7EGPtLWiqeUtqGGtbUNhDaxHmnB9XkbeXW9y7n+8xcRQAUWBvLbfngfhD00xeMxKWYjLmEK5/wjbWjbEupwz4jA6mZ2yiOvzbmFi4nSmu+ZE//94w24iesfh8NNdc5iYOIOgHuTN6n/SEKzt6rS9YjXYGJ84la/l3sjV2d9ibuoF0RrK/Yd5ruwxPm1YQ2Ow7rSvsd+9i6ZQPW9U/ZOmUEPbaxmVxKxiF/WtIVZtredwre+MX0t/SLS3haX2BWh7ymRQSUkwoel6NHidyumOSRNDk8T4HuqqRW1QBTQARzpkT2OWvoH/3b2biGU480zVVJmMJ90Kqp3JYWHjE18w/NM1eL4fwHrTjQNTsxiSTKqZRelLeKXyWdY3riXHWkB6D9Ygi2d2g4NZKQujt3Vd5/26N/BGPMxNuZBcW9uyD4qicG7yfMJ6iF2tW3ij6h9cnn09LlNKn9Rx4lputYEqfJqXbS1fsK3lCzIs2YxxTmCkY0yvFuI+J/k8ApqfPe5tvFn1T5ZlX4/TmEhWsoX0JDP7yj0Y2tc/64edEs6E0aBgM6u4/WGgd8uXtAe1tha1jl2fJzqTgNbbwe4ffvhhr44X8UlCWi8cH9T8kXDbGmmDJaC1G7EQvWIjo3xfYB95BeuaNBzW9zB7u39a/fhRFPx9FXog0DZbVIh+lm7JZEbyPD5v/JBVta9xVfY3OwzOH+yCWgBdh6ZQA29Uv8Aox1jmplyAxWBFURTmplxARI+w172dTxvWsDjz6n6pY4rrXEY5x7HPvYO97h3UBCqpCVSyrmE1i9IuY8SxbahORVEU5qVeSFALcMC7lzer/8nlWddjM9gxqApj89vGFmqazqd7mxiVbSfTFaPdWLrgtBrx+E9c5KNnehLUBroFbf78+f1+jVMZjLPM4420tfZSe1Azq9bBF9AAbMlQ8jUaci+iZGQ+e7XRRMzdfwxCCRZqyqshEMCYk03y128YoGLFUDcpcQbDbIWEtCAt4Z7thjFYWAxWlmYtZ2HaYqyqnS89u1lR8TRV/raNzRVF4bzUi5iWNJuFaf2z7lm7BGMi01yzuT73uyzJXM4ox1hA6dDqdsi7H3e4pdvzqIrKovRLybMW0BRq4O3qFwlqwQ7H6IDdYmDdnib2V3qIl1WgxuU7GJF5+luSddf1KV2c4nRJS9ppMKvm+Fio9jQp2VO4KkunxRdmbKYLzdz9x6B+Zh45q/cCkHHnndFVv4Xob4qisCjtMkJ66KQzIgczRVEoco5nmG0kH9W/y0Hvfl6r+jsL0hZT5CxBVVSmJ3+1IGxQCxLRQ9gM/bN4tKIo5NqGkWsbRkgLRSdKBbQA79e+QVgPU2AbyfjEqeRaC7rssjQoRi7KuII3qv/RNinhhDF3BlVh8ogEkuxGth1qpcUbZvKItgVwYymlD2agdtWiJgFNnAkJaUPUuh37qd/7CXOK0ik1dT+bydYQQNE0LMXFJC5ZMkAVCtHGYrBioa2bU9d16oLVpz3jMV5ZDTYuTF/GrtYtbGvZQI41v9MxAS3A29UrCGlBlmQt7/eN6I+fya7pEcYlTGafeyeHfaUc9pXiMqZQkjiFIuf4Tj0KJtXM4oyrURVDl70NiqJQmGXHaTOw84ibcESPeUgrr/fT4g1Hu2VP1/FBLRhua1GTgCZOl3xqhqipyV4ud+3DroTAdPKPQSDFRtLmtu6XjH/7kSxcK2JG13VW1b7OK5XPU+E7Euty+pyiKJQkTuHa3O/gNLYtrhrRI2j6sdnXqKgYaAjV8UbVC3gjngGrzWawMytlIV/Pu40FaYtJM2fSFG7gk4b3WVnzapfPsRps0YAWiPjZ0bKpU9dmRpKFBeNTsJhUmjyhYwP3Y6OuNUh9a+jUB/ZAe1AzGRUJaOKMyCdniLJll+DRTHjrDlL2wzl4cxPQFNA49kdpGzsSsbQ1ttrPPRfH3LmxLFkMcYqikGnJQSPC2zUvUeUvj3VJ/aJ9vbKIHmFVzWt8WP8uut62j/DizKvItuTTEKrjtcq/0XqKMWJ9zagaKXaO56rsb7Is6wZGOcYyNmFi9PHD3lJ2tWwhqAWi9+m6zrs1r/BJw/tsaV7f6ZztXaZ7jnr4aGdjr5fB6CuRiI6hm5mZvWUyqKQ4zRLQxBmR7s6hymDCk1hMunsHppwEvnjimk6HKKEIueU6U9cEcH3ta3E1ZV4MTROTphPQ/Gxq/pS3qlewOPPqXm+fNFh4wq1UByrwaV4MGJiXemFbN2Lm1aysfZUy30Feq3yeSzOvIdmcOqC1KYpCljW3044Im5s/ozpQwaeNHzDSUcz4hKmkWTKZmTyPN6r/wfqmj3AYHRQ5x3c65/RRSXy+r4mPdjUwZ0xyp+2U+ps/pMXtYrti6JKIP4RlFE5BAc6tDVPYEsAVCDGh3susWg+TG3xMawkwvWQx2T//P9gmdP6mKkQsTHfNYXLSOYSOLfZ60LM/1iX1i0STi6VZy7GqNna7t7KxaR3QNlbs4owrKbQX4460srL21WiXaKzNTD6PUY6x6LrGXvcOXqz8K29UvUBQC3B+2hIUFD6se5cj3oOdnms0KJxb7CItwczHuwe+Rc3tj+C0SkgT8UVa0oay1FGEdAPGQ61MeauUlh3VaJEIqeePJmHKMDA5MaZNinWVQnSgKAozXfOwqFY+b/yQNXVvkmO97axaQ61dsjmNxZlX83rVC2xsXofd4GBc4mQMioHz05fgbExklGNMh+2ZYinHmk+ONR9/io+97u1sb9lEuf8I1YFKvpF3G3NTL2Bt/UpW1r7K5VnXdZoAYlAVZhYlcbDah9M2sIFpzpjkbheiPRsYjfH3I3/r1q2UlJTEuoy4FX9fMTFwDGa2pCyl+ok/M3LL7ujdVU98Qbm6Gec3v0H+5BYMSUkxLFKIzhRFYXLSTOwGBwrKWRnQ2mVYsrkoYxnvVL/Exw2rSDAlkW8bgaqozEpZED0unma+Wg02JiXNZHziNA549uLXfFgMVsYlTKYxWM+O1k28X/sm1+be1ClgqorCyKy2mauHa3xYTCpZyf2/7I9DWtFEHIqPX79EzIwtmUZVuPNikgYtgu/ppwl8+WUMqhKiZ4qcJYx2jove3tT0KbWBqhhW1D/ybSOYl3ohBsXYaa/Pdp80vM/Llc+yu3XbAFd3cgbFwGjnOCYkTuv0mDvczAd1b1PuO3LSBW2bvSE+29dERYO/X+ssrfSyYX9Tv15DiNMhLWlDlK7ruP1h1n/8FhObuv6m7k5NonpYEcPjbJ89IbpS4S9jQ9PHbGxax3TXHCYlzYybbsC+MCZhIvm2QhzGrtfxSjO37Q7wUf27eMKtTHPNjsv/t+MSJhPRw+zz7GL/sT8OQwIjHcWMS5hMkik5euyEggQURWH9/mZmjILc1P5pMa1sDGA9xc4rQsSCfCqHqIqjVXzyl/8P13/8J7ajrV0eY6lvpuaq8/h43RcDXJ0QvZdtyePc5AWAwvqmtbxe9QKtZ9lWUscHtBNbDMckTOCSjKswKiY2Nq9jVe3rhE7YkikeJJtTOS/tYr6Z/z3mplyAVbXhibSyreULAtpXLWY1gUqCepDxw5yMzrazYX8zbl/fTyYIhDTqWoLkpMhOKiL+SEgbgsIRnT0rf0/Gnz7G5NPpqqOhfUlHW60f849vwxuUjXJFfFMUhUlJM7gq5xskm9KoChxlRfnTHPaWxrq0PvdJ/fu8VPlMp9c2zF7I5VnX4TAkcMC7l1cqn6M51BijKrtnUS2MSZgYHUNnNzhJMLSNf9V1nXeqX+KvRx7h9aq/E0jcyfjiEA6roc/3+qxsDKCqSlxt9i5EOwlpQ9AXn7yJ9fXPMAaOfbPr6lOgfHW/rdrL6vvuGqjyhDgjqeYMrsr+JuMTphLUA7xX88opNwYfbLKOrQ23ruF9wlrHX6DSLVlcnfNNsi15NIbqaQnH71grg2LgwvRlZFvy8EbcvFf7KhE9QlALkGsrwKSaqQwcZUPTWt5v/hvPlP2RFw++yr7KvmshDYY0clMtMd+WSoiuyJi0IcizaxUpB+rabhgV6Oo3U4MC7W1sGqSv/gT+z0BVKMSZMapG5qSeT6YlB7/mi26zdLYotBeRZx3OUf8htrVsYKprVofHbQYHl2VdS6X/KHm2ghhV2TMm1cQlmVfzauVzVAWOsr5xLbNSFnB++hI0XaM2WEWZ7yBlvoPUBCpRDfXsOOwjEjFQlGOjOdxIijnttK9flNs/m9UL0RckpA1BhkNHMQRoay0DUBR09OjNr34v/yqo2ep8A1miEH1ilHNsh9u7W7eRbc3DZUqJUUV9Q1EUZqcsYkXFU2xu/pyxCROxGTqGDYNi6BDQdrRswhvxMMM1N+4mFJhVMxdmLOOlimfY1rKBTEsOhY4iVEUl05JDpiWH6a45+CM+vBEPbruDTaUtVAYPsF99lyxLHiUJkxnhKIpuq9UTzZ4QBlXBaZMfhSI+SXfnEKQ2Hwtcx32fjtC2Z2cY0Lv6VMTHguZCnLYqfzkf1b/LK5XPUek/GutyzliyOZUxCRMI66Eu98Q8ni/iZUPjWjY3f8YnDe/3+biuvuAypbAgbTEmxYw/4u3yGKvBRoo5jWHpNmaNcdHoCeBQE6kKHOX9ujd4/ujjbGle32Hv0O7sLHOzs8zdly9D9FI8LrAbTySkDUFK+4a/x32f1o0KEaOCblSgq7EZ8kkRg1yGJZvxCVMJaH7erPoHBzx7Y13SGZuSNAsDBna3biXYzUxOm8HOkmNbTO1s3czG5nUDWGXPFTqK+Eb+bYxLnHzKYzNdFq4omc4N+d9lQfIyss0FeCMePm/8kOeOPs4R74Funx8IadQ0B8lLO3sXQhaDn/zoHYJCacmELdDltM6T8KfZ+q0eIQaCqqjMTlnEucnziRBhZe1rbG/ZGOuyzojTmMB5aRdzVc63MKvmbo9Nt2SxOPPqtiU6mtaxt3XHAFXZO2b1q1mWEb37WeUGVUFVVAKN2XB0AXNt1zHKMRZ0SLNkRo/rquWwosGPQVXIklmdIo5JO+MQZJkwm8Dn+zEebIKIfmySQBd0PdrN6T1/VtfHCI4e7Zuus7y8vD45jzi5tmU6ZmI3OPmg7m3WNazGE27lnOT5cTdOq6eKnD3f9zDDks2F6ct4u2YFHzesJN2SSYo5vR+rOz1BLci6htX4Ih4WZ159yuPHFzgxqLDvoM7wjPOYPewCbMe2CvOG3bxd8yJTks5lhL0o+nU+Wu8nO1lmdYr4JiFtCJp+8XWs2/ox1oqNbRMIugpqut42UA3wp1tZ8JMHBrzOwSIrq2/2SgyHZS26gTLaOQ67wcF7Na+gnSUDLkNakMZQPRmW7G6PG2YfwbSk2WxsXsd+9y7OSZk/QBX2nEFROeItxad5aQzWk2xO7fZ4VVEoGZZAaoKZjaXNqApMGtEW0vZ7dlMXrGFl7WtkWLKZlbyQLGsuY3KdmI0S0ER8k+7OIcjidDHi8luov2QckfZuz7De8U97QEs2kfTo78HQfVeKEINNrq2Aa3JvZlbywkHbitYuEPHz3NHHeaf6pU7rpnVlqmsWS7Oui8uABmBQjJQkTgFgZ+vmHj8vK9nCwgmpjMlr25khGNaYmDidSzKuItmURk2gklernmdVzetY7T6SHKZ+qV+IviIhbYgaNnUuk7/7U3y3XkXTxCzCJ4ydDToNNC2dxvT3VlE8YUFMahSivzmNCdGAVheo5kv37hhXdHosBiuZllx8mpf9np2nPF5VVHKs+QNQ2ekb45wIwEHvvl7NRrVbDFhMKi3eMO9trqOyMUCBfSRfy/k281IvwqbaKfXu4e/lT1AfrOmv8oXoE9LdOUSpqkraqEkkZBXQcn4pnrL9aL5mVKMRR1YOiXnFWFLypAVNDAm+iJfXqv5ORA/jNCaSZc2NdUm9NilpBkd8pWxt3kCxc0KPNpfXdI197p1U+stYmH7pAFTZcw6jkyxLLlWBcqoDFb3+miTYDBRk2Fi/r5mZRZCTYmVcwiRGOcawYu8ajI4GUkxt4/E0XcMb8eA0JvTHSxHitElIG+IsThfpxdNIL54W61KEiBmbwc501xw+bVzDytpXuSbnJqyGwTWjOduSFw01+927KE4Yf8rnaHqEjU3rcEdaGOkYwzB74QBU2nPD7aOpCpRzyPtlr0OaoiiMH9bW7blhfzOzxihkJFnQIyZszVOYm+OKtqIe9n7JqtrXKbCPZJRjLMNshRhV6QoVsSfdnUIIAUxInEahvRhvxMPa+pVxueBrdxRFYYZrLgAbm9edcvkKAKNq4txj49I+a/wATY+vSRS51mEAeCOnt+Bse1DLT7NS29y2jlyLt+19OX48mk/zYlSMHPTuZ2Xta/y17FFW1rzGPvdO/BHZbUXEjoQ0IYSg7Qf6vNQLsRucHPDu5UvP4BuflmMbRq61gNZwM3vdPVsHrdBeTIY5m8ZQPQe8+/q5wt5JMadz87Afsij9stM+h6IoTClMpGRYW1dmqy+MxaRiNn71429cwmS+kX8756cvZbh9FBFd44B3L2vq3uKA96tFj4NacNCFdzG4SXenEEIcYzXYWJB2CW9Vr+CThvfJsQ7DYXTGuqxemZNyPuX+w9GB96eiKArTXLN5u+ZFNjWtY6S9OG5mu6qK2qOxdafS/np2l7lx+8NcPKXzhuwm1cwoxxhGOcYQ1IIc9R3ksLeUAtvI6DEra17BHWml0F5MoaOYFFNa3LxX4uwkIU0IIY6TbxvBWOckInoYozL4vkUmm1NPua7YifJtI0g3Z1EbrOKo/xD5thH9VF3v6bpOWA+hKoZebZ7eldQEE3vKPeSmBshJOfl2UGbVTKGjLYi103QNX8RLU6iBTc2fsqn5U1ymFArtxYx0FJMsgU30A+nuFEKIE8xNvYCF6ZdiMQzufR2P+g6zofHjUx6nKArjEiZjU+1xNwZrZe1r/OXIg9QFqs/4XBkuC0l2Ixv2NxMM9278naqofC33Rq7JuYlpSbNJNqVGA9uLFX/t8abuQvTG4Ps1UQgh+tnxXWyt4RYUlEG3PENIC/J+7ev4NR8JxiTGJEzo9vjRznGMdo4749aqvtb+tYi0r7B9hlITTbT4wuwt9zChoPdf0xRzGinmNKYnz6EhWMcBz15CejAa6D3hVj6oe4eJSdPJsw6X1jVxRiSkCSHESVT7K3ir+p+kW7K4LPPaQfUD16SaWZh2Ke/UvMRH9e9iNdgYbh910uPjLZz1F7NBxW42kNtNd2dPtQe245V69nLUf4ij/kOkmNKY6ppFYRyN8xODi3R3CiHESaSY07EZHJT7j/BF0yexLqfXhtkLmZ96CTo6q2peo8Jf1u3xET1Chb+MA574muXZl0xGBV3XSUkw9ctMzZLEKSxMu5RUcwYNoTpW1b7Oa1V/ozZQ1efXEmc/CWlCCHESJtXEBelLMSomNjV/Oii3jSpOGM85yfOJEOHd6pe6HdsV0oK8XvV3PmlYFTdLTejH1m5T6JuWKIfVCAo0e0O8s6kOX6BvulHbGRQDRc4Srs7+FoszrsZlSqUqUM5Llc9Q4TvSp9cSZz8JaUII0Y00SyaL0trW6fqg7m2O+g7FtqDTMDlpJpMSZxDUg91uWG412Eg2peKNePBGPANY4ckFtbZFaM1q32xRl51s4eIp6STYjCgKHKjun4kSiqIwzF7I13K+zeyURQyzFZJlzeuXa4mzl4Q0IYQ4hRGO0cxKXkCECG9Xv0SVvzzWJfXaOcnzmZ96CfNSL+r2uCRTCgDN4caBKOuU2ndOMCuWvjunphMK6xRm2jlU40XT+q/V0KAYmJA4jUsyropOgmgI1vbJbFVx9pOJA0II0QMTk2YACmW+A6SZM2NdTq8pitJhhqcv4sGsWjtNGEgyJgPQEmokx5o/oDV25fLs64noEdQ+bFP4bG8TDouB4jwHO8vc1DQHyUruuxDYlfaJA76IhzerVxDWglyceVVcvMcifklLmhBC9NDEpOkszvwaRrXt99v6YA2e8OntKxlL9cEaXqx4hs8aPuz0WKLJBUBLuHmgyzopg2Lo09mRKU4TNc1BrCaV4Rm2AR1/Z1XtjHaMI6gHeavqnxz07B+wa4vBR0KaEEL0QnuXVUAL8G7NK6yoeIpdrVvibnPy7hgVEyEtyI7WjRzw7O3wmNPQtnaYJ9wai9I6CGlBAhF/n583O8WCJxChxRtmSmEi2X2wHEdPKYrCuSnzOffYZI6Vta+yp3XbgF1fDC4S0oQQ4jSoKORaC/BrPtbWr2RFxdMc9OwfFGEtyZTMgrTFAHxY9w7NocYOj42wF5FhyY5VeVEHvPt4uuwRNjV91qfnTbIbsVsMVDQE0HWd8no/rb5wn17jVCYlzWRh+9eg/l32tG4f0OuLwUFCmhBCnAaTamZ+2sUsy7qBDEs2jaE63qt9hRfKn2Cfe2esyzulEY7RTEycTlAPsqburWi4TDIlc1HGMkoSp8S4Qqjwl6Gjk3SsC7avKIrC6Gz7sRmeCrvK3JTV9X2L3akUOcdzYfrlKCjsaN00KAK+GFgS0oQQ4gxkWXO5IuvrXJi+jExLDi3hJryRr8ap+SO+uP3hOzP5PFJMaVQHKtjRsjHW5XSg6zrlvsMAZPfD4PrCLDt5aW3dnJkuCzVNsdl7c4SjiIszrmRJ5rUdtiMTAmSMwCGMAAAgAElEQVR2pxBCnDFFUSh0FFHoKKI6UIHLmBJ97KP6d6kNVDHaWUKxczxJpuQYVtqRQTGwIO1SXq58hv2e3YxPnIaqqBzxHiCoBxnlGBOz2qoC5XgirWSYs7EbHP1yjZrmAI3uMJkuM6VVXgIhDYtp4INSgX1k9N8hLUhLuIlUc8aA1yHij4Q0IYToQ5mWnOi/dV0noAVwR1rZ3PwZm5s/I8uSS5FzPCMdxZjV/l32oSfSLZksybyWTGtutCVnTd1bBDR/TENae5fxaOe4fruGP6ix56ibi6akoSpQ3RRgWLqt3653KmEtxBvV/6Al1MRVOd8iwZgYs1pEfJCQJoQQ/URRFJZmLac51Mg+9072uXdQFSinKlDOpw2r+Ub+7XER1HJswzrcVhUVHR1d12OyMbgn3Mo+906MipGR/RgUc1KsbD3USmVDgHOLXbgcpn67Vk8YFCMppnRqApW8V/MKy7JuiC730hfC4YGdHCHOnIQ0IYToZ0mmZGYkz2W6aw7l/iPsc+8grIejAS0Q8bO9dSNjnBNwxrD1pDZQzYamtaC3BTMdvc/2zOwNTdcYbh+F05iAzWDvt+sYDQr5aVYO1fhYOCElJoH0eIqiMDf1fBqCtdQEK/mi6RPOTZkf05pEbElIE0KIAaIoCnm2AvJsBR0WUN3v2cXGpnVsavqUfNsIxjgnMsxe2Gk3gP62veULynwHMSqxbVFKMCVxYcblA7LIbEG6jcM1PryBCFsPtTIszRadUBALBsXI+elL+GfFU2xr2cAIx+gOXehiaJGpJEIIEQPHt9rk20YwMXE6FtXKEd8B3qt9heePPs76xrW0DuDK/7NSFmBRrYT1UFuNA9yKput6h8VrB6Jly+Uwcum0dBxWI6qicLR+4JfiOFGiycU5yeeho/NB3TuENemmHKokpAkhRIwlmZKZlbKQb+TfxvnpS8m1DsMb8bC5+TOq/RXR4/q7ZclmcDDDNXfArneiA969/K38fzng2Tdg11QUBZNRxe0Pk51spropQCgc+yVTShKmkG3JJ6gF4mazezHwpLtTCCHihEExMsoxhlGOMdHJBsPto6OPv171Ak5jAqMc48izFfTLulpjEyaxvmktQS3Afu8uip3j+/waXQlE/HxS/z4BzT/g3a3hiMbqbfVMKGjbEquqKUB+WuxmeUJbeDw/fQlm1YxJNce0FhE7EtKEECIOtU82aOcJu6kJVFAZiLDfswubamekYwzjEiaRbE7rs+uqispF6VfwRvULbGr6lNGOcQOyyOpnjR/g07yMcoxlmH1Ev1/veEaDSnaylbI6PzkpVvzB2LekATiMzliXIGJMujuFEGIQcBidfDP/e8xPvZgc6zB8mpcdrZv4R8WTrKx5rU+7JnNtw8i1FpBjzSd0bHxafyr3HWaPezsW1crslIX9fr2uDM+wUd8aYmyeg9E5/bN47umqDVTxfu0beCOeWJciBpi0pAkhxCBhMVgZkzCRMQkTcYdb2efewY6WTVgNtj4bZK/rOuX+w0xLmk22La9PztkdX8TL6rq3AJidshBbP+0ucCppiSZMRoWa5iAoEInoJMV43bR2e907+NKzm0Sjq0Prqjj7xV1Ie+aZZ3juuecwmUwYDAZeeeWVWJckhBBxx2lMYKprFhMTZxDRv5r9t6npUyJ6hClJ557WQqgaGm9W/xOnIYGv59/WlyV3aVfrFrwRNyMdYxjtKOn3652MoiiMH5ZAos3IriNuQhGdOWPjYwuvCYnT2Nm6mV2tW5nmmi17fA4hcRXS3nvvPd555x1WrFiB0+mktrY21iUJIURcM6pGjMe+lYe0ENtaviCg+Sn17OG81Is67SZwKu2bwSuKii/iZUfLJgyKgamuWX1eO8DUpFlYVRujnONivpjs8Iy2yQL5YRuf7W3CF4xgMw/sWnVdSTIlk2MdRoX/COX+w+TbBnbMnoiduIrjf/nLX7jjjjtwOtsGS6anp8e4IiGEGDxMqokrs79BjnUYzeFGXq9+gQ/q3sEf8fX4HO2tNLquoekam5s/Y3vLRiJ6pE9rbV8PTVEUShKnYImD7bEims72w63YzSpmo8LRutivmdaufXusgVyeRMReXIW00tJStm7dynXXXcdVV13FP/7xj1iXJIQQg0qSKZklmdeyIG0xFtXKXvd2Xij/C4e8X/bo+eqxHwsRPYLD6CTXOgy/5uOo71Cf1KfrOp83fsTfy/9Mlb+8T87ZV1QFjtT6qGsNkZ9m5UgchbRhx1rPKv1lMa5EDKQB7e688sorqaio6PKxdevWEYlEqKys5Pnnn6exsZHrr7+eESNGMGPGjIEsUwghBjVFUSh2jmeYrZBPG9aw37OrV881YIiOcxvlHMdR/2G+9OymwD7yjOoKRPx8VP8eB7x7MSnm6M4G8UJRFFITzDS0Bhmb5yQ7WYvZJvMnchoTSTAm0RxuxBvxYI/RBAsxsAY0pL388svdPp6Tk8OSJUtQVZXU1FRmz57Ntm3bJKQJIcRpsBnsLEq/jAmJ00gzZwJtLVlbW9ZT7Jxw0s3LrQY7nkgrET3MCPtoPuI9DntLieiR095P9KjvEB/UvY0n4sZhcLI482pSzRmn/dr6S2qCidIqL06bEWds17PtZGHapdgNDmxq/206L+JLXHV3LlmyhLVr1wLg9XrZuHEjY8aMiXFVQggxuKVbsqKtQaWePW3djUf/zLbmL7oca5ZlzSXXWkBIC2FWLeRY8wjpwdPqntR0jTW1b/Fm9T/xRNwU2ov4Ws6NcRnQAFISTPiCGt5AhOqmAGt3NQz49lgnk23NI8mUHBcte2JgxNXszhtvvJF7772Xyy67DIBly5YxZ86cGFclhBBnj1xbAWOcE9nj3sanjWvY3rKRqa5ZFDlLoq1kF6Qv7fCcfFshR/2HOeI7QG4PZ4u2dxOqioqGdmyh2kWMdsR+Fmd3kh0mzp+Yis2sEo4YqGsJ0eAOkZogWzOJgafo8fIrQh84evQo559/PocPHyYc/mrdoOP/LUQ7o7Hr31Hk8yKGgtpANZ83fki5/zAAdoODC9MvJ8vaeQFbf8SHO9xCsjkVg3Ly3+0jeoRy3xH2uLeSbs5miuscALxhNwbFiMVg7Z8X048+2F5Pot3I1JFJsS4FT7iV92peJcGYxAUZS0/9BBF3Tvy5YzQaKSgo4P333ycvr/P/vbhqSRNCCDEw0i2ZLMm6lkr/UTY1raMyUE6SKQWAiB5mc9PnOIwJjHQUYzXYsBo6D9DSdI3GUB01gUqq/OUc9pUS0NpmRDaHGpmcNBNFUbAPsj0oD9f4KKvzM3dcMgUZNrYfdjOhQMNkjO0IIaNioiZYSVAPxLQOMXAkpAkhxBCWbc3jsqxr8UU80YkE1f4KNjavA+Cj+nfbBqsbHBgVI4kGF4sy2oakeCMeVlQ8HT2XgkKedTgjHWMY6RgT192a3TGbVGpbgoTCGnlpVg5W+/AEIrhiHNLMqgWVtkWGxdAgIU2I42zdujXWJQgRE8fvmZloSkalbSyZ05CIO9IS3dy7ntrjnmMny5JLuiWLDEsOudZhJ50xOpikJZhQFKhtCZKTYmXhhJS4CJyKomBSzYS0YKxLEQNEQpoQQogOnMYEcm0FlPkOsjD9UjLM2XzSsIo97u1MT54dnRRgUAwsy74h1uX2OZNRJTXBRFVjgJwUK4qiUNcSxOOPUJAR23U5VFR0zpqh5OIU4moJDiGEEPEhx5oPQLnvMEbViNOYCLSNi4qHVqX+lp1sIRz5Kgw1ukNsPdSKP9i322P1lqK0hbSzaM6f6IaENCGEEJ3kWYcDRLeDsqhtMzP9Ws/3AR3MRmU7mFnkit4uzLJjNansKnPHsCrgWCuatKYNDdLdKYQQopNUcwY21U5NsBJfxIv52AboQW3ozCwMhDT8wQhJDhMGVaGkwMn6fc0Mz7ST4jTFpKYlmdcS0PyoirSxDAUS0oQQQnSiKArjEicT0kJounZcSBs6g9b3HHXT6A6xYEIqADnJFjJdZhpaQzELacnmtJhcV8SGhDQhhBBdmu76aseX5vDQa0nLSbFyoNqHNxDBbjGgKAqzil1DYkyeiA/SXiqEEOKU0s2ZXJNzI3NTz491KQMmNdGExaRSXu+P3qcoCuGIxuYDLXj8AzuJoMx3kBcrnmZny+YBva6IHQlpQgghTqrSf5S19StpDbfgNCbREmoZMl2eqqKQk2Lh6HEhrf3+Jk+ITaXNAzrLsiFYS12wZki1Zg51EtKEEEKc1FHfIXa1bqHUs4cafwVBzX/s76ER1Aoz7YzOcXQIY6qqMG1kEg3uEAeqB262a1WgAoBUc+aAXVPEloQ0IYQQJzXMXghAqXsPHzesYl3jGjS0IRPUEu1G8lKt0XFooYhGgzuIzaIyJs/JziOtuH3hfq0hqAWp8lVQ6S9DQSHLmtuv1xP948MPP+z1cySkCSGEOCmXMRUTZpojjTSHG3GHW2gNNQ+poNbqC/PB9no8gTANrSFCYZ2G1hDDM63kplq7XLGsPcyFItoZXTuoBanxV1Afqiag+UkzZ2JWzWd0TjF4SEgTQgjRpaAWpDZQSbolC2jbkkjTIyiKOqSCms1swO2PsK/cg6oomI1q27g0d5iJwxNIsBkJhb8KY6GI1iHMnW5Qaw9oqmKgMVQHQKLRdda/3+IrEtKEEEJ00h4QNLTollA6bSvdG1XjkApqOjppiWaqm4IYjv3UNBoUVEWhoTWExx/mvS11lDf4owHt+DB3OkHt+IBmUk3UB9s2ts+xDjvr32/xFQlpQgghOjg+oLWGmkkxtS2gqqMBbWOzhkpQaw9d2ckWfEGNJs9X48/ag5rbHyE3xcqm0hYq6v2oioLRoHQ4pjdB7cSABjAreSGL0i4jzZyBqhjO2vdbdCQhTQghRNSJAU1RVGxGO2OdkzBg4PhlXM/2oHZ8q1ii3Uh6oolAqGPQag9haYlGLEaFfRVeTlzrtjdBrauABm3rs7lMKSiKgkk1SVAbIiSkCSGEiGoM1hPSQ9GAZlTbNqbJsuYyxXUuU5LO7XD88UEtpIdoDNbHouw+d3xAa28VKxmWQFaypfPBio43qJGTYsEfjFDR4O90SE+CWlcBTdd1agKVaHrH50hQGxokpAkhhIhyGhNoCjYQQYsGtHYJxiQSTa5OzzGqRiJoNAUbcBoTBqrUftNVQDuZsKbR4g1jUlUcViMjs+1kuboIcnQf1E7WgqahUResZmvLhk7nk6B29pOQJoQQIsodbsVlSkZFIaz1bP2vsBZGRcFlSsYdbu3nCvtf67F1z3oa0FQUDAYFg6pgMap4gxpH6/0cret5i1pjsB4dvUNAAzAoBsYlTGZK0jld1mBSTejoZ00LpuhIQpoQQoioZHMqJtVMotGFpkdOGdTCWhhNj5BodGFSzSSbUweo0v6TYGtrQQxHut/yyRto27vTcCzMRTQdUHBYDJgMCi6nscvntYe/1uMWwU02p6KgENJCvao1pIVQUM6K9110JiFNCCFElFk1k2HNQVXUUwa14wOaqqhkWHPOioVWTQaVlAQTmq53G9TsFgMAkYhORNPRtLYdCowGhUyXBae165DWfs72MAhfve+aHulxUAtpITQ9cta876IzCWlCCCE66ElQO1sDWrueBDWjqpJoNxLSNEJhPRrQuhOO6Gi6TkqCCZOh44/g3gQ1CWhDg4Q0IYQQnXQX1M72gNauRy1quoLTasBpNZzyfN0FtHY9CWoS0IYOCWlCCCG61FVQC2qBIRHQ2nUX1NpDV3qShXSXudsw15OA1q67oCYBbWiRkCaEEOKkTgxqJsU8ZAJau66C2omhqydhricBrV1XQU0C2tAjIU0IIUS3jg9qdoNjSAW0dseHsGBY6zJ09STM9cbxQc0f8UlAG4IkpAkhhDil9sBgVq1DNii0hzCTUTlp6OpJmOsNed+Htq7nBwshhBAnMKtmMq3ZsS4jpkwGlRRn90GpPai1+sIk2IynHdDayfs+dElIE0IIIfpYT8KcEKci3Z1CCCGEEHFIQpoQQgghRBySkCaEEEIIEYckpAkhhBBCxCEJaUIIIYQQcUhCmhBCCCFEHJKQJoQQQggRh4bEOmlGY/+9zK1bt/bbuQeb/nyfB9LevXvP+BxVVVV9UMnZYf78+bEuQQghBqWz46dqDE2aNCnWJYg+JF9PIYQQ8UK6O4UQQggh4pCENCGEEEKIOCQhTQghhBAiDp1VY9IikQgABoMhxpUIIYQQQnSvPa+055cTnVUhrba2FoC8vLwYVyKEEEII0TO1tbUUFBR0ul/RdV2PQT39wu/3s2PHDtLT06U1TQghhBBxLRKJUFtby/jx47FarZ0eP6tCmhBCCCHE2UImDgghhBBCxCEJaUIIIYQQcUhCmhBCCCFEHJKQJoQQQggRhySkCSGEEELEIQlpQgghhBBxSEKaEEIIIUQcGjIh7ZlnnuGSSy5h6dKlXHHFFbEuZ1D4/PPPGTt2LM8++2ysS4lrP//5z7nkkku4/PLLue6669i+fXusS4o7Bw8eZPny5Vx88cUsX76cQ4cOxbqkuNXY2Mh3v/tdLr74YpYuXcodd9xBQ0NDrMuKe4888gjFxcXs27cv1qXEvUAgwM9+9jMuuugili5dyr333hvrkuLWmjVruOKKK1i2bBlLly7lvffeG9Drn1XbQp3Me++9xzvvvMOKFStwOp3R7aPEybndbn77299y3nnnxbqUuHfeeefx4x//GJPJxJo1a7jrrrtYtWpVrMuKKz/72c+44YYbWLZsGa+++io//elP+etf/xrrsuKSoij8y7/8C+eccw4A999/P7/97W+57777YlxZ/Nq5cydbtmwhJycn1qUMCv/zP/+DxWLh3XffRVEU6urqYl1SXNJ1nf/4j//gueeeo6ioiD179nD99ddzwQUXoKoD08Y1JFrS/vKXv3DHHXfgdDoBSE9Pj3FF8e/Xv/413/nOd0hOTo51KXFv4cKFmEwmACZPnkxVVRWapsW4qvhRX1/Prl27WLJkCQBLlixh165d0jp0Ei6XKxrQoO0zVVFREcOK4lswGOQXv/gFP/vZz1AUJdblxD2Px8Mrr7zCnXfeGX2/0tLSYlxV/FJVldbWVgBaW1vJyMgYsIAGQ6QlrbS0lK1bt/Lggw8SDAa57rrruPbaa2NdVtz68MMPaWlp4ZJLLuGDDz6IdTmDynPPPceCBQsG9D9xvKusrCQzMzO6n67BYCAjI4PKykpSUlJiXF180zSNv/3tbyxatCjWpcStBx98kMsvv5z8/PxYlzIolJWV4XK5eOSRR/j8889xOBzceeedTJ8+PdalxR1FUfjDH/7A9773Pex2Ox6Ph8cff3xAazgrQtqVV1550t80161bRyQSobKykueff57Gxkauv/56RowYwYwZMwa40vjQ3fv1zjvv8Lvf/Y4nn3xygKuKX6f6fLWHjzfffJPXX3+d5557biDLE2exX/7yl9jtdr7xjW/EupS4tHnzZrZv386//du/xbqUQSMcDlNWVsa4ceO4++672bp1K7fddhsrV66M9jaJNuFwmMcff5w//vGPTJs2jY0bN3LXXXfx5ptv4nA4BqSGsyKkvfzyy90+npOTw5IlS1BVldTUVGbPns22bduGbEjr7v364osvqK2t5ZprrgHaBjGvWbOGpqYm7rjjjoEqMa6c6vMFsHLlSh544AGeeuop6To4QXZ2NtXV1UQiEQwGA5FIhJqaGrKzs2NdWly7//77OXz4MI899pi0zJ7Ehg0bOHDgAOeffz4AVVVVfOc73+FXv/oVc+fOjXF18SknJwej0RgdfjBp0iSSk5M5ePAgEyZMiHF18WX37t3U1NQwbdo0AKZNm4bNZqO0tJSJEycOSA1D4n/+kiVLWLt2LQBer5eNGzcyZsyYGFcVn6ZPn86nn37K6tWrWb16NRdffDHf//73h2xA64k1a9bwq1/9iieeeIK8vLxYlxN3UlNTGTt2LG+88QYAb7zxBmPHjpWuzm488MAD7Nixg0cffRSz2RzrcuLWLbfcwscffxz9fpWVlcUTTzwhAa0bKSkpnHPOOXzyySdA28zr+vp6CgoKYlxZ/MnKyqKqqooDBw4AbUOn6urqGDZs2IDVoOi6rg/Y1WLE7/dz7733smvXLgCWLVvGLbfcEuOqBod77rmH8ePHS3dLN84991xMJlOH0PHUU0/JpIvjlJaWcs8999DS0kJiYiL3338/hYWFsS4rLu3fv58lS5YwfPhwrFYrAHl5eTz66KMxriz+LVq0iMcee4yioqJYlxLXysrK+PGPf0xTUxNGo5Ef/vCHzJ8/P9ZlxaXXXnuN//3f/41OsvjBD37ABRdcMGDXHxIhTQghhBBisBkS3Z1CCCGEEIONhDQhhBBCiDgkIU0IIYQQIg5JSBNCCCGEiEMS0oQQQggh4pCENCGEEEKIOCQhTYgh7M4772TmzJnU1tZ2uD8SiXDVVVdx0UUX4ff7T/v8H374IbfeeiuzZs2ipKSE2bNnR7egiRcPP/wwxcXFHe4rLi7m4Ycf7rdrfv755zz88MNomtZv1zgZr9fL3Llzeffdd/vkfH6/n7lz5/L222/3yfmEEF+RkCbEEPbTn/4URVH4+c9/3uH+J554gl27dvHf//3f0QVVe+vXv/41t9xyCxaLhXvvvZennnqKe++9l8TERH74wx+yZ8+evngJ/eKFF16Ibo3WH9avX88jjzwSk5D2l7/8heTkZC666KI+OZ/VauVf/uVf+P3vf08oFOqTcwoh2khIE2IIS01N5T//8z9ZuXJltCXk4MGDPPLIIyxfvpyZM2ee1nlfffVVnnzySe6++24eeughLr30UmbMmMHixYv5zW9+wwsvvEBiYmJfvpSTikQihMPhXj1n8uTJZGVl9VNFsRMMBnn22We57rrroiuo94Urr7ySysrKuGohFeJsICFNiCHuiiuuYN68efzyl7+koaGB//qv/yIlJYV///d/P+1zPv744xQVFXHzzTd3+fj48ePJycmJ3v7oo49Yvnw5EydOZNq0aXzve9+L7pfXTtd1nnrqKS6++GLGjx/P3Llz+cUvfoHb7e5wXHFxMQ888AB/+tOfWLRoEePHj2ffvn0A7Nq1ixtuuIEJEyYwb948Hn30UbradOXE7s72LtFDhw5xyy23MGXKFBYuXNipNSwQCHDfffexZMkSpkyZwpw5c7jtttsoLS3tcK5HHnkEgJKSEoqLizt0t/p8Pv7nf/4nWvuiRYv4f//v/3W4jsfj4Ze//CULFixg/PjxzJ49mxtvvLHDdbqyatUqmpubWbx4cYf777nnHs477zy2b9/Oddddx8SJE7n44ov54IMPAHjyySdZtGgRU6dO5fbbb6ehoaHD85OSkpg7dy4rVqzo9vpCiN4xxroAIUTs/eIXv+Cyyy7j2muvpaysjD/96U84nc7TOld1dTWlpaXceuutPTr+o48+4tZbb+Xcc8/lgQcewOv18tBDD3HDDTfw6quvkpmZCbRtOv7444/z9a9/nYULF1JaWsqDDz7Inj17ePbZZ1HVr37nfOmll8jPz+fuu+/GZrORkZFBQ0MD3/72t0lLS+P+++/HbDbz5z//mcrKyh6/tjvuuIOrrrqKG2+8kdWrV/Pwww+TnZ3N1VdfDbS1VHk8Hm6//XbS09Npbm7m+eefZ/ny5bz99tukp6dzzTXXUFVVxYoVK3j++ecxGAzR84fDYb7zne9QWlrK7bffTnFxMVu2bOGPf/wjzc3N3HPPPQD86le/YvXq1dx1110MHz6cpqYmNm3aRGtra7f1r127lpEjR3a5ub3b7ebuu+/m5ptvJiMjg8cee4zvf//7fP3rX+fQoUP89Kc/pa6ujvvuu4+f//znPPjggx2eP2PGDB544AECgQAWi6XH76kQohu6EELouv7b3/5WLyoq0u+4444zOs+WLVv0oqIi/W9/+1uPjr/yyiv1Cy+8UA+FQtH7jhw5oo8bN06/7777dF3X9cbGRn38+PH63Xff3eG5r7zyil5UVKSvWrUqel9RUZE+Z84c3efzdTj297//vV5SUqKXl5dH7/N4PPrMmTP1oqKiDscWFRXpDz30UPT2Qw89pBcVFekrVqzocNySJUv0m2666aSvLRwO616vV588ebL+5JNPdjrf8a9Z13X95Zdf1ouKivT169d3uP+Pf/yjXlJSotfV1em6ruuXXXZZ9L3pjUsuuUT/13/9107333333Z2uu3v3br2oqEi/6KKL9HA4HL3/vvvu08eNG9fhPl3X9XXr1ulFRUX6xo0be12XEKJr0t0phMDtdvPqq6+iKArbt2/v1IWo6zrhcLjDn77g9XrZtWsXixcvxmj8qmE/Pz+fqVOnsmHDBgC2bt1KMBjk8ssv7/D8yy67DKPRGD2u3bx58zpNeNi8eTOTJk3q0M1qt9tZtGhRj+tdsGBBh9ujR4+moqKiw31vvfUW11xzDdOnT2fcuHFMnjwZr9fbqfu2K2vXriU3N5cpU6Z0eK/nzJlDKBRiy5YtAEyYMIGXX36Zxx57jO3btxOJRHpUf01NTZetaND2XsyYMSN6u7CwEIDZs2d3aO0rLCwkHA53mhGcnJwcvYYQom9Id6cQgt/85je0tLTw+OOPc8cdd/D73/+en/70p9HH169fz7e+9a0Oz9m7d2+X52ofcH9ieOlKS0sLuq6TkZHR6bG0tDTKy8sBaGpqAiA9Pb3DMUajEZfLRXNzc4f7uzpfbW0to0eP7nR/amrqKetsl5SU1OG22WwmGAxGb7d3QV555ZXccccdJCcnoygKt9xyS4fjTqahoYHy8nJKSkq6fLz9ffjJT35CWloaL774Ig888AAul4tly5Zx1113YbPZTnr+QCCA2Wzu8rGEhIROrw3oNMHDZDJFz3W89lB8Jku2CCE6kpAmxBC3fv16/vGPf3DPPfcwf/58br/9dmMPktAAAAR2SURBVB566CGWLFnC1KlTgbYB7j0dFJ6ZmcnIkSNZs2YN//qv/9rtsYmJiSiK0qlVBqCurg6XywUQ/buurq5D0AqHwzQ1NUUf7056ejr19fWd7u/qvtP15ptvUlBQwK9//evofaFQqFOIPBmXy0VeXh5/+MMfunw8NzcXAIfDwY9+9CN+9KMfUV5ezrvvvsvvfvc7TCZTtxM+XC4XLS0tvXhFPdf+Gttb1IQQZ066O4UYwvx+Pz/5yU+YMGFCtKXsu9/9LqNHj+YnP/lJtPXH6XQyYcKEDn+6c+utt7Jv3z6efPLJLh/ftWsXFRUV2O12SkpKeOeddzp02ZWXl7N58+boEiCTJk3CbDbz5ptvdjjPW2+9RTgc7tBNdzJTpkxh69atHSYKeL1eVq9efcrn9pTf7+/QNQhty5Gc2B3Z3kp1YqvTvHnzqKqqwm63d3q/J0yY0GVXZW5uLjfffDNFRUXs37+/2/oKCwspKys7nZd2SkePHo1eQwjRN6QlTYgh7MEHH6SiooKHH344OjvSZDLxf//v/2X58uU89thj/OAHP+j1eZctW8auXbv49a9/zebNm1m8eHG0JeuDDz7gtdde48UXXyQnJ4c777yTW2+9lVtvvZUbbrgBr9fLww8/jNPp5KabbgLaWoBuuukmHn/8cWw2G/Pnz6e0tJQ//OEPTJs2rdNYsa58+9vf5vnnn+fmm2/m+9//fnR25+ku1tuVefPmsWrVKu677z4WLlzIjh07eOaZZzp1GY4cORJoW9rivPPOQ1VVJkyYwNKlS3nppZe48cYbufnmmxkzZgzBYJCysjJWr17No48+is1mY/ny5SxatIiioiLsdjsbNmxgz549XHHFFd3WN2PGDJ5++mk0TeswG7YvbN26lczMTPLz8/v0vEIMZRLShBiitm/fztNP///t3a+r8lAYB/DvG1YsjvUJNg1qUAwG0aiWpTEErRbDREQWDfsLdKAHBN+gY8EkaLZbjHZFzCbDuG+T997r5f5gYVy/n3x4OKd94Xl4zl+0Wq133yKl02k0m00IIVCpVB7Ocn3GsiwUCgXM53MMBgNcr1dEo1FkMhkMh0MkEgkAQLFYxGQygeM4ME0TkiQhn8+j1+vd128AQKfTgaIocF0XrutClmVomoZut/ulwKEoCmazGWzbRr/fhyzLMAwDvu/DcZxvv+8RXddxPp+xXC7heR5SqRTG4zHa7farc+VyGfV6HYvF4r6r7XA4QJIkTKdTCCHgeR6OxyMikQhUVUWpVLrPg+VyOWw2Gwgh4Ps+VFWFZVnv5gbfqlarGI1G2O12P15U/JHtdotarRZoTaJn9+fl5cEmRyIi+pUajQZisRhs2w6s5n6/h2EYWK/XiMfjgdUlenacSSMieiKmaWK1WuFyuQRWUwgBTdMY0IgCxnYnEdETyWazsCwLp9PpVTv5p263G5LJJHRdD+B2RPQ/tjuJiIiIQojtTiIiIqIQYkgjIiIiCiGGNCIiIqIQYkgjIiIiCiGGNCIiIqIQ+gfxcRVzYJmg3gAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "img = plt.imread(\"background_env3.png\")\n",
    "ax.imshow(img, extent=[-6.1, 8.6, -7.3, 3.3])\n",
    "\n",
    "ax.set_xlabel('X- Coordinates (m)', fontsize=16)\n",
    "ax.set_ylabel('Y- Coordinates (m)', fontsize=16)\n",
    "\n",
    "ax.set_xlim([-6.1, 8.6])\n",
    "ax.set_ylim([-7.3, 3.3])\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(120)\n",
    "\n",
    "thickness = 1.0\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(trajectories.items()):\n",
    "    line = None\n",
    "    for run_key, run_value in checkpoint_value.items():\n",
    "        x_s = [e[0] for e in run_value]\n",
    "        y_s = [e[1] for e in run_value]\n",
    "        starting_point = (x_s[0], y_s[0])\n",
    "        ending_point = (x_s[-1], y_s[-1])\n",
    "        ax.plot(*starting_point, marker='o', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        ax.plot(*ending_point, marker='D', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        line, = ax.plot(x_s, y_s, linestyle='dashed', linewidth=thickness, c=cmap(i * 10))\n",
    "    line.set_label('Episodes played: {}'.format(int(checkpoints[i]*30.5305)))\n",
    "    thickness += 0.3\n",
    "\n",
    "ending_point = plt.Circle((0., 0.), 0.1, alpha=0.5, color='black')\n",
    "ax.add_patch(ending_point)\n",
    "ending_tolerance = plt.Circle((0., 0.), 0.8, alpha=0.2, color='black')\n",
    "ax.add_patch(ending_tolerance)\n",
    "\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(success_rate.items()):\n",
    "    results = 0.0\n",
    "    for _, success in checkpoint_value.items():\n",
    "        results += int(success)\n",
    "    print('Episode: {}, Success Rate: {:10.2f}%'.format(int(checkpoints[i]*30.1658), (results/15.)*100.))\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('training_traj_train.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 30, Success Rate:       0.00%\n",
      "Episode: 1206, Success Rate:      26.67%\n",
      "Episode: 2413, Success Rate:      20.00%\n",
      "Episode: 3619, Success Rate:      40.00%\n",
      "Episode: 4947, Success Rate:      13.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "img = plt.imread(\"background_env4.png\")\n",
    "ax.imshow(img, extent=[-6.1, 2.0, -13.7, -5.0])\n",
    "\n",
    "ax.set_xlabel('X- Coordinates (m)', fontsize=16)\n",
    "ax.set_ylabel('Y- Coordinates (m)', fontsize=16)\n",
    "\n",
    "#ax.set_xlim([-6.1, 8.6])\n",
    "#ax.set_ylim([-7.3, 3.3])\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(120)\n",
    "\n",
    "thickness = 1.0\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(trajectories.items()):\n",
    "    line = None\n",
    "    for run_key, run_value in checkpoint_value.items():\n",
    "        x_s = [e[0] for e in run_value]\n",
    "        y_s = [e[1] for e in run_value]\n",
    "        starting_point = (x_s[0], y_s[0])\n",
    "        ending_point = (x_s[-1], y_s[-1])\n",
    "        ax.plot(*starting_point, marker='o', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        ax.plot(*ending_point, marker='D', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        line, = ax.plot(x_s, y_s, linestyle='dashed', linewidth=thickness, c=cmap(i * 10))\n",
    "    line.set_label('Episodes played: {}'.format(int(checkpoints[i]*30.5305)))\n",
    "    thickness += 0.3\n",
    "\n",
    "ending_point = plt.Circle((-1.0, -6.5), 0.1, alpha=0.5, color='black')\n",
    "ax.add_patch(ending_point)\n",
    "ending_tolerance = plt.Circle((-1.0, -6.5), 0.8, alpha=0.2, color='black')\n",
    "ax.add_patch(ending_tolerance)\n",
    "\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(success_rate.items()):\n",
    "    results = 0.0\n",
    "    for _, success in checkpoint_value.items():\n",
    "        results += int(success)\n",
    "    print('Episode: {}, Success Rate: {:10.2f}%'.format(int(checkpoints[i]*30.1658), (results/15.)*100.))\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('training_traj_eval.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = env.observation_space.sample()\n",
    "action = agent.compute_action(o)\n",
    "action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 84, 84, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_1 (Conv2D)           (None, 42, 42, 16)   592         observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 42, 42, 16)   592         observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_2 (Conv2D)           (None, 21, 21, 32)   4640        conv_value_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 21, 21, 32)   4640        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_3 (Conv2D)           (None, 11, 11, 64)   18496       conv_value_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 11, 11, 64)   18496       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_4 (Conv2D)           (None, 1, 1, 128)    991360      conv_value_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 1, 1, 128)    991360      conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_out (Conv2D)         (None, 1, 1, 1)      129         conv_value_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_out (Conv2D)               (None, 1, 1, 3)      387         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           conv_value_out[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,030,692\n",
      "Trainable params: 2,030,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "policy = agent.get_policy()\n",
    "model = policy.model.base_model\n",
    "obs = env.reset()\n",
    "for i in range(4):\n",
    "    obs, _, _, _ = env.step(1)\n",
    "preprocessed = agent.workers.local_worker().preprocessors[\n",
    "            \"default_policy\"].transform(obs)\n",
    "filtered_obs = agent.workers.local_worker().filters[\"default_policy\"](\n",
    "    preprocessed, update=False)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['default_policy/conv_value_1/kernel', 'default_policy/conv_value_1/bias', 'default_policy/conv1/kernel', 'default_policy/conv1/bias', 'default_policy/conv_value_2/kernel', 'default_policy/conv_value_2/bias', 'default_policy/conv2/kernel', 'default_policy/conv2/bias', 'default_policy/conv_value_3/kernel', 'default_policy/conv_value_3/bias', 'default_policy/conv3/kernel', 'default_policy/conv3/bias', 'default_policy/conv_value_4/kernel', 'default_policy/conv_value_4/bias', 'default_policy/conv4/kernel', 'default_policy/conv4/bias', 'default_policy/conv_value_out/kernel', 'default_policy/conv_value_out/bias', 'default_policy/conv_out/kernel', 'default_policy/conv_out/bias'])\n"
     ]
    }
   ],
   "source": [
    "weights = policy.get_weights()\n",
    "print(weights.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f0d2060bd30>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(weights['default_policy/conv1/kernel'][:, :, 0:3, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 42, 42, 16)        592       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 1, 1, 128)         991360    \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 1, 1, 3)           387       \n",
      "=================================================================\n",
      "Total params: 1,015,475\n",
      "Trainable params: 1,015,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(84, 84, 4,))\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding='same', name='conv1')(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', name='conv2')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', name='conv3')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(128, (11, 11), strides=(1, 1), padding='valid', name='conv4')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(3, (1, 1), strides=(1, 1), padding='valid', name='conv_out')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.layers[1].set_weights([weights['default_policy/conv1/kernel'], weights['default_policy/conv1/bias']])\n",
    "model.layers[3].set_weights([weights['default_policy/conv2/kernel'], weights['default_policy/conv2/bias']])\n",
    "model.layers[5].set_weights([weights['default_policy/conv3/kernel'], weights['default_policy/conv3/bias']])\n",
    "model.layers[7].set_weights([weights['default_policy/conv4/kernel'], weights['default_policy/conv4/bias']])\n",
    "model.layers[9].set_weights([weights['default_policy/conv_out/kernel'], weights['default_policy/conv_out/bias']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 21, 21, 16)        4112      \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 21, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 11, 11, 32)        8224      \n",
      "_________________________________________________________________\n",
      "re_lu_67 (ReLU)              (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 1, 256)         991488    \n",
      "_________________________________________________________________\n",
      "re_lu_68 (ReLU)              (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 1, 1, 3)           771       \n",
      "=================================================================\n",
      "Total params: 1,004,595\n",
      "Trainable params: 1,004,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(84, 84, 4,))\n",
    "x = tf.keras.layers.Conv2D(16, (8, 8), strides=(4, 4), padding='same', name='conv1')(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same', name='conv2')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(256, (11, 11), strides=(1, 1), padding='valid', name='conv3')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(3, (1, 1), strides=(1, 1), padding='valid', name='conv_out')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.layers[1].set_weights([weights['default_policy/conv1/kernel'], weights['default_policy/conv1/bias']])\n",
    "model.layers[3].set_weights([weights['default_policy/conv2/kernel'], weights['default_policy/conv2/bias']])\n",
    "model.layers[5].set_weights([weights['default_policy/conv3/kernel'], weights['default_policy/conv3/bias']])\n",
    "model.layers[7].set_weights([weights['default_policy/conv_out/kernel'], weights['default_policy/conv_out/bias']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_policy/conv_value_1/kernel\n",
      "(8, 8, 4, 16)\n",
      "----------\n",
      "default_policy/conv_value_1/bias\n",
      "(16,)\n",
      "----------\n",
      "default_policy/conv1/kernel\n",
      "(8, 8, 4, 16)\n",
      "----------\n",
      "default_policy/conv1/bias\n",
      "(16,)\n",
      "----------\n",
      "default_policy/conv_value_2/kernel\n",
      "(4, 4, 16, 32)\n",
      "----------\n",
      "default_policy/conv_value_2/bias\n",
      "(32,)\n",
      "----------\n",
      "default_policy/conv2/kernel\n",
      "(4, 4, 16, 32)\n",
      "----------\n",
      "default_policy/conv2/bias\n",
      "(32,)\n",
      "----------\n",
      "default_policy/conv_value_3/kernel\n",
      "(11, 11, 32, 256)\n",
      "----------\n",
      "default_policy/conv_value_3/bias\n",
      "(256,)\n",
      "----------\n",
      "default_policy/conv3/kernel\n",
      "(11, 11, 32, 256)\n",
      "----------\n",
      "default_policy/conv3/bias\n",
      "(256,)\n",
      "----------\n",
      "default_policy/conv_value_out/kernel\n",
      "(1, 1, 256, 1)\n",
      "----------\n",
      "default_policy/conv_value_out/bias\n",
      "(1,)\n",
      "----------\n",
      "default_policy/conv_out/kernel\n",
      "(1, 1, 256, 3)\n",
      "----------\n",
      "default_policy/conv_out/bias\n",
      "(3,)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for key, value in weights.items():\n",
    "    print(key)\n",
    "    print(value.shape)\n",
    "    print(\"----------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f180d2a4520>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d2a4250>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d292220>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d292460>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d2929d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d27cd30>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d200d90>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d207af0>]"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1, 11, 11, 64)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = agent.workers.local_worker().preprocessors[\"default_policy\"].transform(obs)\n",
    "filtered_obs = agent.workers.local_worker().filters[\"default_policy\"](preprocessed, update=False)\n",
    "\n",
    "conv_1 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[2].output)\n",
    "conv_2 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[4].output)\n",
    "conv_3 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[6].output)\n",
    "pred_1 = conv_1.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_2 = conv_2.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_3 = conv_3.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_3.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.colorbar.Colorbar at 0x7f0921bf5550>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(obs[:, :, 0])\n",
    "#np.save('obs_learning.npy', obs)\n",
    "plt.imshow(pred_3[0, :, :, 11])\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x648 with 12 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "obs = np.load('obs_learning.npy')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(12, 9))\n",
    "\n",
    "cols = ['{}'.format(col) for col in ['Input State', 'Layer response', 'Layer response', 'Layer response']]\n",
    "rows = ['ConvLayer {}'.format(row) for row in range(1, 4)]\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i, 0].imshow(obs[:, :, 0], vmin=0., vmax=1., cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([0, 7, 15]):\n",
    "    axes[0, 1+i].imshow(pred_1[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([1, 6, 12]):\n",
    "    axes[1, 1+i].imshow(pred_2[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([7, 11, 12]):\n",
    "    axes[2, 1+i].imshow(pred_3[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, size='large')\n",
    "\n",
    "plt.setp(axes[-1, 1:], xlabel='Layer response')\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    axes[-1, i].set_xlabel(col, size=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('layer_respones.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f18206d4e50>"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAALL0lEQVR4nO3da6il5XmH8evvjBJHa02xJ2ckKhVbCRTTTTAKUjQBbST2QwoKpmkIDJQm0RAIplA03/ohDcmHEBjUGIgoZRQqYk3SHCjpYcj2AFEnIWJSnajVUhKTTKiKdz/slXZmd0btep+115q5rx/I3uvA897MzOW7TvvZqSokHf9OWPYAkraGsUtNGLvUhLFLTRi71MT2rTxYsqPg9K085HHk1MHr/WzweloNP6bqYI50y5bGvhH67q095HHjksHr/dPg9bQa9hz1Fh/GS00Yu9SEsUtNGLvUhLFLTUyKPckVSb6X5IkkN44aStJ4c8eeZBvwOeBK4ALg2iQXjBpM0lhTzuxvB56oqier6iXgLuDqMWNJGm1K7DuBpw+5fGB23WGS7E6ynmQdDk44nKQppsR+pI/k/Z+dMKpqT1WtVdUa7JhwOElTTIn9AHDWIZd3Ac9MG0fSokyJ/dvAeUnOSXIScA1w75ixJI029w/CVNUrST4EfBnYBtxWVY8Nm0zSUJN+6q2q7gfuHzSLpAXyE3RSE8YuNWHsUhPGLjWxpdtSnfkHr/Ln6+P2PnslfzNsLYBPctPQ9cZa8W2krrh57Hq/NXY5br958ILHHs/sUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhNbugfdMw+ewF/l1IErrvKecc088PLY9W45cex6t49d7ljkmV1qwtilJoxdasLYpSaMXWrC2KUm5o49yVlJvpFkf5LHklw/cjBJY015n/0V4GNV9VCSXwEeTPLVqnp80GySBpr7zF5Vz1bVQ7PvfwrsB3aOGkzSWEM+QZfkbOBCYN8RbtsN7N649KsjDidpDpNfoEtyKnA3cENVvbj59qraU1VrVbUGO6YeTtKcJsWe5EQ2Qr+jqu4ZM5KkRZjyanyAW4H9VfXpcSNJWoQpZ/ZLgPcBlyV5ZPbfHw2aS9Jgc79AV1XfAjJwFkkL5CfopCaMXWrC2KUmtnRbql5OXvYAW+wfhq52wlWXDl3v1aGrHZs8s0tNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNuAfdYVZ537hfDF3tg3XG0PVuvfvKoeu9+q9DlxOe2aU2jF1qwtilJoxdasLYpSaMXWpicuxJtiV5OMl9IwaStBgjzuzXA/sHrCNpgSbFnmQX8G7gljHjSFqUqWf2zwAf5zV+SWaS3UnWk6zDwYmHkzSvuWNPchXwfFU9+Fr3q6o9VbVWVWuwY97DSZpoypn9EuA9SX4I3AVcluRLQ6aSNNzcsVfVJ6pqV1WdDVwDfL2qrhs2maShfJ9damLIj7hW1TeBb45YS9JieGaXmjB2qQljl5owdqmJY3wPutMGr/fywLVOHLgWvKWuHrrerblr6Hpw89jlvjV4PXlml7owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5o4xvege3HZA7yGXwxd7WL+eeh6/1V/OnS95x48d+h69bMMXS/cNHS9Y5FndqkJY5eaMHapCWOXmjB2qQljl5qYFHuS05PsTfLdJPuTvGPUYJLGmvo++2eBB6rqvUlOAnYMmEnSAswde5LTgEuBPwOoqpeAl8aMJWm0KQ/jzwVeAL6Q5OEktyQ5ZfOdkuxOsp5kHQ5OOJykKabEvh14G/D5qroQ+Dlw4+Y7VdWeqlqrqjUf5UvLMyX2A8CBqto3u7yXjfglraC5Y6+q54Cnk5w/u+py4PEhU0kabuqr8R8G7pi9Ev8k8IHpI0lahEmxV9UjwNqgWSQtkJ+gk5owdqkJY5eaMHapiVTV1h0sZxbsHrfgE4P3Fbtv4L5nN/z9uLUA2Pf6d5HYQ9UzR/yH7JldasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdamLqb4RZrt/55LInkI4ZntmlJoxdasLYpSaMXWrC2KUmJsWe5KNJHkvyaJI7k7xp1GCSxpo79iQ7gY8Aa1X1VmAbcM2owSSNNfVh/Hbg5CTbgR3AM9NHkrQIc8deVT8CPgU8BTwL/KSqvrL5fkl2J1lPsg4H559U0iRTHsa/GbgaOAc4EzglyXWb71dVe6pqrarWNk7+kpZhysP4dwI/qKoXqupl4B7g4jFjSRptSuxPARcl2ZEkwOXA/jFjSRptynP2fcBe4CHgO7O19gyaS9Jgk37qrapuAm4aNIukBfITdFITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITrxt7ktuSPJ/k0UOu+7UkX03y/dnXNy92TElTvZEz++3AFZuuuxH4WlWdB3xtdlnSCnvd2KvqH4H/3HT11cAXZ99/EfjjwXNJGmze5+y/WVXPAsy+/sbR7phkd5L1JOtwcM7DSZpq4S/QVdWeqlqrqjXYsejDSTqKeWP/9yS/DTD7+vy4kSQtwryx3wu8f/b9+4G/GzOOpEV5I2+93Qn8C3B+kgNJPgj8NfCuJN8H3jW7LGmFbX+9O1TVtUe56fLBs0haID9BJzVh7FITxi41YexSE6mqrTtY8gLwb2/grmcA/7Hgcea1yrPBas+3yrPB8THfW6rq1490w5bG/kYlWd/4xN3qWeXZYLXnW+XZ4Pifz4fxUhPGLjWxqrHvWfYAr2GVZ4PVnm+VZ4PjfL6VfM4uabxVPbNLGszYpSZWKvYkVyT5XpInkqzUvnZJzkryjST7kzyW5Pplz7RZkm1JHk5y37Jn2SzJ6Un2Jvnu7M/wHcue6ZeSfHT2d/pokjuTvGnJ8yxkk9eViT3JNuBzwJXABcC1SS5Y7lSHeQX4WFX9HnAR8BcrNh/A9cD+ZQ9xFJ8FHqiq3wV+nxWZM8lO4CPAWlW9FdgGXLPcqRazyevKxA68HXiiqp6sqpeAu9jY2HIlVNWzVfXQ7PufsvGPdedyp/pfSXYB7wZuWfYsmyU5DbgUuBWgql6qqh8vd6rDbAdOTrKdjb3TnlnmMIva5HWVYt8JPH3I5QOsUEyHSnI2cCGwb7mTHOYzwMeBV5c9yBGcC7wAfGH2NOOWJKcseyiAqvoR8CngKeBZ4CdV9ZXlTnVEb3iT16NZpdhzhOtW7n3BJKcCdwM3VNWLy54HIMlVwPNV9eCyZzmK7cDbgM9X1YXAz1mR3zUwe+57NXAOcCZwSpLrljvVYqxS7AeAsw65vIslP5zaLMmJbIR+R1Xds+x5DnEJ8J4kP2Tj6c9lSb603JEOcwA4UFW/fCS0l434V8E7gR9U1QtV9TJwD3Dxkmc6ksmbvK5S7N8GzktyTpKT2HiR5N4lz/Q/koSN55z7q+rTy57nUFX1iaraVVVns/Hn9vWqWpmzU1U9Bzyd5PzZVZcDjy9xpEM9BVyUZMfs7/hyVuTFw00mb/L6unvQbZWqeiXJh4Avs/GK6G1V9diSxzrUJcD7gO8keWR23V9W1f1LnOlY8mHgjtn/yJ8EPrDkeQCoqn1J9gIPsfGOy8Ms+WOzs01e/xA4I8kB4CY2NnX929mGr08Bf/L/XtePy0o9rNLDeEkLZOxSE8YuNWHsUhPGLjVh7FITxi418d/za4abyf1bmwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_2[0, :, :, 22], cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f1c6a40f490>"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1440 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape = 21\n",
    "height = 4\n",
    "width = 4\n",
    "activations = np.zeros((shape*height, shape*width))\n",
    "k = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        activations[shape*i:shape*(i+1), shape*j:shape*(j+1)] = pred_1[0, :, :, k]\n",
    "        k += 1\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(activations, cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f1b844c8970>"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1440 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape = 11\n",
    "height = 4\n",
    "width = 8\n",
    "activations = np.zeros((shape*height, shape*width))\n",
    "k = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        activations[shape*i:shape*(i+1), shape*j:shape*(j+1)] = pred_2[0, :, :, k]\n",
    "        k += 1\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(activations, cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "tmp = np.zeros((21, 21))\n",
    "for i in range(16):\n",
    "    tmp += pred_1[0, :, :, i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f180d12a9a0>"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-49841455",
   "language": "python",
   "display_name": "PyCharm (MasterThesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}