{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from scouting_gym.tasks.scouting_discrete_task import ScoutingDiscreteTask"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Register Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1614025034.090479, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1614025034.094477, 0.000000]: Start Init ControllersConnection\n",
      "[WARN] [1614025034.095561, 0.000000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box(0.0, 1.0, (84, 84, 4), float32)\n",
      "Action Space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Scouting-v0')\n",
    "\n",
    "print(\"Observation Space: {}\".format(env.observation_space))\n",
    "print(\"Action Space: {}\".format(env.action_space))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Environment State"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for _ in range(1):\n",
    "    obs, _, _, _ = env.step(action=2)\n",
    "plt.imshow(obs[:, :, 0])\n",
    "print(obs.min())\n",
    "print(obs.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ray Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env\": ScoutingDiscreteTask,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    #\"model\": {\"dim\": 84,\n",
    "    #          \"conv_filters\":\n",
    "    #              [[16, [3, 3], 2], [32, [3, 3], 2], [64, [3, 3], 2], [128, [11, 11], 1]]}\n",
    "}\n",
    "\n",
    "stop = {\n",
    "    \"episodes_total\": 6000,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 21:17:20,693\tINFO services.py:1171 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.178.60',\n 'raylet_ip_address': '192.168.178.60',\n 'redis_address': '192.168.178.60:6379',\n 'object_store_address': '/tmp/ray/session_2021-02-22_21-17-20_118092_196097/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2021-02-22_21-17-20_118092_196097/sockets/raylet',\n 'webui_url': '127.0.0.1:8265',\n 'session_dir': '/tmp/ray/session_2021-02-22_21-17-20_118092_196097',\n 'metrics_export_port': 52527,\n 'node_id': 'b6655af89fd5a12c5e9ee8644cf839cf677eb77e'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(stop_criteria, config, restorepath):\n",
    "    \"\"\"\n",
    "    Train an RLlib PPO agent using tune until any of the configured stopping criteria is met.\n",
    "    :param stop_criteria: Dict with stopping criteria.\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/execution.html#tune-run\n",
    "    :return: Return the path to the saved agent (checkpoint) and tune's ExperimentAnalysis object\n",
    "        See https://docs.ray.io/en/latest/tune/api_docs/analysis.html#experimentanalysis-tune-experimentanalysis\n",
    "    \"\"\"\n",
    "    analysis = ray.tune.run(PPOTrainer, config=config,\n",
    "                            stop=stop_criteria,\n",
    "                            checkpoint_freq=1,\n",
    "                            checkpoint_at_end=True)\n",
    "    # list of lists: one list per checkpoint; each checkpoint list contains 1st the path, 2nd the metric value\n",
    "    checkpoints = analysis.get_trial_checkpoints_paths(trial=analysis.get_best_trial('episode_reward_mean', mode='max'),\n",
    "                                                       metric='episode_reward_mean',\n",
    "                                                       )\n",
    "    # retriev the checkpoint path; we only have a single checkpoint, so take the first one\n",
    "    checkpoint_path = checkpoints[0][0]\n",
    "    return checkpoint_path, analysis\n",
    "\n",
    "def load(checkpoint_path, config):\n",
    "    \"\"\"\n",
    "    Load a trained RLlib agent from the specified path. Call this before testing a trained agent.\n",
    "    :param path: Path pointing to the agent's saved checkpoint (only used for RLlib agents)\n",
    "    \"\"\"\n",
    "    agent = PPOTrainer(config=config)\n",
    "    agent.restore(checkpoint_path)\n",
    "    return agent\n",
    "\n",
    "def test(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward\n",
    "\n",
    "def test_traj(agent, env):\n",
    "    \"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "    # instantiate env class\n",
    "\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    positions = []\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        positions.append(info['position'])\n",
    "        episode_reward += reward\n",
    "\n",
    "    return episode_reward, positions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:08:50,275\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:08:50,275\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [ERROR] [1613826533.817069, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [WARN] [1613826533.820390, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m [WARN] [1613826533.821599, 0.000000]: END Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:09:02,828\tINFO trainable.py:99 -- Trainable.setup took 12.554 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m 2021-02-20 14:09:02,828\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m 2021-02-20 14:09:04,010\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2021-02-21 19:20:56,027\tINFO tune.py:448 -- Total run time: 105129.44 seconds (105127.92 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84297)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=84296)\u001B[0m None\n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-18-47\n",
      "  done: false\n",
      "  episode_len_mean: 42.774193548387096\n",
      "  episode_reward_max: 118.3770226650548\n",
      "  episode_reward_mean: -93.49711607437895\n",
      "  episode_reward_min: -108.06729370123062\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 93\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0761983394622803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02286132611334324\n",
      "        model: {}\n",
      "        policy_loss: -0.07078494131565094\n",
      "        total_loss: 4563.99365234375\n",
      "        vf_explained_var: 0.00946330837905407\n",
      "        vf_loss: 4564.0595703125\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.48023952095808\n",
      "    ram_util_percent: 37.813532934131736\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07197494001514879\n",
      "    mean_env_wait_ms: 112.34553633139029\n",
      "    mean_inference_ms: 1.7809661082463453\n",
      "    mean_raw_obs_processing_ms: 27.807813261604643\n",
      "  time_since_restore: 584.9675097465515\n",
      "  time_this_iter_s: 584.9675097465515\n",
      "  time_total_s: 584.9675097465515\n",
      "  timers:\n",
      "    learn_throughput: 253.426\n",
      "    learn_time_ms: 15783.684\n",
      "    load_throughput: 7741.232\n",
      "    load_time_ms: 516.714\n",
      "    sample_throughput: 7.037\n",
      "    sample_time_ms: 568442.875\n",
      "    update_time_ms: 3.667\n",
      "  timestamp: 1613827127\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 45.28\n",
      "  episode_reward_max: 114.28859343326474\n",
      "  episode_reward_mean: -92.27542371741615\n",
      "  episode_reward_min: -108.3686866748935\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 180\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0438920259475708\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023191144689917564\n",
      "        model: {}\n",
      "        policy_loss: -0.07785279303789139\n",
      "        total_loss: 3480.796875\n",
      "        vf_explained_var: 0.046449340879917145\n",
      "        vf_loss: 3480.867431640625\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.84639303482587\n",
      "    ram_util_percent: 40.14216417910448\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07122021483620367\n",
      "    mean_env_wait_ms: 110.89191863652708\n",
      "    mean_inference_ms: 1.7778514251688329\n",
      "    mean_raw_obs_processing_ms: 26.994923029883047\n",
      "  time_since_restore: 1148.2525837421417\n",
      "  time_this_iter_s: 563.2850739955902\n",
      "  time_total_s: 1148.2525837421417\n",
      "  timers:\n",
      "    learn_throughput: 257.011\n",
      "    learn_time_ms: 15563.538\n",
      "    load_throughput: 8988.19\n",
      "    load_time_ms: 445.028\n",
      "    sample_throughput: 7.17\n",
      "    sample_time_ms: 557910.93\n",
      "    update_time_ms: 3.753\n",
      "  timestamp: 1613827691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 54.83\n",
      "  episode_reward_max: 118.27492096385373\n",
      "  episode_reward_mean: -83.1376979845979\n",
      "  episode_reward_min: -108.48955659836412\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 246\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0064120292663574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02330060675740242\n",
      "        model: {}\n",
      "        policy_loss: -0.10005206614732742\n",
      "        total_loss: 2177.936767578125\n",
      "        vf_explained_var: 0.1864335983991623\n",
      "        vf_loss: 2178.0263671875\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.02032520325203\n",
      "    ram_util_percent: 41.75830429732869\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07286805882756153\n",
      "    mean_env_wait_ms: 113.7639370369599\n",
      "    mean_inference_ms: 1.8338129633350764\n",
      "    mean_raw_obs_processing_ms: 25.34804746344035\n",
      "  time_since_restore: 1751.5004198551178\n",
      "  time_this_iter_s: 603.2478361129761\n",
      "  time_total_s: 1751.5004198551178\n",
      "  timers:\n",
      "    learn_throughput: 258.053\n",
      "    learn_time_ms: 15500.72\n",
      "    load_throughput: 9547.432\n",
      "    load_time_ms: 418.961\n",
      "    sample_throughput: 7.046\n",
      "    sample_time_ms: 567723.594\n",
      "    update_time_ms: 3.715\n",
      "  timestamp: 1613828294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-46-56\n",
      "  done: false\n",
      "  episode_len_mean: 68.51\n",
      "  episode_reward_max: 118.31157546697884\n",
      "  episode_reward_mean: -76.31402308357566\n",
      "  episode_reward_min: -108.48955659836412\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 298\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9740287661552429\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019892195239663124\n",
      "        model: {}\n",
      "        policy_loss: -0.10140877962112427\n",
      "        total_loss: 1925.67626953125\n",
      "        vf_explained_var: 0.3578816056251526\n",
      "        vf_loss: 1925.76416015625\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.986577181208055\n",
      "    ram_util_percent: 42.26724832214765\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07324381118410192\n",
      "    mean_env_wait_ms: 114.54295829627914\n",
      "    mean_inference_ms: 1.8481601318124876\n",
      "    mean_raw_obs_processing_ms: 23.396152967037246\n",
      "  time_since_restore: 2273.680137872696\n",
      "  time_this_iter_s: 522.1797180175781\n",
      "  time_total_s: 2273.680137872696\n",
      "  timers:\n",
      "    learn_throughput: 258.695\n",
      "    learn_time_ms: 15462.215\n",
      "    load_throughput: 9614.248\n",
      "    load_time_ms: 416.049\n",
      "    sample_throughput: 7.242\n",
      "    sample_time_ms: 552365.006\n",
      "    update_time_ms: 3.703\n",
      "  timestamp: 1613828816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_14-55-38\n",
      "  done: false\n",
      "  episode_len_mean: 80.5\n",
      "  episode_reward_max: 118.31157546697884\n",
      "  episode_reward_mean: -74.5112076002168\n",
      "  episode_reward_min: -107.92826443871176\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 345\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9424479007720947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02245231159031391\n",
      "        model: {}\n",
      "        policy_loss: -0.11653962731361389\n",
      "        total_loss: 1288.709228515625\n",
      "        vf_explained_var: 0.3869043290615082\n",
      "        vf_loss: 1288.8104248046875\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72577181208053\n",
      "    ram_util_percent: 42.22281879194631\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07249784922092387\n",
      "    mean_env_wait_ms: 113.50241287673661\n",
      "    mean_inference_ms: 1.828461425537306\n",
      "    mean_raw_obs_processing_ms: 21.573286487015874\n",
      "  time_since_restore: 2795.7982223033905\n",
      "  time_this_iter_s: 522.1180844306946\n",
      "  time_total_s: 2795.7982223033905\n",
      "  timers:\n",
      "    learn_throughput: 259.098\n",
      "    learn_time_ms: 15438.197\n",
      "    load_throughput: 9892.16\n",
      "    load_time_ms: 404.361\n",
      "    sample_throughput: 7.365\n",
      "    sample_time_ms: 543144.949\n",
      "    update_time_ms: 3.796\n",
      "  timestamp: 1613829338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 82.55\n",
      "  episode_reward_max: 118.2661259262627\n",
      "  episode_reward_mean: -74.3606947192576\n",
      "  episode_reward_min: -106.65765904648111\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 394\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9189553260803223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017654838040471077\n",
      "        model: {}\n",
      "        policy_loss: -0.11349598318338394\n",
      "        total_loss: 1229.2088623046875\n",
      "        vf_explained_var: 0.5053565502166748\n",
      "        vf_loss: 1229.3043212890625\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.80053547523427\n",
      "    ram_util_percent: 42.14631860776439\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07204796356766235\n",
      "    mean_env_wait_ms: 112.94424999099478\n",
      "    mean_inference_ms: 1.816813155558226\n",
      "    mean_raw_obs_processing_ms: 20.25822482921732\n",
      "  time_since_restore: 3319.5827116966248\n",
      "  time_this_iter_s: 523.7844893932343\n",
      "  time_total_s: 3319.5827116966248\n",
      "  timers:\n",
      "    learn_throughput: 259.328\n",
      "    learn_time_ms: 15424.463\n",
      "    load_throughput: 9852.188\n",
      "    load_time_ms: 406.001\n",
      "    sample_throughput: 7.445\n",
      "    sample_time_ms: 537267.036\n",
      "    update_time_ms: 3.745\n",
      "  timestamp: 1613829862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-12-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.35\n",
      "  episode_reward_max: 118.30713776466433\n",
      "  episode_reward_mean: -63.523381138135264\n",
      "  episode_reward_min: -106.50578201134127\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 435\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8848854899406433\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02142045460641384\n",
      "        model: {}\n",
      "        policy_loss: -0.13100093603134155\n",
      "        total_loss: 1744.0987548828125\n",
      "        vf_explained_var: 0.4920734167098999\n",
      "        vf_loss: 1744.2078857421875\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57983651226158\n",
      "    ram_util_percent: 42.138555858310625\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07175735216903688\n",
      "    mean_env_wait_ms: 112.58858042984367\n",
      "    mean_inference_ms: 1.8089444376977242\n",
      "    mean_raw_obs_processing_ms: 19.35233802635811\n",
      "  time_since_restore: 3833.387715578079\n",
      "  time_this_iter_s: 513.8050038814545\n",
      "  time_total_s: 3833.387715578079\n",
      "  timers:\n",
      "    learn_throughput: 259.526\n",
      "    learn_time_ms: 15412.732\n",
      "    load_throughput: 9930.622\n",
      "    load_time_ms: 402.794\n",
      "    sample_throughput: 7.524\n",
      "    sample_time_ms: 531642.14\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613830376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.72\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -59.63567158117983\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 475\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.893488347530365\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014194161631166935\n",
      "        model: {}\n",
      "        policy_loss: -0.11310682445764542\n",
      "        total_loss: 1079.6142578125\n",
      "        vf_explained_var: 0.5432910919189453\n",
      "        vf_loss: 1079.7060546875\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.78260273972602\n",
      "    ram_util_percent: 42.12671232876713\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07151093329723217\n",
      "    mean_env_wait_ms: 112.28665160518358\n",
      "    mean_inference_ms: 1.8033442706119143\n",
      "    mean_raw_obs_processing_ms: 18.502838213535505\n",
      "  time_since_restore: 4344.969002723694\n",
      "  time_this_iter_s: 511.5812871456146\n",
      "  time_total_s: 4344.969002723694\n",
      "  timers:\n",
      "    learn_throughput: 259.672\n",
      "    learn_time_ms: 15404.019\n",
      "    load_throughput: 10033.785\n",
      "    load_time_ms: 398.653\n",
      "    sample_throughput: 7.588\n",
      "    sample_time_ms: 527152.073\n",
      "    update_time_ms: 3.679\n",
      "  timestamp: 1613830888\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-30-01\n",
      "  done: false\n",
      "  episode_len_mean: 99.61\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -61.824132908364724\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 514\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8881871104240417\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014235087670385838\n",
      "        model: {}\n",
      "        policy_loss: -0.11436835676431656\n",
      "        total_loss: 903.1644897460938\n",
      "        vf_explained_var: 0.5682339668273926\n",
      "        vf_loss: 903.2572631835938\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.68016415868673\n",
      "    ram_util_percent: 42.191928864569086\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07130826269094545\n",
      "    mean_env_wait_ms: 112.04481898841567\n",
      "    mean_inference_ms: 1.7991444980096603\n",
      "    mean_raw_obs_processing_ms: 17.715990003541425\n",
      "  time_since_restore: 4857.632814407349\n",
      "  time_this_iter_s: 512.6638116836548\n",
      "  time_total_s: 4857.632814407349\n",
      "  timers:\n",
      "    learn_throughput: 259.793\n",
      "    learn_time_ms: 15396.888\n",
      "    load_throughput: 10105.322\n",
      "    load_time_ms: 395.831\n",
      "    sample_throughput: 7.637\n",
      "    sample_time_ms: 523776.26\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613831401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-38-31\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_reward_max: 118.39888024524822\n",
      "  episode_reward_mean: -57.32057116780643\n",
      "  episode_reward_min: -107.17238065761742\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 551\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8375014662742615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016036443412303925\n",
      "        model: {}\n",
      "        policy_loss: -0.12444860488176346\n",
      "        total_loss: 1020.59912109375\n",
      "        vf_explained_var: 0.6986218690872192\n",
      "        vf_loss: 1020.6992797851562\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7113854595336\n",
      "    ram_util_percent: 42.184636488340196\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0711633401790614\n",
      "    mean_env_wait_ms: 111.87942778208779\n",
      "    mean_inference_ms: 1.796204792466029\n",
      "    mean_raw_obs_processing_ms: 17.068492334631227\n",
      "  time_since_restore: 5368.266561508179\n",
      "  time_this_iter_s: 510.6337471008301\n",
      "  time_total_s: 5368.266561508179\n",
      "  timers:\n",
      "    learn_throughput: 259.868\n",
      "    learn_time_ms: 15392.406\n",
      "    load_throughput: 10161.363\n",
      "    load_time_ms: 393.648\n",
      "    sample_throughput: 7.679\n",
      "    sample_time_ms: 520870.662\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613831911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-46-55\n",
      "  done: false\n",
      "  episode_len_mean: 107.74\n",
      "  episode_reward_max: 118.37779062602058\n",
      "  episode_reward_mean: -44.2649893294039\n",
      "  episode_reward_min: -106.6639466464975\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 584\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8471274971961975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017741737887263298\n",
      "        model: {}\n",
      "        policy_loss: -0.13405659794807434\n",
      "        total_loss: 949.0671997070312\n",
      "        vf_explained_var: 0.7107579708099365\n",
      "        vf_loss: 949.1742553710938\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71237830319888\n",
      "    ram_util_percent: 42.22141863699583\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07104209578305797\n",
      "    mean_env_wait_ms: 111.75151112031331\n",
      "    mean_inference_ms: 1.7937164648929005\n",
      "    mean_raw_obs_processing_ms: 16.50943981550422\n",
      "  time_since_restore: 5871.953165054321\n",
      "  time_this_iter_s: 503.6866035461426\n",
      "  time_total_s: 5871.953165054321\n",
      "  timers:\n",
      "    learn_throughput: 260.637\n",
      "    learn_time_ms: 15347.012\n",
      "    load_throughput: 10523.864\n",
      "    load_time_ms: 380.089\n",
      "    sample_throughput: 7.8\n",
      "    sample_time_ms: 512807.791\n",
      "    update_time_ms: 3.673\n",
      "  timestamp: 1613832415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_15-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 112.6\n",
      "  episode_reward_max: 118.37779062602058\n",
      "  episode_reward_mean: -37.80436355311525\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 620\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.833489179611206\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01759730838239193\n",
      "        model: {}\n",
      "        policy_loss: -0.13340024650096893\n",
      "        total_loss: 1048.4493408203125\n",
      "        vf_explained_var: 0.6537086367607117\n",
      "        vf_loss: 1048.555908203125\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 48000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61522633744856\n",
      "    ram_util_percent: 42.17366255144033\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07093759001518152\n",
      "    mean_env_wait_ms: 111.64461784042756\n",
      "    mean_inference_ms: 1.7913958009287085\n",
      "    mean_raw_obs_processing_ms: 15.962087600789314\n",
      "  time_since_restore: 6383.151445388794\n",
      "  time_this_iter_s: 511.19828033447266\n",
      "  time_total_s: 6383.151445388794\n",
      "  timers:\n",
      "    learn_throughput: 260.664\n",
      "    learn_time_ms: 15345.431\n",
      "    load_throughput: 10541.219\n",
      "    load_time_ms: 379.463\n",
      "    sample_throughput: 7.88\n",
      "    sample_time_ms: 507605.385\n",
      "    update_time_ms: 3.876\n",
      "  timestamp: 1613832926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-03-50\n",
      "  done: false\n",
      "  episode_len_mean: 117.99\n",
      "  episode_reward_max: 118.32474575086673\n",
      "  episode_reward_mean: -27.58161138389983\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 652\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7921907305717468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01740110106766224\n",
      "        model: {}\n",
      "        policy_loss: -0.13286353647708893\n",
      "        total_loss: 986.4422607421875\n",
      "        vf_explained_var: 0.7495697736740112\n",
      "        vf_loss: 986.5487670898438\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.74923504867871\n",
      "    ram_util_percent: 42.19179415855354\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0708550657451176\n",
      "    mean_env_wait_ms: 111.5553781191144\n",
      "    mean_inference_ms: 1.7895062860252369\n",
      "    mean_raw_obs_processing_ms: 15.49720560298924\n",
      "  time_since_restore: 6886.85665345192\n",
      "  time_this_iter_s: 503.7052080631256\n",
      "  time_total_s: 6886.85665345192\n",
      "  timers:\n",
      "    learn_throughput: 260.747\n",
      "    learn_time_ms: 15340.552\n",
      "    load_throughput: 10429.202\n",
      "    load_time_ms: 383.538\n",
      "    sample_throughput: 8.038\n",
      "    sample_time_ms: 497648.979\n",
      "    update_time_ms: 3.965\n",
      "  timestamp: 1613833430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-12-22\n",
      "  done: false\n",
      "  episode_len_mean: 114.17\n",
      "  episode_reward_max: 118.34763032056395\n",
      "  episode_reward_mean: -27.616167549093642\n",
      "  episode_reward_min: -107.50796406036544\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 691\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7926270961761475\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016526449471712112\n",
      "        model: {}\n",
      "        policy_loss: -0.12517505884170532\n",
      "        total_loss: 1409.384521484375\n",
      "        vf_explained_var: 0.6078544855117798\n",
      "        vf_loss: 1409.4847412109375\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 56000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75342465753425\n",
      "    ram_util_percent: 42.14630136986302\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07078901034130622\n",
      "    mean_env_wait_ms: 111.47776106342957\n",
      "    mean_inference_ms: 1.7877140804958083\n",
      "    mean_raw_obs_processing_ms: 15.09152646575455\n",
      "  time_since_restore: 7398.7250781059265\n",
      "  time_this_iter_s: 511.86842465400696\n",
      "  time_total_s: 7398.7250781059265\n",
      "  timers:\n",
      "    learn_throughput: 260.776\n",
      "    learn_time_ms: 15338.848\n",
      "    load_throughput: 10544.393\n",
      "    load_time_ms: 379.349\n",
      "    sample_throughput: 8.054\n",
      "    sample_time_ms: 496622.122\n",
      "    update_time_ms: 3.964\n",
      "  timestamp: 1613833942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 112.11\n",
      "  episode_reward_max: 118.35346512980267\n",
      "  episode_reward_mean: -20.962442561296843\n",
      "  episode_reward_min: -107.14378950829905\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 725\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7813454866409302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017482509836554527\n",
      "        model: {}\n",
      "        policy_loss: -0.1358514428138733\n",
      "        total_loss: 1851.878173828125\n",
      "        vf_explained_var: 0.5138440132141113\n",
      "        vf_loss: 1851.9873046875\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.659862068965516\n",
      "    ram_util_percent: 42.23862068965517\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07073730141570324\n",
      "    mean_env_wait_ms: 111.41417937432274\n",
      "    mean_inference_ms: 1.7862244263998557\n",
      "    mean_raw_obs_processing_ms: 14.776521986543223\n",
      "  time_since_restore: 7906.858117580414\n",
      "  time_this_iter_s: 508.1330394744873\n",
      "  time_total_s: 7906.858117580414\n",
      "  timers:\n",
      "    learn_throughput: 260.787\n",
      "    learn_time_ms: 15338.184\n",
      "    load_throughput: 10444.494\n",
      "    load_time_ms: 382.977\n",
      "    sample_throughput: 8.077\n",
      "    sample_time_ms: 495219.611\n",
      "    update_time_ms: 3.916\n",
      "  timestamp: 1613834450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 109.96\n",
      "  episode_reward_max: 118.35346512980267\n",
      "  episode_reward_mean: -18.75715464557466\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 761\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7650612592697144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01819213666021824\n",
      "        model: {}\n",
      "        policy_loss: -0.13488051295280457\n",
      "        total_loss: 1805.126708984375\n",
      "        vf_explained_var: 0.504750669002533\n",
      "        vf_loss: 1805.23388671875\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 64000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.68347107438016\n",
      "    ram_util_percent: 42.208953168044076\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07069342223139513\n",
      "    mean_env_wait_ms: 111.3599021075677\n",
      "    mean_inference_ms: 1.7847514919566214\n",
      "    mean_raw_obs_processing_ms: 14.519880312636424\n",
      "  time_since_restore: 8415.256796121597\n",
      "  time_this_iter_s: 508.3986785411835\n",
      "  time_total_s: 8415.256796121597\n",
      "  timers:\n",
      "    learn_throughput: 260.81\n",
      "    learn_time_ms: 15336.824\n",
      "    load_throughput: 10583.22\n",
      "    load_time_ms: 377.957\n",
      "    sample_throughput: 8.102\n",
      "    sample_time_ms: 493684.154\n",
      "    update_time_ms: 4.014\n",
      "  timestamp: 1613834959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 120.49\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -14.285936706308428\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 791\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7496641874313354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019364701583981514\n",
      "        model: {}\n",
      "        policy_loss: -0.13387431204319\n",
      "        total_loss: 1098.99560546875\n",
      "        vf_explained_var: 0.661304235458374\n",
      "        vf_loss: 1099.0999755859375\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60835654596101\n",
      "    ram_util_percent: 42.167270194986074\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07065488171285099\n",
      "    mean_env_wait_ms: 111.3241307552929\n",
      "    mean_inference_ms: 1.7835782570333196\n",
      "    mean_raw_obs_processing_ms: 14.269352176899874\n",
      "  time_since_restore: 8918.76670885086\n",
      "  time_this_iter_s: 503.5099127292633\n",
      "  time_total_s: 8918.76670885086\n",
      "  timers:\n",
      "    learn_throughput: 260.854\n",
      "    learn_time_ms: 15334.221\n",
      "    load_throughput: 10626.154\n",
      "    load_time_ms: 376.43\n",
      "    sample_throughput: 8.119\n",
      "    sample_time_ms: 492661.291\n",
      "    update_time_ms: 4.04\n",
      "  timestamp: 1613835462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 123.46\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -16.785158096241034\n",
      "  episode_reward_min: -108.64998050586729\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 822\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7540880441665649\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019368959590792656\n",
      "        model: {}\n",
      "        policy_loss: -0.14248614013195038\n",
      "        total_loss: 1216.87744140625\n",
      "        vf_explained_var: 0.6238676905632019\n",
      "        vf_loss: 1216.9906005859375\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 72000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7082402234637\n",
      "    ram_util_percent: 42.18617318435754\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07060540628940473\n",
      "    mean_env_wait_ms: 111.28075957730394\n",
      "    mean_inference_ms: 1.7825459579854874\n",
      "    mean_raw_obs_processing_ms: 14.023184899113176\n",
      "  time_since_restore: 9420.529680490494\n",
      "  time_this_iter_s: 501.7629716396332\n",
      "  time_total_s: 9420.529680490494\n",
      "  timers:\n",
      "    learn_throughput: 260.88\n",
      "    learn_time_ms: 15332.692\n",
      "    load_throughput: 10536.835\n",
      "    load_time_ms: 379.621\n",
      "    sample_throughput: 8.135\n",
      "    sample_time_ms: 491674.687\n",
      "    update_time_ms: 4.023\n",
      "  timestamp: 1613835964\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_16-54-28\n",
      "  done: false\n",
      "  episode_len_mean: 125.66\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -16.635151349911744\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 855\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7352050542831421\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01947021298110485\n",
      "        model: {}\n",
      "        policy_loss: -0.1371580809354782\n",
      "        total_loss: 1364.107177734375\n",
      "        vf_explained_var: 0.6220147013664246\n",
      "        vf_loss: 1364.2147216796875\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.838942976356044\n",
      "    ram_util_percent: 42.21223922114048\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07055628986635981\n",
      "    mean_env_wait_ms: 111.23097080172302\n",
      "    mean_inference_ms: 1.7815564425989334\n",
      "    mean_raw_obs_processing_ms: 13.76615522826784\n",
      "  time_since_restore: 9924.060046195984\n",
      "  time_this_iter_s: 503.5303657054901\n",
      "  time_total_s: 9924.060046195984\n",
      "  timers:\n",
      "    learn_throughput: 260.866\n",
      "    learn_time_ms: 15333.563\n",
      "    load_throughput: 10489.54\n",
      "    load_time_ms: 381.332\n",
      "    sample_throughput: 8.151\n",
      "    sample_time_ms: 490761.917\n",
      "    update_time_ms: 3.993\n",
      "  timestamp: 1613836468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-02-55\n",
      "  done: false\n",
      "  episode_len_mean: 122.28\n",
      "  episode_reward_max: 118.3939902776051\n",
      "  episode_reward_mean: -19.05427828901017\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 888\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7261008024215698\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02093971148133278\n",
      "        model: {}\n",
      "        policy_loss: -0.13702255487442017\n",
      "        total_loss: 1568.1337890625\n",
      "        vf_explained_var: 0.5397771596908569\n",
      "        vf_loss: 1568.239013671875\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.70828729281767\n",
      "    ram_util_percent: 42.19530386740332\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07051613655744564\n",
      "    mean_env_wait_ms: 111.18505007432478\n",
      "    mean_inference_ms: 1.780629552901428\n",
      "    mean_raw_obs_processing_ms: 13.540986767124712\n",
      "  time_since_restore: 10431.394457101822\n",
      "  time_this_iter_s: 507.334410905838\n",
      "  time_total_s: 10431.394457101822\n",
      "  timers:\n",
      "    learn_throughput: 260.875\n",
      "    learn_time_ms: 15333.029\n",
      "    load_throughput: 10507.372\n",
      "    load_time_ms: 380.685\n",
      "    sample_throughput: 8.156\n",
      "    sample_time_ms: 490433.243\n",
      "    update_time_ms: 3.988\n",
      "  timestamp: 1613836975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-11-19\n",
      "  done: false\n",
      "  episode_len_mean: 120.9\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: -12.310829991559114\n",
      "  episode_reward_min: -107.60329027263762\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 920\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.70824134349823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01423901692032814\n",
      "        model: {}\n",
      "        policy_loss: -0.12159629911184311\n",
      "        total_loss: 1377.1143798828125\n",
      "        vf_explained_var: 0.5997397303581238\n",
      "        vf_loss: 1377.2037353515625\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57621696801112\n",
      "    ram_util_percent: 42.23449235048678\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07049318642704192\n",
      "    mean_env_wait_ms: 111.14931717979958\n",
      "    mean_inference_ms: 1.7797591977790392\n",
      "    mean_raw_obs_processing_ms: 13.358750470278427\n",
      "  time_since_restore: 10935.541148424149\n",
      "  time_this_iter_s: 504.14669132232666\n",
      "  time_total_s: 10935.541148424149\n",
      "  timers:\n",
      "    learn_throughput: 260.831\n",
      "    learn_time_ms: 15335.624\n",
      "    load_throughput: 10536.602\n",
      "    load_time_ms: 379.629\n",
      "    sample_throughput: 8.155\n",
      "    sample_time_ms: 490478.487\n",
      "    update_time_ms: 3.98\n",
      "  timestamp: 1613837479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 119.66\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: -5.866658288115945\n",
      "  episode_reward_min: -106.86675580611211\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 955\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6930056810379028\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01464045513421297\n",
      "        model: {}\n",
      "        policy_loss: -0.12477900087833405\n",
      "        total_loss: 1798.8236083984375\n",
      "        vf_explained_var: 0.5352810025215149\n",
      "        vf_loss: 1798.9150390625\n",
      "    num_steps_sampled: 88000\n",
      "    num_steps_trained: 88000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71424619640386\n",
      "    ram_util_percent: 42.19128630705394\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0704745226511796\n",
      "    mean_env_wait_ms: 111.11939499798135\n",
      "    mean_inference_ms: 1.7788941975198371\n",
      "    mean_raw_obs_processing_ms: 13.19077736985796\n",
      "  time_since_restore: 11442.23236489296\n",
      "  time_this_iter_s: 506.69121646881104\n",
      "  time_total_s: 11442.23236489296\n",
      "  timers:\n",
      "    learn_throughput: 260.819\n",
      "    learn_time_ms: 15336.297\n",
      "    load_throughput: 10483.409\n",
      "    load_time_ms: 381.555\n",
      "    sample_throughput: 8.163\n",
      "    sample_time_ms: 490023.271\n",
      "    update_time_ms: 3.734\n",
      "  timestamp: 1613837986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 88000\n",
      "  training_iteration: 22\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 124.01\n",
      "  episode_reward_max: 118.38878743679915\n",
      "  episode_reward_mean: 6.998789734124133\n",
      "  episode_reward_min: -106.7017113793944\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 985\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6945086121559143\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014527100138366222\n",
      "        model: {}\n",
      "        policy_loss: -0.12096773833036423\n",
      "        total_loss: 1275.7939453125\n",
      "        vf_explained_var: 0.6098142862319946\n",
      "        vf_loss: 1275.8819580078125\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.636541143654114\n",
      "    ram_util_percent: 42.231659693165966\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07045896523118514\n",
      "    mean_env_wait_ms: 111.09149651191204\n",
      "    mean_inference_ms: 1.778265931415495\n",
      "    mean_raw_obs_processing_ms: 13.050278562975482\n",
      "  time_since_restore: 11944.09179854393\n",
      "  time_this_iter_s: 501.85943365097046\n",
      "  time_total_s: 11944.09179854393\n",
      "  timers:\n",
      "    learn_throughput: 260.827\n",
      "    learn_time_ms: 15335.839\n",
      "    load_throughput: 10589.766\n",
      "    load_time_ms: 377.723\n",
      "    sample_throughput: 8.166\n",
      "    sample_time_ms: 489846.579\n",
      "    update_time_ms: 3.607\n",
      "  timestamp: 1613838488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-36-34\n",
      "  done: false\n",
      "  episode_len_mean: 123.87\n",
      "  episode_reward_max: 118.3395831387293\n",
      "  episode_reward_mean: 15.293911476606176\n",
      "  episode_reward_min: -106.7017113793944\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1018\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6948832273483276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01476839929819107\n",
      "        model: {}\n",
      "        policy_loss: -0.12513484060764313\n",
      "        total_loss: 1115.804931640625\n",
      "        vf_explained_var: 0.6886588931083679\n",
      "        vf_loss: 1115.8966064453125\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 96000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.62991689750693\n",
      "    ram_util_percent: 42.211634349030476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07044008192298663\n",
      "    mean_env_wait_ms: 111.06321753615448\n",
      "    mean_inference_ms: 1.7776164476564702\n",
      "    mean_raw_obs_processing_ms: 12.909237082108405\n",
      "  time_since_restore: 12450.006348371506\n",
      "  time_this_iter_s: 505.9145498275757\n",
      "  time_total_s: 12450.006348371506\n",
      "  timers:\n",
      "    learn_throughput: 260.756\n",
      "    learn_time_ms: 15340.008\n",
      "    load_throughput: 10459.126\n",
      "    load_time_ms: 382.441\n",
      "    sample_throughput: 8.176\n",
      "    sample_time_ms: 489242.181\n",
      "    update_time_ms: 3.58\n",
      "  timestamp: 1613838994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 24\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-44-58\n",
      "  done: false\n",
      "  episode_len_mean: 126.73\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 30.233502197167073\n",
      "  episode_reward_min: -105.22484963962395\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1049\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6816383600234985\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015095611102879047\n",
      "        model: {}\n",
      "        policy_loss: -0.1279529482126236\n",
      "        total_loss: 1255.4622802734375\n",
      "        vf_explained_var: 0.6161641478538513\n",
      "        vf_loss: 1255.5557861328125\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.64283727399165\n",
      "    ram_util_percent: 42.207788595271204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0704241765388529\n",
      "    mean_env_wait_ms: 111.04518944599339\n",
      "    mean_inference_ms: 1.7770956349540592\n",
      "    mean_raw_obs_processing_ms: 12.775610119884405\n",
      "  time_since_restore: 12954.356755018234\n",
      "  time_this_iter_s: 504.3504066467285\n",
      "  time_total_s: 12954.356755018234\n",
      "  timers:\n",
      "    learn_throughput: 260.752\n",
      "    learn_time_ms: 15340.229\n",
      "    load_throughput: 10501.392\n",
      "    load_time_ms: 380.902\n",
      "    sample_throughput: 8.182\n",
      "    sample_time_ms: 488865.351\n",
      "    update_time_ms: 3.546\n",
      "  timestamp: 1613839498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_17-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 125.61\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 23.559431281202528\n",
      "  episode_reward_min: -105.22484963962395\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1082\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6820441484451294\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01384813617914915\n",
      "        model: {}\n",
      "        policy_loss: -0.11520286649465561\n",
      "        total_loss: 1187.2332763671875\n",
      "        vf_explained_var: 0.6505010724067688\n",
      "        vf_loss: 1187.31689453125\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 104000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7009735744089\n",
      "    ram_util_percent: 42.20639777468706\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07040890131315722\n",
      "    mean_env_wait_ms: 111.020601745741\n",
      "    mean_inference_ms: 1.77661679011248\n",
      "    mean_raw_obs_processing_ms: 12.648610157034309\n",
      "  time_since_restore: 13457.7450299263\n",
      "  time_this_iter_s: 503.3882749080658\n",
      "  time_total_s: 13457.7450299263\n",
      "  timers:\n",
      "    learn_throughput: 260.752\n",
      "    learn_time_ms: 15340.253\n",
      "    load_throughput: 10496.954\n",
      "    load_time_ms: 381.063\n",
      "    sample_throughput: 8.191\n",
      "    sample_time_ms: 488365.09\n",
      "    update_time_ms: 3.474\n",
      "  timestamp: 1613840002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 26\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 127.16\n",
      "  episode_reward_max: 118.37376180931558\n",
      "  episode_reward_mean: 36.48697008197477\n",
      "  episode_reward_min: -105.02049054797493\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1112\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6504806280136108\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012804980389773846\n",
      "        model: {}\n",
      "        policy_loss: -0.11266468465328217\n",
      "        total_loss: 1185.9178466796875\n",
      "        vf_explained_var: 0.542258083820343\n",
      "        vf_loss: 1186.001220703125\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.65815899581591\n",
      "    ram_util_percent: 42.21924686192469\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07039732274589429\n",
      "    mean_env_wait_ms: 111.00094092547454\n",
      "    mean_inference_ms: 1.7761994000854702\n",
      "    mean_raw_obs_processing_ms: 12.53645227464082\n",
      "  time_since_restore: 13960.061575174332\n",
      "  time_this_iter_s: 502.3165452480316\n",
      "  time_total_s: 13960.061575174332\n",
      "  timers:\n",
      "    learn_throughput: 260.719\n",
      "    learn_time_ms: 15342.191\n",
      "    load_throughput: 10401.78\n",
      "    load_time_ms: 384.55\n",
      "    sample_throughput: 8.193\n",
      "    sample_time_ms: 488238.812\n",
      "    update_time_ms: 3.457\n",
      "  timestamp: 1613840504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 131.44\n",
      "  episode_reward_max: 118.36507583714197\n",
      "  episode_reward_mean: 36.23231503613656\n",
      "  episode_reward_min: -105.78551474080567\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1140\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6783497929573059\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013919226825237274\n",
      "        model: {}\n",
      "        policy_loss: -0.1166716143488884\n",
      "        total_loss: 1227.0704345703125\n",
      "        vf_explained_var: 0.5477025508880615\n",
      "        vf_loss: 1227.1553955078125\n",
      "    num_steps_sampled: 112000\n",
      "    num_steps_trained: 112000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.758426966292134\n",
      "    ram_util_percent: 42.23160112359551\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07038291347658035\n",
      "    mean_env_wait_ms: 110.98060862891019\n",
      "    mean_inference_ms: 1.775780173131198\n",
      "    mean_raw_obs_processing_ms: 12.425000683116933\n",
      "  time_since_restore: 14459.337463378906\n",
      "  time_this_iter_s: 499.2758882045746\n",
      "  time_total_s: 14459.337463378906\n",
      "  timers:\n",
      "    learn_throughput: 260.671\n",
      "    learn_time_ms: 15344.991\n",
      "    load_throughput: 10511.413\n",
      "    load_time_ms: 380.539\n",
      "    sample_throughput: 8.197\n",
      "    sample_time_ms: 487992.957\n",
      "    update_time_ms: 3.48\n",
      "  timestamp: 1613841004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 112000\n",
      "  training_iteration: 28\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 135.09\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 32.10021681225889\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1170\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6964059472084045\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013909266330301762\n",
      "        model: {}\n",
      "        policy_loss: -0.11934468150138855\n",
      "        total_loss: 1181.1661376953125\n",
      "        vf_explained_var: 0.5709272623062134\n",
      "        vf_loss: 1181.2537841796875\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.857697642163664\n",
      "    ram_util_percent: 39.77101248266297\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703686888714543\n",
      "    mean_env_wait_ms: 110.97097829864457\n",
      "    mean_inference_ms: 1.7753516723352671\n",
      "    mean_raw_obs_processing_ms: 12.302189914191656\n",
      "  time_since_restore: 14964.054445505142\n",
      "  time_this_iter_s: 504.71698212623596\n",
      "  time_total_s: 14964.054445505142\n",
      "  timers:\n",
      "    learn_throughput: 260.711\n",
      "    learn_time_ms: 15342.681\n",
      "    load_throughput: 10415.753\n",
      "    load_time_ms: 384.034\n",
      "    sample_throughput: 8.195\n",
      "    sample_time_ms: 488109.406\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613841508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 140.88\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 40.35233156049454\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 1196\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.674450695514679\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013536256738007069\n",
      "        model: {}\n",
      "        policy_loss: -0.1175597608089447\n",
      "        total_loss: 1170.9039306640625\n",
      "        vf_explained_var: 0.5870176553726196\n",
      "        vf_loss: 1170.9906005859375\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50622347949081\n",
      "    ram_util_percent: 36.924328147100425\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035949048792381\n",
      "    mean_env_wait_ms: 110.96037487540852\n",
      "    mean_inference_ms: 1.7749863169787523\n",
      "    mean_raw_obs_processing_ms: 12.184954414521753\n",
      "  time_since_restore: 15459.731275558472\n",
      "  time_this_iter_s: 495.67683005332947\n",
      "  time_total_s: 15459.731275558472\n",
      "  timers:\n",
      "    learn_throughput: 260.758\n",
      "    learn_time_ms: 15339.91\n",
      "    load_throughput: 10387.519\n",
      "    load_time_ms: 385.078\n",
      "    sample_throughput: 8.214\n",
      "    sample_time_ms: 486947.215\n",
      "    update_time_ms: 3.492\n",
      "  timestamp: 1613842004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 30\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 144.89\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 47.023250764741846\n",
      "  episode_reward_min: -106.25160441791377\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1223\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6427279710769653\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011490685865283012\n",
      "        model: {}\n",
      "        policy_loss: -0.10050224512815475\n",
      "        total_loss: 756.8341674804688\n",
      "        vf_explained_var: 0.6174790859222412\n",
      "        vf_loss: 756.9085083007812\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.377387640449435\n",
      "    ram_util_percent: 36.87710674157304\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07035092872158756\n",
      "    mean_env_wait_ms: 110.95021412938355\n",
      "    mean_inference_ms: 1.774614179317349\n",
      "    mean_raw_obs_processing_ms: 12.061422517334409\n",
      "  time_since_restore: 15958.507922649384\n",
      "  time_this_iter_s: 498.77664709091187\n",
      "  time_total_s: 15958.507922649384\n",
      "  timers:\n",
      "    learn_throughput: 260.83\n",
      "    learn_time_ms: 15335.636\n",
      "    load_throughput: 10336.547\n",
      "    load_time_ms: 386.976\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486409.376\n",
      "    update_time_ms: 3.548\n",
      "  timestamp: 1613842503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 143.39\n",
      "  episode_reward_max: 118.39714415632916\n",
      "  episode_reward_mean: 45.02980851393272\n",
      "  episode_reward_min: -106.13181011328527\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1252\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6459044218063354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013180318288505077\n",
      "        model: {}\n",
      "        policy_loss: -0.10961834341287613\n",
      "        total_loss: 1246.991455078125\n",
      "        vf_explained_var: 0.6224071383476257\n",
      "        vf_loss: 1247.071044921875\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 128000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.74138418079096\n",
      "    ram_util_percent: 36.838418079096044\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034702179490523\n",
      "    mean_env_wait_ms: 110.92817621890161\n",
      "    mean_inference_ms: 1.774262699782484\n",
      "    mean_raw_obs_processing_ms: 11.937789569935498\n",
      "  time_since_restore: 16455.04742050171\n",
      "  time_this_iter_s: 496.53949785232544\n",
      "  time_total_s: 16455.04742050171\n",
      "  timers:\n",
      "    learn_throughput: 260.844\n",
      "    learn_time_ms: 15334.842\n",
      "    load_throughput: 10334.558\n",
      "    load_time_ms: 387.051\n",
      "    sample_throughput: 8.241\n",
      "    sample_time_ms: 485394.114\n",
      "    update_time_ms: 3.588\n",
      "  timestamp: 1613843000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 32\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_18-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 143.61\n",
      "  episode_reward_max: 118.37212468138358\n",
      "  episode_reward_mean: 42.767731893081546\n",
      "  episode_reward_min: -105.07795578663634\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1282\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6835929155349731\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015338728204369545\n",
      "        model: {}\n",
      "        policy_loss: -0.13167516887187958\n",
      "        total_loss: 1369.089599609375\n",
      "        vf_explained_var: 0.6222342252731323\n",
      "        vf_loss: 1369.1864013671875\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51510489510489\n",
      "    ram_util_percent: 36.884195804195805\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07034467118532628\n",
      "    mean_env_wait_ms: 110.89991957438093\n",
      "    mean_inference_ms: 1.7738559267543803\n",
      "    mean_raw_obs_processing_ms: 11.822127288039512\n",
      "  time_since_restore: 16955.506905317307\n",
      "  time_this_iter_s: 500.45948481559753\n",
      "  time_total_s: 16955.506905317307\n",
      "  timers:\n",
      "    learn_throughput: 260.835\n",
      "    learn_time_ms: 15335.365\n",
      "    load_throughput: 10245.805\n",
      "    load_time_ms: 390.404\n",
      "    sample_throughput: 8.243\n",
      "    sample_time_ms: 485247.888\n",
      "    update_time_ms: 3.616\n",
      "  timestamp: 1613843500\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 133.63\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 32.1404880050737\n",
      "  episode_reward_min: -105.07795578663634\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1313\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6472254991531372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014062902890145779\n",
      "        model: {}\n",
      "        policy_loss: -0.1172453835606575\n",
      "        total_loss: 1262.2076416015625\n",
      "        vf_explained_var: 0.57198566198349\n",
      "        vf_loss: 1262.29296875\n",
      "    num_steps_sampled: 136000\n",
      "    num_steps_trained: 136000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61216783216783\n",
      "    ram_util_percent: 36.84965034965035\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033984018987388\n",
      "    mean_env_wait_ms: 110.87097809766998\n",
      "    mean_inference_ms: 1.7733750635766539\n",
      "    mean_raw_obs_processing_ms: 11.728371523588248\n",
      "  time_since_restore: 17456.943140506744\n",
      "  time_this_iter_s: 501.43623518943787\n",
      "  time_total_s: 17456.943140506744\n",
      "  timers:\n",
      "    learn_throughput: 260.908\n",
      "    learn_time_ms: 15331.056\n",
      "    load_throughput: 10305.266\n",
      "    load_time_ms: 388.151\n",
      "    sample_throughput: 8.251\n",
      "    sample_time_ms: 484805.591\n",
      "    update_time_ms: 3.648\n",
      "  timestamp: 1613844002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 136000\n",
      "  training_iteration: 34\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-08-26\n",
      "  done: false\n",
      "  episode_len_mean: 133.22\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 15.54194706711927\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1343\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6586072444915771\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015374414622783661\n",
      "        model: {}\n",
      "        policy_loss: -0.13172367215156555\n",
      "        total_loss: 1605.39208984375\n",
      "        vf_explained_var: 0.5467179417610168\n",
      "        vf_loss: 1605.4888916015625\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.994027777777774\n",
      "    ram_util_percent: 36.948611111111106\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.070340489915848\n",
      "    mean_env_wait_ms: 110.85563415838286\n",
      "    mean_inference_ms: 1.773001997473154\n",
      "    mean_raw_obs_processing_ms: 11.65145366998234\n",
      "  time_since_restore: 17961.057772874832\n",
      "  time_this_iter_s: 504.11463236808777\n",
      "  time_total_s: 17961.057772874832\n",
      "  timers:\n",
      "    learn_throughput: 260.897\n",
      "    learn_time_ms: 15331.723\n",
      "    load_throughput: 10218.106\n",
      "    load_time_ms: 391.462\n",
      "    sample_throughput: 8.251\n",
      "    sample_time_ms: 484779.773\n",
      "    update_time_ms: 3.654\n",
      "  timestamp: 1613844506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-16-43\n",
      "  done: false\n",
      "  episode_len_mean: 130.9\n",
      "  episode_reward_max: 118.39840912865664\n",
      "  episode_reward_mean: 25.976085320763044\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1371\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6460509896278381\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013093412853777409\n",
      "        model: {}\n",
      "        policy_loss: -0.11080330610275269\n",
      "        total_loss: 818.1026000976562\n",
      "        vf_explained_var: 0.7011681199073792\n",
      "        vf_loss: 818.1834106445312\n",
      "    num_steps_sampled: 144000\n",
      "    num_steps_trained: 144000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60070621468927\n",
      "    ram_util_percent: 36.98601694915254\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033730600624276\n",
      "    mean_env_wait_ms: 110.84213018906237\n",
      "    mean_inference_ms: 1.772571484547563\n",
      "    mean_raw_obs_processing_ms: 11.580043678765687\n",
      "  time_since_restore: 18457.762900829315\n",
      "  time_this_iter_s: 496.70512795448303\n",
      "  time_total_s: 18457.762900829315\n",
      "  timers:\n",
      "    learn_throughput: 260.95\n",
      "    learn_time_ms: 15328.593\n",
      "    load_throughput: 10136.049\n",
      "    load_time_ms: 394.631\n",
      "    sample_throughput: 8.263\n",
      "    sample_time_ms: 484109.867\n",
      "    update_time_ms: 3.626\n",
      "  timestamp: 1613845003\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 144000\n",
      "  training_iteration: 36\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-25-04\n",
      "  done: false\n",
      "  episode_len_mean: 133.62\n",
      "  episode_reward_max: 118.37555030139066\n",
      "  episode_reward_mean: 29.844075293892665\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1402\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.666848361492157\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014040189795196056\n",
      "        model: {}\n",
      "        policy_loss: -0.1256057620048523\n",
      "        total_loss: 841.550537109375\n",
      "        vf_explained_var: 0.7548153400421143\n",
      "        vf_loss: 841.644287109375\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.59581005586592\n",
      "    ram_util_percent: 36.905726256983236\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033396749830349\n",
      "    mean_env_wait_ms: 110.82677575562188\n",
      "    mean_inference_ms: 1.7721333454132469\n",
      "    mean_raw_obs_processing_ms: 11.505523211637954\n",
      "  time_since_restore: 18958.79090666771\n",
      "  time_this_iter_s: 501.02800583839417\n",
      "  time_total_s: 18958.79090666771\n",
      "  timers:\n",
      "    learn_throughput: 261.019\n",
      "    learn_time_ms: 15324.581\n",
      "    load_throughput: 10157.973\n",
      "    load_time_ms: 393.779\n",
      "    sample_throughput: 8.265\n",
      "    sample_time_ms: 483988.533\n",
      "    update_time_ms: 3.616\n",
      "  timestamp: 1613845504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 133.4\n",
      "  episode_reward_max: 118.36373005371863\n",
      "  episode_reward_mean: 45.9344929154487\n",
      "  episode_reward_min: -107.43915598280276\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1433\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6199125051498413\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01168330293148756\n",
      "        model: {}\n",
      "        policy_loss: -0.09821189194917679\n",
      "        total_loss: 510.17413330078125\n",
      "        vf_explained_var: 0.738914966583252\n",
      "        vf_loss: 510.2457580566406\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 152000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.09030470914127\n",
      "    ram_util_percent: 36.96204986149584\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032787706505493\n",
      "    mean_env_wait_ms: 110.81615481171275\n",
      "    mean_inference_ms: 1.7717424464307339\n",
      "    mean_raw_obs_processing_ms: 11.43692149765393\n",
      "  time_since_restore: 19465.000452041626\n",
      "  time_this_iter_s: 506.2095453739166\n",
      "  time_total_s: 19465.000452041626\n",
      "  timers:\n",
      "    learn_throughput: 261.036\n",
      "    learn_time_ms: 15323.56\n",
      "    load_throughput: 10089.997\n",
      "    load_time_ms: 396.432\n",
      "    sample_throughput: 8.253\n",
      "    sample_time_ms: 484680.927\n",
      "    update_time_ms: 3.594\n",
      "  timestamp: 1613846010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 38\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-41-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.59\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 46.317101289409294\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1464\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6443673968315125\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011803336441516876\n",
      "        model: {}\n",
      "        policy_loss: -0.10504046827554703\n",
      "        total_loss: 382.9107666015625\n",
      "        vf_explained_var: 0.8292127251625061\n",
      "        vf_loss: 382.9889221191406\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.601820728291315\n",
      "    ram_util_percent: 36.94327731092437\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032114966698425\n",
      "    mean_env_wait_ms: 110.8041680554541\n",
      "    mean_inference_ms: 1.7714408506252282\n",
      "    mean_raw_obs_processing_ms: 11.37802606642925\n",
      "  time_since_restore: 19965.705763101578\n",
      "  time_this_iter_s: 500.7053110599518\n",
      "  time_total_s: 19965.705763101578\n",
      "  timers:\n",
      "    learn_throughput: 261.01\n",
      "    learn_time_ms: 15325.089\n",
      "    load_throughput: 10215.797\n",
      "    load_time_ms: 391.55\n",
      "    sample_throughput: 8.26\n",
      "    sample_time_ms: 484282.824\n",
      "    update_time_ms: 3.587\n",
      "  timestamp: 1613846511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-50-10\n",
      "  done: false\n",
      "  episode_len_mean: 131.63\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 54.302023289065644\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1492\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6468275189399719\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011806544847786427\n",
      "        model: {}\n",
      "        policy_loss: -0.11051733046770096\n",
      "        total_loss: 671.3834838867188\n",
      "        vf_explained_var: 0.7356114983558655\n",
      "        vf_loss: 671.4671630859375\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.430294530154285\n",
      "    ram_util_percent: 36.95918653576438\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703123966149883\n",
      "    mean_env_wait_ms: 110.79749318914422\n",
      "    mean_inference_ms: 1.7712056836951258\n",
      "    mean_raw_obs_processing_ms: 11.324981364048007\n",
      "  time_since_restore: 20464.761628866196\n",
      "  time_this_iter_s: 499.0558657646179\n",
      "  time_total_s: 20464.761628866196\n",
      "  timers:\n",
      "    learn_throughput: 260.995\n",
      "    learn_time_ms: 15325.971\n",
      "    load_throughput: 10218.388\n",
      "    load_time_ms: 391.451\n",
      "    sample_throughput: 8.254\n",
      "    sample_time_ms: 484621.248\n",
      "    update_time_ms: 3.575\n",
      "  timestamp: 1613847010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 40\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_19-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 52.70478508017718\n",
      "  episode_reward_min: -107.07387182033435\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1522\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.641582727432251\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011860525235533714\n",
      "        model: {}\n",
      "        policy_loss: -0.10475405305624008\n",
      "        total_loss: 674.5768432617188\n",
      "        vf_explained_var: 0.7677860260009766\n",
      "        vf_loss: 674.654541015625\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.861398601398605\n",
      "    ram_util_percent: 36.989090909090905\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0703088672631849\n",
      "    mean_env_wait_ms: 110.7861624123223\n",
      "    mean_inference_ms: 1.7709939268138148\n",
      "    mean_raw_obs_processing_ms: 11.26685085159765\n",
      "  time_since_restore: 20965.715186834335\n",
      "  time_this_iter_s: 500.95355796813965\n",
      "  time_total_s: 20965.715186834335\n",
      "  timers:\n",
      "    learn_throughput: 260.957\n",
      "    learn_time_ms: 15328.172\n",
      "    load_throughput: 10266.039\n",
      "    load_time_ms: 389.634\n",
      "    sample_throughput: 8.25\n",
      "    sample_time_ms: 484840.9\n",
      "    update_time_ms: 3.537\n",
      "  timestamp: 1613847511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-06-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.94\n",
      "  episode_reward_max: 118.3958968507586\n",
      "  episode_reward_mean: 48.804333945869594\n",
      "  episode_reward_min: -106.32114279569402\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1552\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6589558720588684\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014141380786895752\n",
      "        model: {}\n",
      "        policy_loss: -0.11567607522010803\n",
      "        total_loss: 1036.539306640625\n",
      "        vf_explained_var: 0.7052029967308044\n",
      "        vf_loss: 1036.62255859375\n",
      "    num_steps_sampled: 168000\n",
      "    num_steps_trained: 168000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51076923076923\n",
      "    ram_util_percent: 37.02181818181818\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030557654297072\n",
      "    mean_env_wait_ms: 110.77457488319823\n",
      "    mean_inference_ms: 1.7706725015214595\n",
      "    mean_raw_obs_processing_ms: 11.208994106094684\n",
      "  time_since_restore: 21466.86609196663\n",
      "  time_this_iter_s: 501.1509051322937\n",
      "  time_total_s: 21466.86609196663\n",
      "  timers:\n",
      "    learn_throughput: 260.938\n",
      "    learn_time_ms: 15329.292\n",
      "    load_throughput: 10276.51\n",
      "    load_time_ms: 389.237\n",
      "    sample_throughput: 8.242\n",
      "    sample_time_ms: 485304.007\n",
      "    update_time_ms: 3.501\n",
      "  timestamp: 1613848012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 168000\n",
      "  training_iteration: 42\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 129.75\n",
      "  episode_reward_max: 118.37743755854237\n",
      "  episode_reward_mean: 40.85230381990975\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 1586\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6482423543930054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013159703463315964\n",
      "        model: {}\n",
      "        policy_loss: -0.11065053939819336\n",
      "        total_loss: 1050.6982421875\n",
      "        vf_explained_var: 0.6948574781417847\n",
      "        vf_loss: 1050.77880859375\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.62097222222222\n",
      "    ram_util_percent: 36.95305555555555\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07030399131913781\n",
      "    mean_env_wait_ms: 110.7607417073646\n",
      "    mean_inference_ms: 1.7702370076517295\n",
      "    mean_raw_obs_processing_ms: 11.158182205607885\n",
      "  time_since_restore: 21971.43261051178\n",
      "  time_this_iter_s: 504.56651854515076\n",
      "  time_total_s: 21971.43261051178\n",
      "  timers:\n",
      "    learn_throughput: 260.953\n",
      "    learn_time_ms: 15328.46\n",
      "    load_throughput: 10343.974\n",
      "    load_time_ms: 386.699\n",
      "    sample_throughput: 8.235\n",
      "    sample_time_ms: 485719.358\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613848517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-23-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.15\n",
      "  episode_reward_max: 118.37543209998196\n",
      "  episode_reward_mean: 42.897584452962874\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1615\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6413830518722534\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010721690952777863\n",
      "        model: {}\n",
      "        policy_loss: -0.09945659339427948\n",
      "        total_loss: 531.45947265625\n",
      "        vf_explained_var: 0.7469833493232727\n",
      "        vf_loss: 531.5345458984375\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 176000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49859943977591\n",
      "    ram_util_percent: 36.96624649859944\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029959625995104\n",
      "    mean_env_wait_ms: 110.7510495015338\n",
      "    mean_inference_ms: 1.7698440937330673\n",
      "    mean_raw_obs_processing_ms: 11.118542366978442\n",
      "  time_since_restore: 22471.852631807327\n",
      "  time_this_iter_s: 500.4200212955475\n",
      "  time_total_s: 22471.852631807327\n",
      "  timers:\n",
      "    learn_throughput: 260.93\n",
      "    learn_time_ms: 15329.771\n",
      "    load_throughput: 10357.307\n",
      "    load_time_ms: 386.201\n",
      "    sample_throughput: 8.237\n",
      "    sample_time_ms: 485618.441\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613849017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 44\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 130.06\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 62.065262610967785\n",
      "  episode_reward_min: -105.6278206838217\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1645\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6233407258987427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00898065697401762\n",
      "        model: {}\n",
      "        policy_loss: -0.08020798116922379\n",
      "        total_loss: 356.6605529785156\n",
      "        vf_explained_var: 0.7845202088356018\n",
      "        vf_loss: 356.7203369140625\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57478991596639\n",
      "    ram_util_percent: 36.95280112044817\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702960367516641\n",
      "    mean_env_wait_ms: 110.74041825539024\n",
      "    mean_inference_ms: 1.7694404392189858\n",
      "    mean_raw_obs_processing_ms: 11.07920669127588\n",
      "  time_since_restore: 22972.452386140823\n",
      "  time_this_iter_s: 500.5997543334961\n",
      "  time_total_s: 22972.452386140823\n",
      "  timers:\n",
      "    learn_throughput: 260.929\n",
      "    learn_time_ms: 15329.818\n",
      "    load_throughput: 10425.457\n",
      "    load_time_ms: 383.676\n",
      "    sample_throughput: 8.243\n",
      "    sample_time_ms: 485266.468\n",
      "    update_time_ms: 3.686\n",
      "  timestamp: 1613849518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-40-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.84\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 59.985331006414555\n",
      "  episode_reward_min: -101.4588881123555\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1673\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6626541614532471\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012667709030210972\n",
      "        model: {}\n",
      "        policy_loss: -0.11400982737541199\n",
      "        total_loss: 800.5023803710938\n",
      "        vf_explained_var: 0.7248692512512207\n",
      "        vf_loss: 800.5874633789062\n",
      "    num_steps_sampled: 184000\n",
      "    num_steps_trained: 184000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.70496551724138\n",
      "    ram_util_percent: 37.08303448275863\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029657900746815\n",
      "    mean_env_wait_ms: 110.74568080511251\n",
      "    mean_inference_ms: 1.769301121008906\n",
      "    mean_raw_obs_processing_ms: 11.034907993071792\n",
      "  time_since_restore: 23480.277863502502\n",
      "  time_this_iter_s: 507.8254773616791\n",
      "  time_total_s: 23480.277863502502\n",
      "  timers:\n",
      "    learn_throughput: 260.852\n",
      "    learn_time_ms: 15334.355\n",
      "    load_throughput: 10488.971\n",
      "    load_time_ms: 381.353\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486377.911\n",
      "    update_time_ms: 3.724\n",
      "  timestamp: 1613850026\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 184000\n",
      "  training_iteration: 46\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 144.04\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 74.52875837504715\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 1698\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6407293677330017\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009831038303673267\n",
      "        model: {}\n",
      "        policy_loss: -0.08865351229906082\n",
      "        total_loss: 250.5148468017578\n",
      "        vf_explained_var: 0.8557254076004028\n",
      "        vf_loss: 250.5811004638672\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53465346534654\n",
      "    ram_util_percent: 37.012588401697315\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029727781938253\n",
      "    mean_env_wait_ms: 110.74992239858908\n",
      "    mean_inference_ms: 1.7692241671302469\n",
      "    mean_raw_obs_processing_ms: 10.985394316609364\n",
      "  time_since_restore: 23975.74490594864\n",
      "  time_this_iter_s: 495.4670424461365\n",
      "  time_total_s: 23975.74490594864\n",
      "  timers:\n",
      "    learn_throughput: 260.761\n",
      "    learn_time_ms: 15339.736\n",
      "    load_throughput: 10497.116\n",
      "    load_time_ms: 381.057\n",
      "    sample_throughput: 8.234\n",
      "    sample_time_ms: 485815.988\n",
      "    update_time_ms: 3.755\n",
      "  timestamp: 1613850522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_20-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 142.98\n",
      "  episode_reward_max: 118.38189377218501\n",
      "  episode_reward_mean: 67.98287444602884\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1727\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6419114470481873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008923264220356941\n",
      "        model: {}\n",
      "        policy_loss: -0.0866682380437851\n",
      "        total_loss: 338.417236328125\n",
      "        vf_explained_var: 0.8316975831985474\n",
      "        vf_loss: 338.4835510253906\n",
      "    num_steps_sampled: 192000\n",
      "    num_steps_trained: 192000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.60056179775281\n",
      "    ram_util_percent: 37.017977528089894\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702983928846514\n",
      "    mean_env_wait_ms: 110.75403191743374\n",
      "    mean_inference_ms: 1.7691664603468693\n",
      "    mean_raw_obs_processing_ms: 10.928172516827154\n",
      "  time_since_restore: 24475.107447862625\n",
      "  time_this_iter_s: 499.3625419139862\n",
      "  time_total_s: 24475.107447862625\n",
      "  timers:\n",
      "    learn_throughput: 260.765\n",
      "    learn_time_ms: 15339.472\n",
      "    load_throughput: 10453.94\n",
      "    load_time_ms: 382.631\n",
      "    sample_throughput: 8.245\n",
      "    sample_time_ms: 485125.038\n",
      "    update_time_ms: 3.776\n",
      "  timestamp: 1613851021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 192000\n",
      "  training_iteration: 48\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-05-20\n",
      "  done: false\n",
      "  episode_len_mean: 148.73\n",
      "  episode_reward_max: 118.37884731579629\n",
      "  episode_reward_mean: 67.8799255374538\n",
      "  episode_reward_min: -106.34779912746163\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1754\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.636057436466217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009555695578455925\n",
      "        model: {}\n",
      "        policy_loss: -0.08797115087509155\n",
      "        total_loss: 359.5047607421875\n",
      "        vf_explained_var: 0.8124749064445496\n",
      "        vf_loss: 359.57098388671875\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.45519662921349\n",
      "    ram_util_percent: 37.0685393258427\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029628939055829\n",
      "    mean_env_wait_ms: 110.75578300235905\n",
      "    mean_inference_ms: 1.7690876277659227\n",
      "    mean_raw_obs_processing_ms: 10.871889056857041\n",
      "  time_since_restore: 24973.8474817276\n",
      "  time_this_iter_s: 498.740033864975\n",
      "  time_total_s: 24973.8474817276\n",
      "  timers:\n",
      "    learn_throughput: 260.758\n",
      "    learn_time_ms: 15339.912\n",
      "    load_throughput: 10499.603\n",
      "    load_time_ms: 380.967\n",
      "    sample_throughput: 8.249\n",
      "    sample_time_ms: 484929.998\n",
      "    update_time_ms: 3.814\n",
      "  timestamp: 1613851520\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 144.17\n",
      "  episode_reward_max: 118.39421396908376\n",
      "  episode_reward_mean: 63.92768333430419\n",
      "  episode_reward_min: -105.11605887423045\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 1783\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6578298211097717\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013607810251414776\n",
      "        model: {}\n",
      "        policy_loss: -0.12195522338151932\n",
      "        total_loss: 667.0701904296875\n",
      "        vf_explained_var: 0.7740439176559448\n",
      "        vf_loss: 667.1612548828125\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.572230014025244\n",
      "    ram_util_percent: 37.04431977559607\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029345552180817\n",
      "    mean_env_wait_ms: 110.74755407693898\n",
      "    mean_inference_ms: 1.7689476389640095\n",
      "    mean_raw_obs_processing_ms: 10.817247726676902\n",
      "  time_since_restore: 25473.063342809677\n",
      "  time_this_iter_s: 499.215861082077\n",
      "  time_total_s: 25473.063342809677\n",
      "  timers:\n",
      "    learn_throughput: 260.76\n",
      "    learn_time_ms: 15339.749\n",
      "    load_throughput: 10514.559\n",
      "    load_time_ms: 380.425\n",
      "    sample_throughput: 8.248\n",
      "    sample_time_ms: 484944.65\n",
      "    update_time_ms: 3.846\n",
      "  timestamp: 1613852019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 50\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-21-58\n",
      "  done: false\n",
      "  episode_len_mean: 142.79\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.382111297120936\n",
      "  episode_reward_min: -105.11605887423045\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 1811\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6633873581886292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011062879115343094\n",
      "        model: {}\n",
      "        policy_loss: -0.1058695986866951\n",
      "        total_loss: 324.61956787109375\n",
      "        vf_explained_var: 0.883109450340271\n",
      "        vf_loss: 324.7002868652344\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.56047819971871\n",
      "    ram_util_percent: 37.102390998593535\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0702925175851268\n",
      "    mean_env_wait_ms: 110.73998913003665\n",
      "    mean_inference_ms: 1.768822287760936\n",
      "    mean_raw_obs_processing_ms: 10.771063188632224\n",
      "  time_since_restore: 25971.54581975937\n",
      "  time_this_iter_s: 498.4824769496918\n",
      "  time_total_s: 25971.54581975937\n",
      "  timers:\n",
      "    learn_throughput: 260.797\n",
      "    learn_time_ms: 15337.601\n",
      "    load_throughput: 10527.517\n",
      "    load_time_ms: 379.957\n",
      "    sample_throughput: 8.253\n",
      "    sample_time_ms: 484701.47\n",
      "    update_time_ms: 3.849\n",
      "  timestamp: 1613852518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 133.19\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.00244247417059\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1844\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.650313138961792\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009966370649635792\n",
      "        model: {}\n",
      "        policy_loss: -0.09712912142276764\n",
      "        total_loss: 640.95947265625\n",
      "        vf_explained_var: 0.7460017800331116\n",
      "        vf_loss: 641.033935546875\n",
      "    num_steps_sampled: 208000\n",
      "    num_steps_trained: 208000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71061452513966\n",
      "    ram_util_percent: 37.14916201117319\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07028977365919233\n",
      "    mean_env_wait_ms: 110.72607899184827\n",
      "    mean_inference_ms: 1.7686210479903621\n",
      "    mean_raw_obs_processing_ms: 10.728863856971861\n",
      "  time_since_restore: 26472.941111803055\n",
      "  time_this_iter_s: 501.3952920436859\n",
      "  time_total_s: 26472.941111803055\n",
      "  timers:\n",
      "    learn_throughput: 260.83\n",
      "    learn_time_ms: 15335.64\n",
      "    load_throughput: 10540.876\n",
      "    load_time_ms: 379.475\n",
      "    sample_throughput: 8.252\n",
      "    sample_time_ms: 484724.861\n",
      "    update_time_ms: 3.85\n",
      "  timestamp: 1613853019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 208000\n",
      "  training_iteration: 52\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-38-49\n",
      "  done: false\n",
      "  episode_len_mean: 132.54\n",
      "  episode_reward_max: 118.39693910591514\n",
      "  episode_reward_mean: 59.091052037477894\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6425826549530029\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011709527112543583\n",
      "        model: {}\n",
      "        policy_loss: -0.10362938046455383\n",
      "        total_loss: 691.9244995117188\n",
      "        vf_explained_var: 0.7485781908035278\n",
      "        vf_loss: 692.0013427734375\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.53287482806053\n",
      "    ram_util_percent: 37.163273727647876\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07029267823481428\n",
      "    mean_env_wait_ms: 110.72434566450103\n",
      "    mean_inference_ms: 1.7685486715322718\n",
      "    mean_raw_obs_processing_ms: 10.697146182569476\n",
      "  time_since_restore: 26982.726992607117\n",
      "  time_this_iter_s: 509.7858808040619\n",
      "  time_total_s: 26982.726992607117\n",
      "  timers:\n",
      "    learn_throughput: 258.57\n",
      "    learn_time_ms: 15469.72\n",
      "    load_throughput: 10456.634\n",
      "    load_time_ms: 382.532\n",
      "    sample_throughput: 8.246\n",
      "    sample_time_ms: 485101.827\n",
      "    update_time_ms: 3.818\n",
      "  timestamp: 1613853529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-47-38\n",
      "  done: false\n",
      "  episode_len_mean: 128.61\n",
      "  episode_reward_max: 118.3323445817829\n",
      "  episode_reward_mean: 65.39139703471686\n",
      "  episode_reward_min: -107.14513596437897\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 1905\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6302710175514221\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008997817523777485\n",
      "        model: {}\n",
      "        policy_loss: -0.08477241545915604\n",
      "        total_loss: 500.035400390625\n",
      "        vf_explained_var: 0.7220929861068726\n",
      "        vf_loss: 500.0996398925781\n",
      "    num_steps_sampled: 216000\n",
      "    num_steps_trained: 216000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.83245033112583\n",
      "    ram_util_percent: 37.139602649006626\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07032062926629683\n",
      "    mean_env_wait_ms: 110.75891469656686\n",
      "    mean_inference_ms: 1.7687999750663093\n",
      "    mean_raw_obs_processing_ms: 10.670978443075951\n",
      "  time_since_restore: 27511.451284885406\n",
      "  time_this_iter_s: 528.7242922782898\n",
      "  time_total_s: 27511.451284885406\n",
      "  timers:\n",
      "    learn_throughput: 256.256\n",
      "    learn_time_ms: 15609.362\n",
      "    load_throughput: 10477.919\n",
      "    load_time_ms: 381.755\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487789.587\n",
      "    update_time_ms: 3.665\n",
      "  timestamp: 1613854058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 216000\n",
      "  training_iteration: 54\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_21-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 133.35\n",
      "  episode_reward_max: 118.38506214263124\n",
      "  episode_reward_mean: 65.80513212460696\n",
      "  episode_reward_min: -106.74443176576358\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 1935\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6315209865570068\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010787761770188808\n",
      "        model: {}\n",
      "        policy_loss: -0.09967464208602905\n",
      "        total_loss: 428.6216735839844\n",
      "        vf_explained_var: 0.8370494842529297\n",
      "        vf_loss: 428.6967468261719\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.20964332892999\n",
      "    ram_util_percent: 37.19075297225891\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07037049189297422\n",
      "    mean_env_wait_ms: 110.83342209570523\n",
      "    mean_inference_ms: 1.769447076085045\n",
      "    mean_raw_obs_processing_ms: 10.645196327199976\n",
      "  time_since_restore: 28042.300265789032\n",
      "  time_this_iter_s: 530.8489809036255\n",
      "  time_total_s: 28042.300265789032\n",
      "  timers:\n",
      "    learn_throughput: 254.037\n",
      "    learn_time_ms: 15745.751\n",
      "    load_throughput: 10468.624\n",
      "    load_time_ms: 382.094\n",
      "    sample_throughput: 8.152\n",
      "    sample_time_ms: 490678.066\n",
      "    update_time_ms: 3.695\n",
      "  timestamp: 1613854589\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-05-14\n",
      "  done: false\n",
      "  episode_len_mean: 126.14\n",
      "  episode_reward_max: 118.38506214263124\n",
      "  episode_reward_mean: 55.31096174174058\n",
      "  episode_reward_min: -106.74443176576358\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 1968\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6478879451751709\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013791813515126705\n",
      "        model: {}\n",
      "        policy_loss: -0.12108524143695831\n",
      "        total_loss: 1167.9112548828125\n",
      "        vf_explained_var: 0.663340151309967\n",
      "        vf_loss: 1168.000732421875\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 224000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.46315086782377\n",
      "    ram_util_percent: 37.16234979973297\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07043649977748466\n",
      "    mean_env_wait_ms: 110.93319091066641\n",
      "    mean_inference_ms: 1.770354065129902\n",
      "    mean_raw_obs_processing_ms: 10.622040529207887\n",
      "  time_since_restore: 28566.90573167801\n",
      "  time_this_iter_s: 524.605465888977\n",
      "  time_total_s: 28566.90573167801\n",
      "  timers:\n",
      "    learn_throughput: 252.023\n",
      "    learn_time_ms: 15871.551\n",
      "    load_throughput: 10398.317\n",
      "    load_time_ms: 384.678\n",
      "    sample_throughput: 8.126\n",
      "    sample_time_ms: 492226.153\n",
      "    update_time_ms: 3.722\n",
      "  timestamp: 1613855114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 56\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-13-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.33\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 68.16007260489052\n",
      "  episode_reward_min: -101.23240739758147\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 1995\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6253086924552917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00979804340749979\n",
      "        model: {}\n",
      "        policy_loss: -0.09172672033309937\n",
      "        total_loss: 141.4500732421875\n",
      "        vf_explained_var: 0.8915672898292542\n",
      "        vf_loss: 141.51947021484375\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.003099730458224\n",
      "    ram_util_percent: 37.12250673854448\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07047223222355245\n",
      "    mean_env_wait_ms: 111.01302383516594\n",
      "    mean_inference_ms: 1.7708231004163704\n",
      "    mean_raw_obs_processing_ms: 10.59936403226933\n",
      "  time_since_restore: 29086.573880910873\n",
      "  time_this_iter_s: 519.6681492328644\n",
      "  time_total_s: 29086.573880910873\n",
      "  timers:\n",
      "    learn_throughput: 252.296\n",
      "    learn_time_ms: 15854.379\n",
      "    load_throughput: 10465.866\n",
      "    load_time_ms: 382.195\n",
      "    sample_throughput: 8.086\n",
      "    sample_time_ms: 494666.712\n",
      "    update_time_ms: 3.682\n",
      "  timestamp: 1613855634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-23-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.2\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 66.33935965107635\n",
      "  episode_reward_min: -101.23240739758147\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2023\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6489342451095581\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012554348446428776\n",
      "        model: {}\n",
      "        policy_loss: -0.11330427974462509\n",
      "        total_loss: 1351.4207763671875\n",
      "        vf_explained_var: 0.45022523403167725\n",
      "        vf_loss: 1351.5054931640625\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 232000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.32729498164015\n",
      "    ram_util_percent: 37.1123623011016\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07046659993996357\n",
      "    mean_env_wait_ms: 111.15418143970867\n",
      "    mean_inference_ms: 1.7705213443087429\n",
      "    mean_raw_obs_processing_ms: 10.57231127310461\n",
      "  time_since_restore: 29659.22930073738\n",
      "  time_this_iter_s: 572.6554198265076\n",
      "  time_total_s: 29659.22930073738\n",
      "  timers:\n",
      "    learn_throughput: 252.608\n",
      "    learn_time_ms: 15834.826\n",
      "    load_throughput: 10554.629\n",
      "    load_time_ms: 378.981\n",
      "    sample_throughput: 7.968\n",
      "    sample_time_ms: 502023.27\n",
      "    update_time_ms: 3.668\n",
      "  timestamp: 1613856206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 58\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 141.39\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 70.29793638788594\n",
      "  episode_reward_min: -100.23973123547925\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2050\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6639514565467834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010656061582267284\n",
      "        model: {}\n",
      "        policy_loss: -0.10116995871067047\n",
      "        total_loss: 572.2363891601562\n",
      "        vf_explained_var: 0.7428793907165527\n",
      "        vf_loss: 572.3132934570312\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.33382352941177\n",
      "    ram_util_percent: 37.13541666666668\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07042244921524958\n",
      "    mean_env_wait_ms: 111.34900230644934\n",
      "    mean_inference_ms: 1.7695008968193702\n",
      "    mean_raw_obs_processing_ms: 10.539710406986257\n",
      "  time_since_restore: 30230.81455373764\n",
      "  time_this_iter_s: 571.5852530002594\n",
      "  time_total_s: 30230.81455373764\n",
      "  timers:\n",
      "    learn_throughput: 252.938\n",
      "    learn_time_ms: 15814.134\n",
      "    load_throughput: 10533.311\n",
      "    load_time_ms: 379.748\n",
      "    sample_throughput: 7.853\n",
      "    sample_time_ms: 509327.434\n",
      "    update_time_ms: 3.716\n",
      "  timestamp: 1613856778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 141.34\n",
      "  episode_reward_max: 118.39686184711292\n",
      "  episode_reward_mean: 74.43891614908803\n",
      "  episode_reward_min: -99.9359350861686\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 2081\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.660055935382843\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010436595417559147\n",
      "        model: {}\n",
      "        policy_loss: -0.10442720353603363\n",
      "        total_loss: 374.71368408203125\n",
      "        vf_explained_var: 0.8304740190505981\n",
      "        vf_loss: 374.7943115234375\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.46243902439024\n",
      "    ram_util_percent: 37.222682926829265\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07033987487465286\n",
      "    mean_env_wait_ms: 111.63979372562945\n",
      "    mean_inference_ms: 1.7676407091750688\n",
      "    mean_raw_obs_processing_ms: 10.503065870075869\n",
      "  time_since_restore: 30805.672479391098\n",
      "  time_this_iter_s: 574.8579256534576\n",
      "  time_total_s: 30805.672479391098\n",
      "  timers:\n",
      "    learn_throughput: 253.234\n",
      "    learn_time_ms: 15795.638\n",
      "    load_throughput: 10549.057\n",
      "    load_time_ms: 379.181\n",
      "    sample_throughput: 7.738\n",
      "    sample_time_ms: 516912.277\n",
      "    update_time_ms: 3.702\n",
      "  timestamp: 1613857353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 60\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_22-52-05\n",
      "  done: false\n",
      "  episode_len_mean: 141.05\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 70.01738176891863\n",
      "  episode_reward_min: -105.68695967977602\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2109\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6409180164337158\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011094327084720135\n",
      "        model: {}\n",
      "        policy_loss: -0.09974440932273865\n",
      "        total_loss: 499.4038391113281\n",
      "        vf_explained_var: 0.801602303981781\n",
      "        vf_loss: 499.4782409667969\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38492647058823\n",
      "    ram_util_percent: 37.204779411764704\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07025371107998246\n",
      "    mean_env_wait_ms: 111.92239434537707\n",
      "    mean_inference_ms: 1.7657413100059511\n",
      "    mean_raw_obs_processing_ms: 10.472746551317464\n",
      "  time_since_restore: 31377.506068468094\n",
      "  time_this_iter_s: 571.8335890769958\n",
      "  time_total_s: 31377.506068468094\n",
      "  timers:\n",
      "    learn_throughput: 253.487\n",
      "    learn_time_ms: 15779.897\n",
      "    load_throughput: 10510.437\n",
      "    load_time_ms: 380.574\n",
      "    sample_throughput: 7.63\n",
      "    sample_time_ms: 524260.903\n",
      "    update_time_ms: 3.69\n",
      "  timestamp: 1613857925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 141.05\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 71.77740101151602\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2137\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.647716224193573\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011794942431151867\n",
      "        model: {}\n",
      "        policy_loss: -0.10908807814121246\n",
      "        total_loss: 351.6716003417969\n",
      "        vf_explained_var: 0.8702437281608582\n",
      "        vf_loss: 351.75384521484375\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 248000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38235294117647\n",
      "    ram_util_percent: 37.1375\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07017104526738993\n",
      "    mean_env_wait_ms: 112.1944696480094\n",
      "    mean_inference_ms: 1.7639460613750333\n",
      "    mean_raw_obs_processing_ms: 10.444230884135225\n",
      "  time_since_restore: 31949.255333185196\n",
      "  time_this_iter_s: 571.749264717102\n",
      "  time_total_s: 31949.255333185196\n",
      "  timers:\n",
      "    learn_throughput: 253.781\n",
      "    learn_time_ms: 15761.617\n",
      "    load_throughput: 10554.807\n",
      "    load_time_ms: 378.974\n",
      "    sample_throughput: 7.528\n",
      "    sample_time_ms: 531319.258\n",
      "    update_time_ms: 3.698\n",
      "  timestamp: 1613858497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 62\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 137.19\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 59.12739302951584\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 2168\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6523399353027344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015450678765773773\n",
      "        model: {}\n",
      "        policy_loss: -0.13272224366664886\n",
      "        total_loss: 956.6912841796875\n",
      "        vf_explained_var: 0.767768144607544\n",
      "        vf_loss: 956.7888793945312\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.49\n",
      "    ram_util_percent: 37.12756097560976\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07008540600133706\n",
      "    mean_env_wait_ms: 112.47689126731144\n",
      "    mean_inference_ms: 1.7620962489760057\n",
      "    mean_raw_obs_processing_ms: 10.417165729232902\n",
      "  time_since_restore: 32523.346776008606\n",
      "  time_this_iter_s: 574.09144282341\n",
      "  time_total_s: 32523.346776008606\n",
      "  timers:\n",
      "    learn_throughput: 256.26\n",
      "    learn_time_ms: 15609.142\n",
      "    load_throughput: 10676.985\n",
      "    load_time_ms: 374.638\n",
      "    sample_throughput: 7.436\n",
      "    sample_time_ms: 537915.417\n",
      "    update_time_ms: 3.694\n",
      "  timestamp: 1613859071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 136.33\n",
      "  episode_reward_max: 118.37612607047315\n",
      "  episode_reward_mean: 55.33395688133094\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2198\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6516956686973572\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0131781455129385\n",
      "        model: {}\n",
      "        policy_loss: -0.11240272223949432\n",
      "        total_loss: 1057.59326171875\n",
      "        vf_explained_var: 0.663433849811554\n",
      "        vf_loss: 1057.675537109375\n",
      "    num_steps_sampled: 256000\n",
      "    num_steps_trained: 256000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.41907090464548\n",
      "    ram_util_percent: 37.134229828850856\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07000277572387784\n",
      "    mean_env_wait_ms: 112.7419967737489\n",
      "    mean_inference_ms: 1.760387598784\n",
      "    mean_raw_obs_processing_ms: 10.393010508156653\n",
      "  time_since_restore: 33097.06607270241\n",
      "  time_this_iter_s: 573.7192966938019\n",
      "  time_total_s: 33097.06607270241\n",
      "  timers:\n",
      "    learn_throughput: 258.926\n",
      "    learn_time_ms: 15448.431\n",
      "    load_throughput: 10711.259\n",
      "    load_time_ms: 373.439\n",
      "    sample_throughput: 7.372\n",
      "    sample_time_ms: 542579.658\n",
      "    update_time_ms: 3.673\n",
      "  timestamp: 1613859645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 256000\n",
      "  training_iteration: 64\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-30-17\n",
      "  done: false\n",
      "  episode_len_mean: 137.77\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 53.52548591209393\n",
      "  episode_reward_min: -106.74472136491764\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2224\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6383890509605408\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011560847982764244\n",
      "        model: {}\n",
      "        policy_loss: -0.11173100769519806\n",
      "        total_loss: 480.3727722167969\n",
      "        vf_explained_var: 0.7947722673416138\n",
      "        vf_loss: 480.45819091796875\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.11481028151774\n",
      "    ram_util_percent: 37.14039167686659\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06993340126743414\n",
      "    mean_env_wait_ms: 112.96682997525554\n",
      "    mean_inference_ms: 1.7589298887241482\n",
      "    mean_raw_obs_processing_ms: 10.37049473048591\n",
      "  time_since_restore: 33669.42586064339\n",
      "  time_this_iter_s: 572.359787940979\n",
      "  time_total_s: 33669.42586064339\n",
      "  timers:\n",
      "    learn_throughput: 261.575\n",
      "    learn_time_ms: 15291.97\n",
      "    load_throughput: 10783.415\n",
      "    load_time_ms: 370.94\n",
      "    sample_throughput: 7.314\n",
      "    sample_time_ms: 546890.711\n",
      "    update_time_ms: 3.698\n",
      "  timestamp: 1613860217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-39-47\n",
      "  done: false\n",
      "  episode_len_mean: 146.28\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 53.7095330284575\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2249\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6173250079154968\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011564599350094795\n",
      "        model: {}\n",
      "        policy_loss: -0.10615907609462738\n",
      "        total_loss: 386.08203125\n",
      "        vf_explained_var: 0.8317555785179138\n",
      "        vf_loss: 386.1618957519531\n",
      "    num_steps_sampled: 264000\n",
      "    num_steps_trained: 264000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.330996309963105\n",
      "    ram_util_percent: 37.14329643296433\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06986738502176004\n",
      "    mean_env_wait_ms: 113.1841719552211\n",
      "    mean_inference_ms: 1.7575292602693813\n",
      "    mean_raw_obs_processing_ms: 10.344066500444315\n",
      "  time_since_restore: 34238.99902796745\n",
      "  time_this_iter_s: 569.5731673240662\n",
      "  time_total_s: 34238.99902796745\n",
      "  timers:\n",
      "    learn_throughput: 264.128\n",
      "    learn_time_ms: 15144.152\n",
      "    load_throughput: 10874.314\n",
      "    load_time_ms: 367.839\n",
      "    sample_throughput: 7.252\n",
      "    sample_time_ms: 551540.589\n",
      "    update_time_ms: 3.637\n",
      "  timestamp: 1613860787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 264000\n",
      "  training_iteration: 66\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 153.63\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 72.57427585311832\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2274\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6286678314208984\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009843600913882256\n",
      "        model: {}\n",
      "        policy_loss: -0.09355968236923218\n",
      "        total_loss: 192.63748168945312\n",
      "        vf_explained_var: 0.8682405948638916\n",
      "        vf_loss: 192.7086181640625\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.22223587223587\n",
      "    ram_util_percent: 37.13353808353809\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06979846207047757\n",
      "    mean_env_wait_ms: 113.41209413425135\n",
      "    mean_inference_ms: 1.7561167436421823\n",
      "    mean_raw_obs_processing_ms: 10.311088908911454\n",
      "  time_since_restore: 34809.06482720375\n",
      "  time_this_iter_s: 570.0657992362976\n",
      "  time_total_s: 34809.06482720375\n",
      "  timers:\n",
      "    learn_throughput: 264.182\n",
      "    learn_time_ms: 15141.078\n",
      "    load_throughput: 10717.712\n",
      "    load_time_ms: 373.214\n",
      "    sample_throughput: 7.187\n",
      "    sample_time_ms: 556576.911\n",
      "    update_time_ms: 3.653\n",
      "  timestamp: 1613861357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-20_23-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 156.83\n",
      "  episode_reward_max: 118.39154367729488\n",
      "  episode_reward_mean: 72.23397259447046\n",
      "  episode_reward_min: -107.53358028733636\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2300\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.631923258304596\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011478865519165993\n",
      "        model: {}\n",
      "        policy_loss: -0.09653747826814651\n",
      "        total_loss: 591.7462158203125\n",
      "        vf_explained_var: 0.7493155002593994\n",
      "        vf_loss: 591.816650390625\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 272000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.23815950920246\n",
      "    ram_util_percent: 37.20539877300614\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06972687405379784\n",
      "    mean_env_wait_ms: 113.6544200247218\n",
      "    mean_inference_ms: 1.7546103799009267\n",
      "    mean_raw_obs_processing_ms: 10.272346092030155\n",
      "  time_since_restore: 35380.29538941383\n",
      "  time_this_iter_s: 571.230562210083\n",
      "  time_total_s: 35380.29538941383\n",
      "  timers:\n",
      "    learn_throughput: 264.19\n",
      "    learn_time_ms: 15140.642\n",
      "    load_throughput: 10734.354\n",
      "    load_time_ms: 372.635\n",
      "    sample_throughput: 7.189\n",
      "    sample_time_ms: 556435.211\n",
      "    update_time_ms: 3.696\n",
      "  timestamp: 1613861928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 68\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 153.58\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 76.41749330845737\n",
      "  episode_reward_min: -100.56077546933885\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2329\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.642822802066803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01272502075880766\n",
      "        model: {}\n",
      "        policy_loss: -0.10968878120183945\n",
      "        total_loss: 596.0990600585938\n",
      "        vf_explained_var: 0.8381652235984802\n",
      "        vf_loss: 596.1798095703125\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.50269277845777\n",
      "    ram_util_percent: 37.21064871481028\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06965382674759313\n",
      "    mean_env_wait_ms: 113.90630316099855\n",
      "    mean_inference_ms: 1.7530769794469412\n",
      "    mean_raw_obs_processing_ms: 10.235387185274998\n",
      "  time_since_restore: 35952.65245747566\n",
      "  time_this_iter_s: 572.3570680618286\n",
      "  time_total_s: 35952.65245747566\n",
      "  timers:\n",
      "    learn_throughput: 264.188\n",
      "    learn_time_ms: 15140.748\n",
      "    load_throughput: 10743.574\n",
      "    load_time_ms: 372.316\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556512.121\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1613862501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 146.37\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 72.25315348460688\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2357\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6185662150382996\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00849862489849329\n",
      "        model: {}\n",
      "        policy_loss: -0.08290470391511917\n",
      "        total_loss: 276.4397888183594\n",
      "        vf_explained_var: 0.8126450777053833\n",
      "        vf_loss: 276.5033264160156\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28716381418093\n",
      "    ram_util_percent: 37.147432762836196\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06958714884610312\n",
      "    mean_env_wait_ms: 114.13442536546694\n",
      "    mean_inference_ms: 1.7516627542151186\n",
      "    mean_raw_obs_processing_ms: 10.205676917041576\n",
      "  time_since_restore: 36525.324548244476\n",
      "  time_this_iter_s: 572.6720907688141\n",
      "  time_total_s: 36525.324548244476\n",
      "  timers:\n",
      "    learn_throughput: 264.169\n",
      "    learn_time_ms: 15141.83\n",
      "    load_throughput: 10747.316\n",
      "    load_time_ms: 372.186\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556292.137\n",
      "    update_time_ms: 3.573\n",
      "  timestamp: 1613863074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 70\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 138.47\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 70.33908638281463\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2387\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.620513916015625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0102561479434371\n",
      "        model: {}\n",
      "        policy_loss: -0.09688905626535416\n",
      "        total_loss: 486.55255126953125\n",
      "        vf_explained_var: 0.7785946130752563\n",
      "        vf_loss: 486.62603759765625\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.37048780487805\n",
      "    ram_util_percent: 37.14780487804879\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06952000873593146\n",
      "    mean_env_wait_ms: 114.36072750793537\n",
      "    mean_inference_ms: 1.7502122374436757\n",
      "    mean_raw_obs_processing_ms: 10.18208803001135\n",
      "  time_since_restore: 37100.08389925957\n",
      "  time_this_iter_s: 574.7593510150909\n",
      "  time_total_s: 37100.08389925957\n",
      "  timers:\n",
      "    learn_throughput: 264.18\n",
      "    learn_time_ms: 15141.198\n",
      "    load_throughput: 10789.537\n",
      "    load_time_ms: 370.73\n",
      "    sample_throughput: 7.187\n",
      "    sample_time_ms: 556585.99\n",
      "    update_time_ms: 3.57\n",
      "  timestamp: 1613863649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-37-00\n",
      "  done: false\n",
      "  episode_len_mean: 139.74\n",
      "  episode_reward_max: 118.39008429300002\n",
      "  episode_reward_mean: 76.67791844425611\n",
      "  episode_reward_min: -106.2353593540642\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2413\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6387255787849426\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009160628542304039\n",
      "        model: {}\n",
      "        policy_loss: -0.08888468146324158\n",
      "        total_loss: 340.0338439941406\n",
      "        vf_explained_var: 0.8237649202346802\n",
      "        vf_loss: 340.10186767578125\n",
      "    num_steps_sampled: 288000\n",
      "    num_steps_trained: 288000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28171779141104\n",
      "    ram_util_percent: 37.229325153374226\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06946422410688925\n",
      "    mean_env_wait_ms: 114.54833315283351\n",
      "    mean_inference_ms: 1.7490402840484245\n",
      "    mean_raw_obs_processing_ms: 10.161260996546233\n",
      "  time_since_restore: 37671.0840651989\n",
      "  time_this_iter_s: 571.000165939331\n",
      "  time_total_s: 37671.0840651989\n",
      "  timers:\n",
      "    learn_throughput: 264.143\n",
      "    learn_time_ms: 15143.286\n",
      "    load_throughput: 10806.218\n",
      "    load_time_ms: 370.157\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556508.3\n",
      "    update_time_ms: 3.563\n",
      "  timestamp: 1613864220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 288000\n",
      "  training_iteration: 72\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-46-33\n",
      "  done: false\n",
      "  episode_len_mean: 143.7\n",
      "  episode_reward_max: 118.38248894924733\n",
      "  episode_reward_mean: 68.12918005097758\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2441\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6250879764556885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012200719676911831\n",
      "        model: {}\n",
      "        policy_loss: -0.09789183735847473\n",
      "        total_loss: 1297.644287109375\n",
      "        vf_explained_var: 0.42024028301239014\n",
      "        vf_loss: 1297.71435546875\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.3661369193154\n",
      "    ram_util_percent: 37.14352078239609\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06940225042377678\n",
      "    mean_env_wait_ms: 114.75023934436805\n",
      "    mean_inference_ms: 1.747791142768952\n",
      "    mean_raw_obs_processing_ms: 10.138264605055625\n",
      "  time_since_restore: 38244.19073843956\n",
      "  time_this_iter_s: 573.1066732406616\n",
      "  time_total_s: 38244.19073843956\n",
      "  timers:\n",
      "    learn_throughput: 264.134\n",
      "    learn_time_ms: 15143.817\n",
      "    load_throughput: 10801.332\n",
      "    load_time_ms: 370.325\n",
      "    sample_throughput: 7.189\n",
      "    sample_time_ms: 556407.515\n",
      "    update_time_ms: 3.553\n",
      "  timestamp: 1613864793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_00-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39758531399424\n",
      "  episode_reward_mean: 63.93510598160217\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2470\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.634858250617981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013342119753360748\n",
      "        model: {}\n",
      "        policy_loss: -0.11227316409349442\n",
      "        total_loss: 958.5897827148438\n",
      "        vf_explained_var: 0.658909261226654\n",
      "        vf_loss: 958.671630859375\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 296000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.47836185819071\n",
      "    ram_util_percent: 37.15929095354524\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06934058052233977\n",
      "    mean_env_wait_ms: 114.95184865274535\n",
      "    mean_inference_ms: 1.746543330488703\n",
      "    mean_raw_obs_processing_ms: 10.115347232298536\n",
      "  time_since_restore: 38817.36667227745\n",
      "  time_this_iter_s: 573.1759338378906\n",
      "  time_total_s: 38817.36667227745\n",
      "  timers:\n",
      "    learn_throughput: 264.048\n",
      "    learn_time_ms: 15148.775\n",
      "    load_throughput: 10813.873\n",
      "    load_time_ms: 369.895\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556349.164\n",
      "    update_time_ms: 3.516\n",
      "  timestamp: 1613865366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 74\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-05-38\n",
      "  done: false\n",
      "  episode_len_mean: 140.98\n",
      "  episode_reward_max: 118.39758531399424\n",
      "  episode_reward_mean: 68.35963371424914\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2499\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6206836700439453\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008158518932759762\n",
      "        model: {}\n",
      "        policy_loss: -0.08408588171005249\n",
      "        total_loss: 402.3951721191406\n",
      "        vf_explained_var: 0.7547827959060669\n",
      "        vf_loss: 402.46063232421875\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.487132352941174\n",
      "    ram_util_percent: 37.5827205882353\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06928106152625599\n",
      "    mean_env_wait_ms: 115.1479551787551\n",
      "    mean_inference_ms: 1.7452991217292035\n",
      "    mean_raw_obs_processing_ms: 10.093613805166735\n",
      "  time_since_restore: 39389.221237659454\n",
      "  time_this_iter_s: 571.8545653820038\n",
      "  time_total_s: 39389.221237659454\n",
      "  timers:\n",
      "    learn_throughput: 264.064\n",
      "    learn_time_ms: 15147.838\n",
      "    load_throughput: 10820.519\n",
      "    load_time_ms: 369.668\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556299.514\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613865938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 144.33\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 70.53637365108484\n",
      "  episode_reward_min: -106.27659037451741\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2524\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6282891631126404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008960314095020294\n",
      "        model: {}\n",
      "        policy_loss: -0.09238934516906738\n",
      "        total_loss: 583.287841796875\n",
      "        vf_explained_var: 0.6873043775558472\n",
      "        vf_loss: 583.3598022460938\n",
      "    num_steps_sampled: 304000\n",
      "    num_steps_trained: 304000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34315659679409\n",
      "    ram_util_percent: 37.643403205918624\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0692304309933987\n",
      "    mean_env_wait_ms: 115.30995820023833\n",
      "    mean_inference_ms: 1.7442220421493562\n",
      "    mean_raw_obs_processing_ms: 10.07362794284602\n",
      "  time_since_restore: 39957.19925880432\n",
      "  time_this_iter_s: 567.978021144867\n",
      "  time_total_s: 39957.19925880432\n",
      "  timers:\n",
      "    learn_throughput: 264.03\n",
      "    learn_time_ms: 15149.767\n",
      "    load_throughput: 10824.969\n",
      "    load_time_ms: 369.516\n",
      "    sample_throughput: 7.192\n",
      "    sample_time_ms: 556136.573\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613866506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 304000\n",
      "  training_iteration: 76\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-24-41\n",
      "  done: false\n",
      "  episode_len_mean: 138.2\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 74.77718520882522\n",
      "  episode_reward_min: -98.78478614366963\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 2556\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6217712163925171\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010317807085812092\n",
      "        model: {}\n",
      "        policy_loss: -0.09684766829013824\n",
      "        total_loss: 471.45892333984375\n",
      "        vf_explained_var: 0.8024389147758484\n",
      "        vf_loss: 471.5322570800781\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.57780487804878\n",
      "    ram_util_percent: 37.633170731707324\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06916814033471935\n",
      "    mean_env_wait_ms: 115.5077081205219\n",
      "    mean_inference_ms: 1.7428648770769166\n",
      "    mean_raw_obs_processing_ms: 10.053242277202832\n",
      "  time_since_restore: 40532.23022842407\n",
      "  time_this_iter_s: 575.030969619751\n",
      "  time_total_s: 40532.23022842407\n",
      "  timers:\n",
      "    learn_throughput: 264.061\n",
      "    learn_time_ms: 15148.015\n",
      "    load_throughput: 10993.946\n",
      "    load_time_ms: 363.837\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556641.082\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613867081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-34-14\n",
      "  done: false\n",
      "  episode_len_mean: 142.53\n",
      "  episode_reward_max: 118.39841749360913\n",
      "  episode_reward_mean: 78.98087082098333\n",
      "  episode_reward_min: -98.7417065471983\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2584\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6119922995567322\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011394803412258625\n",
      "        model: {}\n",
      "        policy_loss: -0.09888093918561935\n",
      "        total_loss: 356.1640625\n",
      "        vf_explained_var: 0.8513246178627014\n",
      "        vf_loss: 356.23699951171875\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 312000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.410281517747855\n",
      "    ram_util_percent: 37.63818849449205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06911540389132194\n",
      "    mean_env_wait_ms: 115.67576647059974\n",
      "    mean_inference_ms: 1.741715638472674\n",
      "    mean_raw_obs_processing_ms: 10.034937057725308\n",
      "  time_since_restore: 41104.826088905334\n",
      "  time_this_iter_s: 572.5958604812622\n",
      "  time_total_s: 41104.826088905334\n",
      "  timers:\n",
      "    learn_throughput: 264.058\n",
      "    learn_time_ms: 15148.206\n",
      "    load_throughput: 10988.041\n",
      "    load_time_ms: 364.032\n",
      "    sample_throughput: 7.184\n",
      "    sample_time_ms: 556776.6\n",
      "    update_time_ms: 3.482\n",
      "  timestamp: 1613867654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 78\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 134.93\n",
      "  episode_reward_max: 118.38809567022436\n",
      "  episode_reward_mean: 66.23044507460551\n",
      "  episode_reward_min: -100.33457397895387\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2614\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6089362502098083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011843282729387283\n",
      "        model: {}\n",
      "        policy_loss: -0.10525768995285034\n",
      "        total_loss: 799.7393188476562\n",
      "        vf_explained_var: 0.6889356970787048\n",
      "        vf_loss: 799.8175659179688\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.479390243902444\n",
      "    ram_util_percent: 37.5989024390244\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06906043211441769\n",
      "    mean_env_wait_ms: 115.85209515094088\n",
      "    mean_inference_ms: 1.7405040158566727\n",
      "    mean_raw_obs_processing_ms: 10.01951022321941\n",
      "  time_since_restore: 41679.47191905975\n",
      "  time_this_iter_s: 574.645830154419\n",
      "  time_total_s: 41679.47191905975\n",
      "  timers:\n",
      "    learn_throughput: 264.04\n",
      "    learn_time_ms: 15149.244\n",
      "    load_throughput: 10991.512\n",
      "    load_time_ms: 363.917\n",
      "    sample_throughput: 7.181\n",
      "    sample_time_ms: 557005.718\n",
      "    update_time_ms: 3.47\n",
      "  timestamp: 1613868229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_01-53-28\n",
      "  done: false\n",
      "  episode_len_mean: 129.62\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 66.30857952219603\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 2648\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.612834095954895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011830639094114304\n",
      "        model: {}\n",
      "        policy_loss: -0.10811416059732437\n",
      "        total_loss: 721.0752563476562\n",
      "        vf_explained_var: 0.7420914173126221\n",
      "        vf_loss: 721.1563720703125\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.457506053268766\n",
      "    ram_util_percent: 37.61973365617434\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0690039489207212\n",
      "    mean_env_wait_ms: 116.03571795318099\n",
      "    mean_inference_ms: 1.73923570012803\n",
      "    mean_raw_obs_processing_ms: 10.009942111648098\n",
      "  time_since_restore: 42258.06580400467\n",
      "  time_this_iter_s: 578.5938849449158\n",
      "  time_total_s: 42258.06580400467\n",
      "  timers:\n",
      "    learn_throughput: 264.09\n",
      "    learn_time_ms: 15146.35\n",
      "    load_throughput: 10990.486\n",
      "    load_time_ms: 363.951\n",
      "    sample_throughput: 7.174\n",
      "    sample_time_ms: 557601.894\n",
      "    update_time_ms: 3.449\n",
      "  timestamp: 1613868808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 80\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-03-02\n",
      "  done: false\n",
      "  episode_len_mean: 128.4\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 60.033566095574386\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2677\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6140277981758118\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008003169670701027\n",
      "        model: {}\n",
      "        policy_loss: -0.08613423258066177\n",
      "        total_loss: 503.7268981933594\n",
      "        vf_explained_var: 0.7947396636009216\n",
      "        vf_loss: 503.7947998046875\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.43577533577534\n",
      "    ram_util_percent: 37.60830280830282\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06895626932661361\n",
      "    mean_env_wait_ms: 116.18808191371505\n",
      "    mean_inference_ms: 1.7382185606484102\n",
      "    mean_raw_obs_processing_ms: 10.002050044919022\n",
      "  time_since_restore: 42831.9421107769\n",
      "  time_this_iter_s: 573.876306772232\n",
      "  time_total_s: 42831.9421107769\n",
      "  timers:\n",
      "    learn_throughput: 264.097\n",
      "    learn_time_ms: 15145.95\n",
      "    load_throughput: 11019.773\n",
      "    load_time_ms: 362.984\n",
      "    sample_throughput: 7.175\n",
      "    sample_time_ms: 557513.472\n",
      "    update_time_ms: 3.463\n",
      "  timestamp: 1613869382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 126.19\n",
      "  episode_reward_max: 118.38994456942554\n",
      "  episode_reward_mean: 55.84332330127691\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 2709\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6395218968391418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010636094957590103\n",
      "        model: {}\n",
      "        policy_loss: -0.1009235680103302\n",
      "        total_loss: 1037.17919921875\n",
      "        vf_explained_var: 0.5761825442314148\n",
      "        vf_loss: 1037.2559814453125\n",
      "    num_steps_sampled: 328000\n",
      "    num_steps_trained: 328000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.428883495145634\n",
      "    ram_util_percent: 37.59550970873787\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06890648467670632\n",
      "    mean_env_wait_ms: 116.34881545523703\n",
      "    mean_inference_ms: 1.7371903569719798\n",
      "    mean_raw_obs_processing_ms: 9.996829275702517\n",
      "  time_since_restore: 43408.906421899796\n",
      "  time_this_iter_s: 576.9643111228943\n",
      "  time_total_s: 43408.906421899796\n",
      "  timers:\n",
      "    learn_throughput: 264.108\n",
      "    learn_time_ms: 15145.311\n",
      "    load_throughput: 11021.604\n",
      "    load_time_ms: 362.924\n",
      "    sample_throughput: 7.167\n",
      "    sample_time_ms: 558111.411\n",
      "    update_time_ms: 3.453\n",
      "  timestamp: 1613869959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 328000\n",
      "  training_iteration: 82\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 134.56\n",
      "  episode_reward_max: 118.37185952922911\n",
      "  episode_reward_mean: 64.17353366881248\n",
      "  episode_reward_min: -100.72462310708792\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2737\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6272621750831604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00920060183852911\n",
      "        model: {}\n",
      "        policy_loss: -0.09657780081033707\n",
      "        total_loss: 591.6361694335938\n",
      "        vf_explained_var: 0.675640881061554\n",
      "        vf_loss: 591.7117309570312\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38996328029376\n",
      "    ram_util_percent: 37.62325581395349\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688652520254107\n",
      "    mean_env_wait_ms: 116.4851184964402\n",
      "    mean_inference_ms: 1.7363364645416846\n",
      "    mean_raw_obs_processing_ms: 9.986971637905215\n",
      "  time_since_restore: 43981.41079258919\n",
      "  time_this_iter_s: 572.5043706893921\n",
      "  time_total_s: 43981.41079258919\n",
      "  timers:\n",
      "    learn_throughput: 264.109\n",
      "    learn_time_ms: 15145.289\n",
      "    load_throughput: 11025.657\n",
      "    load_time_ms: 362.79\n",
      "    sample_throughput: 7.168\n",
      "    sample_time_ms: 558050.636\n",
      "    update_time_ms: 3.474\n",
      "  timestamp: 1613870531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 139.17\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 74.64579489491926\n",
      "  episode_reward_min: -100.4791623546053\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2765\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5827945470809937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006520960479974747\n",
      "        model: {}\n",
      "        policy_loss: -0.06697624921798706\n",
      "        total_loss: 203.43817138671875\n",
      "        vf_explained_var: 0.8140708208084106\n",
      "        vf_loss: 203.49026489257812\n",
      "    num_steps_sampled: 336000\n",
      "    num_steps_trained: 336000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.3812729498164\n",
      "    ram_util_percent: 37.64088127294982\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688231221143372\n",
      "    mean_env_wait_ms: 116.62777605461848\n",
      "    mean_inference_ms: 1.735407625887317\n",
      "    mean_raw_obs_processing_ms: 9.974503712169184\n",
      "  time_since_restore: 44553.97675514221\n",
      "  time_this_iter_s: 572.5659625530243\n",
      "  time_total_s: 44553.97675514221\n",
      "  timers:\n",
      "    learn_throughput: 264.173\n",
      "    learn_time_ms: 15141.617\n",
      "    load_throughput: 11003.219\n",
      "    load_time_ms: 363.53\n",
      "    sample_throughput: 7.169\n",
      "    sample_time_ms: 557992.14\n",
      "    update_time_ms: 3.51\n",
      "  timestamp: 1613871104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 336000\n",
      "  training_iteration: 84\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.91\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 72.48419406469598\n",
      "  episode_reward_min: -100.4791623546053\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 2795\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6341033577919006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01128568034619093\n",
      "        model: {}\n",
      "        policy_loss: -0.1100163459777832\n",
      "        total_loss: 805.0309448242188\n",
      "        vf_explained_var: 0.7002952694892883\n",
      "        vf_loss: 805.1151733398438\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.42576312576312\n",
      "    ram_util_percent: 37.62319902319903\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0687784308105397\n",
      "    mean_env_wait_ms: 116.77627190738745\n",
      "    mean_inference_ms: 1.7344180800662337\n",
      "    mean_raw_obs_processing_ms: 9.960494716418623\n",
      "  time_since_restore: 45127.50771832466\n",
      "  time_this_iter_s: 573.5309631824493\n",
      "  time_total_s: 45127.50771832466\n",
      "  timers:\n",
      "    learn_throughput: 264.164\n",
      "    learn_time_ms: 15142.128\n",
      "    load_throughput: 10999.194\n",
      "    load_time_ms: 363.663\n",
      "    sample_throughput: 7.166\n",
      "    sample_time_ms: 558160.031\n",
      "    update_time_ms: 3.479\n",
      "  timestamp: 1613871678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_02-50-50\n",
      "  done: false\n",
      "  episode_len_mean: 141.88\n",
      "  episode_reward_max: 118.36569738858549\n",
      "  episode_reward_mean: 74.47919637461047\n",
      "  episode_reward_min: -100.33541309345999\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2822\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6619164347648621\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012647053226828575\n",
      "        model: {}\n",
      "        policy_loss: -0.11788468062877655\n",
      "        total_loss: 890.1051635742188\n",
      "        vf_explained_var: 0.667721152305603\n",
      "        vf_loss: 890.1942749023438\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 344000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31176470588235\n",
      "    ram_util_percent: 37.63468137254902\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06873833848833105\n",
      "    mean_env_wait_ms: 116.91226338279147\n",
      "    mean_inference_ms: 1.7335231801235562\n",
      "    mean_raw_obs_processing_ms: 9.945158745382983\n",
      "  time_since_restore: 45699.621527433395\n",
      "  time_this_iter_s: 572.1138091087341\n",
      "  time_total_s: 45699.621527433395\n",
      "  timers:\n",
      "    learn_throughput: 264.207\n",
      "    learn_time_ms: 15139.67\n",
      "    load_throughput: 11016.095\n",
      "    load_time_ms: 363.105\n",
      "    sample_throughput: 7.161\n",
      "    sample_time_ms: 558577.777\n",
      "    update_time_ms: 3.457\n",
      "  timestamp: 1613872250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 86\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 141.63\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 70.23463403469647\n",
      "  episode_reward_min: -100.48570400254098\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2849\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6279558539390564\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008916793391108513\n",
      "        model: {}\n",
      "        policy_loss: -0.08972213417291641\n",
      "        total_loss: 401.4216003417969\n",
      "        vf_explained_var: 0.7704207301139832\n",
      "        vf_loss: 401.4909973144531\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31370869033047\n",
      "    ram_util_percent: 37.6670746634027\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06869867081991787\n",
      "    mean_env_wait_ms: 117.04716744173258\n",
      "    mean_inference_ms: 1.7326487293140218\n",
      "    mean_raw_obs_processing_ms: 9.929296489515842\n",
      "  time_since_restore: 46272.038051605225\n",
      "  time_this_iter_s: 572.4165241718292\n",
      "  time_total_s: 46272.038051605225\n",
      "  timers:\n",
      "    learn_throughput: 264.183\n",
      "    learn_time_ms: 15141.005\n",
      "    load_throughput: 11017.058\n",
      "    load_time_ms: 363.073\n",
      "    sample_throughput: 7.164\n",
      "    sample_time_ms: 558314.856\n",
      "    update_time_ms: 3.489\n",
      "  timestamp: 1613872823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 145.91\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 78.59757373313865\n",
      "  episode_reward_min: -101.48718799048909\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 2874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.609645426273346\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010317403823137283\n",
      "        model: {}\n",
      "        policy_loss: -0.09546666592359543\n",
      "        total_loss: 51.94847106933594\n",
      "        vf_explained_var: 0.9522272348403931\n",
      "        vf_loss: 52.02043151855469\n",
      "    num_steps_sampled: 352000\n",
      "    num_steps_trained: 352000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.37235872235873\n",
      "    ram_util_percent: 37.65970515970516\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06866188360220725\n",
      "    mean_env_wait_ms: 117.1731756625959\n",
      "    mean_inference_ms: 1.7318602560513392\n",
      "    mean_raw_obs_processing_ms: 9.911490483068429\n",
      "  time_since_restore: 46842.017905950546\n",
      "  time_this_iter_s: 569.9798543453217\n",
      "  time_total_s: 46842.017905950546\n",
      "  timers:\n",
      "    learn_throughput: 264.185\n",
      "    learn_time_ms: 15140.929\n",
      "    load_throughput: 11015.432\n",
      "    load_time_ms: 363.127\n",
      "    sample_throughput: 7.168\n",
      "    sample_time_ms: 558051.999\n",
      "    update_time_ms: 3.523\n",
      "  timestamp: 1613873393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 352000\n",
      "  training_iteration: 88\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 151.03\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 86.74178242094577\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 2901\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6083473563194275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006297805346548557\n",
      "        model: {}\n",
      "        policy_loss: -0.06047149375081062\n",
      "        total_loss: 84.03146362304688\n",
      "        vf_explained_var: 0.9165517687797546\n",
      "        vf_loss: 84.07758331298828\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.36279069767442\n",
      "    ram_util_percent: 37.65250917992656\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06862152295259255\n",
      "    mean_env_wait_ms: 117.31282317533726\n",
      "    mean_inference_ms: 1.731016450706324\n",
      "    mean_raw_obs_processing_ms: 9.890075394770157\n",
      "  time_since_restore: 47414.542248249054\n",
      "  time_this_iter_s: 572.5243422985077\n",
      "  time_total_s: 47414.542248249054\n",
      "  timers:\n",
      "    learn_throughput: 264.178\n",
      "    learn_time_ms: 15141.325\n",
      "    load_throughput: 10993.389\n",
      "    load_time_ms: 363.855\n",
      "    sample_throughput: 7.171\n",
      "    sample_time_ms: 557836.4\n",
      "    update_time_ms: 3.545\n",
      "  timestamp: 1613873965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-28-57\n",
      "  done: false\n",
      "  episode_len_mean: 152.05\n",
      "  episode_reward_max: 118.39972560355228\n",
      "  episode_reward_mean: 95.47943811053409\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 2927\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6245173215866089\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008704432286322117\n",
      "        model: {}\n",
      "        policy_loss: -0.07819437235593796\n",
      "        total_loss: 741.48486328125\n",
      "        vf_explained_var: 0.49536240100860596\n",
      "        vf_loss: 741.543212890625\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.23799019607843\n",
      "    ram_util_percent: 37.60428921568628\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06858305551282297\n",
      "    mean_env_wait_ms: 117.44568936548764\n",
      "    mean_inference_ms: 1.730216980502728\n",
      "    mean_raw_obs_processing_ms: 9.868999614297818\n",
      "  time_since_restore: 47986.192225933075\n",
      "  time_this_iter_s: 571.649977684021\n",
      "  time_total_s: 47986.192225933075\n",
      "  timers:\n",
      "    learn_throughput: 264.133\n",
      "    learn_time_ms: 15143.879\n",
      "    load_throughput: 10988.587\n",
      "    load_time_ms: 364.014\n",
      "    sample_throughput: 7.18\n",
      "    sample_time_ms: 557138.008\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613874537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 90\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 148.45\n",
      "  episode_reward_max: 118.36638515678655\n",
      "  episode_reward_mean: 86.87700961007907\n",
      "  episode_reward_min: -106.32426879110315\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 2956\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6059015989303589\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011917388066649437\n",
      "        model: {}\n",
      "        policy_loss: -0.10298958420753479\n",
      "        total_loss: 748.3084106445312\n",
      "        vf_explained_var: 0.6828364729881287\n",
      "        vf_loss: 748.38427734375\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.4583129584352\n",
      "    ram_util_percent: 37.63496332518338\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06854048496142572\n",
      "    mean_env_wait_ms: 117.58732035088931\n",
      "    mean_inference_ms: 1.7293595306129033\n",
      "    mean_raw_obs_processing_ms: 9.84859556894841\n",
      "  time_since_restore: 48559.266986608505\n",
      "  time_this_iter_s: 573.0747606754303\n",
      "  time_total_s: 48559.266986608505\n",
      "  timers:\n",
      "    learn_throughput: 264.152\n",
      "    learn_time_ms: 15142.82\n",
      "    load_throughput: 10967.227\n",
      "    load_time_ms: 364.723\n",
      "    sample_throughput: 7.181\n",
      "    sample_time_ms: 557059.872\n",
      "    update_time_ms: 3.568\n",
      "  timestamp: 1613875110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 147.16\n",
      "  episode_reward_max: 118.36638515678655\n",
      "  episode_reward_mean: 78.53596061698514\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 2984\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6384892463684082\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014252190478146076\n",
      "        model: {}\n",
      "        policy_loss: -0.12938052415847778\n",
      "        total_loss: 1040.5548095703125\n",
      "        vf_explained_var: 0.6462556719779968\n",
      "        vf_loss: 1040.651611328125\n",
      "    num_steps_sampled: 368000\n",
      "    num_steps_trained: 368000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31528117359414\n",
      "    ram_util_percent: 37.71638141809291\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0685013111223692\n",
      "    mean_env_wait_ms: 117.71636245049473\n",
      "    mean_inference_ms: 1.7285761946448637\n",
      "    mean_raw_obs_processing_ms: 9.832269351667906\n",
      "  time_since_restore: 49132.35148835182\n",
      "  time_this_iter_s: 573.0845017433167\n",
      "  time_total_s: 49132.35148835182\n",
      "  timers:\n",
      "    learn_throughput: 264.17\n",
      "    learn_time_ms: 15141.759\n",
      "    load_throughput: 10932.693\n",
      "    load_time_ms: 365.875\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556670.702\n",
      "    update_time_ms: 3.56\n",
      "  timestamp: 1613875683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 368000\n",
      "  training_iteration: 92\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_03-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 148.59\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 76.27011604884156\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3009\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6160101294517517\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008099525235593319\n",
      "        model: {}\n",
      "        policy_loss: -0.08657196909189224\n",
      "        total_loss: 311.40777587890625\n",
      "        vf_explained_var: 0.7959339618682861\n",
      "        vf_loss: 311.4758605957031\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.257493857493856\n",
      "    ram_util_percent: 37.72186732186732\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684672460741856\n",
      "    mean_env_wait_ms: 117.83028991731415\n",
      "    mean_inference_ms: 1.727895503967211\n",
      "    mean_raw_obs_processing_ms: 9.816608724019238\n",
      "  time_since_restore: 49702.79315876961\n",
      "  time_this_iter_s: 570.4416704177856\n",
      "  time_total_s: 49702.79315876961\n",
      "  timers:\n",
      "    learn_throughput: 264.149\n",
      "    learn_time_ms: 15142.975\n",
      "    load_throughput: 10922.587\n",
      "    load_time_ms: 366.214\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556462.525\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1613876254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 144.0\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 76.09072176362433\n",
      "  episode_reward_min: -104.59048121757738\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3036\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.620825469493866\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007575416937470436\n",
      "        model: {}\n",
      "        policy_loss: -0.07958129048347473\n",
      "        total_loss: 195.9188232421875\n",
      "        vf_explained_var: 0.8314293622970581\n",
      "        vf_loss: 195.98106384277344\n",
      "    num_steps_sampled: 376000\n",
      "    num_steps_trained: 376000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38223039215686\n",
      "    ram_util_percent: 37.66531862745098\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06843085041858095\n",
      "    mean_env_wait_ms: 117.94984110136356\n",
      "    mean_inference_ms: 1.7271565825316366\n",
      "    mean_raw_obs_processing_ms: 9.80010601973607\n",
      "  time_since_restore: 50274.3007338047\n",
      "  time_this_iter_s: 571.5075750350952\n",
      "  time_total_s: 50274.3007338047\n",
      "  timers:\n",
      "    learn_throughput: 264.177\n",
      "    learn_time_ms: 15141.335\n",
      "    load_throughput: 10932.309\n",
      "    load_time_ms: 365.888\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556358.174\n",
      "    update_time_ms: 3.595\n",
      "  timestamp: 1613876826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 376000\n",
      "  training_iteration: 94\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 154.13\n",
      "  episode_reward_max: 118.3861980285146\n",
      "  episode_reward_mean: 90.7099485422507\n",
      "  episode_reward_min: -101.66335937256399\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3061\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6019314527511597\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00965670682489872\n",
      "        model: {}\n",
      "        policy_loss: -0.09145587682723999\n",
      "        total_loss: 34.35165023803711\n",
      "        vf_explained_var: 0.9595359563827515\n",
      "        vf_loss: 34.421104431152344\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.28488943488943\n",
      "    ram_util_percent: 37.66216216216216\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06839668156279691\n",
      "    mean_env_wait_ms: 118.06309445303968\n",
      "    mean_inference_ms: 1.7264800011997932\n",
      "    mean_raw_obs_processing_ms: 9.781802359337073\n",
      "  time_since_restore: 50844.359786748886\n",
      "  time_this_iter_s: 570.0590529441833\n",
      "  time_total_s: 50844.359786748886\n",
      "  timers:\n",
      "    learn_throughput: 264.148\n",
      "    learn_time_ms: 15143.038\n",
      "    load_throughput: 10942.055\n",
      "    load_time_ms: 365.562\n",
      "    sample_throughput: 7.194\n",
      "    sample_time_ms: 556008.715\n",
      "    update_time_ms: 3.629\n",
      "  timestamp: 1613877396\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-26-11\n",
      "  done: false\n",
      "  episode_len_mean: 151.55\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 90.73738237431702\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3090\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6180492639541626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01009252667427063\n",
      "        model: {}\n",
      "        policy_loss: -0.0961713045835495\n",
      "        total_loss: 532.2601928710938\n",
      "        vf_explained_var: 0.7508637309074402\n",
      "        vf_loss: 532.3333740234375\n",
      "    num_steps_sampled: 384000\n",
      "    num_steps_trained: 384000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34731707317073\n",
      "    ram_util_percent: 37.65280487804879\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06835815682144136\n",
      "    mean_env_wait_ms: 118.19191298830596\n",
      "    mean_inference_ms: 1.725703411393963\n",
      "    mean_raw_obs_processing_ms: 9.76259727065554\n",
      "  time_since_restore: 51419.60346984863\n",
      "  time_this_iter_s: 575.2436830997467\n",
      "  time_total_s: 51419.60346984863\n",
      "  timers:\n",
      "    learn_throughput: 264.126\n",
      "    learn_time_ms: 15144.265\n",
      "    load_throughput: 10931.565\n",
      "    load_time_ms: 365.913\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556320.133\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1613877971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 384000\n",
      "  training_iteration: 96\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 148.99\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 95.00853702159911\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3117\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6246620416641235\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006574051920324564\n",
      "        model: {}\n",
      "        policy_loss: -0.06613514572381973\n",
      "        total_loss: 164.94639587402344\n",
      "        vf_explained_var: 0.8330784440040588\n",
      "        vf_loss: 164.99755859375\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.297188264058676\n",
      "    ram_util_percent: 37.675794621026895\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0683223278202251\n",
      "    mean_env_wait_ms: 118.30677647535566\n",
      "    mean_inference_ms: 1.7250091530794134\n",
      "    mean_raw_obs_processing_ms: 9.746823513430975\n",
      "  time_since_restore: 51992.47012424469\n",
      "  time_this_iter_s: 572.8666543960571\n",
      "  time_total_s: 51992.47012424469\n",
      "  timers:\n",
      "    learn_throughput: 264.124\n",
      "    learn_time_ms: 15144.379\n",
      "    load_throughput: 10917.265\n",
      "    load_time_ms: 366.392\n",
      "    sample_throughput: 7.19\n",
      "    sample_time_ms: 556364.217\n",
      "    update_time_ms: 3.558\n",
      "  timestamp: 1613878544\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 148.49\n",
      "  episode_reward_max: 118.3754436889049\n",
      "  episode_reward_mean: 92.9885752701855\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3143\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6129283308982849\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007502316031605005\n",
      "        model: {}\n",
      "        policy_loss: -0.07701314240694046\n",
      "        total_loss: 418.00335693359375\n",
      "        vf_explained_var: 0.7102574110031128\n",
      "        vf_loss: 418.063232421875\n",
      "    num_steps_sampled: 392000\n",
      "    num_steps_trained: 392000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.31176470588235\n",
      "    ram_util_percent: 37.693137254901956\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06828794418556879\n",
      "    mean_env_wait_ms: 118.41655315671734\n",
      "    mean_inference_ms: 1.7243705784511854\n",
      "    mean_raw_obs_processing_ms: 9.731387966899245\n",
      "  time_since_restore: 52563.917846918106\n",
      "  time_this_iter_s: 571.4477226734161\n",
      "  time_total_s: 52563.917846918106\n",
      "  timers:\n",
      "    learn_throughput: 264.134\n",
      "    learn_time_ms: 15143.824\n",
      "    load_throughput: 10913.187\n",
      "    load_time_ms: 366.529\n",
      "    sample_throughput: 7.188\n",
      "    sample_time_ms: 556511.074\n",
      "    update_time_ms: 3.511\n",
      "  timestamp: 1613879116\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 392000\n",
      "  training_iteration: 98\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_04-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 145.7\n",
      "  episode_reward_max: 118.33897899119724\n",
      "  episode_reward_mean: 88.84848190246228\n",
      "  episode_reward_min: -105.80907272476225\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3170\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6175667643547058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006731769535690546\n",
      "        model: {}\n",
      "        policy_loss: -0.06991294771432877\n",
      "        total_loss: 247.48231506347656\n",
      "        vf_explained_var: 0.7953845262527466\n",
      "        vf_loss: 247.5369110107422\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.353545232273845\n",
      "    ram_util_percent: 37.635330073349635\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06825275092281008\n",
      "    mean_env_wait_ms: 118.52690351343179\n",
      "    mean_inference_ms: 1.7237184069547202\n",
      "    mean_raw_obs_processing_ms: 9.71665519707479\n",
      "  time_since_restore: 53137.459812402725\n",
      "  time_this_iter_s: 573.5419654846191\n",
      "  time_total_s: 53137.459812402725\n",
      "  timers:\n",
      "    learn_throughput: 264.145\n",
      "    learn_time_ms: 15143.219\n",
      "    load_throughput: 10953.005\n",
      "    load_time_ms: 365.197\n",
      "    sample_throughput: 7.186\n",
      "    sample_time_ms: 556616.653\n",
      "    update_time_ms: 3.54\n",
      "  timestamp: 1613879690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-04-24\n",
      "  done: false\n",
      "  episode_len_mean: 147.11\n",
      "  episode_reward_max: 118.33897899119724\n",
      "  episode_reward_mean: 93.14223227238632\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3199\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6179011464118958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011885471642017365\n",
      "        model: {}\n",
      "        policy_loss: -0.11724616587162018\n",
      "        total_loss: 561.7438354492188\n",
      "        vf_explained_var: 0.7938085198402405\n",
      "        vf_loss: 561.8339233398438\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.43780487804878\n",
      "    ram_util_percent: 37.717317073170726\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06821509692921657\n",
      "    mean_env_wait_ms: 118.64317735068947\n",
      "    mean_inference_ms: 1.7230314647557228\n",
      "    mean_raw_obs_processing_ms: 9.701350603621318\n",
      "  time_since_restore: 53711.56699895859\n",
      "  time_this_iter_s: 574.1071865558624\n",
      "  time_total_s: 53711.56699895859\n",
      "  timers:\n",
      "    learn_throughput: 264.16\n",
      "    learn_time_ms: 15142.316\n",
      "    load_throughput: 10965.797\n",
      "    load_time_ms: 364.771\n",
      "    sample_throughput: 7.183\n",
      "    sample_time_ms: 556863.546\n",
      "    update_time_ms: 3.559\n",
      "  timestamp: 1613880264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 100\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-13-58\n",
      "  done: false\n",
      "  episode_len_mean: 145.16\n",
      "  episode_reward_max: 118.3942711538609\n",
      "  episode_reward_mean: 87.0959860036248\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3227\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6058357954025269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01053436566144228\n",
      "        model: {}\n",
      "        policy_loss: -0.09249967336654663\n",
      "        total_loss: 812.6344604492188\n",
      "        vf_explained_var: 0.5682348012924194\n",
      "        vf_loss: 812.703125\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.33614163614164\n",
      "    ram_util_percent: 37.71672771672772\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06817984997533298\n",
      "    mean_env_wait_ms: 118.75171630927481\n",
      "    mean_inference_ms: 1.722390448427243\n",
      "    mean_raw_obs_processing_ms: 9.688252713676322\n",
      "  time_since_restore: 54285.57768249512\n",
      "  time_this_iter_s: 574.0106835365295\n",
      "  time_total_s: 54285.57768249512\n",
      "  timers:\n",
      "    learn_throughput: 264.144\n",
      "    learn_time_ms: 15143.28\n",
      "    load_throughput: 10978.317\n",
      "    load_time_ms: 364.355\n",
      "    sample_throughput: 7.182\n",
      "    sample_time_ms: 556955.563\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613880838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 147.48\n",
      "  episode_reward_max: 118.3942711538609\n",
      "  episode_reward_mean: 89.24138729586062\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3252\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6104090213775635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005886872764676809\n",
      "        model: {}\n",
      "        policy_loss: -0.06748391687870026\n",
      "        total_loss: 433.7013244628906\n",
      "        vf_explained_var: 0.6146568655967712\n",
      "        vf_loss: 433.75531005859375\n",
      "    num_steps_sampled: 408000\n",
      "    num_steps_trained: 408000\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.2123774509804\n",
      "    ram_util_percent: 37.689338235294116\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06814926838970166\n",
      "    mean_env_wait_ms: 118.84731336256696\n",
      "    mean_inference_ms: 1.7218322173745153\n",
      "    mean_raw_obs_processing_ms: 9.675675333114134\n",
      "  time_since_restore: 54857.00827693939\n",
      "  time_this_iter_s: 571.4305944442749\n",
      "  time_total_s: 54857.00827693939\n",
      "  timers:\n",
      "    learn_throughput: 264.127\n",
      "    learn_time_ms: 15144.202\n",
      "    load_throughput: 10984.24\n",
      "    load_time_ms: 364.158\n",
      "    sample_throughput: 7.184\n",
      "    sample_time_ms: 556790.183\n",
      "    update_time_ms: 3.583\n",
      "  timestamp: 1613881409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 408000\n",
      "  training_iteration: 102\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-33-07\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 80.92598589407584\n",
      "  episode_reward_min: -102.63207047748058\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 3283\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5881627798080444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009681874886155128\n",
      "        model: {}\n",
      "        policy_loss: -0.09490907937288284\n",
      "        total_loss: 613.488525390625\n",
      "        vf_explained_var: 0.7268031239509583\n",
      "        vf_loss: 613.5614624023438\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.415188335358444\n",
      "    ram_util_percent: 37.6681652490887\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06811326274325878\n",
      "    mean_env_wait_ms: 118.9614087773805\n",
      "    mean_inference_ms: 1.7211691998654428\n",
      "    mean_raw_obs_processing_ms: 9.663272480891708\n",
      "  time_since_restore: 55434.1220228672\n",
      "  time_this_iter_s: 577.1137459278107\n",
      "  time_total_s: 55434.1220228672\n",
      "  timers:\n",
      "    learn_throughput: 264.149\n",
      "    learn_time_ms: 15142.988\n",
      "    load_throughput: 11012.724\n",
      "    load_time_ms: 363.216\n",
      "    sample_throughput: 7.175\n",
      "    sample_time_ms: 557460.417\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613881987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-42-43\n",
      "  done: false\n",
      "  episode_len_mean: 143.48\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 82.98365740609349\n",
      "  episode_reward_min: -97.20121284343826\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3312\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6338304281234741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00997522659599781\n",
      "        model: {}\n",
      "        policy_loss: -0.10173895955085754\n",
      "        total_loss: 616.504150390625\n",
      "        vf_explained_var: 0.6925467252731323\n",
      "        vf_loss: 616.583251953125\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 416000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.386026731470224\n",
      "    ram_util_percent: 37.688092345078985\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06808057343717405\n",
      "    mean_env_wait_ms: 119.06631584219063\n",
      "    mean_inference_ms: 1.7205515196110677\n",
      "    mean_raw_obs_processing_ms: 9.652490343340176\n",
      "  time_since_restore: 56010.4632897377\n",
      "  time_this_iter_s: 576.3412668704987\n",
      "  time_total_s: 56010.4632897377\n",
      "  timers:\n",
      "    learn_throughput: 264.144\n",
      "    learn_time_ms: 15143.269\n",
      "    load_throughput: 11032.888\n",
      "    load_time_ms: 362.552\n",
      "    sample_throughput: 7.169\n",
      "    sample_time_ms: 557944.608\n",
      "    update_time_ms: 3.504\n",
      "  timestamp: 1613882563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 104\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_05-52-19\n",
      "  done: false\n",
      "  episode_len_mean: 136.03\n",
      "  episode_reward_max: 118.39790261515664\n",
      "  episode_reward_mean: 78.5377385374056\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3342\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6088712811470032\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006714586168527603\n",
      "        model: {}\n",
      "        policy_loss: -0.0737038105726242\n",
      "        total_loss: 247.77517700195312\n",
      "        vf_explained_var: 0.8366903066635132\n",
      "        vf_loss: 247.83358764648438\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.42153284671533\n",
      "    ram_util_percent: 37.645012165450126\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06804771686450926\n",
      "    mean_env_wait_ms: 119.17053416729992\n",
      "    mean_inference_ms: 1.7199192467552313\n",
      "    mean_raw_obs_processing_ms: 9.644637584509693\n",
      "  time_since_restore: 56586.31327319145\n",
      "  time_this_iter_s: 575.8499834537506\n",
      "  time_total_s: 56586.31327319145\n",
      "  timers:\n",
      "    learn_throughput: 264.127\n",
      "    learn_time_ms: 15144.238\n",
      "    load_throughput: 11031.408\n",
      "    load_time_ms: 362.601\n",
      "    sample_throughput: 7.162\n",
      "    sample_time_ms: 558521.569\n",
      "    update_time_ms: 3.565\n",
      "  timestamp: 1613883139\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.12\n",
      "  episode_reward_max: 118.37974768340268\n",
      "  episode_reward_mean: 78.33170541121916\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3368\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6366078853607178\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007359534502029419\n",
      "        model: {}\n",
      "        policy_loss: -0.07867537438869476\n",
      "        total_loss: 246.06504821777344\n",
      "        vf_explained_var: 0.7994463443756104\n",
      "        vf_loss: 246.12693786621094\n",
      "    num_steps_sampled: 424000\n",
      "    num_steps_trained: 424000\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.38002450980393\n",
      "    ram_util_percent: 37.65894607843138\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06802034589653698\n",
      "    mean_env_wait_ms: 119.25600639206192\n",
      "    mean_inference_ms: 1.7194048049155586\n",
      "    mean_raw_obs_processing_ms: 9.636769088035123\n",
      "  time_since_restore: 57158.2123401165\n",
      "  time_this_iter_s: 571.8990669250488\n",
      "  time_total_s: 57158.2123401165\n",
      "  timers:\n",
      "    learn_throughput: 264.131\n",
      "    learn_time_ms: 15144.006\n",
      "    load_throughput: 11025.053\n",
      "    load_time_ms: 362.81\n",
      "    sample_throughput: 7.166\n",
      "    sample_time_ms: 558185.885\n",
      "    update_time_ms: 3.584\n",
      "  timestamp: 1613883711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 424000\n",
      "  training_iteration: 106\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 143.85\n",
      "  episode_reward_max: 118.37974768340268\n",
      "  episode_reward_mean: 78.0710623959597\n",
      "  episode_reward_min: -105.91604945757742\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3396\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5976383686065674\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011524615809321404\n",
      "        model: {}\n",
      "        policy_loss: -0.11197109520435333\n",
      "        total_loss: 734.0401611328125\n",
      "        vf_explained_var: 0.7225897312164307\n",
      "        vf_loss: 734.125732421875\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.314268292682925\n",
      "    ram_util_percent: 37.653536585365856\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06799000126610652\n",
      "    mean_env_wait_ms: 119.35082608143959\n",
      "    mean_inference_ms: 1.7188636168057259\n",
      "    mean_raw_obs_processing_ms: 9.626542268431034\n",
      "  time_since_restore: 57732.9291408062\n",
      "  time_this_iter_s: 574.7168006896973\n",
      "  time_total_s: 57732.9291408062\n",
      "  timers:\n",
      "    learn_throughput: 264.133\n",
      "    learn_time_ms: 15143.884\n",
      "    load_throughput: 11038.27\n",
      "    load_time_ms: 362.376\n",
      "    sample_throughput: 7.164\n",
      "    sample_time_ms: 558371.727\n",
      "    update_time_ms: 3.582\n",
      "  timestamp: 1613884286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-21-01\n",
      "  done: false\n",
      "  episode_len_mean: 140.5\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 78.42548913021338\n",
      "  episode_reward_min: -103.57103560791688\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3425\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6155497431755066\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010168452747166157\n",
      "        model: {}\n",
      "        policy_loss: -0.09731052070856094\n",
      "        total_loss: 613.9942016601562\n",
      "        vf_explained_var: 0.6528792977333069\n",
      "        vf_loss: 614.0682373046875\n",
      "    num_steps_sampled: 432000\n",
      "    num_steps_trained: 432000\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.426431181486\n",
      "    ram_util_percent: 37.73580998781973\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06795917030188195\n",
      "    mean_env_wait_ms: 119.44732461749955\n",
      "    mean_inference_ms: 1.7183229932026485\n",
      "    mean_raw_obs_processing_ms: 9.615730870533078\n",
      "  time_since_restore: 58308.05718636513\n",
      "  time_this_iter_s: 575.1280455589294\n",
      "  time_total_s: 58308.05718636513\n",
      "  timers:\n",
      "    learn_throughput: 264.162\n",
      "    learn_time_ms: 15142.241\n",
      "    load_throughput: 11043.36\n",
      "    load_time_ms: 362.209\n",
      "    sample_throughput: 7.159\n",
      "    sample_time_ms: 558743.547\n",
      "    update_time_ms: 3.583\n",
      "  timestamp: 1613884861\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 432000\n",
      "  training_iteration: 108\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 144.48\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 76.40687688578578\n",
      "  episode_reward_min: -103.57103560791688\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3453\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6024710536003113\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008523493073880672\n",
      "        model: {}\n",
      "        policy_loss: -0.08596337586641312\n",
      "        total_loss: 467.1566467285156\n",
      "        vf_explained_var: 0.7673541903495789\n",
      "        vf_loss: 467.22320556640625\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.04768292682927\n",
      "    ram_util_percent: 37.73085365853658\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06793033424235004\n",
      "    mean_env_wait_ms: 119.54059989938149\n",
      "    mean_inference_ms: 1.717827526785704\n",
      "    mean_raw_obs_processing_ms: 9.605143538899718\n",
      "  time_since_restore: 58882.57932472229\n",
      "  time_this_iter_s: 574.5221383571625\n",
      "  time_total_s: 58882.57932472229\n",
      "  timers:\n",
      "    learn_throughput: 264.188\n",
      "    learn_time_ms: 15140.746\n",
      "    load_throughput: 11022.084\n",
      "    load_time_ms: 362.908\n",
      "    sample_throughput: 7.158\n",
      "    sample_time_ms: 558841.478\n",
      "    update_time_ms: 3.553\n",
      "  timestamp: 1613885436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-40-11\n",
      "  done: false\n",
      "  episode_len_mean: 141.72\n",
      "  episode_reward_max: 118.38921432646491\n",
      "  episode_reward_mean: 74.62970423392105\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3482\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6014758944511414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012446741573512554\n",
      "        model: {}\n",
      "        policy_loss: -0.1125083863735199\n",
      "        total_loss: 926.1072387695312\n",
      "        vf_explained_var: 0.653423011302948\n",
      "        vf_loss: 926.19140625\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.57551766138855\n",
      "    ram_util_percent: 37.717783191230204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06790196336835012\n",
      "    mean_env_wait_ms: 119.63217729878222\n",
      "    mean_inference_ms: 1.7173653624665526\n",
      "    mean_raw_obs_processing_ms: 9.596482230104904\n",
      "  time_since_restore: 59457.173558950424\n",
      "  time_this_iter_s: 574.5942342281342\n",
      "  time_total_s: 59457.173558950424\n",
      "  timers:\n",
      "    learn_throughput: 264.167\n",
      "    learn_time_ms: 15141.953\n",
      "    load_throughput: 11015.528\n",
      "    load_time_ms: 363.124\n",
      "    sample_throughput: 7.157\n",
      "    sample_time_ms: 558888.116\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613886011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 110\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-49-46\n",
      "  done: false\n",
      "  episode_len_mean: 139.05\n",
      "  episode_reward_max: 118.38598378043406\n",
      "  episode_reward_mean: 76.65343491029904\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3512\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.590711236000061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009029347449541092\n",
      "        model: {}\n",
      "        policy_loss: -0.09848328679800034\n",
      "        total_loss: 387.76031494140625\n",
      "        vf_explained_var: 0.8040342926979065\n",
      "        vf_loss: 387.8382568359375\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.46406820950061\n",
      "    ram_util_percent: 37.733617539585865\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06787322891278114\n",
      "    mean_env_wait_ms: 119.7227312530466\n",
      "    mean_inference_ms: 1.716910321714039\n",
      "    mean_raw_obs_processing_ms: 9.589092465889095\n",
      "  time_since_restore: 60032.382362127304\n",
      "  time_this_iter_s: 575.2088031768799\n",
      "  time_total_s: 60032.382362127304\n",
      "  timers:\n",
      "    learn_throughput: 264.251\n",
      "    learn_time_ms: 15137.109\n",
      "    load_throughput: 11010.962\n",
      "    load_time_ms: 363.274\n",
      "    sample_throughput: 7.155\n",
      "    sample_time_ms: 559013.784\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613886586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_06-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 137.41\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 72.27378223507384\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3539\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5984408259391785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0075990972109138966\n",
      "        model: {}\n",
      "        policy_loss: -0.08635248988866806\n",
      "        total_loss: 253.9138641357422\n",
      "        vf_explained_var: 0.8253668546676636\n",
      "        vf_loss: 253.98289489746094\n",
      "    num_steps_sampled: 448000\n",
      "    num_steps_trained: 448000\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.209157509157514\n",
      "    ram_util_percent: 37.84822954822955\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06784796767137134\n",
      "    mean_env_wait_ms: 119.80372562977568\n",
      "    mean_inference_ms: 1.7165187067082488\n",
      "    mean_raw_obs_processing_ms: 9.58153597114176\n",
      "  time_since_restore: 60606.63854265213\n",
      "  time_this_iter_s: 574.256180524826\n",
      "  time_total_s: 60606.63854265213\n",
      "  timers:\n",
      "    learn_throughput: 264.217\n",
      "    learn_time_ms: 15139.074\n",
      "    load_throughput: 10981.592\n",
      "    load_time_ms: 364.246\n",
      "    sample_throughput: 7.152\n",
      "    sample_time_ms: 559292.284\n",
      "    update_time_ms: 3.547\n",
      "  timestamp: 1613887161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 448000\n",
      "  training_iteration: 112\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 141.31\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 78.43174718781738\n",
      "  episode_reward_min: -105.48941655446629\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3568\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6062167882919312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00849900022149086\n",
      "        model: {}\n",
      "        policy_loss: -0.08769343048334122\n",
      "        total_loss: 283.53985595703125\n",
      "        vf_explained_var: 0.8445320129394531\n",
      "        vf_loss: 283.6081848144531\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.00335329341318\n",
      "    ram_util_percent: 38.13353293413174\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06782688799794695\n",
      "    mean_env_wait_ms: 119.89516835768752\n",
      "    mean_inference_ms: 1.716184160343747\n",
      "    mean_raw_obs_processing_ms: 9.573978922801206\n",
      "  time_since_restore: 61191.2335793972\n",
      "  time_this_iter_s: 584.5950367450714\n",
      "  time_total_s: 61191.2335793972\n",
      "  timers:\n",
      "    learn_throughput: 264.295\n",
      "    learn_time_ms: 15134.624\n",
      "    load_throughput: 10961.008\n",
      "    load_time_ms: 364.93\n",
      "    sample_throughput: 7.142\n",
      "    sample_time_ms: 560044.648\n",
      "    update_time_ms: 3.61\n",
      "  timestamp: 1613887745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 144.6\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 86.82461647095136\n",
      "  episode_reward_min: -105.0321410534626\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3594\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5918995141983032\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006438602227717638\n",
      "        model: {}\n",
      "        policy_loss: -0.06593605875968933\n",
      "        total_loss: 332.7830505371094\n",
      "        vf_explained_var: 0.6599776148796082\n",
      "        vf_loss: 332.8342590332031\n",
      "    num_steps_sampled: 456000\n",
      "    num_steps_trained: 456000\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.34240196078431\n",
      "    ram_util_percent: 38.063357843137254\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06780827979209664\n",
      "    mean_env_wait_ms: 119.97759657799472\n",
      "    mean_inference_ms: 1.7158729855139294\n",
      "    mean_raw_obs_processing_ms: 9.564777671008347\n",
      "  time_since_restore: 61762.852212667465\n",
      "  time_this_iter_s: 571.6186332702637\n",
      "  time_total_s: 61762.852212667465\n",
      "  timers:\n",
      "    learn_throughput: 264.397\n",
      "    learn_time_ms: 15128.754\n",
      "    load_throughput: 10947.792\n",
      "    load_time_ms: 365.37\n",
      "    sample_throughput: 7.148\n",
      "    sample_time_ms: 559576.306\n",
      "    update_time_ms: 3.667\n",
      "  timestamp: 1613888317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 456000\n",
      "  training_iteration: 114\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-28-17\n",
      "  done: false\n",
      "  episode_len_mean: 144.62\n",
      "  episode_reward_max: 118.39091820189648\n",
      "  episode_reward_mean: 86.80167187729789\n",
      "  episode_reward_min: -105.09060085253891\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3622\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6433344483375549\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010839796625077724\n",
      "        model: {}\n",
      "        policy_loss: -0.10590440779924393\n",
      "        total_loss: 570.0552368164062\n",
      "        vf_explained_var: 0.7485004663467407\n",
      "        vf_loss: 570.1365966796875\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.352841596130595\n",
      "    ram_util_percent: 38.07920193470375\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06778949191005351\n",
      "    mean_env_wait_ms: 120.07001042963421\n",
      "    mean_inference_ms: 1.7155426799237201\n",
      "    mean_raw_obs_processing_ms: 9.554230492816803\n",
      "  time_since_restore: 62342.62043309212\n",
      "  time_this_iter_s: 579.7682204246521\n",
      "  time_total_s: 62342.62043309212\n",
      "  timers:\n",
      "    learn_throughput: 261.992\n",
      "    learn_time_ms: 15267.62\n",
      "    load_throughput: 10942.687\n",
      "    load_time_ms: 365.541\n",
      "    sample_throughput: 7.145\n",
      "    sample_time_ms: 559828.975\n",
      "    update_time_ms: 3.615\n",
      "  timestamp: 1613888897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 147.86\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 93.33501276419842\n",
      "  episode_reward_min: -105.09060085253891\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3649\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5805870294570923\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009480483829975128\n",
      "        model: {}\n",
      "        policy_loss: -0.09276328235864639\n",
      "        total_loss: 34.91984939575195\n",
      "        vf_explained_var: 0.9700055718421936\n",
      "        vf_loss: 34.99101638793945\n",
      "    num_steps_sampled: 464000\n",
      "    num_steps_trained: 464000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.62633495145631\n",
      "    ram_util_percent: 38.1372572815534\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0677720796855766\n",
      "    mean_env_wait_ms: 120.15735014680446\n",
      "    mean_inference_ms: 1.7152309768018645\n",
      "    mean_raw_obs_processing_ms: 9.543755308827134\n",
      "  time_since_restore: 62919.88499903679\n",
      "  time_this_iter_s: 577.2645659446716\n",
      "  time_total_s: 62919.88499903679\n",
      "  timers:\n",
      "    learn_throughput: 262.086\n",
      "    learn_time_ms: 15262.151\n",
      "    load_throughput: 10951.716\n",
      "    load_time_ms: 365.24\n",
      "    sample_throughput: 7.138\n",
      "    sample_time_ms: 560371.214\n",
      "    update_time_ms: 3.602\n",
      "  timestamp: 1613889475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 464000\n",
      "  training_iteration: 116\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 151.34\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 97.33516881296664\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 3674\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6057289838790894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00902612879872322\n",
      "        model: {}\n",
      "        policy_loss: -0.08407626301050186\n",
      "        total_loss: 47.36072540283203\n",
      "        vf_explained_var: 0.9562988877296448\n",
      "        vf_loss: 47.42424011230469\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.257720588235294\n",
      "    ram_util_percent: 38.134068627450986\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06775213187945846\n",
      "    mean_env_wait_ms: 120.23711540446456\n",
      "    mean_inference_ms: 1.7148622716953952\n",
      "    mean_raw_obs_processing_ms: 9.531843481668078\n",
      "  time_since_restore: 63491.65019154549\n",
      "  time_this_iter_s: 571.7651925086975\n",
      "  time_total_s: 63491.65019154549\n",
      "  timers:\n",
      "    learn_throughput: 262.208\n",
      "    learn_time_ms: 15255.09\n",
      "    load_throughput: 10960.437\n",
      "    load_time_ms: 364.949\n",
      "    sample_throughput: 7.142\n",
      "    sample_time_ms: 560080.637\n",
      "    update_time_ms: 3.619\n",
      "  timestamp: 1613890046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_07-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 146.86\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 91.05291780335374\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 3704\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6012541651725769\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00911764707416296\n",
      "        model: {}\n",
      "        policy_loss: -0.09254691749811172\n",
      "        total_loss: 685.6951293945312\n",
      "        vf_explained_var: 0.6572573184967041\n",
      "        vf_loss: 685.7669067382812\n",
      "    num_steps_sampled: 472000\n",
      "    num_steps_trained: 472000\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.51634146341465\n",
      "    ram_util_percent: 38.13914634146342\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06772919668110616\n",
      "    mean_env_wait_ms: 120.32691297202932\n",
      "    mean_inference_ms: 1.7144107681494976\n",
      "    mean_raw_obs_processing_ms: 9.520671146772086\n",
      "  time_since_restore: 64066.185210466385\n",
      "  time_this_iter_s: 574.5350189208984\n",
      "  time_total_s: 64066.185210466385\n",
      "  timers:\n",
      "    learn_throughput: 262.137\n",
      "    learn_time_ms: 15259.186\n",
      "    load_throughput: 10969.156\n",
      "    load_time_ms: 364.659\n",
      "    sample_throughput: 7.143\n",
      "    sample_time_ms: 560016.439\n",
      "    update_time_ms: 3.648\n",
      "  timestamp: 1613890621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 472000\n",
      "  training_iteration: 118\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-06-33\n",
      "  done: false\n",
      "  episode_len_mean: 148.66\n",
      "  episode_reward_max: 118.39873892711245\n",
      "  episode_reward_mean: 89.15732775802172\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3730\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6236892342567444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013307305052876472\n",
      "        model: {}\n",
      "        policy_loss: -0.1155630424618721\n",
      "        total_loss: 1010.5505981445312\n",
      "        vf_explained_var: 0.5766982436180115\n",
      "        vf_loss: 1010.6359252929688\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.30882352941177\n",
      "    ram_util_percent: 38.13970588235295\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06770796026275733\n",
      "    mean_env_wait_ms: 120.40130526884197\n",
      "    mean_inference_ms: 1.7140039793359307\n",
      "    mean_raw_obs_processing_ms: 9.510031471826066\n",
      "  time_since_restore: 64637.37950015068\n",
      "  time_this_iter_s: 571.1942896842957\n",
      "  time_total_s: 64637.37950015068\n",
      "  timers:\n",
      "    learn_throughput: 262.135\n",
      "    learn_time_ms: 15259.32\n",
      "    load_throughput: 10973.496\n",
      "    load_time_ms: 364.515\n",
      "    sample_throughput: 7.147\n",
      "    sample_time_ms: 559683.545\n",
      "    update_time_ms: 3.636\n",
      "  timestamp: 1613891193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-16-04\n",
      "  done: false\n",
      "  episode_len_mean: 148.73\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 87.00290944381177\n",
      "  episode_reward_min: -106.43562513752948\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 3756\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5877834558486938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009241716004908085\n",
      "        model: {}\n",
      "        policy_loss: -0.08691494166851044\n",
      "        total_loss: 67.36650848388672\n",
      "        vf_explained_var: 0.944295346736908\n",
      "        vf_loss: 67.432373046875\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.35693251533743\n",
      "    ram_util_percent: 38.141840490797556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0676864742568336\n",
      "    mean_env_wait_ms: 120.47292656211799\n",
      "    mean_inference_ms: 1.7135771052734765\n",
      "    mean_raw_obs_processing_ms: 9.499117822285328\n",
      "  time_since_restore: 65208.24702858925\n",
      "  time_this_iter_s: 570.8675284385681\n",
      "  time_total_s: 65208.24702858925\n",
      "  timers:\n",
      "    learn_throughput: 262.126\n",
      "    learn_time_ms: 15259.811\n",
      "    load_throughput: 10962.411\n",
      "    load_time_ms: 364.883\n",
      "    sample_throughput: 7.152\n",
      "    sample_time_ms: 559310.986\n",
      "    update_time_ms: 3.658\n",
      "  timestamp: 1613891764\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 120\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-24-37\n",
      "  done: false\n",
      "  episode_len_mean: 146.66\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 85.14329107139147\n",
      "  episode_reward_min: -100.99048036755502\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3785\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5510581731796265\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007981202565133572\n",
      "        model: {}\n",
      "        policy_loss: -0.08055435866117477\n",
      "        total_loss: 546.143310546875\n",
      "        vf_explained_var: 0.6825169920921326\n",
      "        vf_loss: 546.2056884765625\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.81270491803278\n",
      "    ram_util_percent: 38.12691256830601\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06767392832483515\n",
      "    mean_env_wait_ms: 120.5110071355082\n",
      "    mean_inference_ms: 1.7133055716367522\n",
      "    mean_raw_obs_processing_ms: 9.489400407951997\n",
      "  time_since_restore: 65721.15237927437\n",
      "  time_this_iter_s: 512.9053506851196\n",
      "  time_total_s: 65721.15237927437\n",
      "  timers:\n",
      "    learn_throughput: 261.767\n",
      "    learn_time_ms: 15280.742\n",
      "    load_throughput: 10970.308\n",
      "    load_time_ms: 364.621\n",
      "    sample_throughput: 7.233\n",
      "    sample_time_ms: 553057.905\n",
      "    update_time_ms: 3.717\n",
      "  timestamp: 1613892277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-33-19\n",
      "  done: false\n",
      "  episode_len_mean: 146.02\n",
      "  episode_reward_max: 118.37573316320498\n",
      "  episode_reward_mean: 85.38652081386765\n",
      "  episode_reward_min: -100.4306152638022\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 3813\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6183977723121643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010066812857985497\n",
      "        model: {}\n",
      "        policy_loss: -0.09824593365192413\n",
      "        total_loss: 581.5679321289062\n",
      "        vf_explained_var: 0.7129077315330505\n",
      "        vf_loss: 581.6431274414062\n",
      "    num_steps_sampled: 488000\n",
      "    num_steps_trained: 488000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.68375838926174\n",
      "    ram_util_percent: 38.153825503355705\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06767878007932275\n",
      "    mean_env_wait_ms: 120.51764218598193\n",
      "    mean_inference_ms: 1.7133476223797286\n",
      "    mean_raw_obs_processing_ms: 9.479803397885286\n",
      "  time_since_restore: 66243.28735876083\n",
      "  time_this_iter_s: 522.1349794864655\n",
      "  time_total_s: 66243.28735876083\n",
      "  timers:\n",
      "    learn_throughput: 259.26\n",
      "    learn_time_ms: 15428.527\n",
      "    load_throughput: 10958.238\n",
      "    load_time_ms: 365.022\n",
      "    sample_throughput: 7.303\n",
      "    sample_time_ms: 547694.19\n",
      "    update_time_ms: 3.689\n",
      "  timestamp: 1613892799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 488000\n",
      "  training_iteration: 122\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 139.65\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 89.45473524232285\n",
      "  episode_reward_min: -100.4306152638022\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 3844\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.577362060546875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007396557833999395\n",
      "        model: {}\n",
      "        policy_loss: -0.07415349781513214\n",
      "        total_loss: 183.14419555664062\n",
      "        vf_explained_var: 0.8363568782806396\n",
      "        vf_loss: 183.2015380859375\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.56627140974966\n",
      "    ram_util_percent: 38.189855072463764\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06770722321730716\n",
      "    mean_env_wait_ms: 120.4917917336477\n",
      "    mean_inference_ms: 1.7137769699131404\n",
      "    mean_raw_obs_processing_ms: 9.473527999217005\n",
      "  time_since_restore: 66775.34722495079\n",
      "  time_this_iter_s: 532.0598661899567\n",
      "  time_total_s: 66775.34722495079\n",
      "  timers:\n",
      "    learn_throughput: 256.674\n",
      "    learn_time_ms: 15583.947\n",
      "    load_throughput: 10864.259\n",
      "    load_time_ms: 368.18\n",
      "    sample_throughput: 7.376\n",
      "    sample_time_ms: 542280.96\n",
      "    update_time_ms: 3.653\n",
      "  timestamp: 1613893331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-50-51\n",
      "  done: false\n",
      "  episode_len_mean: 139.74\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 84.90426776366216\n",
      "  episode_reward_min: -106.0701544586116\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3871\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6015790104866028\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01063192542642355\n",
      "        model: {}\n",
      "        policy_loss: -0.10586980730295181\n",
      "        total_loss: 477.35626220703125\n",
      "        vf_explained_var: 0.7866230010986328\n",
      "        vf_loss: 477.4378356933594\n",
      "    num_steps_sampled: 496000\n",
      "    num_steps_trained: 496000\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.47857142857144\n",
      "    ram_util_percent: 38.21563342318059\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0677439447389491\n",
      "    mean_env_wait_ms: 120.45729120222786\n",
      "    mean_inference_ms: 1.7143439789547819\n",
      "    mean_raw_obs_processing_ms: 9.467971795851675\n",
      "  time_since_restore: 67294.9882683754\n",
      "  time_this_iter_s: 519.6410434246063\n",
      "  time_total_s: 67294.9882683754\n",
      "  timers:\n",
      "    learn_throughput: 256.069\n",
      "    learn_time_ms: 15620.818\n",
      "    load_throughput: 10857.938\n",
      "    load_time_ms: 368.394\n",
      "    sample_throughput: 7.448\n",
      "    sample_time_ms: 537043.94\n",
      "    update_time_ms: 3.594\n",
      "  timestamp: 1613893851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 496000\n",
      "  training_iteration: 124\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_08-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 134.12\n",
      "  episode_reward_max: 118.39513312085698\n",
      "  episode_reward_mean: 84.80443379407956\n",
      "  episode_reward_min: -106.0701544586116\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 3903\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5771121382713318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008310528472065926\n",
      "        model: {}\n",
      "        policy_loss: -0.08232569694519043\n",
      "        total_loss: 534.6954345703125\n",
      "        vf_explained_var: 0.6438747644424438\n",
      "        vf_loss: 534.7588500976562\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.63836565096952\n",
      "    ram_util_percent: 38.17783933518006\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06778464054628712\n",
      "    mean_env_wait_ms: 120.4076427896925\n",
      "    mean_inference_ms: 1.7149836034740622\n",
      "    mean_raw_obs_processing_ms: 9.463932562409434\n",
      "  time_since_restore: 67801.0431239605\n",
      "  time_this_iter_s: 506.05485558509827\n",
      "  time_total_s: 67801.0431239605\n",
      "  timers:\n",
      "    learn_throughput: 258.103\n",
      "    learn_time_ms: 15497.712\n",
      "    load_throughput: 10813.376\n",
      "    load_time_ms: 369.912\n",
      "    sample_throughput: 7.55\n",
      "    sample_time_ms: 529791.92\n",
      "    update_time_ms: 3.559\n",
      "  timestamp: 1613894357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 138.5\n",
      "  episode_reward_max: 118.34709881053\n",
      "  episode_reward_mean: 78.08393089485901\n",
      "  episode_reward_min: -106.32775745859084\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3930\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6117790937423706\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010948827490210533\n",
      "        model: {}\n",
      "        policy_loss: -0.10564907640218735\n",
      "        total_loss: 647.387451171875\n",
      "        vf_explained_var: 0.6757882237434387\n",
      "        vf_loss: 647.4682006835938\n",
      "    num_steps_sampled: 504000\n",
      "    num_steps_trained: 504000\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.61178918169209\n",
      "    ram_util_percent: 38.201386962552014\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0678116961064663\n",
      "    mean_env_wait_ms: 120.35627306923674\n",
      "    mean_inference_ms: 1.715379314195032\n",
      "    mean_raw_obs_processing_ms: 9.458864461888382\n",
      "  time_since_restore: 68305.61447262764\n",
      "  time_this_iter_s: 504.5713486671448\n",
      "  time_total_s: 68305.61447262764\n",
      "  timers:\n",
      "    learn_throughput: 255.586\n",
      "    learn_time_ms: 15650.32\n",
      "    load_throughput: 10791.392\n",
      "    load_time_ms: 370.666\n",
      "    sample_throughput: 7.657\n",
      "    sample_time_ms: 522369.037\n",
      "    update_time_ms: 3.582\n",
      "  timestamp: 1613894862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 504000\n",
      "  training_iteration: 126\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-16-29\n",
      "  done: false\n",
      "  episode_len_mean: 142.47\n",
      "  episode_reward_max: 118.32835011673706\n",
      "  episode_reward_mean: 82.36495306691775\n",
      "  episode_reward_min: -106.32775745859084\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 3957\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5907235741615295\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008743084967136383\n",
      "        model: {}\n",
      "        policy_loss: -0.08979450166225433\n",
      "        total_loss: 294.9871826171875\n",
      "        vf_explained_var: 0.8123583197593689\n",
      "        vf_loss: 295.0570373535156\n",
      "    num_steps_sampled: 508000\n",
      "    num_steps_trained: 508000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.94388297872341\n",
      "    ram_util_percent: 38.37739361702128\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06784055093998786\n",
      "    mean_env_wait_ms: 120.30579860423741\n",
      "    mean_inference_ms: 1.7158013710289555\n",
      "    mean_raw_obs_processing_ms: 9.452628401740492\n",
      "  time_since_restore: 68832.49143481255\n",
      "  time_this_iter_s: 526.876962184906\n",
      "  time_total_s: 68832.49143481255\n",
      "  timers:\n",
      "    learn_throughput: 252.888\n",
      "    learn_time_ms: 15817.3\n",
      "    load_throughput: 10764.004\n",
      "    load_time_ms: 371.609\n",
      "    sample_throughput: 7.726\n",
      "    sample_time_ms: 517709.113\n",
      "    update_time_ms: 3.604\n",
      "  timestamp: 1613895389\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 508000\n",
      "  training_iteration: 127\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 142.03\n",
      "  episode_reward_max: 118.31354670270113\n",
      "  episode_reward_mean: 82.43069567717554\n",
      "  episode_reward_min: -106.80176523156126\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 3986\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5881098508834839\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010245510376989841\n",
      "        model: {}\n",
      "        policy_loss: -0.09339163452386856\n",
      "        total_loss: 627.2103271484375\n",
      "        vf_explained_var: 0.6385515928268433\n",
      "        vf_loss: 627.2803955078125\n",
      "    num_steps_sampled: 512000\n",
      "    num_steps_trained: 512000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.81226666666666\n",
      "    ram_util_percent: 38.380399999999995\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06787463923392938\n",
      "    mean_env_wait_ms: 120.26053147584571\n",
      "    mean_inference_ms: 1.7163259572157061\n",
      "    mean_raw_obs_processing_ms: 9.44585488949249\n",
      "  time_since_restore: 69358.38308548927\n",
      "  time_this_iter_s: 525.8916506767273\n",
      "  time_total_s: 69358.38308548927\n",
      "  timers:\n",
      "    learn_throughput: 252.533\n",
      "    learn_time_ms: 15839.527\n",
      "    load_throughput: 10719.51\n",
      "    load_time_ms: 373.151\n",
      "    sample_throughput: 7.8\n",
      "    sample_time_ms: 512821.553\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613895915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 512000\n",
      "  training_iteration: 128\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 132.8\n",
      "  episode_reward_max: 118.34928746608047\n",
      "  episode_reward_mean: 82.31662489947415\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 4021\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5682926177978516\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007367397658526897\n",
      "        model: {}\n",
      "        policy_loss: -0.07760433107614517\n",
      "        total_loss: 376.2999572753906\n",
      "        vf_explained_var: 0.7548487186431885\n",
      "        vf_loss: 376.3607482910156\n",
      "    num_steps_sampled: 516000\n",
      "    num_steps_trained: 516000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.78049450549451\n",
      "    ram_util_percent: 38.393956043956045\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06791655003039965\n",
      "    mean_env_wait_ms: 120.20590265398637\n",
      "    mean_inference_ms: 1.7169823124501375\n",
      "    mean_raw_obs_processing_ms: 9.442055682272372\n",
      "  time_since_restore: 69867.91096925735\n",
      "  time_this_iter_s: 509.52788376808167\n",
      "  time_total_s: 69867.91096925735\n",
      "  timers:\n",
      "    learn_throughput: 252.141\n",
      "    learn_time_ms: 15864.164\n",
      "    load_throughput: 10711.439\n",
      "    load_time_ms: 373.433\n",
      "    sample_throughput: 7.895\n",
      "    sample_time_ms: 506628.024\n",
      "    update_time_ms: 3.567\n",
      "  timestamp: 1613896425\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 516000\n",
      "  training_iteration: 129\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 129.46\n",
      "  episode_reward_max: 118.34928746608047\n",
      "  episode_reward_mean: 80.40744834850254\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4051\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6039897799491882\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010948044247925282\n",
      "        model: {}\n",
      "        policy_loss: -0.10490277409553528\n",
      "        total_loss: 421.2901611328125\n",
      "        vf_explained_var: 0.8155714869499207\n",
      "        vf_loss: 421.3701171875\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53504867872045\n",
      "    ram_util_percent: 38.365507649513205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06794615383610282\n",
      "    mean_env_wait_ms: 120.15307269858904\n",
      "    mean_inference_ms: 1.7174442956596794\n",
      "    mean_raw_obs_processing_ms: 9.441340066067333\n",
      "  time_since_restore: 70371.77071595192\n",
      "  time_this_iter_s: 503.8597466945648\n",
      "  time_total_s: 70371.77071595192\n",
      "  timers:\n",
      "    learn_throughput: 251.831\n",
      "    learn_time_ms: 15883.643\n",
      "    load_throughput: 10696.796\n",
      "    load_time_ms: 373.944\n",
      "    sample_throughput: 8.001\n",
      "    sample_time_ms: 499906.446\n",
      "    update_time_ms: 3.558\n",
      "  timestamp: 1613896929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 130\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-50-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.5\n",
      "  episode_reward_max: 118.37421759265597\n",
      "  episode_reward_mean: 82.69939237282279\n",
      "  episode_reward_min: -106.89583542846157\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4079\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5987846255302429\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005686358083039522\n",
      "        model: {}\n",
      "        policy_loss: -0.07071297615766525\n",
      "        total_loss: 285.1310119628906\n",
      "        vf_explained_var: 0.7715242505073547\n",
      "        vf_loss: 285.1888122558594\n",
      "    num_steps_sampled: 524000\n",
      "    num_steps_trained: 524000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.519860139860135\n",
      "    ram_util_percent: 38.37874125874126\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06796573233450409\n",
      "    mean_env_wait_ms: 120.09234682412965\n",
      "    mean_inference_ms: 1.7177408642111685\n",
      "    mean_raw_obs_processing_ms: 9.440449571341798\n",
      "  time_since_restore: 70872.90150022507\n",
      "  time_this_iter_s: 501.1307842731476\n",
      "  time_total_s: 70872.90150022507\n",
      "  timers:\n",
      "    learn_throughput: 251.725\n",
      "    learn_time_ms: 15890.363\n",
      "    load_throughput: 10678.404\n",
      "    load_time_ms: 374.588\n",
      "    sample_throughput: 8.02\n",
      "    sample_time_ms: 498723.017\n",
      "    update_time_ms: 3.481\n",
      "  timestamp: 1613897430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 524000\n",
      "  training_iteration: 131\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_09-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.54\n",
      "  episode_reward_max: 118.3795693239413\n",
      "  episode_reward_mean: 82.96836530942372\n",
      "  episode_reward_min: -103.76890862329319\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4108\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5838570594787598\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01188985537737608\n",
      "        model: {}\n",
      "        policy_loss: -0.10170167684555054\n",
      "        total_loss: 772.657958984375\n",
      "        vf_explained_var: 0.653910756111145\n",
      "        vf_loss: 772.7326049804688\n",
      "    num_steps_sampled: 528000\n",
      "    num_steps_trained: 528000\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53216783216783\n",
      "    ram_util_percent: 38.39090909090909\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06798371611601566\n",
      "    mean_env_wait_ms: 120.02619330508769\n",
      "    mean_inference_ms: 1.7180095488962615\n",
      "    mean_raw_obs_processing_ms: 9.436648742925328\n",
      "  time_since_restore: 71374.011282444\n",
      "  time_this_iter_s: 501.1097822189331\n",
      "  time_total_s: 71374.011282444\n",
      "  timers:\n",
      "    learn_throughput: 253.79\n",
      "    learn_time_ms: 15761.042\n",
      "    load_throughput: 10597.706\n",
      "    load_time_ms: 377.44\n",
      "    sample_throughput: 8.052\n",
      "    sample_time_ms: 496749.288\n",
      "    update_time_ms: 3.498\n",
      "  timestamp: 1613897932\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 528000\n",
      "  training_iteration: 132\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.58\n",
      "  episode_reward_max: 118.39521154807612\n",
      "  episode_reward_mean: 83.17846175221419\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4139\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5650530457496643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007939182221889496\n",
      "        model: {}\n",
      "        policy_loss: -0.08119844645261765\n",
      "        total_loss: 407.46173095703125\n",
      "        vf_explained_var: 0.7646421194076538\n",
      "        vf_loss: 407.5248718261719\n",
      "    num_steps_sampled: 532000\n",
      "    num_steps_trained: 532000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55833333333333\n",
      "    ram_util_percent: 38.338055555555556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06800290073032944\n",
      "    mean_env_wait_ms: 119.95183123516772\n",
      "    mean_inference_ms: 1.7182751771675613\n",
      "    mean_raw_obs_processing_ms: 9.432557149867971\n",
      "  time_since_restore: 71877.89301609993\n",
      "  time_this_iter_s: 503.88173365592957\n",
      "  time_total_s: 71877.89301609993\n",
      "  timers:\n",
      "    learn_throughput: 255.939\n",
      "    learn_time_ms: 15628.753\n",
      "    load_throughput: 10630.193\n",
      "    load_time_ms: 376.287\n",
      "    sample_throughput: 8.096\n",
      "    sample_time_ms: 494064.123\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613898436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 532000\n",
      "  training_iteration: 133\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 139.25\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 85.27356494809966\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4164\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.600960373878479\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006746595725417137\n",
      "        model: {}\n",
      "        policy_loss: -0.07783032953739166\n",
      "        total_loss: 314.6885070800781\n",
      "        vf_explained_var: 0.7607309818267822\n",
      "        vf_loss: 314.7509765625\n",
      "    num_steps_sampled: 536000\n",
      "    num_steps_trained: 536000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.494092827004216\n",
      "    ram_util_percent: 38.360759493670884\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06801850421276065\n",
      "    mean_env_wait_ms: 119.8919756049781\n",
      "    mean_inference_ms: 1.718506779837454\n",
      "    mean_raw_obs_processing_ms: 9.426981561005293\n",
      "  time_since_restore: 72376.05636382103\n",
      "  time_this_iter_s: 498.16334772109985\n",
      "  time_total_s: 72376.05636382103\n",
      "  timers:\n",
      "    learn_throughput: 256.104\n",
      "    learn_time_ms: 15618.666\n",
      "    load_throughput: 10530.235\n",
      "    load_time_ms: 379.859\n",
      "    sample_throughput: 8.131\n",
      "    sample_time_ms: 491923.513\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613898934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 536000\n",
      "  training_iteration: 134\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-23-58\n",
      "  done: false\n",
      "  episode_len_mean: 139.5\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 95.64621330132915\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4194\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5370206236839294\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004629514180123806\n",
      "        model: {}\n",
      "        policy_loss: -0.04861670359969139\n",
      "        total_loss: 137.58197021484375\n",
      "        vf_explained_var: 0.8455789685249329\n",
      "        vf_loss: 137.6200408935547\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.59679665738162\n",
      "    ram_util_percent: 38.40431754874651\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06803823480184848\n",
      "    mean_env_wait_ms: 119.82114675593346\n",
      "    mean_inference_ms: 1.718770904202886\n",
      "    mean_raw_obs_processing_ms: 9.42133230428674\n",
      "  time_since_restore: 72879.4960064888\n",
      "  time_this_iter_s: 503.4396426677704\n",
      "  time_total_s: 72879.4960064888\n",
      "  timers:\n",
      "    learn_throughput: 256.095\n",
      "    learn_time_ms: 15619.196\n",
      "    load_throughput: 10534.313\n",
      "    load_time_ms: 379.712\n",
      "    sample_throughput: 8.136\n",
      "    sample_time_ms: 491663.38\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613899438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 135\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-32-20\n",
      "  done: false\n",
      "  episode_len_mean: 138.83\n",
      "  episode_reward_max: 118.39998757567115\n",
      "  episode_reward_mean: 95.68756577876341\n",
      "  episode_reward_min: -105.48697373799484\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4224\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5466543436050415\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011059517040848732\n",
      "        model: {}\n",
      "        policy_loss: -0.08189653605222702\n",
      "        total_loss: 242.59808349609375\n",
      "        vf_explained_var: 0.8244056701660156\n",
      "        vf_loss: 242.66738891601562\n",
      "    num_steps_sampled: 544000\n",
      "    num_steps_trained: 544000\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.639191073919115\n",
      "    ram_util_percent: 38.38967921896793\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06805755736091408\n",
      "    mean_env_wait_ms: 119.75206377602635\n",
      "    mean_inference_ms: 1.7190400202641178\n",
      "    mean_raw_obs_processing_ms: 9.41560263759338\n",
      "  time_since_restore: 73381.71351766586\n",
      "  time_this_iter_s: 502.217511177063\n",
      "  time_total_s: 73381.71351766586\n",
      "  timers:\n",
      "    learn_throughput: 258.177\n",
      "    learn_time_ms: 15493.223\n",
      "    load_throughput: 10535.06\n",
      "    load_time_ms: 379.685\n",
      "    sample_throughput: 8.137\n",
      "    sample_time_ms: 491552.855\n",
      "    update_time_ms: 3.606\n",
      "  timestamp: 1613899940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 544000\n",
      "  training_iteration: 136\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-40-41\n",
      "  done: false\n",
      "  episode_len_mean: 139.2\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 95.88512579679904\n",
      "  episode_reward_min: -100.1750695215878\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4251\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5456653237342834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014115593396127224\n",
      "        model: {}\n",
      "        policy_loss: -0.0856579840183258\n",
      "        total_loss: 516.1102294921875\n",
      "        vf_explained_var: 0.619394838809967\n",
      "        vf_loss: 516.1798095703125\n",
      "    num_steps_sampled: 548000\n",
      "    num_steps_trained: 548000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.451468531468535\n",
      "    ram_util_percent: 38.343916083916085\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06807438256326685\n",
      "    mean_env_wait_ms: 119.68962361357994\n",
      "    mean_inference_ms: 1.7193031557236806\n",
      "    mean_raw_obs_processing_ms: 9.409635454162597\n",
      "  time_since_restore: 73882.23320555687\n",
      "  time_this_iter_s: 500.51968789100647\n",
      "  time_total_s: 73882.23320555687\n",
      "  timers:\n",
      "    learn_throughput: 260.521\n",
      "    learn_time_ms: 15353.831\n",
      "    load_throughput: 10524.565\n",
      "    load_time_ms: 380.063\n",
      "    sample_throughput: 8.179\n",
      "    sample_time_ms: 489059.197\n",
      "    update_time_ms: 3.631\n",
      "  timestamp: 1613900441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 548000\n",
      "  training_iteration: 137\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 142.07\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 97.81481651326742\n",
      "  episode_reward_min: -105.63298102378208\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4277\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5156704783439636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01677967607975006\n",
      "        model: {}\n",
      "        policy_loss: -0.09261477738618851\n",
      "        total_loss: 24.15653419494629\n",
      "        vf_explained_var: 0.974636435508728\n",
      "        vf_loss: 24.230031967163086\n",
      "    num_steps_sampled: 552000\n",
      "    num_steps_trained: 552000\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.479663394109394\n",
      "    ram_util_percent: 38.35035063113605\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06808918160052571\n",
      "    mean_env_wait_ms: 119.63162029126406\n",
      "    mean_inference_ms: 1.7195446712067508\n",
      "    mean_raw_obs_processing_ms: 9.403294456473589\n",
      "  time_since_restore: 74381.7987921238\n",
      "  time_this_iter_s: 499.56558656692505\n",
      "  time_total_s: 74381.7987921238\n",
      "  timers:\n",
      "    learn_throughput: 260.567\n",
      "    learn_time_ms: 15351.132\n",
      "    load_throughput: 10558.554\n",
      "    load_time_ms: 378.84\n",
      "    sample_throughput: 8.223\n",
      "    sample_time_ms: 486429.308\n",
      "    update_time_ms: 3.693\n",
      "  timestamp: 1613900941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 552000\n",
      "  training_iteration: 138\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_10-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 139.24\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 93.40331968238395\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 4309\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5389827489852905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014672734774649143\n",
      "        model: {}\n",
      "        policy_loss: -0.0996832475066185\n",
      "        total_loss: 407.98126220703125\n",
      "        vf_explained_var: 0.790763258934021\n",
      "        vf_loss: 408.0642395019531\n",
      "    num_steps_sampled: 556000\n",
      "    num_steps_trained: 556000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.656726768377254\n",
      "    ram_util_percent: 38.41900138696255\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06810755744305874\n",
      "    mean_env_wait_ms: 119.56045884890777\n",
      "    mean_inference_ms: 1.7198390813878144\n",
      "    mean_raw_obs_processing_ms: 9.39705959078869\n",
      "  time_since_restore: 74887.08270263672\n",
      "  time_this_iter_s: 505.2839105129242\n",
      "  time_total_s: 74887.08270263672\n",
      "  timers:\n",
      "    learn_throughput: 260.56\n",
      "    learn_time_ms: 15351.536\n",
      "    load_throughput: 10547.286\n",
      "    load_time_ms: 379.244\n",
      "    sample_throughput: 8.23\n",
      "    sample_time_ms: 486000.871\n",
      "    update_time_ms: 3.718\n",
      "  timestamp: 1613901446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 556000\n",
      "  training_iteration: 139\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-05-47\n",
      "  done: false\n",
      "  episode_len_mean: 144.46\n",
      "  episode_reward_max: 118.3980188304479\n",
      "  episode_reward_mean: 93.42574276068312\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4336\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5067443251609802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010971568524837494\n",
      "        model: {}\n",
      "        policy_loss: -0.06811364740133286\n",
      "        total_loss: 452.9324951171875\n",
      "        vf_explained_var: 0.6769991517066956\n",
      "        vf_loss: 452.988037109375\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46736694677871\n",
      "    ram_util_percent: 38.378151260504204\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06812365814838989\n",
      "    mean_env_wait_ms: 119.50133882905752\n",
      "    mean_inference_ms: 1.720096938446058\n",
      "    mean_raw_obs_processing_ms: 9.390908318085735\n",
      "  time_since_restore: 75387.62991380692\n",
      "  time_this_iter_s: 500.54721117019653\n",
      "  time_total_s: 75387.62991380692\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.824\n",
      "    load_throughput: 10501.801\n",
      "    load_time_ms: 380.887\n",
      "    sample_throughput: 8.236\n",
      "    sample_time_ms: 485666.887\n",
      "    update_time_ms: 3.724\n",
      "  timestamp: 1613901947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 140\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 141.74\n",
      "  episode_reward_max: 118.38747272626844\n",
      "  episode_reward_mean: 89.11573236867281\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4362\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5270000100135803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013160942122340202\n",
      "        model: {}\n",
      "        policy_loss: -0.08172133564949036\n",
      "        total_loss: 480.5737609863281\n",
      "        vf_explained_var: 0.6476766467094421\n",
      "        vf_loss: 480.6405029296875\n",
      "    num_steps_sampled: 564000\n",
      "    num_steps_trained: 564000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.1931081081081\n",
      "    ram_util_percent: 38.35702702702703\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06814497785539061\n",
      "    mean_env_wait_ms: 119.45281915560403\n",
      "    mean_inference_ms: 1.720415928621482\n",
      "    mean_raw_obs_processing_ms: 9.384962652788973\n",
      "  time_since_restore: 75906.1450073719\n",
      "  time_this_iter_s: 518.5150935649872\n",
      "  time_total_s: 75906.1450073719\n",
      "  timers:\n",
      "    learn_throughput: 258.701\n",
      "    learn_time_ms: 15461.872\n",
      "    load_throughput: 10395.127\n",
      "    load_time_ms: 384.796\n",
      "    sample_throughput: 8.209\n",
      "    sample_time_ms: 487288.568\n",
      "    update_time_ms: 3.87\n",
      "  timestamp: 1613902466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 564000\n",
      "  training_iteration: 141\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 139.19\n",
      "  episode_reward_max: 118.37581776245045\n",
      "  episode_reward_mean: 85.05349157386325\n",
      "  episode_reward_min: -106.52348667552874\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4393\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4903784990310669\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012807418592274189\n",
      "        model: {}\n",
      "        policy_loss: -0.08418212085962296\n",
      "        total_loss: 243.77842712402344\n",
      "        vf_explained_var: 0.827601969242096\n",
      "        vf_loss: 243.84803771972656\n",
      "    num_steps_sampled: 568000\n",
      "    num_steps_trained: 568000\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.514027777777784\n",
      "    ram_util_percent: 38.35930555555556\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06816904112888227\n",
      "    mean_env_wait_ms: 119.39716645914392\n",
      "    mean_inference_ms: 1.7207919127298095\n",
      "    mean_raw_obs_processing_ms: 9.379445230691656\n",
      "  time_since_restore: 76410.0078485012\n",
      "  time_this_iter_s: 503.862841129303\n",
      "  time_total_s: 76410.0078485012\n",
      "  timers:\n",
      "    learn_throughput: 258.661\n",
      "    learn_time_ms: 15464.238\n",
      "    load_throughput: 10496.982\n",
      "    load_time_ms: 381.062\n",
      "    sample_throughput: 8.204\n",
      "    sample_time_ms: 487564.424\n",
      "    update_time_ms: 3.868\n",
      "  timestamp: 1613902970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 568000\n",
      "  training_iteration: 142\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 143.68\n",
      "  episode_reward_max: 118.37902254097419\n",
      "  episode_reward_mean: 91.58540820396809\n",
      "  episode_reward_min: -102.28401878985044\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4421\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5134223699569702\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010403241962194443\n",
      "        model: {}\n",
      "        policy_loss: -0.064632348716259\n",
      "        total_loss: 142.81903076171875\n",
      "        vf_explained_var: 0.8575036525726318\n",
      "        vf_loss: 142.87185668945312\n",
      "    num_steps_sampled: 572000\n",
      "    num_steps_trained: 572000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.490934449093444\n",
      "    ram_util_percent: 38.3768479776848\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0681908187331111\n",
      "    mean_env_wait_ms: 119.34707099125372\n",
      "    mean_inference_ms: 1.7211543747880358\n",
      "    mean_raw_obs_processing_ms: 9.373413416440878\n",
      "  time_since_restore: 76912.78030776978\n",
      "  time_this_iter_s: 502.77245926856995\n",
      "  time_total_s: 76912.78030776978\n",
      "  timers:\n",
      "    learn_throughput: 258.631\n",
      "    learn_time_ms: 15466.04\n",
      "    load_throughput: 10541.963\n",
      "    load_time_ms: 379.436\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487454.452\n",
      "    update_time_ms: 3.895\n",
      "  timestamp: 1613903473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 572000\n",
      "  training_iteration: 143\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 142.24\n",
      "  episode_reward_max: 118.37902254097419\n",
      "  episode_reward_mean: 89.35394718694442\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4448\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.530292809009552\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013976650312542915\n",
      "        model: {}\n",
      "        policy_loss: -0.0955086275935173\n",
      "        total_loss: 412.23358154296875\n",
      "        vf_explained_var: 0.7463707327842712\n",
      "        vf_loss: 412.3132019042969\n",
      "    num_steps_sampled: 576000\n",
      "    num_steps_trained: 576000\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.51969273743018\n",
      "    ram_util_percent: 38.37164804469273\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06820948582796282\n",
      "    mean_env_wait_ms: 119.29646149770547\n",
      "    mean_inference_ms: 1.7214731315585197\n",
      "    mean_raw_obs_processing_ms: 9.367935867080444\n",
      "  time_since_restore: 77414.37563896179\n",
      "  time_this_iter_s: 501.5953311920166\n",
      "  time_total_s: 77414.37563896179\n",
      "  timers:\n",
      "    learn_throughput: 258.62\n",
      "    learn_time_ms: 15466.721\n",
      "    load_throughput: 10471.65\n",
      "    load_time_ms: 381.984\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487792.196\n",
      "    update_time_ms: 3.898\n",
      "  timestamp: 1613903974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 576000\n",
      "  training_iteration: 144\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 146.42\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 99.8468263089411\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4475\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.49783721566200256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011227715760469437\n",
      "        model: {}\n",
      "        policy_loss: -0.07338139414787292\n",
      "        total_loss: 137.79476928710938\n",
      "        vf_explained_var: 0.8573033213615417\n",
      "        vf_loss: 137.8553466796875\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.584129213483145\n",
      "    ram_util_percent: 38.39999999999999\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0682249442096093\n",
      "    mean_env_wait_ms: 119.24202864447405\n",
      "    mean_inference_ms: 1.72173241233231\n",
      "    mean_raw_obs_processing_ms: 9.36173211631575\n",
      "  time_since_restore: 77912.99190068245\n",
      "  time_this_iter_s: 498.61626172065735\n",
      "  time_total_s: 77912.99190068245\n",
      "  timers:\n",
      "    learn_throughput: 258.612\n",
      "    learn_time_ms: 15467.174\n",
      "    load_throughput: 10505.049\n",
      "    load_time_ms: 380.769\n",
      "    sample_throughput: 8.208\n",
      "    sample_time_ms: 487310.161\n",
      "    update_time_ms: 3.911\n",
      "  timestamp: 1613904473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 145\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_11-56-17\n",
      "  done: false\n",
      "  episode_len_mean: 144.87\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 93.49306636159764\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4504\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5081709027290344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01671558804810047\n",
      "        model: {}\n",
      "        policy_loss: -0.09919644147157669\n",
      "        total_loss: 722.3006591796875\n",
      "        vf_explained_var: 0.5905051827430725\n",
      "        vf_loss: 722.3807983398438\n",
      "    num_steps_sampled: 584000\n",
      "    num_steps_trained: 584000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49304589707928\n",
      "    ram_util_percent: 38.400973574408894\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0682419435160842\n",
      "    mean_env_wait_ms: 119.18308159400847\n",
      "    mean_inference_ms: 1.7220153899542447\n",
      "    mean_raw_obs_processing_ms: 9.354646149701574\n",
      "  time_since_restore: 78416.43280887604\n",
      "  time_this_iter_s: 503.44090819358826\n",
      "  time_total_s: 78416.43280887604\n",
      "  timers:\n",
      "    learn_throughput: 258.609\n",
      "    learn_time_ms: 15467.359\n",
      "    load_throughput: 10529.166\n",
      "    load_time_ms: 379.897\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487433.854\n",
      "    update_time_ms: 3.808\n",
      "  timestamp: 1613904977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 584000\n",
      "  training_iteration: 146\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-04-38\n",
      "  done: false\n",
      "  episode_len_mean: 145.58\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 95.37161295857453\n",
      "  episode_reward_min: -105.46655939619049\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4529\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.498735249042511\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013529784977436066\n",
      "        model: {}\n",
      "        policy_loss: -0.07950646430253983\n",
      "        total_loss: 100.89649963378906\n",
      "        vf_explained_var: 0.9133281111717224\n",
      "        vf_loss: 100.9605941772461\n",
      "    num_steps_sampled: 588000\n",
      "    num_steps_trained: 588000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.422797202797206\n",
      "    ram_util_percent: 38.3627972027972\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06825711379685977\n",
      "    mean_env_wait_ms: 119.13289466671448\n",
      "    mean_inference_ms: 1.7222499108562166\n",
      "    mean_raw_obs_processing_ms: 9.347165462326934\n",
      "  time_since_restore: 78917.3786187172\n",
      "  time_this_iter_s: 500.945809841156\n",
      "  time_total_s: 78917.3786187172\n",
      "  timers:\n",
      "    learn_throughput: 258.629\n",
      "    learn_time_ms: 15466.156\n",
      "    load_throughput: 10468.486\n",
      "    load_time_ms: 382.099\n",
      "    sample_throughput: 8.206\n",
      "    sample_time_ms: 487475.379\n",
      "    update_time_ms: 3.788\n",
      "  timestamp: 1613905478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 588000\n",
      "  training_iteration: 147\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-13-00\n",
      "  done: false\n",
      "  episode_len_mean: 147.43\n",
      "  episode_reward_max: 118.39815019229135\n",
      "  episode_reward_mean: 101.79849403752138\n",
      "  episode_reward_min: -105.13455363035769\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4556\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5137531757354736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009980542585253716\n",
      "        model: {}\n",
      "        policy_loss: -0.059497371315956116\n",
      "        total_loss: 96.02701568603516\n",
      "        vf_explained_var: 0.8777271509170532\n",
      "        vf_loss: 96.07512664794922\n",
      "    num_steps_sampled: 592000\n",
      "    num_steps_trained: 592000\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.493994413407826\n",
      "    ram_util_percent: 38.389525139664805\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06827321060552413\n",
      "    mean_env_wait_ms: 119.07944373877535\n",
      "    mean_inference_ms: 1.7224923543115978\n",
      "    mean_raw_obs_processing_ms: 9.339152265753075\n",
      "  time_since_restore: 79418.83561849594\n",
      "  time_this_iter_s: 501.45699977874756\n",
      "  time_total_s: 79418.83561849594\n",
      "  timers:\n",
      "    learn_throughput: 258.656\n",
      "    learn_time_ms: 15464.54\n",
      "    load_throughput: 10408.79\n",
      "    load_time_ms: 384.291\n",
      "    sample_throughput: 8.202\n",
      "    sample_time_ms: 487663.005\n",
      "    update_time_ms: 3.748\n",
      "  timestamp: 1613905980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 592000\n",
      "  training_iteration: 148\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 145.03\n",
      "  episode_reward_max: 118.39018873968277\n",
      "  episode_reward_mean: 95.70636682832276\n",
      "  episode_reward_min: -104.57549434804909\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4586\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4809300899505615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010893009603023529\n",
      "        model: {}\n",
      "        policy_loss: -0.0727214515209198\n",
      "        total_loss: 324.16070556640625\n",
      "        vf_explained_var: 0.7522114515304565\n",
      "        vf_loss: 324.2209777832031\n",
      "    num_steps_sampled: 596000\n",
      "    num_steps_trained: 596000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.886445366528356\n",
      "    ram_util_percent: 38.41355463347165\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06829118105209747\n",
      "    mean_env_wait_ms: 119.02403248065319\n",
      "    mean_inference_ms: 1.7227890537873793\n",
      "    mean_raw_obs_processing_ms: 9.331793122015482\n",
      "  time_since_restore: 79925.64782118797\n",
      "  time_this_iter_s: 506.81220269203186\n",
      "  time_total_s: 79925.64782118797\n",
      "  timers:\n",
      "    learn_throughput: 258.702\n",
      "    learn_time_ms: 15461.835\n",
      "    load_throughput: 10365.983\n",
      "    load_time_ms: 385.878\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487820.742\n",
      "    update_time_ms: 3.736\n",
      "  timestamp: 1613906487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 596000\n",
      "  training_iteration: 149\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 139.82\n",
      "  episode_reward_max: 118.38711441765899\n",
      "  episode_reward_mean: 93.5739814396936\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 4616\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4924875795841217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013687827624380589\n",
      "        model: {}\n",
      "        policy_loss: -0.0899907648563385\n",
      "        total_loss: 656.1348266601562\n",
      "        vf_explained_var: 0.5884491801261902\n",
      "        vf_loss: 656.209228515625\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50681502086231\n",
      "    ram_util_percent: 38.403337969401946\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0683084623806782\n",
      "    mean_env_wait_ms: 118.96917013579419\n",
      "    mean_inference_ms: 1.7230674166506368\n",
      "    mean_raw_obs_processing_ms: 9.325989084085018\n",
      "  time_since_restore: 80429.35766005516\n",
      "  time_this_iter_s: 503.7098388671875\n",
      "  time_total_s: 80429.35766005516\n",
      "  timers:\n",
      "    learn_throughput: 258.785\n",
      "    learn_time_ms: 15456.868\n",
      "    load_throughput: 10437.554\n",
      "    load_time_ms: 383.232\n",
      "    sample_throughput: 8.194\n",
      "    sample_time_ms: 488145.28\n",
      "    update_time_ms: 3.731\n",
      "  timestamp: 1613906991\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 150\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 136.29\n",
      "  episode_reward_max: 118.38711441765899\n",
      "  episode_reward_mean: 89.21912044415974\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4644\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47926148772239685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010709519498050213\n",
      "        model: {}\n",
      "        policy_loss: -0.07456857711076736\n",
      "        total_loss: 257.04217529296875\n",
      "        vf_explained_var: 0.8113617897033691\n",
      "        vf_loss: 257.1045227050781\n",
      "    num_steps_sampled: 604000\n",
      "    num_steps_trained: 604000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72726008344924\n",
      "    ram_util_percent: 38.4279554937413\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06832272952601366\n",
      "    mean_env_wait_ms: 118.92079189347946\n",
      "    mean_inference_ms: 1.7233032813045441\n",
      "    mean_raw_obs_processing_ms: 9.322109060917926\n",
      "  time_since_restore: 80933.29212784767\n",
      "  time_this_iter_s: 503.934467792511\n",
      "  time_total_s: 80933.29212784767\n",
      "  timers:\n",
      "    learn_throughput: 260.669\n",
      "    learn_time_ms: 15345.127\n",
      "    load_throughput: 10533.839\n",
      "    load_time_ms: 379.729\n",
      "    sample_throughput: 8.217\n",
      "    sample_time_ms: 486801.282\n",
      "    update_time_ms: 3.603\n",
      "  timestamp: 1613907495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 604000\n",
      "  training_iteration: 151\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-46-37\n",
      "  done: false\n",
      "  episode_len_mean: 137.96\n",
      "  episode_reward_max: 118.37702578963545\n",
      "  episode_reward_mean: 91.00470087653838\n",
      "  episode_reward_min: -105.59301154200861\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4672\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.483931303024292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00852456409484148\n",
      "        model: {}\n",
      "        policy_loss: -0.05814878270030022\n",
      "        total_loss: 143.52391052246094\n",
      "        vf_explained_var: 0.851458728313446\n",
      "        vf_loss: 143.57232666015625\n",
      "    num_steps_sampled: 608000\n",
      "    num_steps_trained: 608000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.409052924791084\n",
      "    ram_util_percent: 38.43802228412256\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06833577200353232\n",
      "    mean_env_wait_ms: 118.87303903000677\n",
      "    mean_inference_ms: 1.7235220631363324\n",
      "    mean_raw_obs_processing_ms: 9.317992589804787\n",
      "  time_since_restore: 81435.83357095718\n",
      "  time_this_iter_s: 502.54144310951233\n",
      "  time_total_s: 81435.83357095718\n",
      "  timers:\n",
      "    learn_throughput: 260.723\n",
      "    learn_time_ms: 15341.943\n",
      "    load_throughput: 10450.76\n",
      "    load_time_ms: 382.747\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486669.763\n",
      "    update_time_ms: 3.57\n",
      "  timestamp: 1613907997\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 608000\n",
      "  training_iteration: 152\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_12-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 141.33\n",
      "  episode_reward_max: 118.35859723926629\n",
      "  episode_reward_mean: 91.164402135341\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4700\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45184624195098877\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007745564449578524\n",
      "        model: {}\n",
      "        policy_loss: -0.06402236968278885\n",
      "        total_loss: 214.5061492919922\n",
      "        vf_explained_var: 0.8167248964309692\n",
      "        vf_loss: 214.5613555908203\n",
      "    num_steps_sampled: 612000\n",
      "    num_steps_trained: 612000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.58587412587412\n",
      "    ram_util_percent: 38.42741258741258\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06834859427636221\n",
      "    mean_env_wait_ms: 118.82406410294276\n",
      "    mean_inference_ms: 1.7237331875441542\n",
      "    mean_raw_obs_processing_ms: 9.31296374518676\n",
      "  time_since_restore: 81937.16941165924\n",
      "  time_this_iter_s: 501.3358407020569\n",
      "  time_total_s: 81937.16941165924\n",
      "  timers:\n",
      "    learn_throughput: 260.717\n",
      "    learn_time_ms: 15342.318\n",
      "    load_throughput: 10364.624\n",
      "    load_time_ms: 385.928\n",
      "    sample_throughput: 8.222\n",
      "    sample_time_ms: 486521.161\n",
      "    update_time_ms: 3.544\n",
      "  timestamp: 1613908499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 612000\n",
      "  training_iteration: 153\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 138.78\n",
      "  episode_reward_max: 118.35859723926629\n",
      "  episode_reward_mean: 95.12206202352436\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4729\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4588473439216614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009239591658115387\n",
      "        model: {}\n",
      "        policy_loss: -0.06830652803182602\n",
      "        total_loss: 257.38818359375\n",
      "        vf_explained_var: 0.7817555069923401\n",
      "        vf_loss: 257.4459533691406\n",
      "    num_steps_sampled: 616000\n",
      "    num_steps_trained: 616000\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.95006802721089\n",
      "    ram_util_percent: 38.445306122448976\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06836559118749184\n",
      "    mean_env_wait_ms: 118.7779867877806\n",
      "    mean_inference_ms: 1.724009615335417\n",
      "    mean_raw_obs_processing_ms: 9.308062446937843\n",
      "  time_since_restore: 82451.84921574593\n",
      "  time_this_iter_s: 514.6798040866852\n",
      "  time_total_s: 82451.84921574593\n",
      "  timers:\n",
      "    learn_throughput: 260.67\n",
      "    learn_time_ms: 15345.067\n",
      "    load_throughput: 10505.511\n",
      "    load_time_ms: 380.753\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487836.555\n",
      "    update_time_ms: 3.516\n",
      "  timestamp: 1613909014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 616000\n",
      "  training_iteration: 154\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 142.57\n",
      "  episode_reward_max: 118.33498898653042\n",
      "  episode_reward_mean: 93.09943605118976\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 4754\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48156386613845825\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008385772816836834\n",
      "        model: {}\n",
      "        policy_loss: -0.061471596360206604\n",
      "        total_loss: 148.40931701660156\n",
      "        vf_explained_var: 0.8710538744926453\n",
      "        vf_loss: 148.46124267578125\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47201125175808\n",
      "    ram_util_percent: 38.43445850914205\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06838140315100122\n",
      "    mean_env_wait_ms: 118.73755850186022\n",
      "    mean_inference_ms: 1.7242594547379972\n",
      "    mean_raw_obs_processing_ms: 9.302440959107404\n",
      "  time_since_restore: 82950.16076350212\n",
      "  time_this_iter_s: 498.31154775619507\n",
      "  time_total_s: 82950.16076350212\n",
      "  timers:\n",
      "    learn_throughput: 260.64\n",
      "    learn_time_ms: 15346.855\n",
      "    load_throughput: 10452.15\n",
      "    load_time_ms: 382.696\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487801.336\n",
      "    update_time_ms: 3.506\n",
      "  timestamp: 1613909513\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 155\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-20-14\n",
      "  done: false\n",
      "  episode_len_mean: 144.83\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 97.17337704752077\n",
      "  episode_reward_min: -107.67796134002458\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4783\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.139062523841858\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4631302058696747\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022198306396603584\n",
      "        model: {}\n",
      "        policy_loss: -0.1054145023226738\n",
      "        total_loss: 4.604348659515381\n",
      "        vf_explained_var: 0.9934733510017395\n",
      "        vf_loss: 4.684477806091309\n",
      "    num_steps_sampled: 624000\n",
      "    num_steps_trained: 624000\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.636033519553074\n",
      "    ram_util_percent: 38.420251396648034\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06840029110874933\n",
      "    mean_env_wait_ms: 118.69003585615252\n",
      "    mean_inference_ms: 1.7245456448276337\n",
      "    mean_raw_obs_processing_ms: 9.29664632881619\n",
      "  time_since_restore: 83451.58774232864\n",
      "  time_this_iter_s: 501.4269788265228\n",
      "  time_total_s: 83451.58774232864\n",
      "  timers:\n",
      "    learn_throughput: 260.667\n",
      "    learn_time_ms: 15345.235\n",
      "    load_throughput: 10398.272\n",
      "    load_time_ms: 384.679\n",
      "    sample_throughput: 8.203\n",
      "    sample_time_ms: 487600.048\n",
      "    update_time_ms: 3.536\n",
      "  timestamp: 1613910014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 624000\n",
      "  training_iteration: 156\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-28-46\n",
      "  done: false\n",
      "  episode_len_mean: 140.43\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 86.73863290371777\n",
      "  episode_reward_min: -106.73063507915431\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 4814\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4861518442630768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014259721152484417\n",
      "        model: {}\n",
      "        policy_loss: -0.1085641160607338\n",
      "        total_loss: 890.0173950195312\n",
      "        vf_explained_var: 0.6484097242355347\n",
      "        vf_loss: 890.1015014648438\n",
      "    num_steps_sampled: 628000\n",
      "    num_steps_trained: 628000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.30109439124487\n",
      "    ram_util_percent: 38.44856361149111\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684201847453603\n",
      "    mean_env_wait_ms: 118.64182070849293\n",
      "    mean_inference_ms: 1.7248468653481246\n",
      "    mean_raw_obs_processing_ms: 9.292025198467657\n",
      "  time_since_restore: 83963.45505332947\n",
      "  time_this_iter_s: 511.867311000824\n",
      "  time_total_s: 83963.45505332947\n",
      "  timers:\n",
      "    learn_throughput: 260.609\n",
      "    learn_time_ms: 15348.685\n",
      "    load_throughput: 10471.676\n",
      "    load_time_ms: 381.983\n",
      "    sample_throughput: 8.185\n",
      "    sample_time_ms: 488687.637\n",
      "    update_time_ms: 3.527\n",
      "  timestamp: 1613910526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 628000\n",
      "  training_iteration: 157\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-37-12\n",
      "  done: false\n",
      "  episode_len_mean: 134.17\n",
      "  episode_reward_max: 118.39037298642431\n",
      "  episode_reward_mean: 82.49990093625473\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 4846\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4706670641899109\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010649780742824078\n",
      "        model: {}\n",
      "        policy_loss: -0.09022080153226852\n",
      "        total_loss: 630.833251953125\n",
      "        vf_explained_var: 0.6915320158004761\n",
      "        vf_loss: 630.9052124023438\n",
      "    num_steps_sampled: 632000\n",
      "    num_steps_trained: 632000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.651523545706375\n",
      "    ram_util_percent: 38.46246537396121\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06843881547686444\n",
      "    mean_env_wait_ms: 118.59046576565484\n",
      "    mean_inference_ms: 1.7251222264353583\n",
      "    mean_raw_obs_processing_ms: 9.290385136188767\n",
      "  time_since_restore: 84469.41310858727\n",
      "  time_this_iter_s: 505.95805525779724\n",
      "  time_total_s: 84469.41310858727\n",
      "  timers:\n",
      "    learn_throughput: 260.553\n",
      "    learn_time_ms: 15351.982\n",
      "    load_throughput: 10518.798\n",
      "    load_time_ms: 380.272\n",
      "    sample_throughput: 8.178\n",
      "    sample_time_ms: 489137.309\n",
      "    update_time_ms: 3.528\n",
      "  timestamp: 1613911032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 632000\n",
      "  training_iteration: 158\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 132.61\n",
      "  episode_reward_max: 118.36625902754591\n",
      "  episode_reward_mean: 73.9377834859567\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4874\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4453345835208893\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008407643996179104\n",
      "        model: {}\n",
      "        policy_loss: -0.06736180186271667\n",
      "        total_loss: 399.472412109375\n",
      "        vf_explained_var: 0.7319225072860718\n",
      "        vf_loss: 399.5254211425781\n",
      "    num_steps_sampled: 636000\n",
      "    num_steps_trained: 636000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49818941504178\n",
      "    ram_util_percent: 38.534958217270194\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06845410040293094\n",
      "    mean_env_wait_ms: 118.54950370540271\n",
      "    mean_inference_ms: 1.7253463498119288\n",
      "    mean_raw_obs_processing_ms: 9.289647632741172\n",
      "  time_since_restore: 84972.18417716026\n",
      "  time_this_iter_s: 502.77106857299805\n",
      "  time_total_s: 84972.18417716026\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.834\n",
      "    load_throughput: 10563.555\n",
      "    load_time_ms: 378.66\n",
      "    sample_throughput: 8.184\n",
      "    sample_time_ms: 488735.908\n",
      "    update_time_ms: 3.542\n",
      "  timestamp: 1613911535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 636000\n",
      "  training_iteration: 159\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_13-53-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.36\n",
      "  episode_reward_max: 118.34410772090696\n",
      "  episode_reward_mean: 82.48837827915752\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 4902\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48138877749443054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006494223140180111\n",
      "        model: {}\n",
      "        policy_loss: -0.05838268622756004\n",
      "        total_loss: 196.99696350097656\n",
      "        vf_explained_var: 0.8003584742546082\n",
      "        vf_loss: 197.0442352294922\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44755927475594\n",
      "    ram_util_percent: 38.53626220362622\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06846836310301345\n",
      "    mean_env_wait_ms: 118.5073979587736\n",
      "    mean_inference_ms: 1.725555821609911\n",
      "    mean_raw_obs_processing_ms: 9.287606818681013\n",
      "  time_since_restore: 85475.04824829102\n",
      "  time_this_iter_s: 502.86407113075256\n",
      "  time_total_s: 85475.04824829102\n",
      "  timers:\n",
      "    learn_throughput: 260.487\n",
      "    learn_time_ms: 15355.868\n",
      "    load_throughput: 10579.935\n",
      "    load_time_ms: 378.074\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488648.57\n",
      "    update_time_ms: 3.521\n",
      "  timestamp: 1613912038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 160\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-02-22\n",
      "  done: false\n",
      "  episode_len_mean: 138.9\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 82.44115056898363\n",
      "  episode_reward_min: -108.49692041121378\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 4931\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.482185035943985\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009056269191205502\n",
      "        model: {}\n",
      "        policy_loss: -0.0668887123465538\n",
      "        total_loss: 415.8406677246094\n",
      "        vf_explained_var: 0.6967179775238037\n",
      "        vf_loss: 415.8920593261719\n",
      "    num_steps_sampled: 644000\n",
      "    num_steps_trained: 644000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.52962447844229\n",
      "    ram_util_percent: 38.519888734353266\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684830063540474\n",
      "    mean_env_wait_ms: 118.46261854802353\n",
      "    mean_inference_ms: 1.7257911941250763\n",
      "    mean_raw_obs_processing_ms: 9.284068747045817\n",
      "  time_since_restore: 85978.68153715134\n",
      "  time_this_iter_s: 503.63328886032104\n",
      "  time_total_s: 85978.68153715134\n",
      "  timers:\n",
      "    learn_throughput: 260.529\n",
      "    learn_time_ms: 15353.371\n",
      "    load_throughput: 10575.344\n",
      "    load_time_ms: 378.238\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488620.749\n",
      "    update_time_ms: 3.547\n",
      "  timestamp: 1613912542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 644000\n",
      "  training_iteration: 161\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 147.27\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 93.17703128492795\n",
      "  episode_reward_min: -105.14930449860003\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 4957\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5064404010772705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008462098427116871\n",
      "        model: {}\n",
      "        policy_loss: -0.07593437284231186\n",
      "        total_loss: 485.3306884765625\n",
      "        vf_explained_var: 0.6405306458473206\n",
      "        vf_loss: 485.3921203613281\n",
      "    num_steps_sampled: 648000\n",
      "    num_steps_trained: 648000\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34888268156424\n",
      "    ram_util_percent: 38.46480446927374\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0684963894114604\n",
      "    mean_env_wait_ms: 118.42176954953226\n",
      "    mean_inference_ms: 1.7260068639032915\n",
      "    mean_raw_obs_processing_ms: 9.278926797780018\n",
      "  time_since_restore: 86480.10954904556\n",
      "  time_this_iter_s: 501.4280118942261\n",
      "  time_total_s: 86480.10954904556\n",
      "  timers:\n",
      "    learn_throughput: 260.49\n",
      "    learn_time_ms: 15355.671\n",
      "    load_throughput: 10668.732\n",
      "    load_time_ms: 374.927\n",
      "    sample_throughput: 8.188\n",
      "    sample_time_ms: 488510.573\n",
      "    update_time_ms: 3.567\n",
      "  timestamp: 1613913044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 648000\n",
      "  training_iteration: 162\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-19-07\n",
      "  done: false\n",
      "  episode_len_mean: 146.68\n",
      "  episode_reward_max: 118.34560936490521\n",
      "  episode_reward_mean: 90.83358563840925\n",
      "  episode_reward_min: -106.96458987683931\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 4984\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4691942632198334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007456604856997728\n",
      "        model: {}\n",
      "        policy_loss: -0.06715694814920425\n",
      "        total_loss: 167.9293975830078\n",
      "        vf_explained_var: 0.876112699508667\n",
      "        vf_loss: 167.9838409423828\n",
      "    num_steps_sampled: 652000\n",
      "    num_steps_trained: 652000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44568245125348\n",
      "    ram_util_percent: 38.464623955431755\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06851008589635542\n",
      "    mean_env_wait_ms: 118.37968971116618\n",
      "    mean_inference_ms: 1.7262374059642367\n",
      "    mean_raw_obs_processing_ms: 9.273064479720702\n",
      "  time_since_restore: 86982.80327177048\n",
      "  time_this_iter_s: 502.69372272491455\n",
      "  time_total_s: 86982.80327177048\n",
      "  timers:\n",
      "    learn_throughput: 260.482\n",
      "    learn_time_ms: 15356.137\n",
      "    load_throughput: 10752.641\n",
      "    load_time_ms: 372.002\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 488648.189\n",
      "    update_time_ms: 3.569\n",
      "  timestamp: 1613913547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 652000\n",
      "  training_iteration: 163\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 145.8\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 92.87013160735619\n",
      "  episode_reward_min: -106.96458987683931\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5012\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4480264186859131\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006355721037834883\n",
      "        model: {}\n",
      "        policy_loss: -0.05137742683291435\n",
      "        total_loss: 176.2694549560547\n",
      "        vf_explained_var: 0.8188726305961609\n",
      "        vf_loss: 176.30995178222656\n",
      "    num_steps_sampled: 656000\n",
      "    num_steps_trained: 656000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.84214186369958\n",
      "    ram_util_percent: 38.53407510431154\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06852427330376414\n",
      "    mean_env_wait_ms: 118.3369487778647\n",
      "    mean_inference_ms: 1.7264821033324285\n",
      "    mean_raw_obs_processing_ms: 9.266807857567928\n",
      "  time_since_restore: 87486.67959189415\n",
      "  time_this_iter_s: 503.8763201236725\n",
      "  time_total_s: 87486.67959189415\n",
      "  timers:\n",
      "    learn_throughput: 260.502\n",
      "    learn_time_ms: 15354.973\n",
      "    load_throughput: 10772.593\n",
      "    load_time_ms: 371.313\n",
      "    sample_throughput: 8.204\n",
      "    sample_time_ms: 487568.193\n",
      "    update_time_ms: 3.575\n",
      "  timestamp: 1613914051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 656000\n",
      "  training_iteration: 164\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 145.21\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 92.70610928211364\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5040\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46228596568107605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006902496796101332\n",
      "        model: {}\n",
      "        policy_loss: -0.059275072067976\n",
      "        total_loss: 207.67410278320312\n",
      "        vf_explained_var: 0.8182961940765381\n",
      "        vf_loss: 207.72158813476562\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.528351955307265\n",
      "    ram_util_percent: 38.51368715083799\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06853728558560826\n",
      "    mean_env_wait_ms: 118.29366629630957\n",
      "    mean_inference_ms: 1.7266945183978606\n",
      "    mean_raw_obs_processing_ms: 9.260610431761378\n",
      "  time_since_restore: 87988.05377340317\n",
      "  time_this_iter_s: 501.37418150901794\n",
      "  time_total_s: 87988.05377340317\n",
      "  timers:\n",
      "    learn_throughput: 260.559\n",
      "    learn_time_ms: 15351.598\n",
      "    load_throughput: 10820.894\n",
      "    load_time_ms: 369.655\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487880.544\n",
      "    update_time_ms: 3.574\n",
      "  timestamp: 1613914553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 165\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-44-14\n",
      "  done: false\n",
      "  episode_len_mean: 146.88\n",
      "  episode_reward_max: 118.3816349940228\n",
      "  episode_reward_mean: 94.76799787769761\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5067\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4856013059616089\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00634542154148221\n",
      "        model: {}\n",
      "        policy_loss: -0.0633016899228096\n",
      "        total_loss: 289.1907653808594\n",
      "        vf_explained_var: 0.7325077652931213\n",
      "        vf_loss: 289.24322509765625\n",
      "    num_steps_sampled: 664000\n",
      "    num_steps_trained: 664000\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.39762237762238\n",
      "    ram_util_percent: 38.476083916083915\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06854874999601568\n",
      "    mean_env_wait_ms: 118.25243670852525\n",
      "    mean_inference_ms: 1.7268768816733582\n",
      "    mean_raw_obs_processing_ms: 9.255162367471213\n",
      "  time_since_restore: 88489.42773461342\n",
      "  time_this_iter_s: 501.37396121025085\n",
      "  time_total_s: 88489.42773461342\n",
      "  timers:\n",
      "    learn_throughput: 260.505\n",
      "    learn_time_ms: 15354.819\n",
      "    load_throughput: 10840.526\n",
      "    load_time_ms: 368.986\n",
      "    sample_throughput: 8.199\n",
      "    sample_time_ms: 487869.291\n",
      "    update_time_ms: 3.56\n",
      "  timestamp: 1613915054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 664000\n",
      "  training_iteration: 166\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_14-52-34\n",
      "  done: false\n",
      "  episode_len_mean: 147.78\n",
      "  episode_reward_max: 118.37371998946179\n",
      "  episode_reward_mean: 101.20822458460525\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5094\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4862886667251587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010524340905249119\n",
      "        model: {}\n",
      "        policy_loss: -0.07467919588088989\n",
      "        total_loss: 25.640653610229492\n",
      "        vf_explained_var: 0.9721167683601379\n",
      "        vf_loss: 25.697351455688477\n",
      "    num_steps_sampled: 668000\n",
      "    num_steps_trained: 668000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50560224089636\n",
      "    ram_util_percent: 38.51330532212885\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06855955403778359\n",
      "    mean_env_wait_ms: 118.21057267026022\n",
      "    mean_inference_ms: 1.7270392530979362\n",
      "    mean_raw_obs_processing_ms: 9.249604904265391\n",
      "  time_since_restore: 88989.29530453682\n",
      "  time_this_iter_s: 499.8675699234009\n",
      "  time_total_s: 88989.29530453682\n",
      "  timers:\n",
      "    learn_throughput: 260.548\n",
      "    learn_time_ms: 15352.241\n",
      "    load_throughput: 10808.73\n",
      "    load_time_ms: 370.071\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486675.69\n",
      "    update_time_ms: 3.592\n",
      "  timestamp: 1613915554\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 668000\n",
      "  training_iteration: 167\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-01-01\n",
      "  done: false\n",
      "  episode_len_mean: 141.56\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 90.63242252174445\n",
      "  episode_reward_min: -107.0333886008569\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5125\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47574055194854736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008839340880513191\n",
      "        model: {}\n",
      "        policy_loss: -0.07316874712705612\n",
      "        total_loss: 419.13763427734375\n",
      "        vf_explained_var: 0.7200050950050354\n",
      "        vf_loss: 419.1956481933594\n",
      "    num_steps_sampled: 672000\n",
      "    num_steps_trained: 672000\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53033240997229\n",
      "    ram_util_percent: 38.537257617728535\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06857235438949527\n",
      "    mean_env_wait_ms: 118.1635145875799\n",
      "    mean_inference_ms: 1.7272286108516621\n",
      "    mean_raw_obs_processing_ms: 9.245073630018629\n",
      "  time_since_restore: 89495.47280859947\n",
      "  time_this_iter_s: 506.1775040626526\n",
      "  time_total_s: 89495.47280859947\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.74\n",
      "    load_throughput: 10819.157\n",
      "    load_time_ms: 369.715\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486700.839\n",
      "    update_time_ms: 3.745\n",
      "  timestamp: 1613916061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 672000\n",
      "  training_iteration: 168\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-09-23\n",
      "  done: false\n",
      "  episode_len_mean: 140.49\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 94.99584880547278\n",
      "  episode_reward_min: -106.97773984480573\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5154\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45154133439064026\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006227417383342981\n",
      "        model: {}\n",
      "        policy_loss: -0.05392485484480858\n",
      "        total_loss: 98.27760314941406\n",
      "        vf_explained_var: 0.9074139595031738\n",
      "        vf_loss: 98.32087707519531\n",
      "    num_steps_sampled: 676000\n",
      "    num_steps_trained: 676000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.48326359832636\n",
      "    ram_util_percent: 38.480334728033476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06858522124725461\n",
      "    mean_env_wait_ms: 118.1203477170672\n",
      "    mean_inference_ms: 1.7274251660541209\n",
      "    mean_raw_obs_processing_ms: 9.241736193590187\n",
      "  time_since_restore: 89997.56052470207\n",
      "  time_this_iter_s: 502.0877161026001\n",
      "  time_total_s: 89997.56052470207\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.742\n",
      "    load_throughput: 10824.405\n",
      "    load_time_ms: 369.535\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486632.964\n",
      "    update_time_ms: 3.733\n",
      "  timestamp: 1613916563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 676000\n",
      "  training_iteration: 169\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-17-45\n",
      "  done: false\n",
      "  episode_len_mean: 141.28\n",
      "  episode_reward_max: 118.38313091783473\n",
      "  episode_reward_mean: 95.40361710728526\n",
      "  episode_reward_min: -106.97773984480573\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5181\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.456531286239624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00835502427071333\n",
      "        model: {}\n",
      "        policy_loss: -0.07291597872972488\n",
      "        total_loss: 438.1560363769531\n",
      "        vf_explained_var: 0.6468444466590881\n",
      "        vf_loss: 438.214599609375\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.589385474860336\n",
      "    ram_util_percent: 38.45991620111731\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06859723994206116\n",
      "    mean_env_wait_ms: 118.08135252751872\n",
      "    mean_inference_ms: 1.72762725266968\n",
      "    mean_raw_obs_processing_ms: 9.238742112961548\n",
      "  time_since_restore: 90498.98913621902\n",
      "  time_this_iter_s: 501.4286115169525\n",
      "  time_total_s: 90498.98913621902\n",
      "  timers:\n",
      "    learn_throughput: 260.605\n",
      "    learn_time_ms: 15348.918\n",
      "    load_throughput: 10734.402\n",
      "    load_time_ms: 372.634\n",
      "    sample_throughput: 8.222\n",
      "    sample_time_ms: 486485.14\n",
      "    update_time_ms: 3.781\n",
      "  timestamp: 1613917065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 170\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 141.21\n",
      "  episode_reward_max: 118.38904413532654\n",
      "  episode_reward_mean: 99.79128053003798\n",
      "  episode_reward_min: -106.6297525379055\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5207\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4708069860935211\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0068193464539945126\n",
      "        model: {}\n",
      "        policy_loss: -0.0499524287879467\n",
      "        total_loss: 160.94512939453125\n",
      "        vf_explained_var: 0.8235843777656555\n",
      "        vf_loss: 160.98341369628906\n",
      "    num_steps_sampled: 684000\n",
      "    num_steps_trained: 684000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.758750000000006\n",
      "    ram_util_percent: 38.46527777777777\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06860977762982276\n",
      "    mean_env_wait_ms: 118.04583679578282\n",
      "    mean_inference_ms: 1.7278293561979303\n",
      "    mean_raw_obs_processing_ms: 9.234586594223986\n",
      "  time_since_restore: 91003.42678427696\n",
      "  time_this_iter_s: 504.4376480579376\n",
      "  time_total_s: 91003.42678427696\n",
      "  timers:\n",
      "    learn_throughput: 260.542\n",
      "    learn_time_ms: 15352.597\n",
      "    load_throughput: 10778.832\n",
      "    load_time_ms: 371.098\n",
      "    sample_throughput: 8.221\n",
      "    sample_time_ms: 486564.373\n",
      "    update_time_ms: 3.729\n",
      "  timestamp: 1613917569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 684000\n",
      "  training_iteration: 171\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-34-33\n",
      "  done: false\n",
      "  episode_len_mean: 142.26\n",
      "  episode_reward_max: 118.38904413532654\n",
      "  episode_reward_mean: 95.59367805044093\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5236\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46796685457229614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008288552053272724\n",
      "        model: {}\n",
      "        policy_loss: -0.0786781832575798\n",
      "        total_loss: 511.0342102050781\n",
      "        vf_explained_var: 0.6987603306770325\n",
      "        vf_loss: 511.0987548828125\n",
      "    num_steps_sampled: 688000\n",
      "    num_steps_trained: 688000\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47246175243393\n",
      "    ram_util_percent: 38.506815020862305\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06862297427505894\n",
      "    mean_env_wait_ms: 118.0054659057309\n",
      "    mean_inference_ms: 1.728048772605677\n",
      "    mean_raw_obs_processing_ms: 9.229344434382437\n",
      "  time_since_restore: 91506.885689497\n",
      "  time_this_iter_s: 503.45890522003174\n",
      "  time_total_s: 91506.885689497\n",
      "  timers:\n",
      "    learn_throughput: 260.577\n",
      "    learn_time_ms: 15350.576\n",
      "    load_throughput: 10748.637\n",
      "    load_time_ms: 372.14\n",
      "    sample_throughput: 8.217\n",
      "    sample_time_ms: 486768.692\n",
      "    update_time_ms: 3.758\n",
      "  timestamp: 1613918073\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 688000\n",
      "  training_iteration: 172\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-42-55\n",
      "  done: false\n",
      "  episode_len_mean: 140.42\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 91.38592287765752\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5266\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5288376808166504\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008779721334576607\n",
      "        model: {}\n",
      "        policy_loss: -0.08225809037685394\n",
      "        total_loss: 244.55787658691406\n",
      "        vf_explained_var: 0.8416314125061035\n",
      "        vf_loss: 244.62509155273438\n",
      "    num_steps_sampled: 692000\n",
      "    num_steps_trained: 692000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.71019553072626\n",
      "    ram_util_percent: 38.4645251396648\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0686358215296877\n",
      "    mean_env_wait_ms: 117.96378499799098\n",
      "    mean_inference_ms: 1.7282694910678185\n",
      "    mean_raw_obs_processing_ms: 9.224758524784436\n",
      "  time_since_restore: 92008.88655018806\n",
      "  time_this_iter_s: 502.00086069107056\n",
      "  time_total_s: 92008.88655018806\n",
      "  timers:\n",
      "    learn_throughput: 260.591\n",
      "    learn_time_ms: 15349.737\n",
      "    load_throughput: 10771.157\n",
      "    load_time_ms: 371.362\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486701.016\n",
      "    update_time_ms: 3.817\n",
      "  timestamp: 1613918575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 692000\n",
      "  training_iteration: 173\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-51-14\n",
      "  done: false\n",
      "  episode_len_mean: 146.02\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 95.39460807275515\n",
      "  episode_reward_min: -105.04987807272472\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 5290\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5048798322677612\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015141325071454048\n",
      "        model: {}\n",
      "        policy_loss: -0.10032626986503601\n",
      "        total_loss: 8.430785179138184\n",
      "        vf_explained_var: 0.9881623387336731\n",
      "        vf_loss: 8.505240440368652\n",
      "    num_steps_sampled: 696000\n",
      "    num_steps_trained: 696000\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.36910112359551\n",
      "    ram_util_percent: 38.47724719101123\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06864618998927181\n",
      "    mean_env_wait_ms: 117.93039021822675\n",
      "    mean_inference_ms: 1.7284269435281094\n",
      "    mean_raw_obs_processing_ms: 9.220015783477972\n",
      "  time_since_restore: 92507.67228889465\n",
      "  time_this_iter_s: 498.78573870658875\n",
      "  time_total_s: 92507.67228889465\n",
      "  timers:\n",
      "    learn_throughput: 260.593\n",
      "    learn_time_ms: 15349.588\n",
      "    load_throughput: 10737.497\n",
      "    load_time_ms: 372.526\n",
      "    sample_throughput: 8.227\n",
      "    sample_time_ms: 486190.666\n",
      "    update_time_ms: 3.821\n",
      "  timestamp: 1613919074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 696000\n",
      "  training_iteration: 174\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_15-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.08\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 88.93002689290537\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5320\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48957180976867676\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016036346554756165\n",
      "        model: {}\n",
      "        policy_loss: -0.12040140479803085\n",
      "        total_loss: 1086.5328369140625\n",
      "        vf_explained_var: 0.608025074005127\n",
      "        vf_loss: 1086.625732421875\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46898470097357\n",
      "    ram_util_percent: 38.46773296244784\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06865828042400379\n",
      "    mean_env_wait_ms: 117.88816196702668\n",
      "    mean_inference_ms: 1.7286137726635369\n",
      "    mean_raw_obs_processing_ms: 9.215541094601642\n",
      "  time_since_restore: 93011.05297780037\n",
      "  time_this_iter_s: 503.38068890571594\n",
      "  time_total_s: 93011.05297780037\n",
      "  timers:\n",
      "    learn_throughput: 260.568\n",
      "    learn_time_ms: 15351.097\n",
      "    load_throughput: 10591.534\n",
      "    load_time_ms: 377.66\n",
      "    sample_throughput: 8.224\n",
      "    sample_time_ms: 486385.767\n",
      "    update_time_ms: 3.848\n",
      "  timestamp: 1613919578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 175\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 140.05\n",
      "  episode_reward_max: 118.38922858696029\n",
      "  episode_reward_mean: 80.64052161749079\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5351\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4718606770038605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012582182884216309\n",
      "        model: {}\n",
      "        policy_loss: -0.09653011709451675\n",
      "        total_loss: 940.9229736328125\n",
      "        vf_explained_var: 0.5720846652984619\n",
      "        vf_loss: 940.9979248046875\n",
      "    num_steps_sampled: 704000\n",
      "    num_steps_trained: 704000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.56440443213297\n",
      "    ram_util_percent: 38.44349030470914\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06867086727106841\n",
      "    mean_env_wait_ms: 117.8463413084463\n",
      "    mean_inference_ms: 1.7288022408307484\n",
      "    mean_raw_obs_processing_ms: 9.211785975004664\n",
      "  time_since_restore: 93517.2189218998\n",
      "  time_this_iter_s: 506.16594409942627\n",
      "  time_total_s: 93517.2189218998\n",
      "  timers:\n",
      "    learn_throughput: 260.59\n",
      "    learn_time_ms: 15349.806\n",
      "    load_throughput: 10517.681\n",
      "    load_time_ms: 380.312\n",
      "    sample_throughput: 8.216\n",
      "    sample_time_ms: 486867.298\n",
      "    update_time_ms: 3.833\n",
      "  timestamp: 1613920084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 704000\n",
      "  training_iteration: 176\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-16-22\n",
      "  done: false\n",
      "  episode_len_mean: 141.13\n",
      "  episode_reward_max: 118.37493702248727\n",
      "  episode_reward_mean: 78.35876333657444\n",
      "  episode_reward_min: -107.3067573041725\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 5376\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5256088376045227\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009462368674576283\n",
      "        model: {}\n",
      "        policy_loss: -0.08388345688581467\n",
      "        total_loss: 501.4094543457031\n",
      "        vf_explained_var: 0.6416015625\n",
      "        vf_loss: 501.4771423339844\n",
      "    num_steps_sampled: 708000\n",
      "    num_steps_trained: 708000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46357243319268\n",
      "    ram_util_percent: 38.43769338959212\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06868162348637416\n",
      "    mean_env_wait_ms: 117.8122085555477\n",
      "    mean_inference_ms: 1.7289530889830635\n",
      "    mean_raw_obs_processing_ms: 9.207677252935971\n",
      "  time_since_restore: 94015.06229805946\n",
      "  time_this_iter_s: 497.84337615966797\n",
      "  time_total_s: 94015.06229805946\n",
      "  timers:\n",
      "    learn_throughput: 260.6\n",
      "    learn_time_ms: 15349.207\n",
      "    load_throughput: 10478.372\n",
      "    load_time_ms: 381.739\n",
      "    sample_throughput: 8.219\n",
      "    sample_time_ms: 486663.405\n",
      "    update_time_ms: 3.768\n",
      "  timestamp: 1613920582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 708000\n",
      "  training_iteration: 177\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 145.63\n",
      "  episode_reward_max: 118.34340858200574\n",
      "  episode_reward_mean: 84.71461875629933\n",
      "  episode_reward_min: -104.54988999513048\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5402\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46560001373291016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006648436654359102\n",
      "        model: {}\n",
      "        policy_loss: -0.05807759240269661\n",
      "        total_loss: 155.2732696533203\n",
      "        vf_explained_var: 0.8444494009017944\n",
      "        vf_loss: 155.31997680664062\n",
      "    num_steps_sampled: 712000\n",
      "    num_steps_trained: 712000\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47549019607843\n",
      "    ram_util_percent: 38.48473389355742\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0686922814540443\n",
      "    mean_env_wait_ms: 117.77762267661575\n",
      "    mean_inference_ms: 1.7291099226470275\n",
      "    mean_raw_obs_processing_ms: 9.203317976424357\n",
      "  time_since_restore: 94514.89193749428\n",
      "  time_this_iter_s: 499.82963943481445\n",
      "  time_total_s: 94514.89193749428\n",
      "  timers:\n",
      "    learn_throughput: 260.619\n",
      "    learn_time_ms: 15348.096\n",
      "    load_throughput: 10483.485\n",
      "    load_time_ms: 381.553\n",
      "    sample_throughput: 8.23\n",
      "    sample_time_ms: 486028.273\n",
      "    update_time_ms: 3.601\n",
      "  timestamp: 1613921082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 712000\n",
      "  training_iteration: 178\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-33-03\n",
      "  done: false\n",
      "  episode_len_mean: 151.13\n",
      "  episode_reward_max: 118.31820820477397\n",
      "  episode_reward_mean: 93.03315928379716\n",
      "  episode_reward_min: -104.54988999513048\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 5427\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46588629484176636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007632530760020018\n",
      "        model: {}\n",
      "        policy_loss: -0.0638757273554802\n",
      "        total_loss: 280.8990173339844\n",
      "        vf_explained_var: 0.7463623881340027\n",
      "        vf_loss: 280.9498596191406\n",
      "    num_steps_sampled: 716000\n",
      "    num_steps_trained: 716000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.431232492997204\n",
      "    ram_util_percent: 38.42633053221288\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06870344171985562\n",
      "    mean_env_wait_ms: 117.74376743178331\n",
      "    mean_inference_ms: 1.7292855942561431\n",
      "    mean_raw_obs_processing_ms: 9.196971543897542\n",
      "  time_since_restore: 95015.25298166275\n",
      "  time_this_iter_s: 500.3610441684723\n",
      "  time_total_s: 95015.25298166275\n",
      "  timers:\n",
      "    learn_throughput: 260.664\n",
      "    learn_time_ms: 15345.419\n",
      "    load_throughput: 10469.57\n",
      "    load_time_ms: 382.06\n",
      "    sample_throughput: 8.233\n",
      "    sample_time_ms: 485855.474\n",
      "    update_time_ms: 3.592\n",
      "  timestamp: 1613921583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 716000\n",
      "  training_iteration: 179\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 154.2\n",
      "  episode_reward_max: 118.35405133032623\n",
      "  episode_reward_mean: 99.2754836086572\n",
      "  episode_reward_min: -99.1245036832122\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5454\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4846733510494232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006623440887778997\n",
      "        model: {}\n",
      "        policy_loss: -0.04771051183342934\n",
      "        total_loss: 155.57626342773438\n",
      "        vf_explained_var: 0.8229196071624756\n",
      "        vf_loss: 155.61268615722656\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.516363636363636\n",
      "    ram_util_percent: 38.38503496503496\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06871626289123954\n",
      "    mean_env_wait_ms: 117.70570302148782\n",
      "    mean_inference_ms: 1.7294751196604383\n",
      "    mean_raw_obs_processing_ms: 9.188781422176838\n",
      "  time_since_restore: 95516.08112931252\n",
      "  time_this_iter_s: 500.828147649765\n",
      "  time_total_s: 95516.08112931252\n",
      "  timers:\n",
      "    learn_throughput: 260.668\n",
      "    learn_time_ms: 15345.21\n",
      "    load_throughput: 10494.161\n",
      "    load_time_ms: 381.164\n",
      "    sample_throughput: 8.234\n",
      "    sample_time_ms: 485792.654\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613922084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 180\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 144.44\n",
      "  episode_reward_max: 118.39349617717478\n",
      "  episode_reward_mean: 86.86996045042459\n",
      "  episode_reward_min: -100.51393821107163\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5486\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4662671387195587\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012708527036011219\n",
      "        model: {}\n",
      "        policy_loss: -0.09593574702739716\n",
      "        total_loss: 837.884033203125\n",
      "        vf_explained_var: 0.6079728007316589\n",
      "        vf_loss: 837.958251953125\n",
      "    num_steps_sampled: 724000\n",
      "    num_steps_trained: 724000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.55773480662984\n",
      "    ram_util_percent: 38.398618784530385\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06872973339804499\n",
      "    mean_env_wait_ms: 117.66380970529775\n",
      "    mean_inference_ms: 1.7296831400305888\n",
      "    mean_raw_obs_processing_ms: 9.18345595904487\n",
      "  time_since_restore: 96023.5130982399\n",
      "  time_this_iter_s: 507.4319689273834\n",
      "  time_total_s: 96023.5130982399\n",
      "  timers:\n",
      "    learn_throughput: 260.725\n",
      "    learn_time_ms: 15341.832\n",
      "    load_throughput: 10326.081\n",
      "    load_time_ms: 387.369\n",
      "    sample_throughput: 8.229\n",
      "    sample_time_ms: 486088.784\n",
      "    update_time_ms: 3.581\n",
      "  timestamp: 1613922592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 724000\n",
      "  training_iteration: 181\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_16-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 139.98\n",
      "  episode_reward_max: 118.39349617717478\n",
      "  episode_reward_mean: 89.1879758260181\n",
      "  episode_reward_min: -100.51393821107163\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5515\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4440160095691681\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007366834674030542\n",
      "        model: {}\n",
      "        policy_loss: -0.052306752651929855\n",
      "        total_loss: 269.7047424316406\n",
      "        vf_explained_var: 0.7046312689781189\n",
      "        vf_loss: 269.7444152832031\n",
      "    num_steps_sampled: 728000\n",
      "    num_steps_trained: 728000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.6071129707113\n",
      "    ram_util_percent: 38.43179916317991\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06874115014425634\n",
      "    mean_env_wait_ms: 117.62692021537387\n",
      "    mean_inference_ms: 1.7298548942518515\n",
      "    mean_raw_obs_processing_ms: 9.18065413546429\n",
      "  time_since_restore: 96525.79550862312\n",
      "  time_this_iter_s: 502.2824103832245\n",
      "  time_total_s: 96525.79550862312\n",
      "  timers:\n",
      "    learn_throughput: 260.748\n",
      "    learn_time_ms: 15340.502\n",
      "    load_throughput: 10314.417\n",
      "    load_time_ms: 387.807\n",
      "    sample_throughput: 8.231\n",
      "    sample_time_ms: 485970.923\n",
      "    update_time_ms: 3.554\n",
      "  timestamp: 1613923094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 728000\n",
      "  training_iteration: 182\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-06-36\n",
      "  done: false\n",
      "  episode_len_mean: 137.64\n",
      "  episode_reward_max: 118.39542405339023\n",
      "  episode_reward_mean: 93.34721071568654\n",
      "  episode_reward_min: -105.70203195137316\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5543\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4430549442768097\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011044507846236229\n",
      "        model: {}\n",
      "        policy_loss: -0.07171367853879929\n",
      "        total_loss: 26.278682708740234\n",
      "        vf_explained_var: 0.9783812165260315\n",
      "        vf_loss: 26.331523895263672\n",
      "    num_steps_sampled: 732000\n",
      "    num_steps_trained: 732000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.46541143654114\n",
      "    ram_util_percent: 38.35523012552301\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06875123018139143\n",
      "    mean_env_wait_ms: 117.59248582940604\n",
      "    mean_inference_ms: 1.7299942823507348\n",
      "    mean_raw_obs_processing_ms: 9.179147292354722\n",
      "  time_since_restore: 97027.63077235222\n",
      "  time_this_iter_s: 501.83526372909546\n",
      "  time_total_s: 97027.63077235222\n",
      "  timers:\n",
      "    learn_throughput: 260.734\n",
      "    learn_time_ms: 15341.324\n",
      "    load_throughput: 10289.052\n",
      "    load_time_ms: 388.763\n",
      "    sample_throughput: 8.231\n",
      "    sample_time_ms: 485951.319\n",
      "    update_time_ms: 3.499\n",
      "  timestamp: 1613923596\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 732000\n",
      "  training_iteration: 183\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 133.16\n",
      "  episode_reward_max: 118.39542405339023\n",
      "  episode_reward_mean: 89.21097575811257\n",
      "  episode_reward_min: -107.31346635462283\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5575\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47607260942459106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011482289992272854\n",
      "        model: {}\n",
      "        policy_loss: -0.09403268992900848\n",
      "        total_loss: 685.237060546875\n",
      "        vf_explained_var: 0.6918187737464905\n",
      "        vf_loss: 685.3115844726562\n",
      "    num_steps_sampled: 736000\n",
      "    num_steps_trained: 736000\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.605394190871365\n",
      "    ram_util_percent: 38.36528354080221\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06876275525910218\n",
      "    mean_env_wait_ms: 117.55433045998768\n",
      "    mean_inference_ms: 1.7301557845493607\n",
      "    mean_raw_obs_processing_ms: 9.178508671720747\n",
      "  time_since_restore: 97534.4449365139\n",
      "  time_this_iter_s: 506.81416416168213\n",
      "  time_total_s: 97534.4449365139\n",
      "  timers:\n",
      "    learn_throughput: 260.735\n",
      "    learn_time_ms: 15341.27\n",
      "    load_throughput: 10320.858\n",
      "    load_time_ms: 387.565\n",
      "    sample_throughput: 8.218\n",
      "    sample_time_ms: 486753.428\n",
      "    update_time_ms: 3.514\n",
      "  timestamp: 1613924103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 736000\n",
      "  training_iteration: 184\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 137.71\n",
      "  episode_reward_max: 118.39576053671243\n",
      "  episode_reward_mean: 97.43855135668205\n",
      "  episode_reward_min: -107.31346635462283\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5602\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44221940636634827\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007441571447998285\n",
      "        model: {}\n",
      "        policy_loss: -0.06500907987356186\n",
      "        total_loss: 71.3495864868164\n",
      "        vf_explained_var: 0.920139729976654\n",
      "        vf_loss: 71.40189361572266\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.482960893854745\n",
      "    ram_util_percent: 38.3731843575419\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06877308927909531\n",
      "    mean_env_wait_ms: 117.52232623149295\n",
      "    mean_inference_ms: 1.730301866684336\n",
      "    mean_raw_obs_processing_ms: 9.176635585619612\n",
      "  time_since_restore: 98036.24931836128\n",
      "  time_this_iter_s: 501.8043818473816\n",
      "  time_total_s: 98036.24931836128\n",
      "  timers:\n",
      "    learn_throughput: 260.707\n",
      "    learn_time_ms: 15342.9\n",
      "    load_throughput: 10445.603\n",
      "    load_time_ms: 382.936\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486595.992\n",
      "    update_time_ms: 3.48\n",
      "  timestamp: 1613924605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 185\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-31-48\n",
      "  done: false\n",
      "  episode_len_mean: 135.42\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 86.6814424293701\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 5631\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4541889429092407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010883782058954239\n",
      "        model: {}\n",
      "        policy_loss: -0.08654586225748062\n",
      "        total_loss: 782.625244140625\n",
      "        vf_explained_var: 0.5522391200065613\n",
      "        vf_loss: 782.6931762695312\n",
      "    num_steps_sampled: 744000\n",
      "    num_steps_trained: 744000\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.54303621169915\n",
      "    ram_util_percent: 38.38969359331476\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06878404687145184\n",
      "    mean_env_wait_ms: 117.48776817358333\n",
      "    mean_inference_ms: 1.7304641341571485\n",
      "    mean_raw_obs_processing_ms: 9.17493478224007\n",
      "  time_since_restore: 98538.78360366821\n",
      "  time_this_iter_s: 502.53428530693054\n",
      "  time_total_s: 98538.78360366821\n",
      "  timers:\n",
      "    learn_throughput: 260.682\n",
      "    learn_time_ms: 15344.358\n",
      "    load_throughput: 10556.637\n",
      "    load_time_ms: 378.909\n",
      "    sample_throughput: 8.227\n",
      "    sample_time_ms: 486232.038\n",
      "    update_time_ms: 3.471\n",
      "  timestamp: 1613925108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 744000\n",
      "  training_iteration: 186\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-40-10\n",
      "  done: false\n",
      "  episode_len_mean: 142.42\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 95.31215734591702\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5657\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.457278311252594\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0064457799308001995\n",
      "        model: {}\n",
      "        policy_loss: -0.06314153224229813\n",
      "        total_loss: 129.87037658691406\n",
      "        vf_explained_var: 0.8559269309043884\n",
      "        vf_loss: 129.92247009277344\n",
      "    num_steps_sampled: 748000\n",
      "    num_steps_trained: 748000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.47458100558659\n",
      "    ram_util_percent: 38.437569832402225\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06879358209132469\n",
      "    mean_env_wait_ms: 117.45771841085211\n",
      "    mean_inference_ms: 1.7306100761494239\n",
      "    mean_raw_obs_processing_ms: 9.171618487810383\n",
      "  time_since_restore: 99040.21338009834\n",
      "  time_this_iter_s: 501.42977643013\n",
      "  time_total_s: 99040.21338009834\n",
      "  timers:\n",
      "    learn_throughput: 260.653\n",
      "    learn_time_ms: 15346.056\n",
      "    load_throughput: 10625.552\n",
      "    load_time_ms: 376.451\n",
      "    sample_throughput: 8.22\n",
      "    sample_time_ms: 486590.007\n",
      "    update_time_ms: 3.512\n",
      "  timestamp: 1613925610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 748000\n",
      "  training_iteration: 187\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-48-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.52\n",
      "  episode_reward_max: 118.39708028345218\n",
      "  episode_reward_mean: 91.08862888743343\n",
      "  episode_reward_min: -108.20790027106892\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5687\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44903984665870667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008460896089673042\n",
      "        model: {}\n",
      "        policy_loss: -0.07948212325572968\n",
      "        total_loss: 316.0011291503906\n",
      "        vf_explained_var: 0.800960123538971\n",
      "        vf_loss: 316.066162109375\n",
      "    num_steps_sampled: 752000\n",
      "    num_steps_trained: 752000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.88151724137932\n",
      "    ram_util_percent: 38.45862068965517\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06880546283073154\n",
      "    mean_env_wait_ms: 117.42320581612239\n",
      "    mean_inference_ms: 1.730811979971199\n",
      "    mean_raw_obs_processing_ms: 9.167845253267249\n",
      "  time_since_restore: 99547.9966533184\n",
      "  time_this_iter_s: 507.78327322006226\n",
      "  time_total_s: 99547.9966533184\n",
      "  timers:\n",
      "    learn_throughput: 260.555\n",
      "    learn_time_ms: 15351.827\n",
      "    load_throughput: 10536.616\n",
      "    load_time_ms: 379.629\n",
      "    sample_throughput: 8.207\n",
      "    sample_time_ms: 487376.937\n",
      "    update_time_ms: 3.52\n",
      "  timestamp: 1613926118\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 752000\n",
      "  training_iteration: 188\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_17-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 140.18\n",
      "  episode_reward_max: 118.38243891327723\n",
      "  episode_reward_mean: 87.11892782788351\n",
      "  episode_reward_min: -104.86896589473784\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5717\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4141284227371216\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00811158586293459\n",
      "        model: {}\n",
      "        policy_loss: -0.07657773792743683\n",
      "        total_loss: 425.97039794921875\n",
      "        vf_explained_var: 0.7353231310844421\n",
      "        vf_loss: 426.0330810546875\n",
      "    num_steps_sampled: 756000\n",
      "    num_steps_trained: 756000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.6038942976356\n",
      "    ram_util_percent: 38.409318497913766\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688166799210907\n",
      "    mean_env_wait_ms: 117.38973558548936\n",
      "    mean_inference_ms: 1.731003723660797\n",
      "    mean_raw_obs_processing_ms: 9.165262739863397\n",
      "  time_since_restore: 100051.91476297379\n",
      "  time_this_iter_s: 503.91810965538025\n",
      "  time_total_s: 100051.91476297379\n",
      "  timers:\n",
      "    learn_throughput: 260.44\n",
      "    learn_time_ms: 15358.647\n",
      "    load_throughput: 10481.852\n",
      "    load_time_ms: 381.612\n",
      "    sample_throughput: 8.201\n",
      "    sample_time_ms: 487723.613\n",
      "    update_time_ms: 3.524\n",
      "  timestamp: 1613926622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 756000\n",
      "  training_iteration: 189\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 139.42\n",
      "  episode_reward_max: 118.38243891327723\n",
      "  episode_reward_mean: 87.3092010228227\n",
      "  episode_reward_min: -99.1539639651303\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 5743\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4504252076148987\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008290223777294159\n",
      "        model: {}\n",
      "        policy_loss: -0.06829310208559036\n",
      "        total_loss: 572.34716796875\n",
      "        vf_explained_var: 0.5892797112464905\n",
      "        vf_loss: 572.4014282226562\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.458379888268155\n",
      "    ram_util_percent: 38.467737430167595\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688263892342844\n",
      "    mean_env_wait_ms: 117.36105588966177\n",
      "    mean_inference_ms: 1.7311708017025933\n",
      "    mean_raw_obs_processing_ms: 9.16247071305064\n",
      "  time_since_restore: 100553.34527301788\n",
      "  time_this_iter_s: 501.4305100440979\n",
      "  time_total_s: 100553.34527301788\n",
      "  timers:\n",
      "    learn_throughput: 260.435\n",
      "    learn_time_ms: 15358.894\n",
      "    load_throughput: 10440.625\n",
      "    load_time_ms: 383.119\n",
      "    sample_throughput: 8.2\n",
      "    sample_time_ms: 487784.813\n",
      "    update_time_ms: 3.526\n",
      "  timestamp: 1613927124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 190\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 143.17\n",
      "  episode_reward_max: 118.37372136028051\n",
      "  episode_reward_mean: 91.30206714487505\n",
      "  episode_reward_min: -99.1539639651303\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5770\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42250144481658936\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006526424083858728\n",
      "        model: {}\n",
      "        policy_loss: -0.05536552518606186\n",
      "        total_loss: 193.9767303466797\n",
      "        vf_explained_var: 0.8199180960655212\n",
      "        vf_loss: 194.0209197998047\n",
      "    num_steps_sampled: 764000\n",
      "    num_steps_trained: 764000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.48100558659217\n",
      "    ram_util_percent: 38.48701117318436\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06883584798012388\n",
      "    mean_env_wait_ms: 117.3310553603252\n",
      "    mean_inference_ms: 1.7313293135656977\n",
      "    mean_raw_obs_processing_ms: 9.159199007370155\n",
      "  time_since_restore: 101054.5346596241\n",
      "  time_this_iter_s: 501.18938660621643\n",
      "  time_total_s: 101054.5346596241\n",
      "  timers:\n",
      "    learn_throughput: 260.427\n",
      "    learn_time_ms: 15359.376\n",
      "    load_throughput: 10534.029\n",
      "    load_time_ms: 379.722\n",
      "    sample_throughput: 8.211\n",
      "    sample_time_ms: 487165.523\n",
      "    update_time_ms: 3.509\n",
      "  timestamp: 1613927625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 764000\n",
      "  training_iteration: 191\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 138.97\n",
      "  episode_reward_max: 118.33499069266497\n",
      "  episode_reward_mean: 84.75324872804698\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 5802\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48007702827453613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012584340758621693\n",
      "        model: {}\n",
      "        policy_loss: -0.09932564198970795\n",
      "        total_loss: 728.4404907226562\n",
      "        vf_explained_var: 0.6476417183876038\n",
      "        vf_loss: 728.5183715820312\n",
      "    num_steps_sampled: 768000\n",
      "    num_steps_trained: 768000\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.90993103448277\n",
      "    ram_util_percent: 38.470068965517235\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06884751022889775\n",
      "    mean_env_wait_ms: 117.2953505584617\n",
      "    mean_inference_ms: 1.7315061560061569\n",
      "    mean_raw_obs_processing_ms: 9.156271346885227\n",
      "  time_since_restore: 101562.37695145607\n",
      "  time_this_iter_s: 507.8422918319702\n",
      "  time_total_s: 101562.37695145607\n",
      "  timers:\n",
      "    learn_throughput: 259.223\n",
      "    learn_time_ms: 15430.755\n",
      "    load_throughput: 10585.392\n",
      "    load_time_ms: 377.879\n",
      "    sample_throughput: 8.203\n",
      "    sample_time_ms: 487652.062\n",
      "    update_time_ms: 3.492\n",
      "  timestamp: 1613928133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 768000\n",
      "  training_iteration: 192\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 118.32947700638533\n",
      "  episode_reward_mean: 88.82997558811356\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5830\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47835829854011536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010771854780614376\n",
      "        model: {}\n",
      "        policy_loss: -0.08759791404008865\n",
      "        total_loss: 685.3577880859375\n",
      "        vf_explained_var: 0.5802308320999146\n",
      "        vf_loss: 685.4270629882812\n",
      "    num_steps_sampled: 772000\n",
      "    num_steps_trained: 772000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.510055865921785\n",
      "    ram_util_percent: 38.51578212290503\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06885747574321907\n",
      "    mean_env_wait_ms: 117.26444235467844\n",
      "    mean_inference_ms: 1.7316449178343003\n",
      "    mean_raw_obs_processing_ms: 9.153492962958348\n",
      "  time_since_restore: 102064.4938955307\n",
      "  time_this_iter_s: 502.11694407463074\n",
      "  time_total_s: 102064.4938955307\n",
      "  timers:\n",
      "    learn_throughput: 259.258\n",
      "    learn_time_ms: 15428.676\n",
      "    load_throughput: 10581.754\n",
      "    load_time_ms: 378.009\n",
      "    sample_throughput: 8.202\n",
      "    sample_time_ms: 487683.671\n",
      "    update_time_ms: 3.476\n",
      "  timestamp: 1613928636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 772000\n",
      "  training_iteration: 193\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-38-56\n",
      "  done: false\n",
      "  episode_len_mean: 139.6\n",
      "  episode_reward_max: 118.32947700638533\n",
      "  episode_reward_mean: 86.55391506173646\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 5857\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.46270233392715454\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00774323008954525\n",
      "        model: {}\n",
      "        policy_loss: -0.07308743894100189\n",
      "        total_loss: 156.12130737304688\n",
      "        vf_explained_var: 0.8850777745246887\n",
      "        vf_loss: 156.18115234375\n",
      "    num_steps_sampled: 776000\n",
      "    num_steps_trained: 776000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.477902097902096\n",
      "    ram_util_percent: 38.45314685314685\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688671396590762\n",
      "    mean_env_wait_ms: 117.23489272819705\n",
      "    mean_inference_ms: 1.7317737628743544\n",
      "    mean_raw_obs_processing_ms: 9.151175244274633\n",
      "  time_since_restore: 102564.99697709084\n",
      "  time_this_iter_s: 500.5030815601349\n",
      "  time_total_s: 102564.99697709084\n",
      "  timers:\n",
      "    learn_throughput: 259.315\n",
      "    learn_time_ms: 15425.279\n",
      "    load_throughput: 10581.729\n",
      "    load_time_ms: 378.01\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487056.506\n",
      "    update_time_ms: 3.485\n",
      "  timestamp: 1613929136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 776000\n",
      "  training_iteration: 194\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 97.17839582171707\n",
      "  episode_reward_min: -106.0289334979842\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5885\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44672891497612\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015807699412107468\n",
      "        model: {}\n",
      "        policy_loss: -0.10444864630699158\n",
      "        total_loss: 4.103693962097168\n",
      "        vf_explained_var: 0.9922036528587341\n",
      "        vf_loss: 4.18113374710083\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.50251396648045\n",
      "    ram_util_percent: 38.45167597765362\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06887643826364688\n",
      "    mean_env_wait_ms: 117.20436109499063\n",
      "    mean_inference_ms: 1.7318841697148941\n",
      "    mean_raw_obs_processing_ms: 9.14814497512818\n",
      "  time_since_restore: 103066.50950145721\n",
      "  time_this_iter_s: 501.5125243663788\n",
      "  time_total_s: 103066.50950145721\n",
      "  timers:\n",
      "    learn_throughput: 259.242\n",
      "    learn_time_ms: 15429.578\n",
      "    load_throughput: 10568.217\n",
      "    load_time_ms: 378.493\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487024.19\n",
      "    update_time_ms: 3.523\n",
      "  timestamp: 1613929638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 195\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_18-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 141.24\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 99.04113578713537\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 5916\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4446447491645813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007330939639359713\n",
      "        model: {}\n",
      "        policy_loss: -0.06801272928714752\n",
      "        total_loss: 325.7757263183594\n",
      "        vf_explained_var: 0.7580990791320801\n",
      "        vf_loss: 325.8312072753906\n",
      "    num_steps_sampled: 784000\n",
      "    num_steps_trained: 784000\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.5625\n",
      "    ram_util_percent: 38.440416666666664\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0688861500968792\n",
      "    mean_env_wait_ms: 117.16950231676245\n",
      "    mean_inference_ms: 1.7320091447873387\n",
      "    mean_raw_obs_processing_ms: 9.14526705178258\n",
      "  time_since_restore: 103570.86333155632\n",
      "  time_this_iter_s: 504.35383009910583\n",
      "  time_total_s: 103570.86333155632\n",
      "  timers:\n",
      "    learn_throughput: 259.316\n",
      "    learn_time_ms: 15425.214\n",
      "    load_throughput: 10555.77\n",
      "    load_time_ms: 378.94\n",
      "    sample_throughput: 8.21\n",
      "    sample_time_ms: 487211.327\n",
      "    update_time_ms: 3.531\n",
      "  timestamp: 1613930143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 784000\n",
      "  training_iteration: 196\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 138.77\n",
      "  episode_reward_max: 118.39086243496018\n",
      "  episode_reward_mean: 90.86260867776606\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 5944\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4569801688194275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010883398354053497\n",
      "        model: {}\n",
      "        policy_loss: -0.09370122104883194\n",
      "        total_loss: 565.4652099609375\n",
      "        vf_explained_var: 0.7109858393669128\n",
      "        vf_loss: 565.5403442382812\n",
      "    num_steps_sampled: 788000\n",
      "    num_steps_trained: 788000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.52175732217573\n",
      "    ram_util_percent: 38.50195258019526\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06889490639963572\n",
      "    mean_env_wait_ms: 117.13893273738398\n",
      "    mean_inference_ms: 1.7321253873039135\n",
      "    mean_raw_obs_processing_ms: 9.142997044733525\n",
      "  time_since_restore: 104073.42679667473\n",
      "  time_this_iter_s: 502.5634651184082\n",
      "  time_total_s: 104073.42679667473\n",
      "  timers:\n",
      "    learn_throughput: 259.252\n",
      "    learn_time_ms: 15429.024\n",
      "    load_throughput: 10559.05\n",
      "    load_time_ms: 378.822\n",
      "    sample_throughput: 8.208\n",
      "    sample_time_ms: 487323.336\n",
      "    update_time_ms: 3.489\n",
      "  timestamp: 1613930646\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 788000\n",
      "  training_iteration: 197\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-12-30\n",
      "  done: false\n",
      "  episode_len_mean: 137.05\n",
      "  episode_reward_max: 118.38534078592863\n",
      "  episode_reward_mean: 88.86870043619578\n",
      "  episode_reward_min: -106.12997736688158\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 5974\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43862196803092957\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006011617369949818\n",
      "        model: {}\n",
      "        policy_loss: -0.06377123296260834\n",
      "        total_loss: 181.75660705566406\n",
      "        vf_explained_var: 0.8628853559494019\n",
      "        vf_loss: 181.81011962890625\n",
      "    num_steps_sampled: 792000\n",
      "    num_steps_trained: 792000\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.44396671289876\n",
      "    ram_util_percent: 38.54105409153953\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0689038510570063\n",
      "    mean_env_wait_ms: 117.1074986980277\n",
      "    mean_inference_ms: 1.7322632502674735\n",
      "    mean_raw_obs_processing_ms: 9.141648403708048\n",
      "  time_since_restore: 104578.01215744019\n",
      "  time_this_iter_s: 504.58536076545715\n",
      "  time_total_s: 104578.01215744019\n",
      "  timers:\n",
      "    learn_throughput: 259.323\n",
      "    learn_time_ms: 15424.795\n",
      "    load_throughput: 10560.106\n",
      "    load_time_ms: 378.784\n",
      "    sample_throughput: 8.213\n",
      "    sample_time_ms: 487008.488\n",
      "    update_time_ms: 3.502\n",
      "  timestamp: 1613931150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 792000\n",
      "  training_iteration: 198\n",
      "  trial_id: c4001_00000\n",
      "  \n",
      "Result for PPO_ScoutingDiscreteTask_c4001_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-02-21_19-20-54\n",
      "  done: true\n",
      "  episode_len_mean: 135.65\n",
      "  episode_reward_max: 118.37682836900566\n",
      "  episode_reward_mean: 84.91120274687219\n",
      "  episode_reward_min: -106.00795496124721\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 6003\n",
      "  experiment_id: abecbdbfd48a4155b643541c7842f7d3\n",
      "  hostname: workstation\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.708593726158142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43731579184532166\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011441821232438087\n",
      "        model: {}\n",
      "        policy_loss: -0.08611249923706055\n",
      "        total_loss: 731.3579711914062\n",
      "        vf_explained_var: 0.5641735792160034\n",
      "        vf_loss: 731.4244995117188\n",
      "    num_steps_sampled: 796000\n",
      "    num_steps_trained: 796000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.178.60\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.49972144846797\n",
      "    ram_util_percent: 38.53398328690808\n",
      "  pid: 84297\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0689123747585987\n",
      "    mean_env_wait_ms: 117.07826797938513\n",
      "    mean_inference_ms: 1.7324010880958718\n",
      "    mean_raw_obs_processing_ms: 9.140069862547081\n",
      "  time_since_restore: 105081.37180137634\n",
      "  time_this_iter_s: 503.3596439361572\n",
      "  time_total_s: 105081.37180137634\n",
      "  timers:\n",
      "    learn_throughput: 259.4\n",
      "    learn_time_ms: 15420.206\n",
      "    load_throughput: 10596.499\n",
      "    load_time_ms: 377.483\n",
      "    sample_throughput: 8.214\n",
      "    sample_time_ms: 486957.601\n",
      "    update_time_ms: 3.509\n",
      "  timestamp: 1613931654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 796000\n",
      "  training_iteration: 199\n",
      "  trial_id: c4001_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         584.968</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-93.4971</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -108.067</td><td style=\"text-align: right;\">           42.7742</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1148.25</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-92.2754</td><td style=\"text-align: right;\">             114.289</td><td style=\"text-align: right;\">            -108.369</td><td style=\"text-align: right;\">             45.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          1751.5</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-83.1377</td><td style=\"text-align: right;\">             118.275</td><td style=\"text-align: right;\">             -108.49</td><td style=\"text-align: right;\">             54.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2273.68</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> -76.314</td><td style=\"text-align: right;\">             118.312</td><td style=\"text-align: right;\">             -108.49</td><td style=\"text-align: right;\">             68.51</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          2795.8</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-74.5112</td><td style=\"text-align: right;\">             118.312</td><td style=\"text-align: right;\">            -107.928</td><td style=\"text-align: right;\">              80.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         3319.58</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-74.3607</td><td style=\"text-align: right;\">             118.266</td><td style=\"text-align: right;\">            -106.658</td><td style=\"text-align: right;\">             82.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         3833.39</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-63.5234</td><td style=\"text-align: right;\">             118.307</td><td style=\"text-align: right;\">            -106.506</td><td style=\"text-align: right;\">             87.35</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         4344.97</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-59.6357</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">             94.72</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         4857.63</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-61.8241</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">             99.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5368.27</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-57.3206</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -107.172</td><td style=\"text-align: right;\">            105.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         5871.95</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\"> -44.265</td><td style=\"text-align: right;\">             118.378</td><td style=\"text-align: right;\">            -106.664</td><td style=\"text-align: right;\">            107.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         6383.15</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-37.8044</td><td style=\"text-align: right;\">             118.378</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">             112.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         6886.86</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-27.5816</td><td style=\"text-align: right;\">             118.325</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">            117.99</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         7398.73</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-27.6162</td><td style=\"text-align: right;\">             118.348</td><td style=\"text-align: right;\">            -107.508</td><td style=\"text-align: right;\">            114.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         7906.86</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-20.9624</td><td style=\"text-align: right;\">             118.353</td><td style=\"text-align: right;\">            -107.144</td><td style=\"text-align: right;\">            112.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         8415.26</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-18.7572</td><td style=\"text-align: right;\">             118.353</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            109.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         8918.77</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-14.2859</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            120.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         9420.53</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-16.7852</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">             -108.65</td><td style=\"text-align: right;\">            123.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         9924.06</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-16.6352</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">            125.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         10431.4</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-19.0543</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">            122.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         10935.5</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-12.3108</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.603</td><td style=\"text-align: right;\">             120.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         11442.2</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-5.86666</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -106.867</td><td style=\"text-align: right;\">            119.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         11944.1</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\"> 6.99879</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -106.702</td><td style=\"text-align: right;\">            124.01</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">           12450</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\"> 15.2939</td><td style=\"text-align: right;\">              118.34</td><td style=\"text-align: right;\">            -106.702</td><td style=\"text-align: right;\">            123.87</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         12954.4</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> 30.2335</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -105.225</td><td style=\"text-align: right;\">            126.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         13457.7</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\"> 23.5594</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -105.225</td><td style=\"text-align: right;\">            125.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         13960.1</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">  36.487</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">             -105.02</td><td style=\"text-align: right;\">            127.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 13.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         14459.3</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> 36.2323</td><td style=\"text-align: right;\">             118.365</td><td style=\"text-align: right;\">            -105.786</td><td style=\"text-align: right;\">            131.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         14964.1</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\"> 32.1002</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            135.09</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         15459.7</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> 40.3523</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            140.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         15958.5</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\"> 47.0233</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.252</td><td style=\"text-align: right;\">            144.89</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">           16455</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\"> 45.0298</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -106.132</td><td style=\"text-align: right;\">            143.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         16955.5</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\"> 42.7677</td><td style=\"text-align: right;\">             118.372</td><td style=\"text-align: right;\">            -105.078</td><td style=\"text-align: right;\">            143.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         17456.9</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> 32.1405</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.078</td><td style=\"text-align: right;\">            133.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         17961.1</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> 15.5419</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">            133.22</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         18457.8</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> 25.9761</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">             130.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         18958.8</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> 29.8441</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">            133.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">           19465</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> 45.9345</td><td style=\"text-align: right;\">             118.364</td><td style=\"text-align: right;\">            -107.439</td><td style=\"text-align: right;\">             133.4</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         19965.7</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> 46.3171</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            129.59</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         20464.8</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">  54.302</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            131.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         20965.7</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> 52.7048</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.074</td><td style=\"text-align: right;\">            133.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         21466.9</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> 48.8043</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -106.321</td><td style=\"text-align: right;\">            135.94</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         21971.4</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> 40.8523</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            129.75</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         22471.9</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> 42.8976</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            129.15</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         22972.5</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> 62.0653</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -105.628</td><td style=\"text-align: right;\">            130.06</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         23480.3</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> 59.9853</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -101.459</td><td style=\"text-align: right;\">            134.84</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         23975.7</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> 74.5288</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            144.04</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         24475.1</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> 67.9829</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            142.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         24973.8</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> 67.8799</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -106.348</td><td style=\"text-align: right;\">            148.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         25473.1</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> 63.9277</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -105.116</td><td style=\"text-align: right;\">            144.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         25971.5</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> 59.3821</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -105.116</td><td style=\"text-align: right;\">            142.79</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         26472.9</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> 59.0024</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            133.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         26982.7</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> 59.0911</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            132.54</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         27511.5</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> 65.3914</td><td style=\"text-align: right;\">             118.332</td><td style=\"text-align: right;\">            -107.145</td><td style=\"text-align: right;\">            128.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         28042.3</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> 65.8051</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -106.744</td><td style=\"text-align: right;\">            133.35</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         28566.9</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">  55.311</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">            -106.744</td><td style=\"text-align: right;\">            126.14</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         29086.6</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> 68.1601</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -101.232</td><td style=\"text-align: right;\">            136.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         29659.2</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> 66.3394</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -101.232</td><td style=\"text-align: right;\">             136.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         30230.8</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> 70.2979</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">             -100.24</td><td style=\"text-align: right;\">            141.39</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         30805.7</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> 74.4389</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -99.9359</td><td style=\"text-align: right;\">            141.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         31377.5</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> 70.0174</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -105.687</td><td style=\"text-align: right;\">            141.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         31949.3</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> 71.7774</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            141.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         32523.3</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> 59.1274</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            137.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         33097.1</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">  55.334</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            136.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         33669.4</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> 53.5255</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -106.745</td><td style=\"text-align: right;\">            137.77</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">           34239</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> 53.7095</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            146.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         34809.1</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> 72.5743</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            153.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         35380.3</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  72.234</td><td style=\"text-align: right;\">             118.392</td><td style=\"text-align: right;\">            -107.534</td><td style=\"text-align: right;\">            156.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         35952.7</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\"> 76.4175</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.561</td><td style=\"text-align: right;\">            153.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         36525.3</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\"> 72.2532</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            146.37</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         37100.1</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\"> 70.3391</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            138.47</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         37671.1</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\"> 76.6779</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.235</td><td style=\"text-align: right;\">            139.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         38244.2</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> 68.1292</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">             143.7</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         38817.4</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\"> 63.9351</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         39389.2</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> 68.3596</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            140.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         39957.2</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\"> 70.5364</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.277</td><td style=\"text-align: right;\">            144.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         40532.2</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\"> 74.7772</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -98.7848</td><td style=\"text-align: right;\">             138.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         41104.8</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\"> 78.9809</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -98.7417</td><td style=\"text-align: right;\">            142.53</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         41679.5</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\"> 66.2304</td><td style=\"text-align: right;\">             118.388</td><td style=\"text-align: right;\">            -100.335</td><td style=\"text-align: right;\">            134.93</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         42258.1</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\"> 66.3086</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            129.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         42831.9</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\"> 60.0336</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">             128.4</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         43408.9</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\"> 55.8433</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            126.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         43981.4</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\"> 64.1735</td><td style=\"text-align: right;\">             118.372</td><td style=\"text-align: right;\">            -100.725</td><td style=\"text-align: right;\">            134.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">           44554</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\"> 74.6458</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.479</td><td style=\"text-align: right;\">            139.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         45127.5</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\"> 72.4842</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.479</td><td style=\"text-align: right;\">            135.91</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         45699.6</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\"> 74.4792</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -100.335</td><td style=\"text-align: right;\">            141.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">           46272</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\"> 70.2346</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -100.486</td><td style=\"text-align: right;\">            141.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">           46842</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\"> 78.5976</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -101.487</td><td style=\"text-align: right;\">            145.91</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         47414.5</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\"> 86.7418</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            151.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         47986.2</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> 95.4794</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            152.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         48559.3</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  86.877</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -106.324</td><td style=\"text-align: right;\">            148.45</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         49132.4</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  78.536</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">            147.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         49702.8</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\"> 76.2701</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">            148.59</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         50274.3</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\"> 76.0907</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">             -104.59</td><td style=\"text-align: right;\">               144</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         50844.4</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\"> 90.7099</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">            -101.663</td><td style=\"text-align: right;\">            154.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         51419.6</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\"> 90.7374</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            151.55</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         51992.5</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 95.0085</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            148.99</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         52563.9</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 92.9886</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">            148.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         53137.5</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\"> 88.8485</td><td style=\"text-align: right;\">             118.339</td><td style=\"text-align: right;\">            -105.809</td><td style=\"text-align: right;\">             145.7</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         53711.6</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 93.1422</td><td style=\"text-align: right;\">             118.339</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            147.11</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         54285.6</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">  87.096</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            145.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">           54857</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\"> 89.2414</td><td style=\"text-align: right;\">             118.394</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            147.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         55434.1</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">  80.926</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -102.632</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         56010.5</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\"> 82.9837</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -97.2012</td><td style=\"text-align: right;\">            143.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         56586.3</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 78.5377</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            136.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         57158.2</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\"> 78.3317</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            137.12</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         57732.9</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 78.0711</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -105.916</td><td style=\"text-align: right;\">            143.85</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         58308.1</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\"> 78.4255</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -103.571</td><td style=\"text-align: right;\">             140.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         58882.6</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 76.4069</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -103.571</td><td style=\"text-align: right;\">            144.48</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         59457.2</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\"> 74.6297</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            141.72</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         60032.4</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 76.6534</td><td style=\"text-align: right;\">             118.386</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            139.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         60606.6</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\"> 72.2738</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            137.41</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         61191.2</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 78.4317</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.489</td><td style=\"text-align: right;\">            141.31</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         61762.9</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 86.8246</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.032</td><td style=\"text-align: right;\">             144.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         62342.6</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\"> 86.8017</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -105.091</td><td style=\"text-align: right;\">            144.62</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         62919.9</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">  93.335</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -105.091</td><td style=\"text-align: right;\">            147.86</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         63491.7</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 97.3352</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            151.34</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         64066.2</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 91.0529</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            146.86</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         64637.4</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\"> 89.1573</td><td style=\"text-align: right;\">             118.399</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            148.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         65208.2</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 87.0029</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.436</td><td style=\"text-align: right;\">            148.73</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         65721.2</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 85.1433</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">             -100.99</td><td style=\"text-align: right;\">            146.66</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         66243.3</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\"> 85.3865</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -100.431</td><td style=\"text-align: right;\">            146.02</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         66775.3</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 89.4547</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -100.431</td><td style=\"text-align: right;\">            139.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">           67295</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\"> 84.9043</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -106.07</td><td style=\"text-align: right;\">            139.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 11.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">           67801</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 84.8044</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">             -106.07</td><td style=\"text-align: right;\">            134.12</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         68305.6</td><td style=\"text-align: right;\">504000</td><td style=\"text-align: right;\"> 78.0839</td><td style=\"text-align: right;\">             118.347</td><td style=\"text-align: right;\">            -106.328</td><td style=\"text-align: right;\">             138.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         68832.5</td><td style=\"text-align: right;\">508000</td><td style=\"text-align: right;\">  82.365</td><td style=\"text-align: right;\">             118.328</td><td style=\"text-align: right;\">            -106.328</td><td style=\"text-align: right;\">            142.47</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         69358.4</td><td style=\"text-align: right;\">512000</td><td style=\"text-align: right;\"> 82.4307</td><td style=\"text-align: right;\">             118.314</td><td style=\"text-align: right;\">            -106.802</td><td style=\"text-align: right;\">            142.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         69867.9</td><td style=\"text-align: right;\">516000</td><td style=\"text-align: right;\"> 82.3166</td><td style=\"text-align: right;\">             118.349</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">             132.8</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         70371.8</td><td style=\"text-align: right;\">520000</td><td style=\"text-align: right;\"> 80.4074</td><td style=\"text-align: right;\">             118.349</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">            129.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         70872.9</td><td style=\"text-align: right;\">524000</td><td style=\"text-align: right;\"> 82.6994</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -106.896</td><td style=\"text-align: right;\">             131.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">           71374</td><td style=\"text-align: right;\">528000</td><td style=\"text-align: right;\"> 82.9684</td><td style=\"text-align: right;\">              118.38</td><td style=\"text-align: right;\">            -103.769</td><td style=\"text-align: right;\">            135.54</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         71877.9</td><td style=\"text-align: right;\">532000</td><td style=\"text-align: right;\"> 83.1785</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            133.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         72376.1</td><td style=\"text-align: right;\">536000</td><td style=\"text-align: right;\"> 85.2736</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            139.25</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         72879.5</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\"> 95.6462</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">             139.5</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         73381.7</td><td style=\"text-align: right;\">544000</td><td style=\"text-align: right;\"> 95.6876</td><td style=\"text-align: right;\">               118.4</td><td style=\"text-align: right;\">            -105.487</td><td style=\"text-align: right;\">            138.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         73882.2</td><td style=\"text-align: right;\">548000</td><td style=\"text-align: right;\"> 95.8851</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -100.175</td><td style=\"text-align: right;\">             139.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         74381.8</td><td style=\"text-align: right;\">552000</td><td style=\"text-align: right;\"> 97.8148</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.633</td><td style=\"text-align: right;\">            142.07</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         74887.1</td><td style=\"text-align: right;\">556000</td><td style=\"text-align: right;\"> 93.4033</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            139.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         75387.6</td><td style=\"text-align: right;\">560000</td><td style=\"text-align: right;\"> 93.4257</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            144.46</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         75906.1</td><td style=\"text-align: right;\">564000</td><td style=\"text-align: right;\"> 89.1157</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            141.74</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">           76410</td><td style=\"text-align: right;\">568000</td><td style=\"text-align: right;\"> 85.0535</td><td style=\"text-align: right;\">             118.376</td><td style=\"text-align: right;\">            -106.523</td><td style=\"text-align: right;\">            139.19</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         76912.8</td><td style=\"text-align: right;\">572000</td><td style=\"text-align: right;\"> 91.5854</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -102.284</td><td style=\"text-align: right;\">            143.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         77414.4</td><td style=\"text-align: right;\">576000</td><td style=\"text-align: right;\"> 89.3539</td><td style=\"text-align: right;\">             118.379</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            142.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">           77913</td><td style=\"text-align: right;\">580000</td><td style=\"text-align: right;\"> 99.8468</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            146.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         78416.4</td><td style=\"text-align: right;\">584000</td><td style=\"text-align: right;\"> 93.4931</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            144.87</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         78917.4</td><td style=\"text-align: right;\">588000</td><td style=\"text-align: right;\"> 95.3716</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.467</td><td style=\"text-align: right;\">            145.58</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         79418.8</td><td style=\"text-align: right;\">592000</td><td style=\"text-align: right;\"> 101.798</td><td style=\"text-align: right;\">             118.398</td><td style=\"text-align: right;\">            -105.135</td><td style=\"text-align: right;\">            147.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         79925.6</td><td style=\"text-align: right;\">596000</td><td style=\"text-align: right;\"> 95.7064</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -104.575</td><td style=\"text-align: right;\">            145.03</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         80429.4</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\">  93.574</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            139.82</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         80933.3</td><td style=\"text-align: right;\">604000</td><td style=\"text-align: right;\"> 89.2191</td><td style=\"text-align: right;\">             118.387</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            136.29</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         81435.8</td><td style=\"text-align: right;\">608000</td><td style=\"text-align: right;\"> 91.0047</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -105.593</td><td style=\"text-align: right;\">            137.96</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         81937.2</td><td style=\"text-align: right;\">612000</td><td style=\"text-align: right;\"> 91.1644</td><td style=\"text-align: right;\">             118.359</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            141.33</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         82451.8</td><td style=\"text-align: right;\">616000</td><td style=\"text-align: right;\"> 95.1221</td><td style=\"text-align: right;\">             118.359</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            138.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         82950.2</td><td style=\"text-align: right;\">620000</td><td style=\"text-align: right;\"> 93.0994</td><td style=\"text-align: right;\">             118.335</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            142.57</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         83451.6</td><td style=\"text-align: right;\">624000</td><td style=\"text-align: right;\"> 97.1734</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -107.678</td><td style=\"text-align: right;\">            144.83</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         83963.5</td><td style=\"text-align: right;\">628000</td><td style=\"text-align: right;\"> 86.7386</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -106.731</td><td style=\"text-align: right;\">            140.43</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         84469.4</td><td style=\"text-align: right;\">632000</td><td style=\"text-align: right;\"> 82.4999</td><td style=\"text-align: right;\">              118.39</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            134.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         84972.2</td><td style=\"text-align: right;\">636000</td><td style=\"text-align: right;\"> 73.9378</td><td style=\"text-align: right;\">             118.366</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            132.61</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">           85475</td><td style=\"text-align: right;\">640000</td><td style=\"text-align: right;\"> 82.4884</td><td style=\"text-align: right;\">             118.344</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">            137.36</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         85978.7</td><td style=\"text-align: right;\">644000</td><td style=\"text-align: right;\"> 82.4412</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -108.497</td><td style=\"text-align: right;\">             138.9</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         86480.1</td><td style=\"text-align: right;\">648000</td><td style=\"text-align: right;\">  93.177</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -105.149</td><td style=\"text-align: right;\">            147.27</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         86982.8</td><td style=\"text-align: right;\">652000</td><td style=\"text-align: right;\"> 90.8336</td><td style=\"text-align: right;\">             118.346</td><td style=\"text-align: right;\">            -106.965</td><td style=\"text-align: right;\">            146.68</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         87486.7</td><td style=\"text-align: right;\">656000</td><td style=\"text-align: right;\"> 92.8701</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -106.965</td><td style=\"text-align: right;\">             145.8</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         87988.1</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\"> 92.7061</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            145.21</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         88489.4</td><td style=\"text-align: right;\">664000</td><td style=\"text-align: right;\">  94.768</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            146.88</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         88989.3</td><td style=\"text-align: right;\">668000</td><td style=\"text-align: right;\"> 101.208</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            147.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         89495.5</td><td style=\"text-align: right;\">672000</td><td style=\"text-align: right;\"> 90.6324</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -107.033</td><td style=\"text-align: right;\">            141.56</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         89997.6</td><td style=\"text-align: right;\">676000</td><td style=\"text-align: right;\"> 94.9958</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -106.978</td><td style=\"text-align: right;\">            140.49</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">           90499</td><td style=\"text-align: right;\">680000</td><td style=\"text-align: right;\"> 95.4036</td><td style=\"text-align: right;\">             118.383</td><td style=\"text-align: right;\">            -106.978</td><td style=\"text-align: right;\">            141.28</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         91003.4</td><td style=\"text-align: right;\">684000</td><td style=\"text-align: right;\"> 99.7913</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -106.63</td><td style=\"text-align: right;\">            141.21</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         91506.9</td><td style=\"text-align: right;\">688000</td><td style=\"text-align: right;\"> 95.5937</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            142.26</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         92008.9</td><td style=\"text-align: right;\">692000</td><td style=\"text-align: right;\"> 91.3859</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            140.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         92507.7</td><td style=\"text-align: right;\">696000</td><td style=\"text-align: right;\"> 95.3946</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">             -105.05</td><td style=\"text-align: right;\">            146.02</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         93011.1</td><td style=\"text-align: right;\">700000</td><td style=\"text-align: right;\">   88.93</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            141.08</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         93517.2</td><td style=\"text-align: right;\">704000</td><td style=\"text-align: right;\"> 80.6405</td><td style=\"text-align: right;\">             118.389</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            140.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         94015.1</td><td style=\"text-align: right;\">708000</td><td style=\"text-align: right;\"> 78.3588</td><td style=\"text-align: right;\">             118.375</td><td style=\"text-align: right;\">            -107.307</td><td style=\"text-align: right;\">            141.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         94514.9</td><td style=\"text-align: right;\">712000</td><td style=\"text-align: right;\"> 84.7146</td><td style=\"text-align: right;\">             118.343</td><td style=\"text-align: right;\">             -104.55</td><td style=\"text-align: right;\">            145.63</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         95015.3</td><td style=\"text-align: right;\">716000</td><td style=\"text-align: right;\"> 93.0332</td><td style=\"text-align: right;\">             118.318</td><td style=\"text-align: right;\">             -104.55</td><td style=\"text-align: right;\">            151.13</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         95516.1</td><td style=\"text-align: right;\">720000</td><td style=\"text-align: right;\"> 99.2755</td><td style=\"text-align: right;\">             118.354</td><td style=\"text-align: right;\">            -99.1245</td><td style=\"text-align: right;\">             154.2</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         96023.5</td><td style=\"text-align: right;\">724000</td><td style=\"text-align: right;\">   86.87</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -100.514</td><td style=\"text-align: right;\">            144.44</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         96525.8</td><td style=\"text-align: right;\">728000</td><td style=\"text-align: right;\">  89.188</td><td style=\"text-align: right;\">             118.393</td><td style=\"text-align: right;\">            -100.514</td><td style=\"text-align: right;\">            139.98</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         97027.6</td><td style=\"text-align: right;\">732000</td><td style=\"text-align: right;\"> 93.3472</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -105.702</td><td style=\"text-align: right;\">            137.64</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         97534.4</td><td style=\"text-align: right;\">736000</td><td style=\"text-align: right;\">  89.211</td><td style=\"text-align: right;\">             118.395</td><td style=\"text-align: right;\">            -107.313</td><td style=\"text-align: right;\">            133.16</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         98036.2</td><td style=\"text-align: right;\">740000</td><td style=\"text-align: right;\"> 97.4386</td><td style=\"text-align: right;\">             118.396</td><td style=\"text-align: right;\">            -107.313</td><td style=\"text-align: right;\">            137.71</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         98538.8</td><td style=\"text-align: right;\">744000</td><td style=\"text-align: right;\"> 86.6814</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            135.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         99040.2</td><td style=\"text-align: right;\">748000</td><td style=\"text-align: right;\"> 95.3122</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            142.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">           99548</td><td style=\"text-align: right;\">752000</td><td style=\"text-align: right;\"> 91.0886</td><td style=\"text-align: right;\">             118.397</td><td style=\"text-align: right;\">            -108.208</td><td style=\"text-align: right;\">            141.52</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">          100052</td><td style=\"text-align: right;\">756000</td><td style=\"text-align: right;\"> 87.1189</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">            -104.869</td><td style=\"text-align: right;\">            140.18</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">          100553</td><td style=\"text-align: right;\">760000</td><td style=\"text-align: right;\"> 87.3092</td><td style=\"text-align: right;\">             118.382</td><td style=\"text-align: right;\">             -99.154</td><td style=\"text-align: right;\">            139.42</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">          101055</td><td style=\"text-align: right;\">764000</td><td style=\"text-align: right;\"> 91.3021</td><td style=\"text-align: right;\">             118.374</td><td style=\"text-align: right;\">             -99.154</td><td style=\"text-align: right;\">            143.17</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">          101562</td><td style=\"text-align: right;\">768000</td><td style=\"text-align: right;\"> 84.7532</td><td style=\"text-align: right;\">             118.335</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            138.97</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">          102064</td><td style=\"text-align: right;\">772000</td><td style=\"text-align: right;\">   88.83</td><td style=\"text-align: right;\">             118.329</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            140.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">          102565</td><td style=\"text-align: right;\">776000</td><td style=\"text-align: right;\"> 86.5539</td><td style=\"text-align: right;\">             118.329</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">             139.6</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">          103067</td><td style=\"text-align: right;\">780000</td><td style=\"text-align: right;\"> 97.1784</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">            -106.029</td><td style=\"text-align: right;\">            140.78</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">          103571</td><td style=\"text-align: right;\">784000</td><td style=\"text-align: right;\"> 99.0411</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            141.24</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">          104073</td><td style=\"text-align: right;\">788000</td><td style=\"text-align: right;\"> 90.8626</td><td style=\"text-align: right;\">             118.391</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            138.77</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">          104578</td><td style=\"text-align: right;\">792000</td><td style=\"text-align: right;\"> 88.8687</td><td style=\"text-align: right;\">             118.385</td><td style=\"text-align: right;\">             -106.13</td><td style=\"text-align: right;\">            137.05</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/8 CPUs, 1/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>RUNNING </td><td>192.168.178.60:84297</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">          105081</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> 84.9112</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -106.008</td><td style=\"text-align: right;\">            135.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/13.67 GiB heap, 0.0/4.69 GiB objects (0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dschori/ray_results/PPO_2021-02-20_14-08-46<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                          </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_ScoutingDiscreteTask_c4001_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">          105081</td><td style=\"text-align: right;\">796000</td><td style=\"text-align: right;\"> 84.9112</td><td style=\"text-align: right;\">             118.377</td><td style=\"text-align: right;\">            -106.008</td><td style=\"text-align: right;\">            135.65</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path, analysis = train(stop_criteria=stop,\n",
    "                                  config=config,\n",
    "                                  restorepath='/home/dschori/ray_results/'\n",
    "                                              'PPO_2021-02-09_17-09-27/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_2f1df_00000_0_2021-02-09_17-09-27/' \\\n",
    "                  'checkpoint_201/checkpoint-201')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Restore Agent for Testing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [ERROR] [1613935483.013750, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [WARN] [1613935483.017946, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m [WARN] [1613935483.019186, 0.000000]: END Init ControllersConnection\n",
      "2021-02-21 20:24:49,121\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-21 20:24:49,247\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-21 20:24:49,248\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=84294)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_nr = 164\n",
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 16:25:11,270\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-22 16:25:11,270\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [ERROR] [1614007514.360105, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [WARN] [1614007514.364186, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m [WARN] [1614007514.365176, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 16:25:22,346\tINFO trainable.py:99 -- Trainable.setup took 11.077 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-22 16:25:22,347\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 16:25:22,485\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-20_14-08-46/PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/checkpoint_199/checkpoint-199\n",
      "2021-02-22 16:25:22,485\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 199, '_timesteps_total': None, '_time_total': 105081.37180137634, '_episodes_total': 6003}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=10317)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_nr = 199\n",
    "checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-20_14-08-46/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "agent = load(checkpoint_path=checkpoint_path, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m None\n",
      "199\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m [ERROR] [1614016888.651456, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m [WARN] [1614016888.655481, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=88718)\u001B[0m [WARN] [1614016888.656589, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 19:01:34,758\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 19:01:34,904\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-20_14-08-46/PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/checkpoint_160/checkpoint-160\n",
      "2021-02-22 19:01:34,905\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 160, '_timesteps_total': None, '_time_total': 85475.04824829102, '_episodes_total': 4902}\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m [ERROR] [1614017023.198229, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m [WARN] [1614017023.201130, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=91119)\u001B[0m [WARN] [1614017023.201988, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 19:03:50,009\tINFO trainable.py:99 -- Trainable.setup took 10.213 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-22 19:03:50,010\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 19:03:50,190\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-20_14-08-46/PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/checkpoint_199/checkpoint-199\n",
      "2021-02-22 19:03:50,191\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 199, '_timesteps_total': None, '_time_total': 105081.37180137634, '_episodes_total': 6003}\n"
     ]
    }
   ],
   "source": [
    "# Video recording\n",
    "import time\n",
    "checkpoints = [1, 40, 80, 120, 160, 199]\n",
    "checkpoints = [1, 40]\n",
    "for checkpoint in checkpoints:\n",
    "    time_now = time.time()\n",
    "    print(checkpoint)\n",
    "    checkpoint_nr = checkpoint\n",
    "    checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-20_14-08-46/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_c4001_00000_0_2021-02-20_14-08-46/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "    agent = load(checkpoint_path=checkpoint_path, config=config)\n",
    "    env.img_prefix = 'check_{}'.format(checkpoint)\n",
    "    while True:\n",
    "        episode_reward = test_traj(agent=agent, env=env)\n",
    "        if time.time() - time_now > 100:\n",
    "            break\n",
    "    time.sleep(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 21:18:01,715\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-22 21:18:01,716\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m [ERROR] [1614025084.720583, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m [WARN] [1614025084.724933, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m [WARN] [1614025084.726053, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 21:18:11,852\tINFO trainable.py:99 -- Trainable.setup took 10.138 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-22 21:18:11,853\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 21:18:11,976\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_1/checkpoint-1\n",
      "2021-02-22 21:18:11,977\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 580.1686522960663, '_episodes_total': 92}\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m [ERROR] [1614025174.482917, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m [WARN] [1614025174.485836, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m [WARN] [1614025174.486711, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 21:19:39,996\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 21:19:40,152\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_40/checkpoint-40\n",
      "2021-02-22 21:19:40,153\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 40, '_timesteps_total': None, '_time_total': 20344.65621137619, '_episodes_total': 1464}\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m [ERROR] [1614025502.539521, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m [WARN] [1614025502.542282, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m [WARN] [1614025502.543086, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 21:25:07,901\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 21:25:08,104\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_80/checkpoint-80\n",
      "2021-02-22 21:25:08,105\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 80, '_timesteps_total': None, '_time_total': 40383.41257071495, '_episodes_total': 2641}\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m [ERROR] [1614025773.367385, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m [WARN] [1614025773.370567, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m [WARN] [1614025773.371473, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 21:29:38,749\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 21:29:38,921\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_120/checkpoint-120\n",
      "2021-02-22 21:29:38,921\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 120, '_timesteps_total': None, '_time_total': 60434.630679130554, '_episodes_total': 3790}\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m WARNING:tensorflow:From /home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m Instructions for updating:\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m non-resource variables are not supported in the long term\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m [ERROR] [1614026132.110820, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m [WARN] [1614026132.113748, 0.000000]: Start Init ControllersConnection\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m [WARN] [1614026132.114500, 0.000000]: END Init ControllersConnection\n",
      "2021-02-22 21:35:37,712\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n",
      "2021-02-22 21:35:37,881\tINFO trainable.py:328 -- Restored on 192.168.178.60 from checkpoint: /home/dschori/ray_results/PPO_2021-02-17_15-27-03/PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/checkpoint_164/checkpoint-164\n",
      "2021-02-22 21:35:37,882\tINFO trainable.py:336 -- Current state after restoring: {'_iteration': 164, '_timesteps_total': None, '_time_total': 82471.74639606476, '_episodes_total': 5007}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(pid=196301)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=196300)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=196306)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=196304)\u001B[0m None\n",
      "\u001B[2m\u001B[36m(pid=196308)\u001B[0m None\n"
     ]
    }
   ],
   "source": [
    "trajectories = {}\n",
    "success_rate = {}\n",
    "runs = 15\n",
    "checkpoints = [1, 40, 80, 120, 164]\n",
    "for checkpoint in checkpoints:\n",
    "    checkpoint_nr = checkpoint\n",
    "    checkpoint_path = '/home/dschori/ray_results/PPO_2021-02-17_15-27-03/' \\\n",
    "                  'PPO_ScoutingDiscreteTask_34787_00000_0_2021-02-17_15-27-03/' \\\n",
    "                  'checkpoint_{}/checkpoint-{}'.format(checkpoint_nr, checkpoint_nr)\n",
    "    agent = load(checkpoint_path=checkpoint_path, config=config)\n",
    "    trajectories['checkpoint_traj_{}'.format(checkpoint)] = {}\n",
    "    success_rate['checkpoint_success_{}'.format(checkpoint)] = {}\n",
    "    for i in range(runs):\n",
    "        episode_reward, positions = test_traj(agent=agent, env=env)\n",
    "        trajectories['checkpoint_traj_{}'.format(checkpoint)]['run{}'.format(i)] = positions\n",
    "        if episode_reward > 0:\n",
    "           success_rate['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = True\n",
    "        else:\n",
    "           success_rate['checkpoint_success_{}'.format(checkpoint)]['run{}'.format(i)] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 30, Success Rate:       0.00%\n",
      "Episode: 1206, Success Rate:      20.00%\n",
      "Episode: 2413, Success Rate:      53.33%\n",
      "Episode: 3619, Success Rate:      60.00%\n",
      "Episode: 4947, Success Rate:      80.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "img = plt.imread(\"background_env3.png\")\n",
    "ax.imshow(img, extent=[-6.1, 8.6, -7.3, 3.3])\n",
    "\n",
    "ax.set_xlabel('X- Coordinates (m)', fontsize=16)\n",
    "ax.set_ylabel('Y- Coordinates (m)', fontsize=16)\n",
    "\n",
    "ax.set_xlim([-6.1, 8.6])\n",
    "ax.set_ylim([-7.3, 3.3])\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(120)\n",
    "\n",
    "thickness = 1.0\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(trajectories.items()):\n",
    "    line = None\n",
    "    for run_key, run_value in checkpoint_value.items():\n",
    "        x_s = [e[0] for e in run_value]\n",
    "        y_s = [e[1] for e in run_value]\n",
    "        starting_point = (x_s[0], y_s[0])\n",
    "        ending_point = (x_s[-1], y_s[-1])\n",
    "        ax.plot(*starting_point, marker='o', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        ax.plot(*ending_point, marker='D', markersize=12, c=cmap(i * 10), alpha=0.2)\n",
    "        line, = ax.plot(x_s, y_s, linestyle='dashed', linewidth=thickness, c=cmap(i * 10))\n",
    "    line.set_label('Episodes played: {}'.format(int(checkpoints[i]*30.5305)))\n",
    "    thickness += 0.3\n",
    "\n",
    "for i, (checkpoint_key, checkpoint_value) in enumerate(success_rate.items()):\n",
    "    results = 0.0\n",
    "    for _, success in checkpoint_value.items():\n",
    "        results += int(success)\n",
    "    print('Episode: {}, Success Rate: {:10.2f}%'.format(int(checkpoints[i]*30.1658), (results/15.)*100.))\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('training_traj.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = env.observation_space.sample()\n",
    "action = agent.compute_action(o)\n",
    "action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 84, 84, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_1 (Conv2D)           (None, 42, 42, 16)   592         observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 42, 42, 16)   592         observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_2 (Conv2D)           (None, 21, 21, 32)   4640        conv_value_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 21, 21, 32)   4640        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_3 (Conv2D)           (None, 11, 11, 64)   18496       conv_value_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 11, 11, 64)   18496       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_4 (Conv2D)           (None, 1, 1, 128)    991360      conv_value_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 1, 1, 128)    991360      conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_value_out (Conv2D)         (None, 1, 1, 1)      129         conv_value_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_out (Conv2D)               (None, 1, 1, 3)      387         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           conv_value_out[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,030,692\n",
      "Trainable params: 2,030,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "policy = agent.get_policy()\n",
    "model = policy.model.base_model\n",
    "obs = env.reset()\n",
    "for i in range(4):\n",
    "    obs, _, _, _ = env.step(1)\n",
    "preprocessed = agent.workers.local_worker().preprocessors[\n",
    "            \"default_policy\"].transform(obs)\n",
    "filtered_obs = agent.workers.local_worker().filters[\"default_policy\"](\n",
    "    preprocessed, update=False)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['default_policy/conv_value_1/kernel', 'default_policy/conv_value_1/bias', 'default_policy/conv1/kernel', 'default_policy/conv1/bias', 'default_policy/conv_value_2/kernel', 'default_policy/conv_value_2/bias', 'default_policy/conv2/kernel', 'default_policy/conv2/bias', 'default_policy/conv_value_3/kernel', 'default_policy/conv_value_3/bias', 'default_policy/conv3/kernel', 'default_policy/conv3/bias', 'default_policy/conv_value_4/kernel', 'default_policy/conv_value_4/bias', 'default_policy/conv4/kernel', 'default_policy/conv4/bias', 'default_policy/conv_value_out/kernel', 'default_policy/conv_value_out/bias', 'default_policy/conv_out/kernel', 'default_policy/conv_out/bias'])\n"
     ]
    }
   ],
   "source": [
    "weights = policy.get_weights()\n",
    "print(weights.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f0d2060bd30>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(weights['default_policy/conv1/kernel'][:, :, 0:3, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 42, 42, 16)        592       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 1, 1, 128)         991360    \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 1, 1, 3)           387       \n",
      "=================================================================\n",
      "Total params: 1,015,475\n",
      "Trainable params: 1,015,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(84, 84, 4,))\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding='same', name='conv1')(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', name='conv2')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', name='conv3')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(128, (11, 11), strides=(1, 1), padding='valid', name='conv4')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(3, (1, 1), strides=(1, 1), padding='valid', name='conv_out')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.layers[1].set_weights([weights['default_policy/conv1/kernel'], weights['default_policy/conv1/bias']])\n",
    "model.layers[3].set_weights([weights['default_policy/conv2/kernel'], weights['default_policy/conv2/bias']])\n",
    "model.layers[5].set_weights([weights['default_policy/conv3/kernel'], weights['default_policy/conv3/bias']])\n",
    "model.layers[7].set_weights([weights['default_policy/conv4/kernel'], weights['default_policy/conv4/bias']])\n",
    "model.layers[9].set_weights([weights['default_policy/conv_out/kernel'], weights['default_policy/conv_out/bias']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 21, 21, 16)        4112      \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 21, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 11, 11, 32)        8224      \n",
      "_________________________________________________________________\n",
      "re_lu_67 (ReLU)              (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 1, 256)         991488    \n",
      "_________________________________________________________________\n",
      "re_lu_68 (ReLU)              (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 1, 1, 3)           771       \n",
      "=================================================================\n",
      "Total params: 1,004,595\n",
      "Trainable params: 1,004,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(84, 84, 4,))\n",
    "x = tf.keras.layers.Conv2D(16, (8, 8), strides=(4, 4), padding='same', name='conv1')(inputs)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same', name='conv2')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(256, (11, 11), strides=(1, 1), padding='valid', name='conv3')(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Conv2D(3, (1, 1), strides=(1, 1), padding='valid', name='conv_out')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.layers[1].set_weights([weights['default_policy/conv1/kernel'], weights['default_policy/conv1/bias']])\n",
    "model.layers[3].set_weights([weights['default_policy/conv2/kernel'], weights['default_policy/conv2/bias']])\n",
    "model.layers[5].set_weights([weights['default_policy/conv3/kernel'], weights['default_policy/conv3/bias']])\n",
    "model.layers[7].set_weights([weights['default_policy/conv_out/kernel'], weights['default_policy/conv_out/bias']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_policy/conv_value_1/kernel\n",
      "(8, 8, 4, 16)\n",
      "----------\n",
      "default_policy/conv_value_1/bias\n",
      "(16,)\n",
      "----------\n",
      "default_policy/conv1/kernel\n",
      "(8, 8, 4, 16)\n",
      "----------\n",
      "default_policy/conv1/bias\n",
      "(16,)\n",
      "----------\n",
      "default_policy/conv_value_2/kernel\n",
      "(4, 4, 16, 32)\n",
      "----------\n",
      "default_policy/conv_value_2/bias\n",
      "(32,)\n",
      "----------\n",
      "default_policy/conv2/kernel\n",
      "(4, 4, 16, 32)\n",
      "----------\n",
      "default_policy/conv2/bias\n",
      "(32,)\n",
      "----------\n",
      "default_policy/conv_value_3/kernel\n",
      "(11, 11, 32, 256)\n",
      "----------\n",
      "default_policy/conv_value_3/bias\n",
      "(256,)\n",
      "----------\n",
      "default_policy/conv3/kernel\n",
      "(11, 11, 32, 256)\n",
      "----------\n",
      "default_policy/conv3/bias\n",
      "(256,)\n",
      "----------\n",
      "default_policy/conv_value_out/kernel\n",
      "(1, 1, 256, 1)\n",
      "----------\n",
      "default_policy/conv_value_out/bias\n",
      "(1,)\n",
      "----------\n",
      "default_policy/conv_out/kernel\n",
      "(1, 1, 256, 3)\n",
      "----------\n",
      "default_policy/conv_out/bias\n",
      "(3,)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for key, value in weights.items():\n",
    "    print(key)\n",
    "    print(value.shape)\n",
    "    print(\"----------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f180d2a4520>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d2a4250>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d292220>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d292460>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d2929d0>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d27cd30>,\n <tensorflow.python.keras.layers.advanced_activations.ReLU at 0x7f180d200d90>,\n <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f180d207af0>]"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dschori/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1, 11, 11, 64)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = agent.workers.local_worker().preprocessors[\"default_policy\"].transform(obs)\n",
    "filtered_obs = agent.workers.local_worker().filters[\"default_policy\"](preprocessed, update=False)\n",
    "\n",
    "conv_1 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[2].output)\n",
    "conv_2 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[4].output)\n",
    "conv_3 = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[6].output)\n",
    "pred_1 = conv_1.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_2 = conv_2.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_3 = conv_3.predict(filtered_obs.reshape(1, 84, 84, 4))\n",
    "pred_3.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.colorbar.Colorbar at 0x7f0921bf5550>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(obs[:, :, 0])\n",
    "#np.save('obs_learning.npy', obs)\n",
    "plt.imshow(pred_3[0, :, :, 11])\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x648 with 12 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "obs = np.load('obs_learning.npy')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(12, 9))\n",
    "\n",
    "cols = ['{}'.format(col) for col in ['Input State', 'Layer response', 'Layer response', 'Layer response']]\n",
    "rows = ['ConvLayer {}'.format(row) for row in range(1, 4)]\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i, 0].imshow(obs[:, :, 0], vmin=0., vmax=1., cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([0, 7, 15]):\n",
    "    axes[0, 1+i].imshow(pred_1[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([1, 6, 12]):\n",
    "    axes[1, 1+i].imshow(pred_2[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for i, kernel in enumerate([7, 11, 12]):\n",
    "    axes[2, 1+i].imshow(pred_3[0, :, :, kernel], cmap='jet')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "for ax, row in zip(axes[:,0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, size='large')\n",
    "\n",
    "plt.setp(axes[-1, 1:], xlabel='Layer response')\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    axes[-1, i].set_xlabel(col, size=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('layer_respones.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f18206d4e50>"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_2[0, :, :, 22], cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f1c6a40f490>"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1440 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape = 21\n",
    "height = 4\n",
    "width = 4\n",
    "activations = np.zeros((shape*height, shape*width))\n",
    "k = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        activations[shape*i:shape*(i+1), shape*j:shape*(j+1)] = pred_1[0, :, :, k]\n",
    "        k += 1\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(activations, cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f1b844c8970>"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1440 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape = 11\n",
    "height = 4\n",
    "width = 8\n",
    "activations = np.zeros((shape*height, shape*width))\n",
    "k = 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        activations[shape*i:shape*(i+1), shape*j:shape*(j+1)] = pred_2[0, :, :, k]\n",
    "        k += 1\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(activations, cmap='jet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "tmp = np.zeros((21, 21))\n",
    "for i in range(16):\n",
    "    tmp += pred_1[0, :, :, i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f180d12a9a0>"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-49841455",
   "language": "python",
   "display_name": "PyCharm (MasterThesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}