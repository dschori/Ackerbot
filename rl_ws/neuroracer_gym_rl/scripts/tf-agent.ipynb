{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import rospy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from gym.envs.registration import register\n",
    "from neuroracer_gym import neuroracer_env\n",
    "from tf_agents.environments import tf_py_environment, utils\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "from tf_agents.replay_buffers.tf_uniform_replay_buffer import TFUniformReplayBuffer\n",
    "\n",
    "# just to register env:\n",
    "from neuroracer_gym.tasks.neuroracer_discrete_task import NeuroRacerTfAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1609522860.754155, 0.000000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1609522860.757541, 0.000000]: Start Init ControllersConnection\n",
      "[WARN] [1609522860.758352, 0.000000]: END Init ControllersConnection\n",
      "[ERROR] [1609522863.128410, 2.068000]: NOT Initialising Simulation Physics Parameters\n",
      "[WARN] [1609522863.133154, 2.068000]: Start Init ControllersConnection\n",
      "[WARN] [1609522863.134753, 2.068000]: END Init ControllersConnection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec: BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=2)\n",
      "time_step_spec.observation: BoundedArraySpec(shape=(40,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=10.0)\n",
      "time_step_spec.step_type: ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')\n",
      "time_step_spec.discount: BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)\n",
      "time_step_spec.reward: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "rospy.init_node('neuroracer_qlearn', anonymous=True, log_level=rospy.INFO)\n",
    "\n",
    "env = NeuroRacerTfAgents()\n",
    "env_eval = NeuroRacerTfAgents(val=True)\n",
    "\n",
    "print('action_spec:', env.action_spec())\n",
    "print('time_step_spec.observation:', env.time_step_spec().observation)\n",
    "print('time_step_spec.step_type:', env.time_step_spec().step_type)\n",
    "print('time_step_spec.discount:', env.time_step_spec().discount)\n",
    "print('time_step_spec.reward:', env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulated Reward: -8.619360290831485\n",
      "Cumulated Reward: -41.37939231710127\n",
      "Cumulated Reward: -166.32034977677299\n"
     ]
    }
   ],
   "source": [
    "utils.validate_py_environment(env, episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5693615e-06\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "\n",
    "for _ in range(1):\n",
    "    time_step = env.step(np.array(2, dtype=np.int32))\n",
    "    print(time_step.reward)\n",
    "\n",
    "cumulative_reward = time_step.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedArraySpec(shape=(40,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=10.0)\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=2)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_spec())\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = tf_py_environment.TFPyEnvironment(env)\n",
    "env_eval = tf_py_environment.TFPyEnvironment(env_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, )\n",
    "dropout_layer_params = (0.15, )\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    env.observation_spec(),\n",
    "    env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params,\n",
    "    dropout_layer_params=dropout_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=BoundedTensorSpec(shape=(40,), dtype=tf.float32, name='observation', minimum=array(0., dtype=float32), maximum=array(10., dtype=float32)), action=BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)), policy_info=(), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-2)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    n_step_update=30,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    gradient_clipping=1.0,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "print(env.batch_size)\n",
    "print(agent.collect_data_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    # observation = tf.ones((1080))\n",
    "    # observation = tf.reshape(time_step.observation, [1080])\n",
    "    # time_step = ts.restart(observation)\n",
    "    # time_step = ts.restart(time_step.observation, 1)\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    buffer.add_batch(traj)\n",
    "\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "\n",
    "\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(env.time_step_spec(),\n",
    "                                                env.action_spec())\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=env.batch_size,\n",
    "    max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "\n",
    "class ExperienceReply(object):\n",
    "    def __init__(self, agent, environment):\n",
    "        self._replay_buffer = TFUniformReplayBuffer(\n",
    "            data_spec=agent.collect_data_spec,\n",
    "            batch_size=environment.batch_size,\n",
    "            max_length=50000)\n",
    "\n",
    "        self._random_policy = RandomTFPolicy(environment.time_step_spec(),\n",
    "                                             environment.action_spec())\n",
    "\n",
    "        self._fill_buffer(environment, self._random_policy, steps=100)\n",
    "\n",
    "        self.dataset = self._replay_buffer.as_dataset(\n",
    "            num_parallel_calls=3,\n",
    "            sample_batch_size=64,\n",
    "            num_steps=31).prefetch(3)\n",
    "\n",
    "        self.iterator = iter(self.dataset)\n",
    "\n",
    "    def _fill_buffer(self, environment, policy, steps):\n",
    "        for _ in range(steps):\n",
    "            self.timestamp_data(environment, policy)\n",
    "\n",
    "    def timestamp_data(self, environment, policy):\n",
    "        time_step = environment.current_time_step()\n",
    "        action_step = policy.action(time_step)\n",
    "        next_time_step = environment.step(action_step.action)\n",
    "        timestamp_trajectory = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "        self._replay_buffer.add_batch(timestamp_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulated Reward: -113.97793926422347\n",
      "Cumulated Reward: -20.20867547714823\n",
      "Cumulated Reward: -4.696041654733431\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tf_agents/utils/value_ops.py:85: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "Cumulated Reward: -13.919138909631714\n",
      "Cumulated Reward: -10.570791023005299\n",
      "Cumulated Reward: -8.915540933993329\n",
      "Cumulated Reward: -0.38949824659244975\n",
      "Cumulated Reward: -3.689574661051416\n",
      "Cumulated Reward: -4.7477624953573585\n",
      "step = 200: loss = 5.7023444175720215\n",
      "Cumulated Reward: -91.2949998426567\n",
      "step = 400: loss = 1226.163330078125\n",
      "Cumulated Reward: -121.90869423622739\n",
      "Cumulated Reward: -5.32303619787808\n",
      "step = 600: loss = 1267.283203125\n",
      "step = 800: loss = 229858.0\n",
      "step = 1000: loss = 746143.5\n",
      "step = 1200: loss = 1332216.75\n",
      "step = 1400: loss = 2512352.75\n",
      "Cumulated Reward: -10921.505038298292\n",
      "step = 1600: loss = 11999448.0\n",
      "Cumulated Reward: -367.5160785573013\n",
      "Cumulated Reward: -3.5367715231132184\n",
      "Cumulated Reward: -6.359566246910788\n",
      "Cumulated Reward: -16.444080585626725\n",
      "step = 1800: loss = 4521867.0\n",
      "Cumulated Reward: -367.16648037510447\n",
      "Cumulated Reward: -0.3344905629358384\n",
      "step = 2000: loss = 5670528.5\n",
      "Cumulated Reward: -154.3252704262744\n",
      "step = 2200: loss = 2528038.0\n",
      "Cumulated Reward: -519.2876858309407\n",
      "Cumulated Reward: -5.710914918449537\n",
      "step = 2400: loss = 2270708.5\n",
      "Cumulated Reward: -147.57410296555662\n",
      "Cumulated Reward: -2.820214404138671\n",
      "step = 2600: loss = 1471826.25\n",
      "Cumulated Reward: -119.96999532635505\n",
      "Cumulated Reward: -130.49765244899157\n",
      "step = 2800: loss = 1105240.125\n",
      "Cumulated Reward: -111.80126783168765\n",
      "step = 3000: loss = 1890907.375\n",
      "Cumulated Reward: -418.8211078342451\n",
      "Cumulated Reward: -0.5913197826281631\n",
      "step = 3200: loss = 483546.4375\n",
      "step = 3400: loss = 585593.25\n",
      "Cumulated Reward: -710.4398443596233\n",
      "Cumulated Reward: -157.96700824982153\n",
      "step = 3600: loss = 557959.5\n",
      "Cumulated Reward: -188.07785364154864\n",
      "step = 3800: loss = 1115364.625\n",
      "step = 4000: loss = 353975.5625\n",
      "Cumulated Reward: -657.6235349105059\n",
      "Cumulated Reward: -14.139525610942668\n",
      "Cumulated Reward: -23.458165573463997\n",
      "step = 4200: loss = 596834.4375\n",
      "step = 4400: loss = 669672.1875\n",
      "Cumulated Reward: -820.1368659744246\n",
      "Cumulated Reward: -6.192575796734368\n",
      "step = 4600: loss = 539037.875\n",
      "Cumulated Reward: -465.7956554499946\n",
      "Cumulated Reward: -5.1296133016230305\n",
      "step = 4800: loss = 221035.0\n",
      "step = 5000: loss = 137104.65625\n",
      "Cumulated Reward: -1065.9449764380017\n",
      "Cumulated Reward: -367.6900465732421\n",
      "Cumulated Reward: -4998.58937965096\n",
      "Cumulated Reward: -71.02833006116127\n",
      "step = 5000: Average Return = 5.159610271453857\n",
      "Cumulated Reward: -654.7455070075254\n",
      "Cumulated Reward: -220.01509564128025\n",
      "step = 5200: loss = 405252.90625\n",
      "step = 5400: loss = 341912.03125\n",
      "step = 5600: loss = 320743.5\n",
      "Cumulated Reward: -1434.0319322428725\n",
      "step = 5800: loss = 189189.71875\n",
      "Cumulated Reward: -20.35296973058158\n",
      "step = 6000: loss = 142463.28125\n",
      "Cumulated Reward: -573.4584642563007\n",
      "Cumulated Reward: -5.089220300882001\n",
      "step = 6200: loss = 227519.171875\n",
      "Cumulated Reward: -152.47081544777674\n",
      "step = 6400: loss = 254329.109375\n",
      "Cumulated Reward: -112.4381105353834\n",
      "Cumulated Reward: -4.538989295806015\n",
      "step = 6600: loss = 256633.265625\n",
      "step = 6800: loss = 131970.125\n",
      "step = 7000: loss = 180786.125\n",
      "step = 7200: loss = 128534.421875\n",
      "step = 7400: loss = 174975.0625\n",
      "step = 7600: loss = 402766.75\n",
      "step = 7800: loss = 349416.21875\n",
      "step = 8000: loss = 416354.1875\n",
      "step = 8200: loss = 474966.125\n",
      "Cumulated Reward: -14423.765140251156\n",
      "Cumulated Reward: -69.33010811961094\n",
      "Cumulated Reward: -16.18971518808096\n",
      "step = 8400: loss = 473459.1875\n",
      "step = 8600: loss = 359801.1875\n",
      "step = 8800: loss = 4326228.0\n",
      "Cumulated Reward: -2198.5008057090454\n",
      "Cumulated Reward: -140.38841795458185\n",
      "step = 9000: loss = 424510.3125\n",
      "Cumulated Reward: -135.09447912503686\n",
      "step = 9200: loss = 992959.8125\n",
      "step = 9400: loss = 450461.59375\n",
      "step = 9600: loss = 716767.8125\n",
      "step = 9800: loss = 462788.25\n",
      "step = 10000: loss = 1489412.5\n",
      "Cumulated Reward: -271.7842791679337\n",
      "Cumulated Reward: -13.619829370414266\n",
      "Cumulated Reward: -208.65963502751958\n",
      "Cumulated Reward: -174.12141042239122\n",
      "step = 10000: Average Return = 1.974623680114746\n",
      "Cumulated Reward: -8483.95039814933\n",
      "Cumulated Reward: -18.119149375163822\n",
      "step = 10200: loss = 562845.625\n",
      "Cumulated Reward: -207.30772359089804\n",
      "step = 10400: loss = 4575986.0\n",
      "step = 10600: loss = 639645.0\n",
      "step = 10800: loss = 2381431.75\n",
      "step = 11000: loss = 547517.625\n",
      "step = 11200: loss = 2607220.5\n",
      "step = 11400: loss = 805451.9375\n",
      "step = 11600: loss = 863081.375\n",
      "step = 11800: loss = 3861228.5\n",
      "step = 12000: loss = 1990497.875\n",
      "step = 12200: loss = 1747150.625\n",
      "Cumulated Reward: -52217.192047300254\n",
      "step = 12400: loss = 1983715.75\n",
      "step = 12600: loss = 48591624.0\n",
      "step = 12800: loss = 5361498.5\n",
      "step = 13000: loss = 40559772.0\n",
      "step = 13200: loss = 2164159.5\n",
      "step = 13400: loss = 3458774.0\n",
      "step = 13600: loss = 3412766.75\n",
      "step = 13800: loss = 3265715.5\n",
      "step = 14000: loss = 6551401.0\n",
      "step = 14200: loss = 47978424.0\n",
      "step = 14400: loss = 4132722.25\n",
      "step = 14600: loss = 14872708.0\n",
      "Cumulated Reward: -64213.098961535405\n",
      "Cumulated Reward: -67.77479452095216\n",
      "step = 14800: loss = 45373516.0\n",
      "step = 15000: loss = 6058738.0\n",
      "Cumulated Reward: -7.705793573146196\n",
      "Cumulated Reward: -78.83295810564009\n",
      "Cumulated Reward: -549.8591379527362\n",
      "Cumulated Reward: -91.22071543667177\n",
      "step = 15000: Average Return = 2.0562283992767334\n",
      "Cumulated Reward: -254.05091055724134\n",
      "step = 15200: loss = 17672918.0\n",
      "Cumulated Reward: -542.8234678884245\n",
      "Cumulated Reward: -3.775784142199306\n",
      "step = 15400: loss = 12061492.0\n",
      "step = 15600: loss = 12236297.0\n",
      "step = 15800: loss = 7555394.0\n",
      "step = 16000: loss = 9531736.0\n",
      "step = 16200: loss = 7240134.0\n",
      "step = 16400: loss = 10748002.0\n",
      "step = 16600: loss = 5345878.0\n",
      "step = 16800: loss = 4773408.5\n",
      "step = 17000: loss = 44585812.0\n",
      "Cumulated Reward: -37732.036601120926\n",
      "step = 17200: loss = 10702854.0\n",
      "step = 17400: loss = 59207940.0\n",
      "step = 17600: loss = 5819384.0\n",
      "step = 17800: loss = 73040912.0\n",
      "step = 18000: loss = 5932632.5\n",
      "step = 18200: loss = 43931996.0\n",
      "step = 18400: loss = 18583486.0\n",
      "step = 18600: loss = 8371229.0\n",
      "step = 18800: loss = 6365775.0\n",
      "step = 19000: loss = 9786392.0\n",
      "step = 19200: loss = 7062604.5\n",
      "Cumulated Reward: -62587.9903831976\n",
      "step = 19400: loss = 6703673.0\n",
      "Cumulated Reward: -197.2089194581792\n",
      "step = 19600: loss = 13433356.0\n",
      "step = 19800: loss = 8005639.0\n",
      "step = 20000: loss = 13682150.0\n",
      "Cumulated Reward: -60.69049109050574\n",
      "Cumulated Reward: -546.3615843349721\n",
      "Cumulated Reward: -99.75035190185375\n",
      "Cumulated Reward: -72.90919395592692\n",
      "step = 20000: Average Return = 2.2624034881591797\n",
      "Cumulated Reward: -2124.7766918968414\n",
      "step = 20200: loss = 13920456.0\n",
      "step = 20400: loss = 102561776.0\n",
      "step = 20600: loss = 7703118.0\n",
      "step = 20800: loss = 102315752.0\n",
      "step = 21000: loss = 46509016.0\n",
      "step = 21200: loss = 12765591.0\n",
      "step = 21400: loss = 7428014.5\n",
      "step = 21600: loss = 14727428.0\n",
      "step = 21800: loss = 46906336.0\n",
      "Cumulated Reward: -37752.772691689424\n",
      "Cumulated Reward: -3.592951208935749\n",
      "Cumulated Reward: -52.25451455441815\n",
      "step = 22000: loss = 8336969.5\n",
      "step = 22200: loss = 13499170.0\n",
      "step = 22400: loss = 12258344.0\n",
      "step = 22600: loss = 7617900.5\n",
      "Cumulated Reward: -5818.8933103242625\n",
      "step = 22800: loss = 14253008.0\n",
      "step = 23000: loss = 10240807.0\n",
      "step = 23200: loss = 11075272.0\n",
      "step = 23400: loss = 8668064.0\n",
      "step = 23600: loss = 11837972.0\n",
      "Cumulated Reward: -10506.439413230286\n",
      "step = 23800: loss = 11822026.0\n",
      "step = 24000: loss = 43612064.0\n",
      "step = 24200: loss = 13209433.0\n",
      "step = 24400: loss = 15550328.0\n",
      "step = 24600: loss = 16681195.0\n",
      "step = 24800: loss = 30704790.0\n",
      "step = 25000: loss = 22480476.0\n",
      "Cumulated Reward: -16083.474330674104\n",
      "Cumulated Reward: -71.75862844458756\n",
      "Cumulated Reward: -190.49055967855494\n",
      "Cumulated Reward: -134.4576553442777\n",
      "step = 25000: Average Return = 8.645774841308594\n",
      "Cumulated Reward: -16869.455154405445\n",
      "step = 25200: loss = 24836312.0\n",
      "step = 25400: loss = 10331454.0\n",
      "step = 25600: loss = 49011536.0\n",
      "step = 25800: loss = 16005926.0\n",
      "Cumulated Reward: -9631.186478486845\n",
      "step = 26000: loss = 14267815.0\n",
      "step = 26200: loss = 55019180.0\n",
      "step = 26400: loss = 14448606.0\n",
      "step = 26600: loss = 142089344.0\n",
      "step = 26800: loss = 27540104.0\n",
      "step = 27000: loss = 13735716.0\n",
      "step = 27200: loss = 32166578.0\n",
      "step = 27400: loss = 11365944.0\n",
      "step = 27600: loss = 65306272.0\n",
      "step = 27800: loss = 11765650.0\n",
      "Cumulated Reward: -48726.74014803951\n",
      "step = 28000: loss = 16287580.0\n",
      "step = 28200: loss = 44801632.0\n",
      "step = 28400: loss = 14199955.0\n",
      "step = 28600: loss = 7062882.0\n",
      "step = 28800: loss = 23141994.0\n",
      "Cumulated Reward: -10786.113409802629\n",
      "step = 29000: loss = 9851386.0\n",
      "Cumulated Reward: -122.65656354922116\n",
      "step = 29200: loss = 16197677.0\n",
      "step = 29400: loss = 99839064.0\n",
      "step = 29600: loss = 68492560.0\n",
      "step = 29800: loss = 62423240.0\n",
      "step = 30000: loss = 14179829.0\n",
      "Cumulated Reward: -516.3111436101445\n",
      "Cumulated Reward: -200.98741347319725\n",
      "Cumulated Reward: -40.41203484979454\n",
      "Cumulated Reward: -48213.47568342149\n",
      "step = 30000: Average Return = 14.957709312438965\n",
      "Cumulated Reward: -10172.025604346036\n",
      "step = 30200: loss = 61524192.0\n",
      "step = 30400: loss = 68388248.0\n",
      "step = 30600: loss = 75298224.0\n",
      "step = 30800: loss = 66736484.0\n",
      "step = 31000: loss = 11432701.0\n",
      "step = 31200: loss = 9935658.0\n",
      "step = 31400: loss = 36829856.0\n",
      "step = 31600: loss = 71404112.0\n",
      "step = 31800: loss = 7006262.5\n",
      "step = 32000: loss = 60042424.0\n",
      "step = 32200: loss = 18374630.0\n",
      "Cumulated Reward: -66652.32667574834\n",
      "step = 32400: loss = 13862667.0\n",
      "step = 32600: loss = 11108281.0\n",
      "step = 32800: loss = 23004438.0\n",
      "step = 33000: loss = 8870959.0\n",
      "step = 33200: loss = 31950570.0\n",
      "step = 33400: loss = 22346138.0\n",
      "step = 33600: loss = 62394888.0\n",
      "step = 33800: loss = 11583766.0\n",
      "step = 34000: loss = 120686208.0\n",
      "step = 34200: loss = 14648795.0\n",
      "step = 34400: loss = 12123818.0\n",
      "step = 34600: loss = 24841150.0\n",
      "step = 34800: loss = 10808284.0\n",
      "step = 35000: loss = 9158114.0\n",
      "Cumulated Reward: -75.12990022375755\n",
      "Cumulated Reward: -446.48336471915724\n",
      "Cumulated Reward: -4.254315262972372\n",
      "Cumulated Reward: -143.31140760600772\n",
      "step = 35000: Average Return = 1.9641997814178467\n",
      "Cumulated Reward: -81829.27030795743\n",
      "Cumulated Reward: -3.9642600567395174\n",
      "step = 35200: loss = 52227708.0\n",
      "step = 35400: loss = 15882276.0\n",
      "step = 35600: loss = 29870016.0\n",
      "step = 35800: loss = 12850867.0\n",
      "step = 36000: loss = 16553672.0\n",
      "step = 36200: loss = 9223033.0\n",
      "step = 36400: loss = 93341512.0\n",
      "step = 36600: loss = 21111352.0\n",
      "step = 36800: loss = 12672160.0\n",
      "step = 37000: loss = 13233466.0\n",
      "step = 37200: loss = 59365576.0\n",
      "Cumulated Reward: -60118.90786727857\n",
      "step = 37400: loss = 11903474.0\n",
      "step = 37600: loss = 19380164.0\n",
      "step = 37800: loss = 77583976.0\n",
      "step = 38000: loss = 37941080.0\n",
      "Cumulated Reward: -8113.410342578957\n",
      "step = 38200: loss = 22223056.0\n",
      "step = 38400: loss = 89213736.0\n",
      "Cumulated Reward: -532.3681702142939\n",
      "step = 38600: loss = 23822122.0\n",
      "step = 38800: loss = 14991453.0\n",
      "step = 39000: loss = 13233002.0\n",
      "step = 39200: loss = 61729152.0\n",
      "step = 39400: loss = 88492832.0\n",
      "step = 39600: loss = 37121312.0\n",
      "step = 39800: loss = 29049140.0\n",
      "step = 40000: loss = 14725058.0\n",
      "Cumulated Reward: -3.172038785314981\n",
      "Cumulated Reward: -132.32700735874042\n",
      "Cumulated Reward: -11719.53433723629\n",
      "Cumulated Reward: -49331.94024593904\n",
      "step = 40000: Average Return = 19.585906982421875\n",
      "Cumulated Reward: -26503.043133599214\n",
      "step = 40200: loss = 132376104.0\n",
      "step = 40400: loss = 18146786.0\n",
      "step = 40600: loss = 211334400.0\n",
      "step = 40800: loss = 13828457.0\n",
      "step = 41000: loss = 15789059.0\n",
      "step = 41200: loss = 17362444.0\n",
      "step = 41400: loss = 38626904.0\n",
      "step = 41600: loss = 72347720.0\n",
      "step = 41800: loss = 49260600.0\n",
      "step = 42000: loss = 21252600.0\n",
      "step = 42200: loss = 26248340.0\n",
      "step = 42400: loss = 39840120.0\n",
      "Cumulated Reward: -63057.00531837969\n",
      "Cumulated Reward: -101.41414876193139\n",
      "Cumulated Reward: -72.25268874110442\n",
      "step = 42600: loss = 52781024.0\n",
      "step = 42800: loss = 15388808.0\n",
      "step = 43000: loss = 101264192.0\n",
      "step = 43200: loss = 61850432.0\n",
      "step = 43400: loss = 15327212.0\n",
      "step = 43600: loss = 18621470.0\n",
      "Cumulated Reward: -10528.616039930695\n",
      "Cumulated Reward: -6.863806375042222\n",
      "Cumulated Reward: -85.89355516870727\n",
      "step = 43800: loss = 16740423.0\n",
      "step = 44000: loss = 23123076.0\n",
      "step = 44200: loss = 16398492.0\n",
      "step = 44400: loss = 88713280.0\n",
      "step = 44600: loss = 49299936.0\n",
      "Cumulated Reward: -10107.234223500956\n",
      "step = 44800: loss = 31486354.0\n",
      "Cumulated Reward: -160.27744090548995\n",
      "Cumulated Reward: -107.79824292825879\n",
      "step = 45000: loss = 11480956.0\n",
      "Cumulated Reward: -503.4490712954296\n",
      "Cumulated Reward: -44717.35976589697\n",
      "Cumulated Reward: -76.76135584755876\n",
      "Cumulated Reward: -11148.689412036045\n",
      "step = 45000: Average Return = 18.255800247192383\n",
      "Cumulated Reward: -25.239879722415214\n",
      "step = 45200: loss = 13333031.0\n",
      "step = 45400: loss = 18122956.0\n",
      "step = 45600: loss = 16606248.0\n",
      "Cumulated Reward: -4852.71496571739\n",
      "Cumulated Reward: -69.84327651235196\n",
      "step = 45800: loss = 36045288.0\n",
      "Cumulated Reward: -138.38475987782815\n",
      "step = 46000: loss = 21387248.0\n",
      "step = 46200: loss = 10966932.0\n",
      "step = 46400: loss = 8754649.0\n",
      "step = 46600: loss = 22472362.0\n",
      "step = 46800: loss = 22993956.0\n",
      "Cumulated Reward: -11079.402226555616\n",
      "step = 47000: loss = 44814152.0\n",
      "step = 47200: loss = 14491459.0\n",
      "step = 47400: loss = 26404464.0\n",
      "step = 47600: loss = 17447240.0\n",
      "step = 47800: loss = 79309344.0\n",
      "step = 48000: loss = 43043616.0\n",
      "Cumulated Reward: -16349.709664316726\n",
      "step = 48200: loss = 15796003.0\n",
      "step = 48400: loss = 17108924.0\n",
      "step = 48600: loss = 168786048.0\n",
      "step = 48800: loss = 11969933.0\n",
      "step = 49000: loss = 36156596.0\n",
      "Cumulated Reward: -9964.230334368942\n",
      "step = 49200: loss = 13534476.0\n",
      "step = 49400: loss = 17280890.0\n",
      "step = 49600: loss = 14463536.0\n",
      "step = 49800: loss = 87016944.0\n",
      "step = 50000: loss = 70397296.0\n",
      "Cumulated Reward: -41.38845050714886\n",
      "Cumulated Reward: -14.73799244397625\n",
      "Cumulated Reward: -468.6292199747191\n",
      "Cumulated Reward: -6792.095844750443\n",
      "step = 50000: Average Return = 5.342940330505371\n",
      "Cumulated Reward: -8161.188737936983\n",
      "Cumulated Reward: -134.26788559752762\n",
      "step = 50200: loss = 67855688.0\n",
      "Cumulated Reward: -75.98998537818673\n",
      "Cumulated Reward: -154.51173974782557\n",
      "Cumulated Reward: -2.949484501642789\n",
      "step = 50400: loss = 18024074.0\n",
      "Cumulated Reward: -95.89641886478452\n",
      "step = 50600: loss = 74012904.0\n",
      "step = 50800: loss = 78218232.0\n",
      "step = 51000: loss = 21258608.0\n",
      "Cumulated Reward: -4251.11009359705\n",
      "step = 51200: loss = 59593288.0\n",
      "Cumulated Reward: -34.989269955851675\n",
      "step = 51400: loss = 47827672.0\n",
      "step = 51600: loss = 76633824.0\n",
      "step = 51800: loss = 322583872.0\n",
      "step = 52000: loss = 15538801.0\n",
      "step = 52200: loss = 32555100.0\n",
      "Cumulated Reward: -9645.74676236141\n",
      "Cumulated Reward: -6.239833123123049\n",
      "Cumulated Reward: -73.53758069448033\n",
      "step = 52400: loss = 60300104.0\n",
      "step = 52600: loss = 17157946.0\n",
      "step = 52800: loss = 11978464.0\n",
      "step = 53000: loss = 14638038.0\n",
      "step = 53200: loss = 10666511.0\n",
      "step = 53400: loss = 58539976.0\n",
      "step = 53600: loss = 15524195.0\n",
      "step = 53800: loss = 9999198.0\n",
      "step = 54000: loss = 8470730.0\n",
      "step = 54200: loss = 24758848.0\n",
      "Cumulated Reward: -46660.16588031479\n",
      "step = 54400: loss = 18144168.0\n",
      "step = 54600: loss = 18377972.0\n",
      "step = 54800: loss = 15214759.0\n",
      "step = 55000: loss = 32609682.0\n",
      "Cumulated Reward: -8029.672864021907\n",
      "Cumulated Reward: -88.38210019479277\n",
      "Cumulated Reward: -108.32238816264244\n",
      "Cumulated Reward: -136.4301610029457\n",
      "step = 55000: Average Return = 6.312054634094238\n",
      "Cumulated Reward: -3607.5806188459\n",
      "Cumulated Reward: -5.945039540891074\n",
      "Cumulated Reward: -77.1532454059032\n",
      "step = 55200: loss = 11062861.0\n",
      "step = 55400: loss = 16126855.0\n",
      "step = 55600: loss = 6973900.0\n",
      "step = 55800: loss = 59491840.0\n",
      "step = 56000: loss = 11121664.0\n",
      "Cumulated Reward: -8982.866506492273\n",
      "step = 56200: loss = 12807486.0\n",
      "step = 56400: loss = 33563708.0\n",
      "step = 56600: loss = 11361631.0\n",
      "step = 56800: loss = 14533169.0\n",
      "step = 57000: loss = 7536843.5\n",
      "step = 57200: loss = 52274980.0\n",
      "step = 57400: loss = 10607986.0\n",
      "step = 57600: loss = 73349840.0\n",
      "step = 57800: loss = 19101472.0\n",
      "Cumulated Reward: -42877.64722834509\n",
      "step = 58000: loss = 31575552.0\n",
      "step = 58200: loss = 195512352.0\n",
      "step = 58400: loss = 11628528.0\n",
      "step = 58600: loss = 9403154.0\n",
      "step = 58800: loss = 18327172.0\n",
      "Cumulated Reward: -9264.16300695032\n",
      "step = 59000: loss = 34925900.0\n",
      "step = 59200: loss = 15909869.0\n",
      "step = 59400: loss = 72714720.0\n",
      "Cumulated Reward: -4706.189866841761\n",
      "step = 59600: loss = 17128324.0\n",
      "step = 59800: loss = 113002784.0\n",
      "step = 60000: loss = 232333696.0\n",
      "Cumulated Reward: -111.11541865572397\n",
      "Cumulated Reward: -134.94850899191547\n",
      "Cumulated Reward: -48170.45620771057\n",
      "Cumulated Reward: -4.689987570160541\n",
      "step = 60000: Average Return = 12.635390281677246\n",
      "Cumulated Reward: -2441.063128966942\n",
      "step = 60200: loss = 14886471.0\n",
      "step = 60400: loss = 11304558.0\n",
      "step = 60600: loss = 8043530.0\n",
      "step = 60800: loss = 34041516.0\n",
      "step = 61000: loss = 15832510.0\n",
      "step = 61200: loss = 223893088.0\n",
      "step = 61400: loss = 5995575.0\n",
      "Cumulated Reward: -25387.864790000636\n",
      "step = 61600: loss = 10148972.0\n",
      "step = 61800: loss = 26581222.0\n",
      "step = 62000: loss = 9902524.0\n",
      "Cumulated Reward: -5681.67371079368\n",
      "step = 62200: loss = 21731872.0\n",
      "step = 62400: loss = 19362732.0\n",
      "step = 62600: loss = 18236608.0\n",
      "step = 62800: loss = 9007300.0\n",
      "step = 63000: loss = 16194246.0\n",
      "step = 63200: loss = 25066436.0\n",
      "step = 63400: loss = 14384538.0\n",
      "step = 63600: loss = 24172222.0\n",
      "step = 63800: loss = 20911700.0\n",
      "step = 64000: loss = 74612464.0\n",
      "step = 64200: loss = 39255888.0\n",
      "step = 64400: loss = 18386996.0\n",
      "step = 64600: loss = 16051514.0\n",
      "Cumulated Reward: -72733.83667182685\n",
      "step = 64800: loss = 93616944.0\n",
      "step = 65000: loss = 34498620.0\n",
      "Cumulated Reward: -563.325593942867\n",
      "Cumulated Reward: -15.245780001977428\n",
      "Cumulated Reward: -130.28739508880324\n",
      "Cumulated Reward: -52.72372205685461\n",
      "step = 65000: Average Return = 1.6665786504745483\n",
      "Cumulated Reward: -415.4572728541042\n",
      "step = 65200: loss = 16035612.0\n",
      "step = 65400: loss = 77941592.0\n",
      "step = 65600: loss = 21845950.0\n",
      "step = 65800: loss = 47784168.0\n",
      "Cumulated Reward: -8601.355663319751\n",
      "step = 66000: loss = 8282079.5\n",
      "step = 66200: loss = 12926231.0\n",
      "step = 66400: loss = 30290508.0\n",
      "step = 66600: loss = 55077504.0\n",
      "Cumulated Reward: -7652.801740233451\n",
      "Cumulated Reward: -0.625436718362902\n",
      "step = 66800: loss = 79768768.0\n",
      "step = 67000: loss = 32421890.0\n",
      "step = 67200: loss = 24442472.0\n",
      "step = 67400: loss = 11736169.0\n",
      "step = 67600: loss = 18965008.0\n",
      "step = 67800: loss = 9880345.0\n",
      "step = 68000: loss = 59695804.0\n",
      "step = 68200: loss = 12486218.0\n",
      "step = 68400: loss = 8220322.0\n",
      "step = 68600: loss = 17262522.0\n",
      "step = 68800: loss = 10062266.0\n",
      "step = 69000: loss = 46769720.0\n",
      "step = 69200: loss = 8586830.0\n",
      "step = 69400: loss = 63369868.0\n",
      "step = 69600: loss = 26613466.0\n",
      "step = 69800: loss = 17024990.0\n",
      "step = 70000: loss = 15065050.0\n",
      "Cumulated Reward: -19.202137231799874\n",
      "Cumulated Reward: -3362.078109686914\n",
      "Cumulated Reward: -0.47706497432877354\n",
      "Cumulated Reward: -754.2814481913543\n",
      "step = 70000: Average Return = 4.19482946395874\n",
      "Cumulated Reward: -99873.03066987408\n",
      "Cumulated Reward: -47.97818472693188\n",
      "step = 70200: loss = 99435104.0\n",
      "Cumulated Reward: -137.07260679716168\n",
      "step = 70400: loss = 25209244.0\n",
      "step = 70600: loss = 9140997.0\n",
      "step = 70800: loss = 12442908.0\n",
      "Cumulated Reward: -4752.000010021576\n",
      "Cumulated Reward: -8.756059275602986\n",
      "step = 71000: loss = 22977332.0\n",
      "step = 71200: loss = 17152330.0\n",
      "step = 71400: loss = 38769716.0\n",
      "step = 71600: loss = 18257982.0\n",
      "Cumulated Reward: -4693.376572378937\n",
      "Cumulated Reward: -16.282121086345313\n",
      "step = 71800: loss = 166635728.0\n",
      "Cumulated Reward: -173.33782234745843\n",
      "step = 72000: loss = 218532752.0\n",
      "step = 72200: loss = 8766558.0\n",
      "step = 72400: loss = 116472416.0\n",
      "step = 72600: loss = 189549952.0\n",
      "Cumulated Reward: -6831.99140486877\n",
      "step = 72800: loss = 83490568.0\n",
      "Cumulated Reward: -498.0048811819822\n",
      "step = 73000: loss = 91313392.0\n",
      "step = 73200: loss = 50706980.0\n",
      "step = 73400: loss = 20271592.0\n",
      "step = 73600: loss = 32521412.0\n",
      "Cumulated Reward: -6306.074239348633\n",
      "step = 73800: loss = 216739232.0\n",
      "Cumulated Reward: -91.44644159554781\n",
      "step = 74000: loss = 16720447.0\n",
      "step = 74200: loss = 11007864.0\n",
      "step = 74400: loss = 11789860.0\n",
      "step = 74600: loss = 16377879.0\n",
      "step = 74800: loss = 12433486.0\n",
      "step = 75000: loss = 23707552.0\n",
      "Cumulated Reward: -72.93710924120217\n",
      "Cumulated Reward: -15350.662487447697\n",
      "Cumulated Reward: -72.68365506528303\n",
      "Cumulated Reward: -378.76274721081825\n",
      "step = 75000: Average Return = 8.25403881072998\n",
      "Cumulated Reward: -14020.551100048282\n",
      "Cumulated Reward: -62.09911510239878\n",
      "step = 75200: loss = 13019325.0\n",
      "Cumulated Reward: -138.90119385462026\n",
      "Cumulated Reward: -114.70634097993828\n",
      "step = 75400: loss = 29306398.0\n",
      "step = 75600: loss = 36372640.0\n",
      "step = 75800: loss = 21689318.0\n",
      "Cumulated Reward: -3421.2786387101037\n",
      "step = 76000: loss = 36071944.0\n",
      "Cumulated Reward: -379.49716231481233\n",
      "step = 76200: loss = 24931640.0\n",
      "step = 76400: loss = 10118437.0\n",
      "Cumulated Reward: -648.5657411960467\n",
      "step = 76600: loss = 24188416.0\n",
      "step = 76800: loss = 19083096.0\n",
      "step = 77000: loss = 22227344.0\n",
      "step = 77200: loss = 10905786.0\n",
      "step = 77400: loss = 7954383.0\n",
      "Cumulated Reward: -10078.374769726028\n",
      "step = 77600: loss = 17242860.0\n",
      "Cumulated Reward: -179.0093785056012\n",
      "Cumulated Reward: -40.32926052027185\n",
      "Cumulated Reward: -62.546692210528185\n",
      "step = 77800: loss = 6447685.0\n",
      "step = 78000: loss = 14418901.0\n",
      "step = 78200: loss = 35310172.0\n",
      "step = 78400: loss = 9722529.0\n",
      "step = 78600: loss = 11472092.0\n",
      "step = 78800: loss = 19107980.0\n",
      "Cumulated Reward: -15473.236654010274\n",
      "step = 79000: loss = 13369847.0\n",
      "Cumulated Reward: -65.52688386059884\n",
      "step = 79200: loss = 65867484.0\n",
      "step = 79400: loss = 10951354.0\n",
      "step = 79600: loss = 48840840.0\n",
      "Cumulated Reward: -3568.019615312405\n",
      "Cumulated Reward: -0.6314408481666679\n",
      "step = 79800: loss = 61616748.0\n",
      "Cumulated Reward: -94.19394348276123\n",
      "step = 80000: loss = 20834230.0\n",
      "Cumulated Reward: -11011.649860545142\n",
      "Cumulated Reward: -173.63978122873576\n",
      "Cumulated Reward: -90.87964400462492\n",
      "Cumulated Reward: -15148.12997763807\n",
      "step = 80000: Average Return = 13.743701934814453\n",
      "Cumulated Reward: -193.11993944617936\n",
      "step = 80200: loss = 39072000.0\n",
      "step = 80400: loss = 23639196.0\n",
      "step = 80600: loss = 20197544.0\n",
      "step = 80800: loss = 18807444.0\n",
      "step = 81000: loss = 25057024.0\n",
      "step = 81200: loss = 19155636.0\n",
      "Cumulated Reward: -16955.629400206955\n",
      "step = 81400: loss = 13192127.0\n",
      "step = 81600: loss = 19162356.0\n",
      "step = 81800: loss = 14802098.0\n",
      "Cumulated Reward: -4861.912721300705\n",
      "step = 82000: loss = 85237760.0\n",
      "Cumulated Reward: -410.3994801528318\n",
      "Cumulated Reward: -0.6150505387150594\n",
      "Cumulated Reward: -7.884359433417217\n",
      "step = 82200: loss = 86139216.0\n",
      "step = 82400: loss = 10554106.0\n",
      "step = 82600: loss = 6700281.0\n",
      "step = 82800: loss = 10280716.0\n",
      "step = 83000: loss = 10739668.0\n",
      "step = 83200: loss = 38504480.0\n",
      "step = 83400: loss = 11203266.0\n",
      "step = 83600: loss = 21314772.0\n",
      "step = 83800: loss = 7241014.0\n",
      "step = 84000: loss = 10268338.0\n",
      "step = 84200: loss = 36926616.0\n",
      "step = 84400: loss = 210488048.0\n",
      "step = 84600: loss = 14668498.0\n",
      "step = 84800: loss = 19859664.0\n",
      "step = 85000: loss = 23962394.0\n",
      "Cumulated Reward: -46.76912457651823\n",
      "Cumulated Reward: -141.82553808766303\n",
      "Cumulated Reward: -24265.795295522297\n",
      "Cumulated Reward: -164479.04535693125\n",
      "step = 85000: Average Return = 26.47362518310547\n",
      "Cumulated Reward: -83666.18008864607\n",
      "Cumulated Reward: -6.645751491485763\n",
      "Cumulated Reward: -26.135842585124173\n",
      "step = 85200: loss = 10635373.0\n",
      "step = 85400: loss = 15170170.0\n",
      "step = 85600: loss = 35213360.0\n",
      "step = 85800: loss = 11350461.0\n",
      "Cumulated Reward: -6375.781988207207\n",
      "step = 86000: loss = 16237901.0\n",
      "step = 86200: loss = 6095599.0\n",
      "step = 86400: loss = 31241464.0\n",
      "step = 86600: loss = 16246929.0\n",
      "step = 86800: loss = 17491356.0\n",
      "step = 87000: loss = 31475608.0\n",
      "step = 87200: loss = 10270656.0\n",
      "step = 87400: loss = 21869648.0\n",
      "step = 87600: loss = 12706942.0\n",
      "step = 87800: loss = 14305477.0\n",
      "step = 88000: loss = 9281596.0\n",
      "step = 88200: loss = 26685116.0\n",
      "step = 88400: loss = 26709888.0\n",
      "step = 88600: loss = 14138900.0\n",
      "step = 88800: loss = 17050628.0\n",
      "step = 89000: loss = 9888575.0\n",
      "step = 89200: loss = 18582308.0\n",
      "step = 89400: loss = 12312365.0\n",
      "step = 89600: loss = 33700248.0\n",
      "step = 89800: loss = 13313633.0\n",
      "step = 90000: loss = 13520681.0\n",
      "Cumulated Reward: -83211.25170378281\n",
      "Cumulated Reward: -467.717769687496\n",
      "Cumulated Reward: -82866.66284409916\n",
      "Cumulated Reward: -0.7402543014621323\n",
      "step = 90000: Average Return = 22.53858184814453\n",
      "Cumulated Reward: -157081.67911897678\n",
      "Cumulated Reward: -49.471001153678124\n",
      "step = 90200: loss = 14320838.0\n",
      "step = 90400: loss = 228657856.0\n",
      "step = 90600: loss = 35992392.0\n",
      "step = 90800: loss = 33864424.0\n",
      "step = 91000: loss = 16233993.0\n",
      "step = 91200: loss = 16075402.0\n",
      "step = 91400: loss = 222909104.0\n",
      "step = 91600: loss = 18831048.0\n",
      "step = 91800: loss = 12940061.0\n",
      "step = 92000: loss = 40115832.0\n",
      "step = 92200: loss = 13446732.0\n",
      "step = 92400: loss = 66803496.0\n",
      "step = 92600: loss = 27256932.0\n",
      "step = 92800: loss = 24669332.0\n",
      "step = 93000: loss = 17764736.0\n",
      "step = 93200: loss = 21250644.0\n",
      "step = 93400: loss = 32750360.0\n",
      "step = 93600: loss = 87579496.0\n",
      "Cumulated Reward: -124086.26338193768\n",
      "step = 93800: loss = 78358880.0\n",
      "step = 94000: loss = 8514816.0\n",
      "step = 94200: loss = 20101426.0\n",
      "step = 94400: loss = 306393536.0\n",
      "step = 94600: loss = 25220210.0\n",
      "step = 94800: loss = 29069112.0\n",
      "step = 95000: loss = 298666592.0\n",
      "Cumulated Reward: -270423.9126094442\n",
      "Cumulated Reward: -108182.75854668119\n",
      "Cumulated Reward: -15981.159079085824\n",
      "Cumulated Reward: -134.43115052231494\n",
      "step = 95000: Average Return = 46.36959457397461\n",
      "Cumulated Reward: -19188.44583154712\n",
      "step = 95200: loss = 17388520.0\n",
      "step = 95400: loss = 237523376.0\n",
      "step = 95600: loss = 371855168.0\n",
      "step = 95800: loss = 299151136.0\n",
      "step = 96000: loss = 21693584.0\n",
      "step = 96200: loss = 29718528.0\n",
      "step = 96400: loss = 13194110.0\n",
      "step = 96600: loss = 21412962.0\n",
      "step = 96800: loss = 35390508.0\n",
      "step = 97000: loss = 14544622.0\n",
      "step = 97200: loss = 66656200.0\n",
      "step = 97400: loss = 186205248.0\n",
      "step = 97600: loss = 41930632.0\n",
      "step = 97800: loss = 21325576.0\n",
      "step = 98000: loss = 17804176.0\n",
      "step = 98200: loss = 327479328.0\n",
      "step = 98400: loss = 34157100.0\n",
      "step = 98600: loss = 14443428.0\n",
      "step = 98800: loss = 302368480.0\n",
      "step = 99000: loss = 80933552.0\n",
      "step = 99200: loss = 53377768.0\n",
      "step = 99400: loss = 315085664.0\n",
      "Cumulated Reward: -182810.27113830906\n",
      "Cumulated Reward: -83.33438578965422\n",
      "step = 99600: loss = 56235400.0\n",
      "Cumulated Reward: -16.757304562737588\n",
      "Cumulated Reward: -0.6490830160205731\n",
      "step = 99800: loss = 36123656.0\n",
      "Cumulated Reward: -493.01725604807143\n",
      "step = 100000: loss = 15569624.0\n",
      "Cumulated Reward: -79.02157635882757\n",
      "Cumulated Reward: -403.3903774259529\n",
      "Cumulated Reward: -159.7959090250659\n",
      "Cumulated Reward: -83276.3196890189\n",
      "step = 100000: Average Return = 12.520685195922852\n",
      "Cumulated Reward: -137.612959989486\n",
      "Cumulated Reward: -14.057400464450016\n",
      "Cumulated Reward: -197.12215362961916\n",
      "step = 100200: loss = 320704480.0\n",
      "Cumulated Reward: -50.44246207966388\n",
      "step = 100400: loss = 507723168.0\n",
      "step = 100600: loss = 74015296.0\n",
      "step = 100800: loss = 26674378.0\n",
      "step = 101000: loss = 28421642.0\n",
      "step = 101200: loss = 18729448.0\n",
      "step = 101400: loss = 34817384.0\n",
      "step = 101600: loss = 215374160.0\n",
      "Cumulated Reward: -27452.545958528222\n",
      "step = 101800: loss = 21099512.0\n",
      "step = 102000: loss = 27914328.0\n",
      "step = 102200: loss = 29096826.0\n",
      "Cumulated Reward: -3224.922979081749\n",
      "step = 102400: loss = 16686584.0\n",
      "step = 102600: loss = 323006624.0\n",
      "step = 102800: loss = 47015656.0\n",
      "step = 103000: loss = 723420160.0\n",
      "step = 103200: loss = 21172688.0\n",
      "step = 103400: loss = 20179714.0\n",
      "step = 103600: loss = 34276700.0\n",
      "step = 103800: loss = 101313960.0\n",
      "step = 104000: loss = 208464976.0\n",
      "step = 104200: loss = 66401184.0\n",
      "step = 104400: loss = 73420192.0\n",
      "step = 104600: loss = 19092140.0\n",
      "step = 104800: loss = 44829968.0\n",
      "step = 105000: loss = 44065016.0\n",
      "Cumulated Reward: -382.69675100101915\n",
      "Cumulated Reward: -138.26477673724253\n",
      "Cumulated Reward: -84886.01054689595\n",
      "Cumulated Reward: -10.952355764546652\n",
      "step = 105000: Average Return = 12.435973167419434\n",
      "Cumulated Reward: -77900.20241535317\n",
      "step = 105200: loss = 35305040.0\n",
      "step = 105400: loss = 45301564.0\n",
      "Cumulated Reward: -3698.1324223971965\n",
      "step = 105600: loss = 529528160.0\n",
      "Cumulated Reward: -37.20758201271936\n",
      "step = 105800: loss = 735132160.0\n",
      "step = 106000: loss = 101777104.0\n",
      "step = 106200: loss = 21184418.0\n",
      "step = 106400: loss = 488060480.0\n",
      "step = 106600: loss = 49874256.0\n",
      "step = 106800: loss = 235437728.0\n",
      "step = 107000: loss = 206975728.0\n",
      "step = 107200: loss = 32288724.0\n",
      "Cumulated Reward: -25496.266612821495\n",
      "step = 107400: loss = 34289808.0\n",
      "step = 107600: loss = 277406688.0\n",
      "step = 107800: loss = 25504392.0\n",
      "step = 108000: loss = 22730908.0\n",
      "Cumulated Reward: -8143.404516396819\n",
      "Cumulated Reward: -7.119650828073545\n",
      "step = 108200: loss = 42776144.0\n",
      "step = 108400: loss = 16878688.0\n",
      "step = 108600: loss = 31089700.0\n",
      "step = 108800: loss = 64767112.0\n",
      "step = 109000: loss = 327390368.0\n",
      "Cumulated Reward: -9840.857785249558\n",
      "Cumulated Reward: -16.81150954613973\n",
      "step = 109200: loss = 29186500.0\n",
      "step = 109400: loss = 188343920.0\n",
      "step = 109600: loss = 34226464.0\n",
      "step = 109800: loss = 16474964.0\n",
      "step = 110000: loss = 27443810.0\n",
      "Cumulated Reward: -3532.752531034242\n",
      "Cumulated Reward: -0.6789314578640157\n",
      "Cumulated Reward: -75.5082294611632\n",
      "Cumulated Reward: -8060.3536878018695\n",
      "step = 110000: Average Return = 8.643797874450684\n",
      "Cumulated Reward: -5782.278578831366\n",
      "Cumulated Reward: -9.028429027457195\n",
      "step = 110200: loss = 30073792.0\n",
      "step = 110400: loss = 24135156.0\n",
      "step = 110600: loss = 99557064.0\n",
      "Cumulated Reward: -2963.459646773548\n",
      "Cumulated Reward: -14.32031725859115\n",
      "Cumulated Reward: -60.32800736505596\n",
      "step = 110800: loss = 78388960.0\n",
      "step = 111000: loss = 35361504.0\n",
      "step = 111200: loss = 29414648.0\n",
      "Cumulated Reward: -2993.3052998529656\n",
      "step = 111400: loss = 27947296.0\n",
      "step = 111600: loss = 60902704.0\n",
      "step = 111800: loss = 26873532.0\n",
      "step = 112000: loss = 15748366.0\n",
      "step = 112200: loss = 14289286.0\n",
      "step = 112400: loss = 23469624.0\n",
      "Cumulated Reward: -15411.72314183859\n",
      "step = 112600: loss = 23931308.0\n",
      "Cumulated Reward: -143.31142871797724\n",
      "step = 112800: loss = 240794832.0\n",
      "Cumulated Reward: -133.9638991330876\n",
      "step = 113000: loss = 37850052.0\n",
      "step = 113200: loss = 265728928.0\n",
      "step = 113400: loss = 24194928.0\n",
      "Cumulated Reward: -3351.5351540533916\n",
      "step = 113600: loss = 29192130.0\n",
      "Cumulated Reward: -271.43918249140046\n",
      "step = 113800: loss = 11512436.0\n",
      "step = 114000: loss = 34517424.0\n",
      "step = 114200: loss = 22016896.0\n",
      "step = 114400: loss = 25903226.0\n",
      "step = 114600: loss = 14527985.0\n",
      "step = 114800: loss = 23247862.0\n",
      "step = 115000: loss = 188229152.0\n",
      "Cumulated Reward: -57.663236147060516\n",
      "Cumulated Reward: -179.39459201949344\n",
      "Cumulated Reward: -53.73155623518582\n",
      "Cumulated Reward: -95.15240918329496\n",
      "step = 115000: Average Return = 1.56181001663208\n",
      "Cumulated Reward: -22105.255011576555\n",
      "Cumulated Reward: -237.7179227489706\n",
      "step = 115200: loss = 21320260.0\n",
      "Cumulated Reward: -12.002679405623152\n",
      "Cumulated Reward: -130.37478136264588\n",
      "step = 115400: loss = 14433734.0\n",
      "Cumulated Reward: -16.231714122875896\n",
      "Cumulated Reward: -143.88799231826795\n",
      "step = 115600: loss = 26795446.0\n",
      "step = 115800: loss = 22433220.0\n",
      "step = 116000: loss = 46924356.0\n",
      "step = 116200: loss = 16446864.0\n",
      "step = 116400: loss = 295684320.0\n",
      "Cumulated Reward: -8348.880137418324\n",
      "step = 116600: loss = 16665908.0\n",
      "step = 116800: loss = 8639394.0\n",
      "step = 117000: loss = 21030220.0\n",
      "step = 117200: loss = 463323680.0\n",
      "step = 117400: loss = 20164068.0\n",
      "Cumulated Reward: -14757.760884433863\n",
      "step = 117600: loss = 29882016.0\n",
      "Cumulated Reward: -92.6028677429429\n",
      "step = 117800: loss = 59868020.0\n",
      "Cumulated Reward: -148.92370478254009\n",
      "Cumulated Reward: -15.958225268180794\n",
      "step = 118000: loss = 68695448.0\n",
      "step = 118200: loss = 18641244.0\n",
      "step = 118400: loss = 17474696.0\n",
      "step = 118600: loss = 223332784.0\n",
      "step = 118800: loss = 9635916.0\n",
      "step = 119000: loss = 249580816.0\n",
      "step = 119200: loss = 23102726.0\n",
      "step = 119400: loss = 40377420.0\n",
      "step = 119600: loss = 10992200.0\n",
      "step = 119800: loss = 13487427.0\n",
      "step = 120000: loss = 589972864.0\n",
      "Cumulated Reward: -27406.210364875304\n",
      "Cumulated Reward: -167.47096882265703\n",
      "Cumulated Reward: -52.400120677531376\n",
      "Cumulated Reward: -207.81154574777787\n",
      "step = 120000: Average Return = 10.940569877624512\n",
      "Cumulated Reward: -57702.39847621043\n",
      "Cumulated Reward: -63.34968351833389\n",
      "Cumulated Reward: -100.94026154987134\n",
      "Cumulated Reward: -9.015113712551214\n",
      "step = 120200: loss = 27494942.0\n",
      "Cumulated Reward: -78.63178356703897\n",
      "step = 120400: loss = 473839552.0\n",
      "step = 120600: loss = 108052800.0\n",
      "step = 120800: loss = 45508672.0\n",
      "step = 121000: loss = 12032716.0\n",
      "step = 121200: loss = 7195923.0\n",
      "Cumulated Reward: -8987.85175720845\n",
      "step = 121400: loss = 1033099584.0\n",
      "step = 121600: loss = 13583015.0\n",
      "step = 121800: loss = 18349956.0\n",
      "step = 122000: loss = 9719222.0\n",
      "step = 122200: loss = 32324336.0\n",
      "step = 122400: loss = 40456200.0\n",
      "step = 122600: loss = 21441694.0\n",
      "step = 122800: loss = 24407916.0\n",
      "step = 123000: loss = 18106486.0\n",
      "Cumulated Reward: -49346.23896581343\n",
      "Cumulated Reward: -0.7258702796680366\n",
      "step = 123200: loss = 38887236.0\n",
      "Cumulated Reward: -74.15010140636407\n",
      "Cumulated Reward: -147.19634169090713\n",
      "step = 123400: loss = 9683376.0\n",
      "Cumulated Reward: -68.91647236387794\n",
      "Cumulated Reward: -18.36003784722359\n",
      "step = 123600: loss = 10940398.0\n",
      "Cumulated Reward: -195.11312691743757\n",
      "Cumulated Reward: -129.0977958874497\n",
      "step = 123800: loss = 13916415.0\n",
      "Cumulated Reward: -38.02792096273752\n",
      "Cumulated Reward: -43.644057817982606\n",
      "step = 124000: loss = 11957657.0\n",
      "step = 124200: loss = 17188296.0\n",
      "step = 124400: loss = 21144050.0\n",
      "step = 124600: loss = 32128332.0\n",
      "step = 124800: loss = 143016528.0\n",
      "step = 125000: loss = 18715896.0\n",
      "Cumulated Reward: -445.4784699187975\n",
      "Cumulated Reward: -158.25433925998513\n",
      "Cumulated Reward: -123.17129445374867\n",
      "Cumulated Reward: -160.67188015476995\n",
      "step = 125000: Average Return = 2.6830899715423584\n",
      "Cumulated Reward: -12936.216738550322\n",
      "Cumulated Reward: -78.47455196206714\n",
      "step = 125200: loss = 19579128.0\n",
      "Cumulated Reward: -167.9634413647714\n",
      "Cumulated Reward: -44.23882509212428\n",
      "Cumulated Reward: -25.519382321256376\n",
      "step = 125400: loss = 19395608.0\n",
      "Cumulated Reward: -101.63044477398897\n",
      "Cumulated Reward: -1.1905201754916068\n",
      "Cumulated Reward: -9.45241532163421\n",
      "step = 125600: loss = 15234196.0\n",
      "step = 125800: loss = 37694292.0\n",
      "step = 126000: loss = 31009966.0\n",
      "step = 126200: loss = 11677564.0\n",
      "step = 126400: loss = 14952751.0\n",
      "Cumulated Reward: -9876.182640833056\n",
      "step = 126600: loss = 459834656.0\n",
      "Cumulated Reward: -444.07937200961703\n",
      "step = 126800: loss = 19187328.0\n",
      "Cumulated Reward: -141.8034534513204\n",
      "step = 127000: loss = 29195472.0\n",
      "step = 127200: loss = 465459840.0\n",
      "step = 127400: loss = 53594568.0\n",
      "step = 127600: loss = 15865572.0\n",
      "step = 127800: loss = 27835100.0\n",
      "Cumulated Reward: -10068.55390254773\n",
      "Cumulated Reward: -105.20498952600177\n",
      "step = 128000: loss = 7693827.5\n",
      "Cumulated Reward: -21.079661146640397\n",
      "Cumulated Reward: -51.705810526716014\n",
      "step = 128200: loss = 43565720.0\n",
      "Cumulated Reward: -105.12701339438695\n",
      "Cumulated Reward: -49.7767088666345\n",
      "step = 128400: loss = 9678761.0\n",
      "Cumulated Reward: -168.62993832685163\n",
      "Cumulated Reward: -146.69481978842876\n",
      "step = 128600: loss = 14297194.0\n",
      "Cumulated Reward: -235.43171900860867\n",
      "Cumulated Reward: -16.82487894071836\n",
      "step = 128800: loss = 20287122.0\n",
      "Cumulated Reward: -130.50864300394653\n",
      "step = 129000: loss = 37345956.0\n",
      "step = 129200: loss = 16607377.0\n",
      "step = 129400: loss = 117685696.0\n",
      "step = 129600: loss = 260216496.0\n",
      "step = 129800: loss = 36402340.0\n",
      "Cumulated Reward: -9786.958457767529\n",
      "Cumulated Reward: -106.03274594320075\n",
      "step = 130000: loss = 15260000.0\n",
      "Cumulated Reward: -0.5023945895086729\n",
      "Cumulated Reward: -114.236830198791\n",
      "Cumulated Reward: -80090.30412664104\n",
      "Cumulated Reward: -66.98424277540657\n",
      "step = 130000: Average Return = 11.361161231994629\n",
      "Cumulated Reward: -47.36657509002173\n",
      "Cumulated Reward: -0.087770227533306\n",
      "step = 130200: loss = 605050816.0\n",
      "step = 130400: loss = 146026944.0\n",
      "step = 130600: loss = 168250080.0\n",
      "step = 130800: loss = 332294176.0\n",
      "step = 131000: loss = 20605564.0\n",
      "Cumulated Reward: -11089.386709291444\n",
      "step = 131200: loss = 431033504.0\n",
      "step = 131400: loss = 12724331.0\n",
      "step = 131600: loss = 14962302.0\n",
      "step = 131800: loss = 432883936.0\n",
      "Cumulated Reward: -10118.25563120676\n",
      "step = 132000: loss = 23376144.0\n",
      "Cumulated Reward: -172.2335396581239\n",
      "step = 132200: loss = 28235422.0\n",
      "step = 132400: loss = 163382560.0\n",
      "step = 132600: loss = 20538794.0\n",
      "Cumulated Reward: -2519.707623625909\n",
      "step = 132800: loss = 45902052.0\n",
      "step = 133000: loss = 11300460.0\n",
      "step = 133200: loss = 31129724.0\n",
      "Cumulated Reward: -6418.091270157077\n",
      "step = 133400: loss = 285129792.0\n",
      "Cumulated Reward: -19.645893879214796\n",
      "step = 133600: loss = 14007683.0\n",
      "Cumulated Reward: -216.6797914962865\n",
      "Cumulated Reward: -101.5276987423315\n",
      "Cumulated Reward: -46.363021785586916\n",
      "step = 133800: loss = 9862070.0\n",
      "Cumulated Reward: -87.43413171702628\n",
      "step = 134000: loss = 15364180.0\n",
      "step = 134200: loss = 35541164.0\n",
      "step = 134400: loss = 252857792.0\n",
      "step = 134600: loss = 10425236.0\n",
      "step = 134800: loss = 9219691.0\n",
      "Cumulated Reward: -9204.30610965579\n",
      "Cumulated Reward: -67.95708514667835\n",
      "step = 135000: loss = 24904614.0\n",
      "Cumulated Reward: -23.809572372067024\n",
      "Cumulated Reward: -36.706331694398955\n",
      "Cumulated Reward: -2791.8912683590297\n",
      "Cumulated Reward: -134.46194327514056\n",
      "step = 135000: Average Return = 3.825949192047119\n",
      "Cumulated Reward: -104.87634404850728\n",
      "Cumulated Reward: -24.97963144278219\n",
      "Cumulated Reward: -53.02612465709692\n",
      "step = 135200: loss = 15687284.0\n",
      "Cumulated Reward: -61.501811581882826\n",
      "Cumulated Reward: -226.70888093415425\n",
      "Cumulated Reward: -10.935657247717641\n",
      "step = 135400: loss = 13616599.0\n",
      "Cumulated Reward: -161.4477573431527\n",
      "step = 135600: loss = 435288960.0\n",
      "Cumulated Reward: -136.16582154771635\n",
      "Cumulated Reward: -199.92651114800654\n",
      "step = 135800: loss = 29523232.0\n",
      "Cumulated Reward: -107.64915535034294\n",
      "step = 136000: loss = 6991137.5\n",
      "step = 136200: loss = 96663360.0\n",
      "step = 136400: loss = 600109696.0\n",
      "step = 136600: loss = 17192904.0\n",
      "Cumulated Reward: -5079.9890019559825\n",
      "Cumulated Reward: -44.729793458744766\n",
      "step = 136800: loss = 18466546.0\n",
      "Cumulated Reward: -138.90757199404396\n",
      "Cumulated Reward: -136.47060570003447\n",
      "step = 137000: loss = 13315444.0\n",
      "Cumulated Reward: -129.51637039267555\n",
      "step = 137200: loss = 17721590.0\n",
      "Cumulated Reward: -190.07153593483935\n",
      "Cumulated Reward: -18.589058094096252\n",
      "step = 137400: loss = 14617284.0\n",
      "step = 137600: loss = 12365658.0\n",
      "step = 137800: loss = 18803468.0\n",
      "Cumulated Reward: -4395.325506571118\n",
      "step = 138000: loss = 10516786.0\n",
      "Cumulated Reward: -136.38720003677713\n",
      "step = 138200: loss = 165425744.0\n",
      "Cumulated Reward: -154.07604513596425\n",
      "step = 138400: loss = 11173662.0\n",
      "Cumulated Reward: -318.6626384113844\n",
      "step = 138600: loss = 34014388.0\n",
      "Cumulated Reward: -225.45553710070706\n",
      "Cumulated Reward: -110.76708219313342\n",
      "step = 138800: loss = 9196467.0\n",
      "Cumulated Reward: -218.89102680347582\n",
      "step = 139000: loss = 14898842.0\n",
      "Cumulated Reward: -227.56722870773322\n",
      "step = 139200: loss = 234850336.0\n",
      "Cumulated Reward: -135.33855871137683\n",
      "Cumulated Reward: -194.34432617818265\n",
      "step = 139400: loss = 9467588.0\n",
      "step = 139600: loss = 86443416.0\n",
      "step = 139800: loss = 219810288.0\n",
      "step = 140000: loss = 137882432.0\n",
      "Cumulated Reward: -8731.374416064255\n",
      "Cumulated Reward: -11400.398343581548\n",
      "Cumulated Reward: -117.82325912277368\n",
      "Cumulated Reward: -6260.780922118726\n",
      "step = 140000: Average Return = 16.081762313842773\n",
      "Cumulated Reward: -4550.789953187065\n",
      "Cumulated Reward: -225.05698511648313\n",
      "step = 140200: loss = 9956087.0\n",
      "Cumulated Reward: -213.2566192619152\n",
      "step = 140400: loss = 5371557.0\n",
      "step = 140600: loss = 6562412.0\n",
      "step = 140800: loss = 309430560.0\n",
      "step = 141000: loss = 14213459.0\n",
      "step = 141200: loss = 576170240.0\n",
      "Cumulated Reward: -9931.898100909775\n",
      "Cumulated Reward: -7.62947457557287\n",
      "step = 141400: loss = 28804242.0\n",
      "Cumulated Reward: -295.3389198994269\n",
      "step = 141600: loss = 17143852.0\n",
      "step = 141800: loss = 9380974.0\n",
      "step = 142000: loss = 92751848.0\n",
      "step = 142200: loss = 33457994.0\n",
      "step = 142400: loss = 123977960.0\n",
      "Cumulated Reward: -10161.177370376281\n",
      "Cumulated Reward: -179.11056395144746\n",
      "step = 142600: loss = 14328340.0\n",
      "step = 142800: loss = 6378352.0\n",
      "step = 143000: loss = 27171034.0\n",
      "step = 143200: loss = 7298172.5\n",
      "step = 143400: loss = 16191704.0\n",
      "Cumulated Reward: -8521.51714851898\n",
      "Cumulated Reward: -140.15161264618152\n",
      "step = 143600: loss = 15503660.0\n",
      "step = 143800: loss = 19587484.0\n",
      "step = 144000: loss = 10890822.0\n",
      "Cumulated Reward: -3143.1751910455177\n",
      "step = 144200: loss = 6339061.0\n",
      "Cumulated Reward: -353.410959492233\n",
      "step = 144400: loss = 5797768.5\n",
      "step = 144600: loss = 126930968.0\n",
      "step = 144800: loss = 4651630.0\n",
      "step = 145000: loss = 21747118.0\n",
      "Cumulated Reward: -161.05753955631965\n",
      "Cumulated Reward: -4.267728173781904\n",
      "Cumulated Reward: -5456.602464328351\n",
      "Cumulated Reward: -169.79013045795838\n",
      "step = 145000: Average Return = 5.4530816078186035\n",
      "Cumulated Reward: -5268.122683648284\n",
      "Cumulated Reward: -134.50128503021375\n",
      "Cumulated Reward: -14.69189269159713\n",
      "step = 145200: loss = 6390496.0\n",
      "step = 145400: loss = 9257116.0\n",
      "step = 145600: loss = 7706778.0\n",
      "step = 145800: loss = 3627389.5\n",
      "step = 146000: loss = 21657730.0\n",
      "step = 146200: loss = 18940400.0\n",
      "step = 146400: loss = 11396284.0\n",
      "Cumulated Reward: -16263.277300425214\n",
      "Cumulated Reward: -18.876555500208244\n",
      "step = 146600: loss = 4396225.0\n",
      "step = 146800: loss = 15992696.0\n",
      "step = 147000: loss = 8810276.0\n",
      "step = 147200: loss = 13628671.0\n",
      "Cumulated Reward: -5602.636816790788\n",
      "Cumulated Reward: -207.24671433146378\n",
      "step = 147400: loss = 6978405.5\n",
      "step = 147600: loss = 3497454.25\n",
      "Cumulated Reward: -582.1380526288601\n",
      "step = 147800: loss = 548862464.0\n",
      "Cumulated Reward: -195.74742547693674\n",
      "Cumulated Reward: -150.18516979510625\n",
      "step = 148000: loss = 6032749.5\n",
      "step = 148200: loss = 4978921.5\n",
      "step = 148400: loss = 6151540.0\n",
      "step = 148600: loss = 5916251.0\n",
      "Cumulated Reward: -5249.613601847389\n",
      "Cumulated Reward: -83.62988597671814\n",
      "Cumulated Reward: -10.894057563352622\n",
      "step = 148800: loss = 2655384.0\n",
      "Cumulated Reward: -110.56927184097833\n",
      "Cumulated Reward: -42.62649776267558\n",
      "step = 149000: loss = 3048152.5\n",
      "step = 149200: loss = 6269146.0\n",
      "step = 149400: loss = 67206808.0\n",
      "step = 149600: loss = 2860813.25\n",
      "step = 149800: loss = 5829164.0\n",
      "step = 150000: loss = 4090587.0\n",
      "Cumulated Reward: -11444.10956402618\n",
      "Cumulated Reward: -3183.7605640399884\n",
      "Cumulated Reward: -225.4879560424697\n",
      "Cumulated Reward: -3062.664928283139\n",
      "step = 150000: Average Return = 13.03613567352295\n"
     ]
    }
   ],
   "source": [
    "avg_return = compute_avg_return(env, agent.policy, 1)\n",
    "returns = [avg_return]\n",
    "losses = []\n",
    "# iterator = iter(dataset)\n",
    "experience_replay = ExperienceReply(agent, env)\n",
    "for _ in range(150000):\n",
    "\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    # collect_data(env, agent.collect_policy, replay_buffer, 1)\n",
    "    # collect_data(env, random_policy, replay_buffer, 1)\n",
    "    for _ in range(1):\n",
    "        experience_replay.timestamp_data(env, agent.collect_policy)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    # experience, unused_info = next(iterator)\n",
    "    experience, unused_info = next(experience_replay.iterator)\n",
    "    \n",
    "    train_loss = agent.train(experience).loss\n",
    "    \n",
    "    losses.append(train_loss.numpy())\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % 5000 == 0:\n",
    "        avg_return = compute_avg_return(env_eval, agent.policy, 4)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, 10000 + 1, 1)\n",
    "plt.plot(losses)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "#plt.ylim(top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulated Reward: -12057.968108850846\n",
      "Cumulated Reward: -64.98383883523594\n",
      "Cumulated Reward: -2490.406397698968\n",
      "Cumulated Reward: -100.31972583027935\n",
      "Cumulated Reward: -137.2177372996804\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    experience_replay.timestamp_data(env, agent.collect_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
